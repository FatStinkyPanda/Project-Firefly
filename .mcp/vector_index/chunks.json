{"8f40571c6b7a_file": {"id": "8f40571c6b7a_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\debug_arch.py", "content": "from dataclasses import dataclass\nfrom pathlib import Path\nfrom typing import List\nimport re\n\n@dataclass\nclass LayerRule:\n    layer: str\n    patterns: List[str]\n\nDEFAULT_RULES = [\n    LayerRule(\n        layer='controller',\n        patterns=['*controller*', '*handler*', '*route*', 'app.api*', 'app.view*']\n    ),\n    LayerRule(\n        layer='service',\n        patterns=['*service*', '*manager*', '*logic*']\n    ),\n    LayerRule(\n        layer='repository',\n        patterns=['*repository*', '*dao*', '*dal*']\n    ),\n    LayerRule(\n        layer='model',\n        patterns=['*model*', '*entity*', '*schema*', '*dto*']\n    ),\n    LayerRule(\n        layer='util',\n        patterns=['*util*', '*helper*', '*common*', '*lib*']\n    ),\n]\n\ndef detect_layer(path: Path, rules: List[LayerRule]) -> str:\n    name = path.stem.lower()\n    parts = [p.lower() for p in path.parts]\n\n    for rule in rules:\n        for pattern in rule.patterns:\n            regex = pattern.replace('*', '.*')\n            if re.search(regex, name) or any(re.search(regex, p) for p in parts):\n                return rule.layer\n    return \"unknown\"\n\nroot = Path(r\"c:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\")\nfor path in root.rglob(\"*.py\"):\n    layer = detect_layer(path, DEFAULT_RULES)\n    if layer == \"controller\":\n        print(f\"CONTROLLER: {path}\")\n    elif layer == \"model\":\n        print(f\"MODEL: {path}\")\n    elif layer == \"service\":\n        pass # Service is expected default for agent_manager\n    else:\n        print(f\"{layer.upper()}: {path}\")\n", "chunk_type": "file", "line_start": 1, "line_end": 56, "language": "python", "name": "debug_arch.py"}, "8f40571c6b7a_func_detect_layer": {"id": "8f40571c6b7a_func_detect_layer", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\debug_arch.py", "content": "def detect_layer(path: Path, rules: List[LayerRule]) -> str:\n    name = path.stem.lower()\n    parts = [p.lower() for p in path.parts]\n\n    for rule in rules:\n        for pattern in rule.patterns:\n            regex = pattern.replace('*', '.*')\n            if re.search(regex, name) or any(re.search(regex, p) for p in parts):\n                return rule.layer\n    return \"unknown\"", "chunk_type": "function", "line_start": 34, "line_end": 43, "language": "python", "name": "detect_layer"}, "8f40571c6b7a_class_LayerRule": {"id": "8f40571c6b7a_class_LayerRule", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\debug_arch.py", "content": "class LayerRule:\n    layer: str\n    patterns: List[str]", "chunk_type": "class", "line_start": 7, "line_end": 9, "language": "python", "name": "LayerRule"}, "d715421ee2f7_file": {"id": "d715421ee2f7_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\main_controller.py", "content": "import logging\nimport os # Added for os.environ.get\nimport time\n\nfrom agent_manager.core.api_controller import APIController\nfrom agent_manager.core.api_service import APIService\nfrom agent_manager.core.artifact_service import ArtifactService\nfrom agent_manager.core.browser_adapter import BrowserService\nfrom agent_manager.core.config_service import ConfigurationService\nfrom agent_manager.core.dashboard_service import DashboardService\nfrom agent_manager.core.event_bus import EventBusService\nfrom agent_manager.core.git_service import GitMonitoringService\nfrom agent_manager.core.ide_integration import WorkspaceMonitoringService as MonitoringService # Renamed for clarity\nfrom agent_manager.core.memory_service import MemoryService\nfrom agent_manager.core.notification_service import NotificationService\nfrom agent_manager.core.peer_discovery import PeerDiscoveryService\nfrom agent_manager.core.prompt_service import PromptService\nfrom agent_manager.core.session_manager import SessionManager\nfrom agent_manager.models.manager import ModelClientManager\nfrom agent_manager.orchestrator import OrchestratorManager\nfrom agent_manager.triggers.email import EmailService\nfrom agent_manager.triggers.ide_control import IDEControlService\nfrom agent_manager.triggers.sms import SMSService\nfrom agent_manager.triggers.system_events import WorkspaceMonitoringService # To be removed\nfrom agent_manager.triggers.telegram import TelegramService\nfrom agent_manager.triggers.webhook import WebhookService\n\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n    handlers=[\n        logging.StreamHandler(sys.stdout),\n        logging.FileHandler('firefly_agent_manager.log')\n    ]\n)\nlogger = logging.getLogger(\"FireflyMain\")\n\ndef main():\n    logger.info(\"Initializing Firefly Agent Manager...\")\n\n    # 1. Initialize Event Bus\n    bus = EventBusService()\n\n    # 2. Initialize Configuration\n    config = ConfigurationService()\n\n    #", "chunk_type": "file", "line_start": 1, "line_end": 138, "language": "python", "name": "main_controller.py"}, "d715421ee2f7_func_main": {"id": "d715421ee2f7_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\main_controller.py", "content": "def main():\n    logger.info(\"Initializing Firefly Agent Manager...\")\n\n    # 1. Initialize Event Bus\n    bus = EventBusService()\n\n    # 2. Initialize Configuration\n    config = ConfigurationService()\n\n    # 3. Initialize Model Client Manager\n    model_client = ModelClientManager(event_bus=bus, config_service=config)\n\n    # 3.5 Initialize Session Management\n    session_manager = SessionManager()\n\n    # 3.8 Initialize Prompt Service\n    prompt_service = PromptService()\n\n    # 3.9 Initialize Memory Service\n    memory_service = MemoryService(model_client=model_client)\n\n    # 3.10 Initialize Notification Service\n    notifier = NotificationService(event_bus=bus, config_service=config)\n\n    # 3.6 Initialize Browser Adapter\n    browser_adapter = BrowserService(event_bus=bus)\n\n    # 3.7 Initialize Artifact Service\n    artifact_service = ArtifactService()\n\n    # 3.11 Initialize API Service (Artifacts Viewer Support)\n    api_service = APIService(event_bus=bus, artifact_service=artifact_service, mo", "chunk_type": "function", "line_start": 40, "line_end": 134, "language": "python", "name": "main"}, "dd96b5af957b_file": {"id": "dd96b5af957b_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\orchestrator.py", "content": "import logging\nimport os\nimport re\nimport subprocess\n\nfrom agent_manager.core.git_manager import GitManager\nfrom agent_manager.core.tag_parser import TagParserService\nimport asyncio\n\nlogger = logging.getLogger(\"FireflyOrchestrator\")\n\nclass OrchestratorManager:\n    \"\"\"\n    Manages the lifecycle and execution of agents based on triggers.\n    Robustly handles AI responses using the Firefly Tagging System (FTS).\n    \"\"\"\n    def __init__(self, event_bus, model_client, config_service=None, peer_discovery=None, session_manager=None, browser_service=None, artifact_service=None, prompt_service=None, memory_service=None, notification_service=None):\n        self.event_bus = event_bus\n        self.model_client = model_client\n        self.config_service = config_service\n        self.peer_discovery = peer_discovery\n        self.session_manager = session_manager\n        self.browser_service = browser_service\n        self.artifact_service = artifact_service\n        self.prompt_service = prompt_service\n        self.memory_service = memory_service\n        self.notification_service = notification_service\n        self.is_autonomous = False\n        self.git_manager = GitManager()\n        self.tag_parser = TagParserService()\n        self._current_conflicts = set()\n        self._total_cost = 0.0\n        self._is_autonomous = False\n        self.is_running = False\n\n    def start(self):\n        self.is_running = True\n        logger.info(\"Orchestrator started. Defined role: Lead Developer.\")\n        self.event_bus.subscribe(\"webhook_event\", self.handle_event)\n        self.event_bus.subscribe(\"telegram_input\", self.handle_event)\n        self.event_bus.subscribe(\"system_event\", self.handle_event)\n        self.event_bus.subscribe(\"peer_message\", self.handle_event)\n        self.event_bus.subscribe(\"peer_joined\", self.handle_event)\n        self.event_bus.subscribe(\"peer_left\", self.handle_event)\n        self.event_bus.subscribe(\"git_event\", self.handle_event)\n        self.event_bus.subscribe(\"emai", "chunk_type": "file", "line_start": 1, "line_end": 486, "language": "python", "name": "orchestrator.py"}, "dd96b5af957b_func___init__": {"id": "dd96b5af957b_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\orchestrator.py", "content": "    def __init__(self, event_bus, model_client, config_service=None, peer_discovery=None, session_manager=None, browser_service=None, artifact_service=None, prompt_service=None, memory_service=None, notification_service=None):\n        self.event_bus = event_bus\n        self.model_client = model_client\n        self.config_service = config_service\n        self.peer_discovery = peer_discovery\n        self.session_manager = session_manager\n        self.browser_service = browser_service\n        self.artifact_service = artifact_service\n        self.prompt_service = prompt_service\n        self.memory_service = memory_service\n        self.notification_service = notification_service\n        self.is_autonomous = False\n        self.git_manager = GitManager()\n        self.tag_parser = TagParserService()\n        self._current_conflicts = set()\n        self._total_cost = 0.0\n        self._is_autonomous = False\n        self.is_running = False", "chunk_type": "function", "line_start": 17, "line_end": 34, "language": "python", "name": "__init__"}, "dd96b5af957b_func_start": {"id": "dd96b5af957b_func_start", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\orchestrator.py", "content": "    def start(self):\n        self.is_running = True\n        logger.info(\"Orchestrator started. Defined role: Lead Developer.\")\n        self.event_bus.subscribe(\"webhook_event\", self.handle_event)\n        self.event_bus.subscribe(\"telegram_input\", self.handle_event)\n        self.event_bus.subscribe(\"system_event\", self.handle_event)\n        self.event_bus.subscribe(\"peer_message\", self.handle_event)\n        self.event_bus.subscribe(\"peer_joined\", self.handle_event)\n        self.event_bus.subscribe(\"peer_left\", self.handle_event)\n        self.event_bus.subscribe(\"git_event\", self.handle_event)\n        self.event_bus.subscribe(\"email_input\", self.handle_event)\n        self.event_bus.subscribe(\"sms_input\", self.handle_event)\n        self.event_bus.subscribe(\"ide_set_mode\", self.handle_event)\n        self.event_bus.subscribe(\"ide_intent\", self.handle_event)\n        self.event_bus.subscribe(\"ide_create_agent\", self.handle_event)\n        self.event_bus.subscribe(\"ide_delete_agent\", self.handl", "chunk_type": "function", "line_start": 36, "line_end": 54, "language": "python", "name": "start"}, "dd96b5af957b_func_stop": {"id": "dd96b5af957b_func_stop", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\orchestrator.py", "content": "    def stop(self):\n        self.is_running = False\n        if self.browser_service:\n            asyncio.run(self.browser_service.stop())\n        logger.info(\"Orchestrator stopped.\")", "chunk_type": "function", "line_start": 56, "line_end": 60, "language": "python", "name": "stop"}, "dd96b5af957b_func_handle_event": {"id": "dd96b5af957b_func_handle_event", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\orchestrator.py", "content": "    def handle_event(self, event_type: str, payload: dict):\n        \"\"\"Main routing hub for incoming events.\"\"\"\n        if not self.is_running: return\n\n        logger.info(f\"Orchestrator received event: {event_type}\")\n\n        if event_type == \"webhook_event\":\n            self.process_request(f\"Webhook Payload: {payload.get('data')}\", source=\"webhook\")\n        elif event_type == \"telegram_input\":\n            session_id = f\"tg_{payload.get('chat_id')}\"\n            self.process_request(payload.get(\"text\"), source=\"telegram\", context=payload, session_id=session_id)\n        elif event_type == \"email_input\":\n            from_addr = payload.get(\"from\")\n            session_id = f\"email_{from_addr.replace('@', '_').replace('.', '_')}\"\n            self.process_request(payload.get(\"text\"), source=\"email\", context=payload, session_id=session_id)\n        elif event_type == \"sms_input\":\n            from_num = payload.get(\"from\")\n            session_id = f\"sms_{from_num.replace('+', '').replace(' ',", "chunk_type": "function", "line_start": 62, "line_end": 106, "language": "python", "name": "handle_event"}, "dd96b5af957b_func_set_autonomous_mode": {"id": "dd96b5af957b_func_set_autonomous_mode", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\orchestrator.py", "content": "    def set_autonomous_mode(self, enabled: bool):\n        \"\"\"Toggle autonomous execution mode.\"\"\"\n        self.is_autonomous = enabled\n        logger.info(f\"Orchestrator autonomous mode: {'ENABLED' if enabled else 'DISABLED'}\")\n        # Log this as an artifact\n        if self.artifact_service:\n            self.artifact_service.create_artifact(\n                \"internal\",\n                \"mode_change\",\n                f\"Autonomous mode set to {enabled}\",\n                session_id=\"system\"\n            )\n        # We also broadcast a status update to the IDE\n        print(f\"[FIREFLY:STATUS] mode={'autonomous' if enabled else 'manual'}\")", "chunk_type": "function", "line_start": 108, "line_end": 121, "language": "python", "name": "set_autonomous_mode"}, "dd96b5af957b_func_handle_intent": {"id": "dd96b5af957b_func_handle_intent", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\orchestrator.py", "content": "    def handle_intent(self, intent_id: str, args: Any):\n        \"\"\"Process a user intent as an observation for the agent.\"\"\"\n        logger.info(f\"Processing user intent: {intent_id}\")\n        # In a real scenario, this would trigger a planning pulse if in autonomous mode\n        if self.is_autonomous:\n             message = f\"User performed action: {intent_id} with args: {args}. Does this require any follow-up?\"\n             # We could queue a background task here\n             self.process_request(message, source=\"system_intent\", session_id=\"autonomous_loop\")", "chunk_type": "function", "line_start": 123, "line_end": 130, "language": "python", "name": "handle_intent"}, "dd96b5af957b_func_handle_create_agent": {"id": "dd96b5af957b_func_handle_create_agent", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\orchestrator.py", "content": "    def handle_create_agent(self, payload: dict):\n        \"\"\"Handle agent creation request from the IDE.\"\"\"\n        agent_id = payload.get(\"id\")\n        name = payload.get(\"name\")\n        persona = payload.get(\"persona\")\n        logger.info(f\"Summoning Agent: {name} (ID: {agent_id}) -> {persona}\")\n        self.set_status(thought=f\"Spectral manifest of '{name}' complete. Focus: {persona}\")", "chunk_type": "function", "line_start": 132, "line_end": 138, "language": "python", "name": "handle_create_agent"}, "dd96b5af957b_func_handle_delete_agent": {"id": "dd96b5af957b_func_handle_delete_agent", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\orchestrator.py", "content": "    def handle_delete_agent(self, payload: dict):\n        \"\"\"Handle agent deletion request from the IDE.\"\"\"\n        agent_id = payload.get(\"id\")\n        logger.info(f\"Banishing Agent: {agent_id}\")\n        self.set_status(thought=f\"Agent {agent_id} returned to the void.\")", "chunk_type": "function", "line_start": 140, "line_end": 144, "language": "python", "name": "handle_delete_agent"}, "dd96b5af957b_func_handle_set_safety_mode": {"id": "dd96b5af957b_func_handle_set_safety_mode", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\orchestrator.py", "content": "    def handle_set_safety_mode(self, payload: dict):\n        \"\"\"Handle safety mode change from IDE.\"\"\"\n        mode = payload.get(\"mode\", \"MANUAL\")\n        logger.info(f\"Safety Mode -> {mode}\")\n        self._safety_mode = mode\n        self.set_status(thought=f\"Command approval mode: {mode}\")", "chunk_type": "function", "line_start": 146, "line_end": 151, "language": "python", "name": "handle_set_safety_mode"}, "dd96b5af957b_func_handle_set_active_model": {"id": "dd96b5af957b_func_handle_set_active_model", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\orchestrator.py", "content": "    def handle_set_active_model(self, payload: dict):\n        \"\"\"Handle active model change from IDE.\"\"\"\n        model_id = payload.get(\"model_id\", \"gemini-2.0-flash\")\n        logger.info(f\"Active Model -> {model_id}\")\n        if self.model_client:\n            # Update the model client's active model\n            self.model_client.set_active_model(model_id)\n        self.set_status(thought=f\"Model switched to: {model_id}\")", "chunk_type": "function", "line_start": 153, "line_end": 160, "language": "python", "name": "handle_set_active_model"}, "dd96b5af957b_func_process_request": {"id": "dd96b5af957b_func_process_request", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\orchestrator.py", "content": "    def process_request(self, text: str, source: str = \"manual\", context: Optional[Dict] = None, session_id: str = \"default\", agent_role: str = \"Lead Orchestrator\"):\n        \"\"\"\n        Sync bridge to async processing.\n        \"\"\"\n        try:\n            loop = asyncio.get_event_loop()\n        except RuntimeError:\n            loop = asyncio.new_event_loop()\n            asyncio.set_event_loop(loop)\n\n        return loop.run_until_complete(self.process_request_async(prompt, source, context, session_id, agent_role))", "chunk_type": "function", "line_start": 162, "line_end": 172, "language": "python", "name": "process_request"}, "dd96b5af957b_func_process_request_async": {"id": "dd96b5af957b_func_process_request_async", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\orchestrator.py", "content": "    async def process_request_async(self, prompt: str, source: str, context: dict = None, session_id: str = \"default\", agent_role: str = \"Lead Orchestrator\"):\n        \"\"\"\n        Unified processing logic using AI + Tag Parsing + Session Memory.\n        \"\"\"\n        if not self.model_client:\n            logger.warning(\"No Model Client available.\")\n            return\n\n        # 0. Sync UI Mode\n        if source in [\"system\", \"git\", \"delegate\", \"peer\"]:\n            self.set_status(mode=\"autonomous\")\n        else:\n            self.set_status(mode=\"interactive\")\n\n        # 1. Manage History\n        history_context = \"\"\n        if self.session_manager:\n            self.session_manager.add_message(session_id, \"user\", prompt)\n            history_context = self.session_manager.format_for_ai(session_id)\n\n            # Retrieve relevant semantic memories\n            if self.memory_service:\n                memories = self.memory_service.query(prompt, top_k=3)\n                if memories:\n          ", "chunk_type": "function", "line_start": 174, "line_end": 274, "language": "python", "name": "process_request_async"}, "dd96b5af957b_func__handle_browser_actions": {"id": "dd96b5af957b_func__handle_browser_actions", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\orchestrator.py", "content": "    async def _handle_browser_actions(self, text: str, session_id: str):\n        \"\"\"Extracts and executes <browser> tags.\"\"\"\n        if not self.browser_service:\n            return\n\n        # Regex to find <browser action=\"...\" ... />\n        # Example: <browser action=\"navigate\" url=\"https://google.com\"/>\n        browser_tags = re.findall(r'<browser\\s+([^>]*?)/?>', text, re.IGNORECASE)\n        for tag_content in browser_tags:\n            # Parse attributes\n            attrs = dict(re.findall(r'(\\w+)=[\"\\'](.*?)[\"\\']', tag_content))\n            action = attrs.get(\"action\")\n            if not action:\n                continue\n\n            logger.info(f\"Browser Action: {action} with {attrs}\")\n            self.set_status(thought=f\"Executing browser action: {action}\")\n\n            result = await self.browser_service.run_action(action, **attrs)\n\n            # Feed result back to the session history\n            if self.session_manager:\n                result_msg = f\"[BROWSER RESULT] {action}: ", "chunk_type": "function", "line_start": 276, "line_end": 308, "language": "python", "name": "_handle_browser_actions"}, "dd96b5af957b_func_execute_command": {"id": "dd96b5af957b_func_execute_command", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\orchestrator.py", "content": "    def execute_command(self, command: str):\n        \"\"\"Executes a command if it passes the safety policy.\"\"\"\n        if self.config_service:\n            if not self.config_service.is_command_safe(command, agent_context=\"orchestrator\"):\n                logger.warning(f\"BLOCKED: Command '{command}' failed safety check.\")\n                return False\n\n        logger.info(f\"EXECUTING: {command}\")\n        try:\n            # Note: Avoid shell=True for security. We wrap in powershell/sh instead to keep shell features.\n            if os.name == 'nt':\n                cmd_args = [\"powershell.exe\", \"-Command\", command]\n            else:\n                cmd_args = [\"/bin/sh\", \"-c\", command]\n\n            result = subprocess.run(cmd_args, shell=False, capture_output=True, text=True, timeout=30)\n            if result.stdout:\n                logger.info(f\"STDOUT: {result.stdout.strip()}\")\n            if result.stderr:\n                logger.error(f\"STDERR: {result.stderr.strip()}\")\n\n            if se", "chunk_type": "function", "line_start": 310, "line_end": 339, "language": "python", "name": "execute_command"}, "dd96b5af957b_func_set_status": {"id": "dd96b5af957b_func_set_status", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\orchestrator.py", "content": "    def set_status(self, thought=None, cost=None, mode=None):\n        \"\"\"Communicates the current status to the Firefly IDE host.\"\"\"\n        status_parts = [\"[FIREFLY:STATUS]\"]\n        if thought: status_parts.append(f'thought=\"{thought}\"')\n        if cost is not None: status_parts.append(f\"cost={cost:.6f}\")\n        if mode:\n            self._is_autonomous = (mode.lower() == \"autonomous\")\n            status_parts.append(f\"mode={mode}\")\n        elif self._is_autonomous:\n            status_parts.append(\"mode=autonomous\")\n        else:\n            status_parts.append(\"mode=idle\")\n\n        print(\" \".join(status_parts), flush=True)", "chunk_type": "function", "line_start": 341, "line_end": 354, "language": "python", "name": "set_status"}, "dd96b5af957b_func_handle_system_event": {"id": "dd96b5af957b_func_handle_system_event", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\orchestrator.py", "content": "    def handle_system_event(self, payload: dict):\n        \"\"\"Logic for file changes and other system events.\"\"\"\n        ev_type = payload.get(\"type\")\n        path = payload.get(\"path\")\n        if ev_type == \"file_change\" and path.endswith(\".py\"):\n             self.process_request(f\"Analyze change in file: {path}\", source=\"system\")", "chunk_type": "function", "line_start": 356, "line_end": 361, "language": "python", "name": "handle_system_event"}, "dd96b5af957b_func_handle_git_event": {"id": "dd96b5af957b_func_handle_git_event", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\orchestrator.py", "content": "    def handle_git_event(self, payload: dict):\n        \"\"\"Logic for Git events like commits, checkouts, and merges.\"\"\"\n        ev_type = payload.get(\"type\")\n        data = payload.get(\"data\", {})\n\n        if ev_type == \"merge_state_change\":\n            # Check for conflicts\n            conflicts = self.git_manager.get_conflicts()\n            if conflicts:\n                self._current_conflicts = set(conflicts)\n                logger.warning(f\"Git Conflicts detected in files: {conflicts}\")\n                self.set_status(mode=\"autonomous\", thought=\"Analyzing merge conflicts...\")\n\n                # Activate GitFlowManager logic or handle in Orchestrator\n                for conflict_file in conflicts:\n                    content = self.git_manager.get_file_content_with_conflicts(conflict_file)\n                    self.process_request(\n                        f\"CRITICAL: Git merge conflict detected in {conflict_file}.\\n\"\n                        f\"Content with markers:\\n{content}\\n\"\n      ", "chunk_type": "function", "line_start": 363, "line_end": 400, "language": "python", "name": "handle_git_event"}, "dd96b5af957b_func__handle_plans": {"id": "dd96b5af957b_func__handle_plans", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\orchestrator.py", "content": "    def _handle_plans(self, text: str, session_id: str):\n        \"\"\"Extracts and parses <plan> tags for task decomposition.\"\"\"\n        plans = re.findall(r'<plan>(.*?)</plan>', text, re.DOTALL | re.IGNORECASE)\n        for plan_content in plans:\n            logger.info(f\"PLAN DETECTED: {plan_content.strip()}\")\n            if self.artifact_service:\n                self.artifact_service.create_artifact(session_id, \"plan\", plan_content.strip())\n\n            # Simple parsing of checkboxes like: - [ ] Task name (Role)\n            tasks = re.findall(r'- \\[ \\] (.*?) \\((.*?)\\)', plan_content)\n            for task_desc, role in tasks:\n                 logger.info(f\"Sub-task identified: {task_desc} (Assigned to: {role})\")\n                 if self.notification_service:\n                     self.notification_service.notify(f\"Decomposing task: {task_desc} -> Routing to {role}\")\n                 # Autonomously delegate sub-tasks\n                 self.delegate_task(role, f\"Part of plan for {session_id", "chunk_type": "function", "line_start": 402, "line_end": 417, "language": "python", "name": "_handle_plans"}, "dd96b5af957b_func_handle_peer_message": {"id": "dd96b5af957b_func_handle_peer_message", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\orchestrator.py", "content": "    def handle_peer_message(self, payload: dict, session_id: str = \"peer_unknown\"):\n        \"\"\"Handle coordination messages from other agents.\"\"\"\n        msg_from = payload.get(\"from\")\n        msg_type = payload.get(\"type\")\n        content = payload.get(\"content\", {})\n\n        logger.info(f\"Peer Message from {msg_from}: {msg_type}\")\n        if msg_type == \"result\":\n            self.process_request(f\"Agent {msg_from} returned result: {content.get('text')}\", source=\"peer\", session_id=session_id)", "chunk_type": "function", "line_start": 419, "line_end": 427, "language": "python", "name": "handle_peer_message"}, "dd96b5af957b_func__handle_delegations": {"id": "dd96b5af957b_func__handle_delegations", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\orchestrator.py", "content": "    def _handle_delegations(self, text: str):\n        \"\"\"Extract and process <delegate> tags.\"\"\"\n        # More robust regex for delegation\n        delegations = re.findall(r'<delegate\\s+recipient=[\"\\'](.*?)[\"\\']>(.*?)</delegate>', text, re.DOTALL | re.IGNORECASE)\n        for recipient, task in delegations:\n            self.delegate_task(recipient, task.strip())", "chunk_type": "function", "line_start": 429, "line_end": 434, "language": "python", "name": "_handle_delegations"}, "dd96b5af957b_func_delegate_task": {"id": "dd96b5af957b_func_delegate_task", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\orchestrator.py", "content": "    def delegate_task(self, recipient: str, task: str):\n        \"\"\"Delegates a task to a discovered peer by identity, role, or capability.\"\"\"\n        if not self.peer_discovery:\n            logger.warning(\"No PeerDiscoveryService available.\")\n            return\n\n        if recipient == \"GitFlowManager\" and not any(p.get(\"role\") == \"GitFlowManager\" for p in self.peer_discovery.peers.values()):\n            logger.info(\"No remote GitFlowManager found. Spawning local GitFlowManager logic.\")\n            self.process_request(task, source=\"delegate\", agent_role=\"GitFlowManager\")\n            return\n\n        target_agents = []\n\n        # 1. Match by Identity\n        if recipient in self.peer_discovery.peers:\n            target_agents.append(recipient)\n\n        # 2. Match by Role\n        elif recipient != \"broadcast\":\n            for p_id, p_data in self.peer_discovery.peers.items():\n                if p_data.get(\"role\") == recipient:\n                    target_agents.append(p_id)\n              ", "chunk_type": "function", "line_start": 436, "line_end": 476, "language": "python", "name": "delegate_task"}, "dd96b5af957b_func_handle_peer_auth": {"id": "dd96b5af957b_func_handle_peer_auth", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\orchestrator.py", "content": "    def handle_peer_auth(self, payload: dict):\n        \"\"\"Handle new peer discovery.\"\"\"\n        identity = payload.get(\"identity\")\n        logger.info(f\"\ud83e\udd1d Handshake with peer: {identity}\")", "chunk_type": "function", "line_start": 478, "line_end": 481, "language": "python", "name": "handle_peer_auth"}, "dd96b5af957b_func_dispatch_agent": {"id": "dd96b5af957b_func_dispatch_agent", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\orchestrator.py", "content": "    def dispatch_agent(self, agent_name: str, payload: dict):\n        \"\"\"Local agent dispatch (simulated).\"\"\"\n        logger.info(f\"\ud83d\ude80 [Orchestrator] -> Assigning task to {agent_name}\")", "chunk_type": "function", "line_start": 483, "line_end": 485, "language": "python", "name": "dispatch_agent"}, "dd96b5af957b_class_OrchestratorManager": {"id": "dd96b5af957b_class_OrchestratorManager", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\orchestrator.py", "content": "class OrchestratorManager:\n    \"\"\"\n    Manages the lifecycle and execution of agents based on triggers.\n    Robustly handles AI responses using the Firefly Tagging System (FTS).\n    \"\"\"\n    def __init__(self, event_bus, model_client, config_service=None, peer_discovery=None, session_manager=None, browser_service=None, artifact_service=None, prompt_service=None, memory_service=None, notification_service=None):\n        self.event_bus = event_bus\n        self.model_client = model_client\n        self.config_service = config_service\n        self.peer_discovery = peer_discovery\n        self.session_manager = session_manager\n        self.browser_service = browser_service\n        self.artifact_service = artifact_service\n        self.prompt_service = prompt_service\n        self.memory_service = memory_service\n        self.notification_service = notification_service\n        self.is_autonomous = False\n        self.git_manager = GitManager()\n        self.tag_parser = TagParserService()\n        sel", "chunk_type": "class", "line_start": 12, "line_end": 485, "language": "python", "name": "OrchestratorManager"}, "72034d65918b_file": {"id": "72034d65918b_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\__init__.py", "content": "\"\"\"\nFirefly Agent Manager\n\"\"\"\n", "chunk_type": "file", "line_start": 1, "line_end": 4, "language": "python", "name": "__init__.py"}, "8005688fe6f4_file": {"id": "8005688fe6f4_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\api_controller.py", "content": "from http.server import BaseHTTPRequestHandler, HTTPServer\nfrom pathlib import Path\nfrom threading import Thread\nfrom typing import Optional, Any, Dict\nimport json\nimport logging\nimport os\nimport urllib.parse\n\nlogger = logging.getLogger(\"FireflyAPI\")\n\nclass APIResponseManager:\n    @staticmethod\n    def json(handler, data, status=200):\n        handler.send_response(status)\n        handler.send_header('Content-type', 'application/json')\n        handler.send_header('Access-Control-Allow-Origin', '*') # Enable CORS for IDE frontend\n        handler.end_headers()\n        handler.wfile.write(json.dumps(data).encode('utf-8'))\n\n    @staticmethod\n    def error(handler, message, status=404):\n        APIResponseManager.json(handler, {\"error\": message}, status)\n\nclass APIRequestHandler(BaseHTTPRequestHandler):\n    def do_GET(self):\n        \"\"\"Handle GET requests for artifacts and status.\"\"\"\n        parsed_path = urllib.parse.urlparse(self.path)\n        path_parts = parsed_path.path.strip('/').split('/')\n\n        if not path_parts or path_parts[0] != 'api':\n            APIResponseManager.error(self, \"Not Found\", 404)\n            return\n\n        # /api/artifacts\n        if len(path_parts) == 2 and path_parts[1] == 'artifacts':\n            self.handle_list_sessions()\n\n        # /api/artifacts/{session_id}\n        elif len(path_parts) == 3 and path_parts[1] == 'artifacts':\n            self.handle_list_artifacts(path_parts[2])\n\n        # /api/artifacts/{session_id}/{filename}\n        elif len(path_parts) == 4 and path_parts[1] == 'artifacts':\n            self.handle_get_artifact(path_parts[2], path_parts[3])\n\n        # /api/status\n        elif len(path_parts) == 2 and path_parts[1] == 'status':\n            self.handle_get_status()\n\n        # /api/usage\n        elif len(path_parts) == 2 and path_parts[1] == 'usage':\n            self.handle_get_usage()\n\n        else:\n            APIResponseManager.error(self, \"Endpoint not found\", 404)\n\n    def handle_list_sessions(self):\n        artif", "chunk_type": "file", "line_start": 1, "line_end": 158, "language": "python", "name": "api_controller.py"}, "8005688fe6f4_func_json": {"id": "8005688fe6f4_func_json", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\api_controller.py", "content": "    def json(handler, data, status=200):\n        handler.send_response(status)\n        handler.send_header('Content-type', 'application/json')\n        handler.send_header('Access-Control-Allow-Origin', '*') # Enable CORS for IDE frontend\n        handler.end_headers()\n        handler.wfile.write(json.dumps(data).encode('utf-8'))", "chunk_type": "function", "line_start": 14, "line_end": 19, "language": "python", "name": "json"}, "8005688fe6f4_func_error": {"id": "8005688fe6f4_func_error", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\api_controller.py", "content": "    def error(handler, message, status=404):\n        APIResponseManager.json(handler, {\"error\": message}, status)", "chunk_type": "function", "line_start": 22, "line_end": 23, "language": "python", "name": "error"}, "8005688fe6f4_func_do_GET": {"id": "8005688fe6f4_func_do_GET", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\api_controller.py", "content": "    def do_GET(self):\n        \"\"\"Handle GET requests for artifacts and status.\"\"\"\n        parsed_path = urllib.parse.urlparse(self.path)\n        path_parts = parsed_path.path.strip('/').split('/')\n\n        if not path_parts or path_parts[0] != 'api':\n            APIResponseManager.error(self, \"Not Found\", 404)\n            return\n\n        # /api/artifacts\n        if len(path_parts) == 2 and path_parts[1] == 'artifacts':\n            self.handle_list_sessions()\n\n        # /api/artifacts/{session_id}\n        elif len(path_parts) == 3 and path_parts[1] == 'artifacts':\n            self.handle_list_artifacts(path_parts[2])\n\n        # /api/artifacts/{session_id}/{filename}\n        elif len(path_parts) == 4 and path_parts[1] == 'artifacts':\n            self.handle_get_artifact(path_parts[2], path_parts[3])\n\n        # /api/status\n        elif len(path_parts) == 2 and path_parts[1] == 'status':\n            self.handle_get_status()\n\n        # /api/usage\n        elif len(path_parts) == 2 and path_p", "chunk_type": "function", "line_start": 26, "line_end": 56, "language": "python", "name": "do_GET"}, "8005688fe6f4_func_handle_list_sessions": {"id": "8005688fe6f4_func_handle_list_sessions", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\api_controller.py", "content": "    def handle_list_sessions(self):\n        artifact_service = self.server.artifact_service\n        base_dir = artifact_service.artifact_base_dir\n\n        if not base_dir.exists():\n            APIResponseManager.json(self, [])\n            return\n\n        sessions = [d.name for d in base_dir.iterdir() if d.is_dir()]\n        APIResponseManager.json(self, sorted(sessions, reverse=True))", "chunk_type": "function", "line_start": 58, "line_end": 67, "language": "python", "name": "handle_list_sessions"}, "8005688fe6f4_func_handle_list_artifacts": {"id": "8005688fe6f4_func_handle_list_artifacts", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\api_controller.py", "content": "    def handle_list_artifacts(self, session_id):\n        artifact_service = self.server.artifact_service\n        session_dir = artifact_service.artifact_base_dir / session_id\n\n        if not session_dir.exists():\n            APIResponseManager.error(self, \"Session not found\")\n            return\n\n        artifacts = []\n        for file in sorted(session_dir.glob(\"*.json\")):\n            artifacts.append({\n                \"name\": file.name,\n                \"type\": file.name.split('-')[-1].replace('.json', ''),\n                \"path\": f\"/api/artifacts/{session_id}/{file.name}\"\n            })\n        APIResponseManager.json(self, artifacts)", "chunk_type": "function", "line_start": 69, "line_end": 84, "language": "python", "name": "handle_list_artifacts"}, "8005688fe6f4_func_handle_get_artifact": {"id": "8005688fe6f4_func_handle_get_artifact", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\api_controller.py", "content": "    def handle_get_artifact(self, session_id, filename):\n        artifact_service = self.server.artifact_service\n        file_path = artifact_service.artifact_base_dir / session_id / filename\n\n        if not file_path.exists() or not file_path.is_file():\n            APIResponseManager.error(self, \"Artifact not found\")\n            return\n\n        try:\n            with open(file_path, 'r', encoding='utf-8') as f:\n                data = json.load(f)\n            APIResponseManager.json(self, data)\n        except Exception as e:\n            APIResponseManager.error(self, f\"Error reading artifact: {str(e)}\", 500)", "chunk_type": "function", "line_start": 86, "line_end": 99, "language": "python", "name": "handle_get_artifact"}, "8005688fe6f4_func_handle_get_status": {"id": "8005688fe6f4_func_handle_get_status", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\api_controller.py", "content": "    def handle_get_status(self):\n        # This could be expanded to include more runtime info\n        status = {\n            \"status\": \"online\",\n            \"version\": \"1.0.0\",\n            \"capabilities\": [\"browser\", \"memory\", \"artifacts\", \"triggers\", \"usage_api\"]\n        }\n        APIResponseManager.json(self, status)", "chunk_type": "function", "line_start": 101, "line_end": 108, "language": "python", "name": "handle_get_status"}, "8005688fe6f4_func_handle_get_usage": {"id": "8005688fe6f4_func_handle_get_usage", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\api_controller.py", "content": "    def handle_get_usage(self):\n        # Access the model client manager via the server\n        model_client = self.server.model_client\n        if model_client:\n            APIResponseManager.json(self, model_client.usage_ledger)\n        else:\n            APIResponseManager.error(self, \"Model client not available\", 500)", "chunk_type": "function", "line_start": 110, "line_end": 116, "language": "python", "name": "handle_get_usage"}, "8005688fe6f4_func_log_message": {"id": "8005688fe6f4_func_log_message", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\api_controller.py", "content": "    def log_message(self, format, *args):\n        # Override to suppress standard HTTP logging to stdout to keep Firefly logs clean\n        logger.debug(format % args)", "chunk_type": "function", "line_start": 118, "line_end": 120, "language": "python", "name": "log_message"}, "8005688fe6f4_func___init__": {"id": "8005688fe6f4_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\api_controller.py", "content": "    def __init__(self, event_bus, artifact_service=None, model_client=None, port=5000):\n        self.port = port\n        self.server = None\n        self.thread = None\n        self.event_bus = event_bus\n        self.artifact_service = artifact_service\n        self.model_client = model_client", "chunk_type": "function", "line_start": 126, "line_end": 132, "language": "python", "name": "__init__"}, "8005688fe6f4_func_start": {"id": "8005688fe6f4_func_start", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\api_controller.py", "content": "    def start(self):\n        self.thread = threading.Thread(target=self._run)\n        self.thread.daemon = True\n        self.thread.start()\n        logger.info(f\"API Controller started on port {self.port}\")", "chunk_type": "function", "line_start": 134, "line_end": 138, "language": "python", "name": "start"}, "8005688fe6f4_func__run": {"id": "8005688fe6f4_func__run", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\api_controller.py", "content": "    def _run(self):\n        try:\n            self.server = HTTPServer(('0.0.0.0', self.port), APIRequestHandler)\n            # Inject services into server for handler access\n            self.server.artifact_service = self.artifact_service\n            self.server.model_client = self.model_client\n            self.server.event_bus = self.event_bus\n\n            self.server.serve_forever()\n        except Exception as e:\n            logger.error(f\"API Server failed: {e}\")", "chunk_type": "function", "line_start": 140, "line_end": 150, "language": "python", "name": "_run"}, "8005688fe6f4_func_stop": {"id": "8005688fe6f4_func_stop", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\api_controller.py", "content": "    def stop(self):\n        \"\"\"Stop the API server.\"\"\"\n        if self.server:\n            self.server.shutdown()\n            self.server.server_close()\n            logger.info(\"Firefly API server stopped\")", "chunk_type": "function", "line_start": 152, "line_end": 157, "language": "python", "name": "stop"}, "8005688fe6f4_class_APIResponseManager": {"id": "8005688fe6f4_class_APIResponseManager", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\api_controller.py", "content": "class APIResponseManager:\n    @staticmethod\n    def json(handler, data, status=200):\n        handler.send_response(status)\n        handler.send_header('Content-type', 'application/json')\n        handler.send_header('Access-Control-Allow-Origin', '*') # Enable CORS for IDE frontend\n        handler.end_headers()\n        handler.wfile.write(json.dumps(data).encode('utf-8'))\n\n    @staticmethod\n    def error(handler, message, status=404):\n        APIResponseManager.json(handler, {\"error\": message}, status)", "chunk_type": "class", "line_start": 12, "line_end": 23, "language": "python", "name": "APIResponseManager"}, "8005688fe6f4_class_APIRequestHandler": {"id": "8005688fe6f4_class_APIRequestHandler", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\api_controller.py", "content": "class APIRequestHandler(BaseHTTPRequestHandler):\n    def do_GET(self):\n        \"\"\"Handle GET requests for artifacts and status.\"\"\"\n        parsed_path = urllib.parse.urlparse(self.path)\n        path_parts = parsed_path.path.strip('/').split('/')\n\n        if not path_parts or path_parts[0] != 'api':\n            APIResponseManager.error(self, \"Not Found\", 404)\n            return\n\n        # /api/artifacts\n        if len(path_parts) == 2 and path_parts[1] == 'artifacts':\n            self.handle_list_sessions()\n\n        # /api/artifacts/{session_id}\n        elif len(path_parts) == 3 and path_parts[1] == 'artifacts':\n            self.handle_list_artifacts(path_parts[2])\n\n        # /api/artifacts/{session_id}/{filename}\n        elif len(path_parts) == 4 and path_parts[1] == 'artifacts':\n            self.handle_get_artifact(path_parts[2], path_parts[3])\n\n        # /api/status\n        elif len(path_parts) == 2 and path_parts[1] == 'status':\n            self.handle_get_status()\n\n        # /api/u", "chunk_type": "class", "line_start": 25, "line_end": 120, "language": "python", "name": "APIRequestHandler"}, "8005688fe6f4_class_APIController": {"id": "8005688fe6f4_class_APIController", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\api_controller.py", "content": "class APIController:\n    \"\"\"\n    Manages the HTTP API Server.\n    \"\"\"\n    def __init__(self, event_bus, artifact_service=None, model_client=None, port=5000):\n        self.port = port\n        self.server = None\n        self.thread = None\n        self.event_bus = event_bus\n        self.artifact_service = artifact_service\n        self.model_client = model_client\n\n    def start(self):\n        self.thread = threading.Thread(target=self._run)\n        self.thread.daemon = True\n        self.thread.start()\n        logger.info(f\"API Controller started on port {self.port}\")\n\n    def _run(self):\n        try:\n            self.server = HTTPServer(('0.0.0.0', self.port), APIRequestHandler)\n            # Inject services into server for handler access\n            self.server.artifact_service = self.artifact_service\n            self.server.model_client = self.model_client\n            self.server.event_bus = self.event_bus\n\n            self.server.serve_forever()\n        except Exception as e:\n          ", "chunk_type": "class", "line_start": 122, "line_end": 157, "language": "python", "name": "APIController"}, "2cfd8249d4f4_file": {"id": "2cfd8249d4f4_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\artifact_service.py", "content": "from pathlib import Path\nfrom typing import Any, Dict, Optional\nimport json\nimport logging\nimport os\nimport time\n\nlogger = logging.getLogger(\"ArtifactService\")\n\nclass ArtifactService:\n    \"\"\"\n    Manages persistent storage of agent actions, thoughts, and results.\n    Artifacts are stored in .firefly/artifacts/ organized by session and timestamp.\n    \"\"\"\n    def __init__(self, root_path: str = \".\"):\n        self.root_path = Path(root_path).resolve()\n        self.artifact_base_dir = self.root_path / \".firefly\" / \"artifacts\"\n        self._ensure_dir()\n\n    def _ensure_dir(self):\n        \"\"\"Ensures the artifact directory exists.\"\"\"\n        try:\n            self.artifact_base_dir.mkdir(parents=True, exist_ok=True)\n            logger.info(f\"Artifact storage initialized at {self.artifact_base_dir}\")\n        except Exception as e:\n            logger.error(f\"Failed to create artifact directory: {e}\")\n\n    def create_artifact(self, session_id: str, artifact_type: str, content: Any, metadata: Optional[Dict[str, Any]] = None):\n        \"\"\"\n        Creates a new artifact entry.\n\n        Args:\n            session_id: The ID of the current agent session.\n            artifact_type: The type of artifact (e.g., 'thought', 'command', 'browser_result').\n            content: The data to store.\n            metadata: Optional additional context.\n        \"\"\"\n        timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n        millis = int(time.time() * 1000) % 1000\n        filename = f\"{timestamp}-{millis}-{artifact_type}.json\"\n\n        session_dir = self.artifact_base_dir / session_id\n        session_dir.mkdir(exist_ok=True)\n\n        artifact_path = session_dir / filename\n\n        data = {\n            \"timestamp\": time.time(),\n            \"formatted_time\": f\"{timestamp}-{millis}\",\n            \"type\": artifact_type,\n            \"session_id\": session_id,\n            \"content\": content,\n            \"metadata\": metadata or {}\n        }\n\n        try:\n            with open(artifact_path, 'w', encoding='ut", "chunk_type": "file", "line_start": 1, "line_end": 105, "language": "python", "name": "artifact_service.py"}, "2cfd8249d4f4_func___init__": {"id": "2cfd8249d4f4_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\artifact_service.py", "content": "    def __init__(self, root_path: str = \".\"):\n        self.root_path = Path(root_path).resolve()\n        self.artifact_base_dir = self.root_path / \".firefly\" / \"artifacts\"\n        self._ensure_dir()", "chunk_type": "function", "line_start": 15, "line_end": 18, "language": "python", "name": "__init__"}, "2cfd8249d4f4_func__ensure_dir": {"id": "2cfd8249d4f4_func__ensure_dir", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\artifact_service.py", "content": "    def _ensure_dir(self):\n        \"\"\"Ensures the artifact directory exists.\"\"\"\n        try:\n            self.artifact_base_dir.mkdir(parents=True, exist_ok=True)\n            logger.info(f\"Artifact storage initialized at {self.artifact_base_dir}\")\n        except Exception as e:\n            logger.error(f\"Failed to create artifact directory: {e}\")", "chunk_type": "function", "line_start": 20, "line_end": 26, "language": "python", "name": "_ensure_dir"}, "2cfd8249d4f4_func_create_artifact": {"id": "2cfd8249d4f4_func_create_artifact", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\artifact_service.py", "content": "    def create_artifact(self, session_id: str, artifact_type: str, content: Any, metadata: Optional[Dict[str, Any]] = None):\n        \"\"\"\n        Creates a new artifact entry.\n\n        Args:\n            session_id: The ID of the current agent session.\n            artifact_type: The type of artifact (e.g., 'thought', 'command', 'browser_result').\n            content: The data to store.\n            metadata: Optional additional context.\n        \"\"\"\n        timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n        millis = int(time.time() * 1000) % 1000\n        filename = f\"{timestamp}-{millis}-{artifact_type}.json\"\n\n        session_dir = self.artifact_base_dir / session_id\n        session_dir.mkdir(exist_ok=True)\n\n        artifact_path = session_dir / filename\n\n        data = {\n            \"timestamp\": time.time(),\n            \"formatted_time\": f\"{timestamp}-{millis}\",\n            \"type\": artifact_type,\n            \"session_id\": session_id,\n            \"content\": content,\n            \"metadata\":", "chunk_type": "function", "line_start": 28, "line_end": 63, "language": "python", "name": "create_artifact"}, "2cfd8249d4f4_func_export_session_log": {"id": "2cfd8249d4f4_func_export_session_log", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\artifact_service.py", "content": "    def export_session_log(self, session_id: str):\n        \"\"\"\n        Exports a consolidated markdown log for a specific session.\n        \"\"\"\n        session_dir = self.artifact_base_dir / session_id\n        if not session_dir.exists():\n            return None\n\n        artifacts = []\n        for file in sorted(session_dir.glob(\"*.json\")):\n            try:\n                with open(file, 'r', encoding='utf-8') as f:\n                    artifacts.append(json.load(f))\n            except Exception:\n                continue\n\n        if not artifacts:\n            return None\n\n        md_content = [f\"# Session Log: {session_id}\\n\"]\n        for art in artifacts:\n            t = art.get(\"formatted_time\")\n            atype = art.get(\"type\", \"unknown\").upper()\n            content = art.get(\"content\")\n\n            md_content.append(f\"## [{t}] {atype}\")\n            if isinstance(content, str):\n                md_content.append(content)\n            else:\n                md_content.append(f\"```json\\", "chunk_type": "function", "line_start": 65, "line_end": 104, "language": "python", "name": "export_session_log"}, "2cfd8249d4f4_class_ArtifactService": {"id": "2cfd8249d4f4_class_ArtifactService", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\artifact_service.py", "content": "class ArtifactService:\n    \"\"\"\n    Manages persistent storage of agent actions, thoughts, and results.\n    Artifacts are stored in .firefly/artifacts/ organized by session and timestamp.\n    \"\"\"\n    def __init__(self, root_path: str = \".\"):\n        self.root_path = Path(root_path).resolve()\n        self.artifact_base_dir = self.root_path / \".firefly\" / \"artifacts\"\n        self._ensure_dir()\n\n    def _ensure_dir(self):\n        \"\"\"Ensures the artifact directory exists.\"\"\"\n        try:\n            self.artifact_base_dir.mkdir(parents=True, exist_ok=True)\n            logger.info(f\"Artifact storage initialized at {self.artifact_base_dir}\")\n        except Exception as e:\n            logger.error(f\"Failed to create artifact directory: {e}\")\n\n    def create_artifact(self, session_id: str, artifact_type: str, content: Any, metadata: Optional[Dict[str, Any]] = None):\n        \"\"\"\n        Creates a new artifact entry.\n\n        Args:\n            session_id: The ID of the current agent session.\n    ", "chunk_type": "class", "line_start": 10, "line_end": 104, "language": "python", "name": "ArtifactService"}, "87005df8bb3a_file": {"id": "87005df8bb3a_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\browser_adapter.py", "content": "import logging\n\nfrom playwright.async_api import async_playwright\nimport asyncio\n\nlogger = logging.getLogger(\"FireflyBrowserService\")\n\nclass BrowserService:\n    \"\"\"\n    Adapter for browser automation using Playwright.\n    Supports navigation, clicking, typing, screenshots, and text extraction.\n    \"\"\"\n    def __init__(self, event_bus):\n        self.event_bus = event_bus\n        self.browser = None\n        self.context = None\n        self.page = None\n        self._lock = asyncio.Lock()\n\n    async def start(self):\n        \"\"\"Initializes the browser instance.\"\"\"\n        async with self._lock:\n            if not self.browser:\n                logger.info(\"Starting Chromium browser...\")\n                self.playwright = await async_playwright().start()\n                self.browser = await self.playwright.chromium.launch(headless=True)\n                self.context = await self.browser.new_context()\n                self.page = await self.context.new_page()\n                logger.info(\"Browser initialized successfully.\")\n\n    async def stop(self):\n        \"\"\"Closes the browser instance.\"\"\"\n        async with self._lock:\n            if self.browser:\n                logger.info(\"Closing browser...\")\n                await self.browser.close()\n                await self.playwright.stop()\n                self.browser = None\n                self.context = None\n                self.page = None\n                logger.info(\"Browser closed.\")\n\n    async def navigate(self, url: str):\n        \"\"\"Navigates to a specific URL.\"\"\"\n        if not self.page: await self.start()\n        logger.info(f\"Navigating to: {url}\")\n        await self.page.goto(url, wait_until=\"networkidle\")\n        return {\"status\": \"success\", \"url\": self.page.url}\n\n    async def click(self, selector: str):\n        \"\"\"Clicks an element specified by the selector.\"\"\"\n        if not self.page: await self.start()\n        logger.info(f\"Clicking: {selector}\")\n        await self.page.click(selector)\n        return {\"status\": \"", "chunk_type": "file", "line_start": 1, "line_end": 98, "language": "python", "name": "browser_adapter.py"}, "87005df8bb3a_func___init__": {"id": "87005df8bb3a_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\browser_adapter.py", "content": "    def __init__(self, event_bus):\n        self.event_bus = event_bus\n        self.browser = None\n        self.context = None\n        self.page = None\n        self._lock = asyncio.Lock()", "chunk_type": "function", "line_start": 13, "line_end": 18, "language": "python", "name": "__init__"}, "87005df8bb3a_func_start": {"id": "87005df8bb3a_func_start", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\browser_adapter.py", "content": "    async def start(self):\n        \"\"\"Initializes the browser instance.\"\"\"\n        async with self._lock:\n            if not self.browser:\n                logger.info(\"Starting Chromium browser...\")\n                self.playwright = await async_playwright().start()\n                self.browser = await self.playwright.chromium.launch(headless=True)\n                self.context = await self.browser.new_context()\n                self.page = await self.context.new_page()\n                logger.info(\"Browser initialized successfully.\")", "chunk_type": "function", "line_start": 20, "line_end": 29, "language": "python", "name": "start"}, "87005df8bb3a_func_stop": {"id": "87005df8bb3a_func_stop", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\browser_adapter.py", "content": "    async def stop(self):\n        \"\"\"Closes the browser instance.\"\"\"\n        async with self._lock:\n            if self.browser:\n                logger.info(\"Closing browser...\")\n                await self.browser.close()\n                await self.playwright.stop()\n                self.browser = None\n                self.context = None\n                self.page = None\n                logger.info(\"Browser closed.\")", "chunk_type": "function", "line_start": 31, "line_end": 41, "language": "python", "name": "stop"}, "87005df8bb3a_func_navigate": {"id": "87005df8bb3a_func_navigate", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\browser_adapter.py", "content": "    async def navigate(self, url: str):\n        \"\"\"Navigates to a specific URL.\"\"\"\n        if not self.page: await self.start()\n        logger.info(f\"Navigating to: {url}\")\n        await self.page.goto(url, wait_until=\"networkidle\")\n        return {\"status\": \"success\", \"url\": self.page.url}", "chunk_type": "function", "line_start": 43, "line_end": 48, "language": "python", "name": "navigate"}, "87005df8bb3a_func_click": {"id": "87005df8bb3a_func_click", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\browser_adapter.py", "content": "    async def click(self, selector: str):\n        \"\"\"Clicks an element specified by the selector.\"\"\"\n        if not self.page: await self.start()\n        logger.info(f\"Clicking: {selector}\")\n        await self.page.click(selector)\n        return {\"status\": \"success\", \"selector\": selector}", "chunk_type": "function", "line_start": 50, "line_end": 55, "language": "python", "name": "click"}, "87005df8bb3a_func_type": {"id": "87005df8bb3a_func_type", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\browser_adapter.py", "content": "    async def type(self, selector: str, text: str):\n        \"\"\"Types text into an element specified by the selector.\"\"\"\n        if not self.page: await self.start()\n        logger.info(f\"Typing '{text}' into: {selector}\")\n        await self.page.fill(selector, text)\n        return {\"status\": \"success\", \"selector\": selector}", "chunk_type": "function", "line_start": 57, "line_end": 62, "language": "python", "name": "type"}, "87005df8bb3a_func_screenshot": {"id": "87005df8bb3a_func_screenshot", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\browser_adapter.py", "content": "    async def screenshot(self, path: str = \"screenshot.png\"):\n        \"\"\"Captures a screenshot of the current page.\"\"\"\n        if not self.page: await self.start()\n        logger.info(f\"Taking screenshot to: {path}\")\n        await self.page.screenshot(path=path)\n        return {\"status\": \"success\", \"path\": path}", "chunk_type": "function", "line_start": 64, "line_end": 69, "language": "python", "name": "screenshot"}, "87005df8bb3a_func_get_text": {"id": "87005df8bb3a_func_get_text", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\browser_adapter.py", "content": "    async def get_text(self):\n        \"\"\"Extracts text content from the current page.\"\"\"\n        if not self.page: await self.start()\n        logger.info(\"Extracting page text.\")\n        text = await self.page.content() # or page.inner_text(\"body\")\n        # For AI consumption, inner_text is usually better\n        text = await self.page.inner_text(\"body\")\n        return {\"status\": \"success\", \"content\": text[:5000]} # Truncate for now", "chunk_type": "function", "line_start": 71, "line_end": 78, "language": "python", "name": "get_text"}, "87005df8bb3a_func_run_action": {"id": "87005df8bb3a_func_run_action", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\browser_adapter.py", "content": "    async def run_action(self, action: str, **kwargs):\n        \"\"\"Runs a browser action based on string name.\"\"\"\n        try:\n            if action == \"navigate\":\n                return await self.navigate(kwargs.get(\"url\"))\n            elif action == \"click\":\n                return await self.click(kwargs.get(\"selector\"))\n            elif action == \"type\":\n                return await self.type(kwargs.get(\"selector\"), kwargs.get(\"text\"))\n            elif action == \"screenshot\":\n                return await self.screenshot(kwargs.get(\"path\", \"screenshot.png\"))\n            elif action == \"get_text\":\n                return await self.get_text()\n            else:\n                return {\"status\": \"error\", \"message\": f\"Unknown action: {action}\"}\n        except Exception as e:\n            logger.error(f\"Browser action '{action}' failed: {e}\")\n            return {\"status\": \"error\", \"message\": str(e)}", "chunk_type": "function", "line_start": 80, "line_end": 97, "language": "python", "name": "run_action"}, "87005df8bb3a_class_BrowserService": {"id": "87005df8bb3a_class_BrowserService", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\browser_adapter.py", "content": "class BrowserService:\n    \"\"\"\n    Adapter for browser automation using Playwright.\n    Supports navigation, clicking, typing, screenshots, and text extraction.\n    \"\"\"\n    def __init__(self, event_bus):\n        self.event_bus = event_bus\n        self.browser = None\n        self.context = None\n        self.page = None\n        self._lock = asyncio.Lock()\n\n    async def start(self):\n        \"\"\"Initializes the browser instance.\"\"\"\n        async with self._lock:\n            if not self.browser:\n                logger.info(\"Starting Chromium browser...\")\n                self.playwright = await async_playwright().start()\n                self.browser = await self.playwright.chromium.launch(headless=True)\n                self.context = await self.browser.new_context()\n                self.page = await self.context.new_page()\n                logger.info(\"Browser initialized successfully.\")\n\n    async def stop(self):\n        \"\"\"Closes the browser instance.\"\"\"\n        async with self._lock:\n      ", "chunk_type": "class", "line_start": 8, "line_end": 97, "language": "python", "name": "BrowserService"}, "f0118ee0846e_file": {"id": "f0118ee0846e_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\config_service.py", "content": "from pathlib import Path\nfrom typing import Dict, Any, List\nimport json\nimport logging\nimport os\n\nlogger = logging.getLogger(\"FireflyConfigService\")\n\nclass ConfigurationService:\n    \"\"\"\n    Manages Firefly options and policies.\n    \"\"\"\n    DEFAULT_CONFIG = {\n        \"model_priority\": [\"gemini\", \"openai\", \"anthropic\", \"openrouter\", \"ollama\"],\n        \"approval_policy\": \"ORCHESTRATOR_ONLY\",  # AUTO, ORCHESTRATOR_ONLY, MANUAL\n        \"auto_approved_commands\": [\n            \"ls\", \"pwd\", \"git status\", \"git diff\", \"cat\", \"mcp.py context\", \"mcp.py search\"\n        ],\n        \"orchestrator_approved_commands\": [\n            \"git add\", \"git commit\", \"git push\", \"git merge\", \"git checkout\", \"git branch\", \"mcp.py fix\", \"mcp.py review\", \"npm test\", \"pytest\"\n        ],\n        \"always_ask_commands\": [\n            \"rm -rf\", \"format C:\", \"del /s\", \"curl -X POST\", \"sh\", \"bash\", \"powershell\"\n        ],\n        \"git_agent_always_live\": False\n    }\n\n    def __init__(self, config_path: str = \"options.json\"):\n        self.config_path = Path(config_path)\n        self.config = self.load_config()\n\n    def load_config(self) -> Dict[str, Any]:\n        if not self.config_path.exists():\n            logger.info(f\"Config file not found. Creating default at {self.config_path}\")\n            self.save_config(self.DEFAULT_CONFIG)\n            return self.DEFAULT_CONFIG.copy()\n\n        try:\n            with open(self.config_path, 'r') as f:\n                return json.load(f)\n        except Exception as e:\n            logger.error(f\"Failed to load config: {e}. Using defaults.\")\n            return self.DEFAULT_CONFIG.copy()\n\n    def save_config(self, config: Dict[str, Any]):\n        try:\n            with open(self.config_path, 'w') as f:\n                json.dump(config, f, indent=4)\n        except Exception as e:\n            logger.error(f\"Failed to save config: {e}\")\n\n    def get(self, key: str, default: Any = None) -> Any:\n        return self.config.get(key, default)\n\n    def set(self, key: str, value", "chunk_type": "file", "line_start": 1, "line_end": 82, "language": "python", "name": "config_service.py"}, "f0118ee0846e_func___init__": {"id": "f0118ee0846e_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\config_service.py", "content": "    def __init__(self, config_path: str = \"options.json\"):\n        self.config_path = Path(config_path)\n        self.config = self.load_config()", "chunk_type": "function", "line_start": 28, "line_end": 30, "language": "python", "name": "__init__"}, "f0118ee0846e_func_load_config": {"id": "f0118ee0846e_func_load_config", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\config_service.py", "content": "    def load_config(self) -> Dict[str, Any]:\n        if not self.config_path.exists():\n            logger.info(f\"Config file not found. Creating default at {self.config_path}\")\n            self.save_config(self.DEFAULT_CONFIG)\n            return self.DEFAULT_CONFIG.copy()\n\n        try:\n            with open(self.config_path, 'r') as f:\n                return json.load(f)\n        except Exception as e:\n            logger.error(f\"Failed to load config: {e}. Using defaults.\")\n            return self.DEFAULT_CONFIG.copy()", "chunk_type": "function", "line_start": 32, "line_end": 43, "language": "python", "name": "load_config"}, "f0118ee0846e_func_save_config": {"id": "f0118ee0846e_func_save_config", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\config_service.py", "content": "    def save_config(self, config: Dict[str, Any]):\n        try:\n            with open(self.config_path, 'w') as f:\n                json.dump(config, f, indent=4)\n        except Exception as e:\n            logger.error(f\"Failed to save config: {e}\")", "chunk_type": "function", "line_start": 45, "line_end": 50, "language": "python", "name": "save_config"}, "f0118ee0846e_func_get": {"id": "f0118ee0846e_func_get", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\config_service.py", "content": "    def get(self, key: str, default: Any = None) -> Any:\n        return self.config.get(key, default)", "chunk_type": "function", "line_start": 52, "line_end": 53, "language": "python", "name": "get"}, "f0118ee0846e_func_set": {"id": "f0118ee0846e_func_set", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\config_service.py", "content": "    def set(self, key: str, value: Any):\n        self.config[key] = value\n        self.save_config(self.config)", "chunk_type": "function", "line_start": 55, "line_end": 57, "language": "python", "name": "set"}, "f0118ee0846e_func_is_command_safe": {"id": "f0118ee0846e_func_is_command_safe", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\config_service.py", "content": "    def is_command_safe(self, command: str, agent_context: str = \"default\") -> bool:\n        \"\"\"\n        Check if a command is approved based on the current policy.\n        \"\"\"\n        policy = self.get(\"approval_policy\", \"MANUAL\")\n\n        if policy == \"AUTO\":\n            # Still check against 'always_ask' for extreme safety\n            if any(forbidden in command.lower() for forbidden in self.get(\"always_ask_commands\", [])):\n                 return False\n            return True\n\n        # Check if explicitly auto-approved\n        if any(cmd in command for cmd in self.get(\"auto_approved_commands\", [])):\n            return True\n\n        if policy == \"ORCHESTRATOR_ONLY\":\n            if agent_context == \"orchestrator\":\n                # Check if it's in the orchestrator-approved list\n                if any(cmd in command for cmd in self.get(\"orchestrator_approved_commands\", [])):\n                    return True\n\n        return False", "chunk_type": "function", "line_start": 59, "line_end": 81, "language": "python", "name": "is_command_safe"}, "f0118ee0846e_class_ConfigurationService": {"id": "f0118ee0846e_class_ConfigurationService", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\config_service.py", "content": "class ConfigurationService:\n    \"\"\"\n    Manages Firefly options and policies.\n    \"\"\"\n    DEFAULT_CONFIG = {\n        \"model_priority\": [\"gemini\", \"openai\", \"anthropic\", \"openrouter\", \"ollama\"],\n        \"approval_policy\": \"ORCHESTRATOR_ONLY\",  # AUTO, ORCHESTRATOR_ONLY, MANUAL\n        \"auto_approved_commands\": [\n            \"ls\", \"pwd\", \"git status\", \"git diff\", \"cat\", \"mcp.py context\", \"mcp.py search\"\n        ],\n        \"orchestrator_approved_commands\": [\n            \"git add\", \"git commit\", \"git push\", \"git merge\", \"git checkout\", \"git branch\", \"mcp.py fix\", \"mcp.py review\", \"npm test\", \"pytest\"\n        ],\n        \"always_ask_commands\": [\n            \"rm -rf\", \"format C:\", \"del /s\", \"curl -X POST\", \"sh\", \"bash\", \"powershell\"\n        ],\n        \"git_agent_always_live\": False\n    }\n\n    def __init__(self, config_path: str = \"options.json\"):\n        self.config_path = Path(config_path)\n        self.config = self.load_config()\n\n    def load_config(self) -> Dict[str, Any]:\n        if not s", "chunk_type": "class", "line_start": 9, "line_end": 81, "language": "python", "name": "ConfigurationService"}, "9fe68a41bde6_file": {"id": "9fe68a41bde6_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\dashboard_service.py", "content": "from typing import Dict, Any, List\nimport logging\nimport os\nimport threading\nimport time\n\nlogger = logging.getLogger(\"FireflyDashboard\")\n\nclass DashboardService:\n    \"\"\"\n    Real-time CLI dashboard for Project-Firefly.\n    Aggregates events, usage, and peer status.\n    \"\"\"\n    def __init__(self, event_bus):\n        self.event_bus = event_bus\n        self.peers = {}\n        self.usage = {\"tokens\": 0, \"cost\": 0.0, \"completions\": 0}\n        self.last_events = []\n        self.is_running = False\n        self._render_thread = None\n\n    def start(self):\n        self.is_running = True\n        self.event_bus.subscribe(\"peer_joined\", self._on_peer_joined)\n        self.event_bus.subscribe(\"peer_left\", self._on_peer_left)\n        self.event_bus.subscribe(\"usage_report\", self._on_usage_report)\n        self.event_bus.subscribe(\"system_event\", self._on_event)\n        self.event_bus.subscribe(\"telegram_input\", self._on_event)\n        self.event_bus.subscribe(\"webhook_event\", self._on_event)\n\n        self._render_thread = threading.Thread(target=self._render_loop, daemon=True)\n        self._render_thread.start()\n        logger.info(\"DashboardService started.\")\n\n    def stop(self):\n        self.is_running = False\n        if self._render_thread:\n            self._render_thread.join(timeout=1)\n\n    def _on_peer_joined(self, event_type, payload):\n        self.peers[payload.get(\"identity\")] = payload\n\n    def _on_peer_left(self, event_type, payload):\n        identity = payload.get(\"identity\")\n        if identity in self.peers:\n            del self.peers[identity]\n\n    def _on_usage_report(self, event_type, payload):\n        self.usage[\"tokens\"] += payload.get(\"total_tokens\", 0)\n        self.usage[\"cost\"] += payload.get(\"cost_usd\", 0.0)\n        self.usage[\"completions\"] += 1\n\n    def _on_event(self, event_type, payload):\n        timestamp = time.strftime(\"%H:%M:%S\")\n        self.last_events.append(f\"[{timestamp}] {event_type}\")\n        if len(self.last_events) > 8:\n            self.last_e", "chunk_type": "file", "line_start": 1, "line_end": 96, "language": "python", "name": "dashboard_service.py"}, "9fe68a41bde6_func___init__": {"id": "9fe68a41bde6_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\dashboard_service.py", "content": "    def __init__(self, event_bus):\n        self.event_bus = event_bus\n        self.peers = {}\n        self.usage = {\"tokens\": 0, \"cost\": 0.0, \"completions\": 0}\n        self.last_events = []\n        self.is_running = False\n        self._render_thread = None", "chunk_type": "function", "line_start": 14, "line_end": 20, "language": "python", "name": "__init__"}, "9fe68a41bde6_func_start": {"id": "9fe68a41bde6_func_start", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\dashboard_service.py", "content": "    def start(self):\n        self.is_running = True\n        self.event_bus.subscribe(\"peer_joined\", self._on_peer_joined)\n        self.event_bus.subscribe(\"peer_left\", self._on_peer_left)\n        self.event_bus.subscribe(\"usage_report\", self._on_usage_report)\n        self.event_bus.subscribe(\"system_event\", self._on_event)\n        self.event_bus.subscribe(\"telegram_input\", self._on_event)\n        self.event_bus.subscribe(\"webhook_event\", self._on_event)\n\n        self._render_thread = threading.Thread(target=self._render_loop, daemon=True)\n        self._render_thread.start()\n        logger.info(\"DashboardService started.\")", "chunk_type": "function", "line_start": 22, "line_end": 33, "language": "python", "name": "start"}, "9fe68a41bde6_func_stop": {"id": "9fe68a41bde6_func_stop", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\dashboard_service.py", "content": "    def stop(self):\n        self.is_running = False\n        if self._render_thread:\n            self._render_thread.join(timeout=1)", "chunk_type": "function", "line_start": 35, "line_end": 38, "language": "python", "name": "stop"}, "9fe68a41bde6_func__on_peer_joined": {"id": "9fe68a41bde6_func__on_peer_joined", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\dashboard_service.py", "content": "    def _on_peer_joined(self, event_type, payload):\n        self.peers[payload.get(\"identity\")] = payload", "chunk_type": "function", "line_start": 40, "line_end": 41, "language": "python", "name": "_on_peer_joined"}, "9fe68a41bde6_func__on_peer_left": {"id": "9fe68a41bde6_func__on_peer_left", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\dashboard_service.py", "content": "    def _on_peer_left(self, event_type, payload):\n        identity = payload.get(\"identity\")\n        if identity in self.peers:\n            del self.peers[identity]", "chunk_type": "function", "line_start": 43, "line_end": 46, "language": "python", "name": "_on_peer_left"}, "9fe68a41bde6_func__on_usage_report": {"id": "9fe68a41bde6_func__on_usage_report", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\dashboard_service.py", "content": "    def _on_usage_report(self, event_type, payload):\n        self.usage[\"tokens\"] += payload.get(\"total_tokens\", 0)\n        self.usage[\"cost\"] += payload.get(\"cost_usd\", 0.0)\n        self.usage[\"completions\"] += 1", "chunk_type": "function", "line_start": 48, "line_end": 51, "language": "python", "name": "_on_usage_report"}, "9fe68a41bde6_func__on_event": {"id": "9fe68a41bde6_func__on_event", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\dashboard_service.py", "content": "    def _on_event(self, event_type, payload):\n        timestamp = time.strftime(\"%H:%M:%S\")\n        self.last_events.append(f\"[{timestamp}] {event_type}\")\n        if len(self.last_events) > 8:\n            self.last_events.pop(0)", "chunk_type": "function", "line_start": 53, "line_end": 57, "language": "python", "name": "_on_event"}, "9fe68a41bde6_func__render_loop": {"id": "9fe68a41bde6_func__render_loop", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\dashboard_service.py", "content": "    def _render_loop(self):\n        while self.is_running:\n            self._render()\n            time.sleep(5) # Refresh every 5 seconds", "chunk_type": "function", "line_start": 59, "line_end": 62, "language": "python", "name": "_render_loop"}, "9fe68a41bde6_func__render": {"id": "9fe68a41bde6_func__render", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\dashboard_service.py", "content": "    def _render(self):\n        # Use terminal escape codes to clear and home on supported terminals,\n        # but for simplicity and compatibility with standard logs, we'll just print a headered block.\n        # os.system('cls' if os.name == 'nt' else 'clear')\n\n        output = []\n        output.append(\"\\n\" + \"=\"*50)\n        output.append(\"\ud83e\udd89 PROJECT-FIREFLY AGENT HUB DASHBOARD\")\n        output.append(\"=\"*50)\n\n        # 1. Resource Usage\n        output.append(f\"\\n[RESOURCE USAGE]\")\n        output.append(f\"  - Total Tokens: {self.usage['tokens']}\")\n        output.append(f\"  - Total Cost:   ${self.usage['cost']:.4f}\")\n        output.append(f\"  - Completions:  {self.usage['completions']}\")\n\n        # 2. Peer Registry\n        output.append(f\"\\n[PEER REGISTRY] ({len(self.peers)} active)\")\n        for p_id, p_data in self.peers.items():\n            output.append(f\"  - {p_id} (@{p_data.get('hostname')}) | Status: {p_data.get('status')}\")\n\n        # 3. Recent Activity\n        output.append(f\"\\", "chunk_type": "function", "line_start": 64, "line_end": 95, "language": "python", "name": "_render"}, "9fe68a41bde6_class_DashboardService": {"id": "9fe68a41bde6_class_DashboardService", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\dashboard_service.py", "content": "class DashboardService:\n    \"\"\"\n    Real-time CLI dashboard for Project-Firefly.\n    Aggregates events, usage, and peer status.\n    \"\"\"\n    def __init__(self, event_bus):\n        self.event_bus = event_bus\n        self.peers = {}\n        self.usage = {\"tokens\": 0, \"cost\": 0.0, \"completions\": 0}\n        self.last_events = []\n        self.is_running = False\n        self._render_thread = None\n\n    def start(self):\n        self.is_running = True\n        self.event_bus.subscribe(\"peer_joined\", self._on_peer_joined)\n        self.event_bus.subscribe(\"peer_left\", self._on_peer_left)\n        self.event_bus.subscribe(\"usage_report\", self._on_usage_report)\n        self.event_bus.subscribe(\"system_event\", self._on_event)\n        self.event_bus.subscribe(\"telegram_input\", self._on_event)\n        self.event_bus.subscribe(\"webhook_event\", self._on_event)\n\n        self._render_thread = threading.Thread(target=self._render_loop, daemon=True)\n        self._render_thread.start()\n        logger.info(\"Dash", "chunk_type": "class", "line_start": 9, "line_end": 95, "language": "python", "name": "DashboardService"}, "b4c96d9d2396_file": {"id": "b4c96d9d2396_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\event_bus.py", "content": "from threading import Lock\nfrom typing import Callable, Dict, List, Any\nimport logging\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\nlogger = logging.getLogger(\"FireflyEventBus\")\n\nclass EventBusService:\n    \"\"\"\n    Central event bus for the agent system.\n    Follows a simple Publish-Subscribe pattern.\n    \"\"\"\n    def __init__(self):\n        self._subscribers: Dict[str, List[Callable]] = {}\n        self._lock = Lock()\n\n    def subscribe(self, event_type: str, callback: Callable[[Any], None]):\n        \"\"\"Subscribe a callback function to a specific event type.\"\"\"\n        with self._lock:\n            if event_type not in self._subscribers:\n                self._subscribers[event_type] = []\n            self._subscribers[event_type].append(callback)\n        logger.info(f\"Subscribed to event: {event_type}\")\n\n    def publish(self, event_type: str, data: Any):\n        \"\"\"Publish an event to all subscribers.\"\"\"\n        with self._lock:\n            if event_type not in self._subscribers:\n                # No subscribers for this event\n                return\n\n            subscribers = self._subscribers[event_type][:] # Copy list to avoid modification issues during iteration\n\n        logger.info(f\"Publishing event: {event_type}\")\n        for callback in subscribers:\n            try:\n                callback(event_type, data)\n            except Exception as e:\n                logger.error(f\"Error in subscriber callback for {event_type}: {e}\")\n", "chunk_type": "file", "line_start": 1, "line_end": 41, "language": "python", "name": "event_bus.py"}, "b4c96d9d2396_func___init__": {"id": "b4c96d9d2396_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\event_bus.py", "content": "    def __init__(self):\n        self._subscribers: Dict[str, List[Callable]] = {}\n        self._lock = Lock()", "chunk_type": "function", "line_start": 14, "line_end": 16, "language": "python", "name": "__init__"}, "b4c96d9d2396_func_subscribe": {"id": "b4c96d9d2396_func_subscribe", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\event_bus.py", "content": "    def subscribe(self, event_type: str, callback: Callable[[Any], None]):\n        \"\"\"Subscribe a callback function to a specific event type.\"\"\"\n        with self._lock:\n            if event_type not in self._subscribers:\n                self._subscribers[event_type] = []\n            self._subscribers[event_type].append(callback)\n        logger.info(f\"Subscribed to event: {event_type}\")", "chunk_type": "function", "line_start": 18, "line_end": 24, "language": "python", "name": "subscribe"}, "b4c96d9d2396_func_publish": {"id": "b4c96d9d2396_func_publish", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\event_bus.py", "content": "    def publish(self, event_type: str, data: Any):\n        \"\"\"Publish an event to all subscribers.\"\"\"\n        with self._lock:\n            if event_type not in self._subscribers:\n                # No subscribers for this event\n                return\n\n            subscribers = self._subscribers[event_type][:] # Copy list to avoid modification issues during iteration\n\n        logger.info(f\"Publishing event: {event_type}\")\n        for callback in subscribers:\n            try:\n                callback(event_type, data)\n            except Exception as e:\n                logger.error(f\"Error in subscriber callback for {event_type}: {e}\")", "chunk_type": "function", "line_start": 26, "line_end": 40, "language": "python", "name": "publish"}, "b4c96d9d2396_class_EventBusService": {"id": "b4c96d9d2396_class_EventBusService", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\event_bus.py", "content": "class EventBusService:\n    \"\"\"\n    Central event bus for the agent system.\n    Follows a simple Publish-Subscribe pattern.\n    \"\"\"\n    def __init__(self):\n        self._subscribers: Dict[str, List[Callable]] = {}\n        self._lock = Lock()\n\n    def subscribe(self, event_type: str, callback: Callable[[Any], None]):\n        \"\"\"Subscribe a callback function to a specific event type.\"\"\"\n        with self._lock:\n            if event_type not in self._subscribers:\n                self._subscribers[event_type] = []\n            self._subscribers[event_type].append(callback)\n        logger.info(f\"Subscribed to event: {event_type}\")\n\n    def publish(self, event_type: str, data: Any):\n        \"\"\"Publish an event to all subscribers.\"\"\"\n        with self._lock:\n            if event_type not in self._subscribers:\n                # No subscribers for this event\n                return\n\n            subscribers = self._subscribers[event_type][:] # Copy list to avoid modification issues during iteration", "chunk_type": "class", "line_start": 9, "line_end": 40, "language": "python", "name": "EventBusService"}, "78d4229b20dc_file": {"id": "78d4229b20dc_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\git_manager.py", "content": "from typing import List, Optional\nimport logging\nimport os\nimport subprocess\n\nlogger = logging.getLogger(\"GitManager\")\n\nclass GitManager:\n    \"\"\"\n    Wrapper for Git CLI commands, used by agents to manage branches and conflicts.\n    \"\"\"\n    def __init__(self, root_path: str = \".\"):\n        self.root_path = os.path.abspath(root_path)\n\n    def _run_git(self, args: List[str]) -> str:\n        try:\n            result = subprocess.run(\n                [\"git\"] + args,\n                cwd=self.root_path,\n                capture_output=True,\n                text=True,\n                check=True\n            )\n            return result.stdout.strip()\n        except subprocess.CalledProcessError as e:\n            logger.error(f\"Git command failed: git {' '.join(args)}\\nError: {e.stderr}\")\n            raise Exception(f\"Git Error: {e.stderr.strip()}\")\n\n    def get_current_branch(self) -> str:\n        return self._run_git([\"rev-parse\", \"--abbrev-ref\", \"HEAD\"])\n\n    def create_branch(self, branch_name: str, base: str = \"HEAD\"):\n        return self._run_git([\"checkout\", \"-b\", branch_name, base])\n\n    def commit(self, message: str, all_files: bool = True):\n        if all_files:\n            self._run_git([\"add\", \"-A\"])\n        return self._run_git([\"commit\", \"-m\", message])\n\n    def merge(self, branch_name: str) -> str:\n        try:\n            return self._run_git([\"merge\", branch_name])\n        except Exception as e:\n            if \"CONFLICT\" in str(e):\n                return \"CONFLICT\"\n            raise e\n\n    def get_conflicts(self) -> List[str]:\n        output = self._run_git([\"diff\", \"--name-only\", \"--diff-filter=U\"])\n        return output.splitlines() if output else []\n\n    def get_file_content_with_conflicts(self, filepath: str) -> str:\n        path = os.path.join(self.root_path, filepath)\n        if os.path.exists(path):\n            with open(path, 'r', encoding='utf-8') as f:\n                return f.read()\n        return \"\"\n\n    def resolve_file(self, filepath: str, resolve", "chunk_type": "file", "line_start": 1, "line_end": 75, "language": "python", "name": "git_manager.py"}, "78d4229b20dc_func___init__": {"id": "78d4229b20dc_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\git_manager.py", "content": "    def __init__(self, root_path: str = \".\"):\n        self.root_path = os.path.abspath(root_path)", "chunk_type": "function", "line_start": 12, "line_end": 13, "language": "python", "name": "__init__"}, "78d4229b20dc_func__run_git": {"id": "78d4229b20dc_func__run_git", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\git_manager.py", "content": "    def _run_git(self, args: List[str]) -> str:\n        try:\n            result = subprocess.run(\n                [\"git\"] + args,\n                cwd=self.root_path,\n                capture_output=True,\n                text=True,\n                check=True\n            )\n            return result.stdout.strip()\n        except subprocess.CalledProcessError as e:\n            logger.error(f\"Git command failed: git {' '.join(args)}\\nError: {e.stderr}\")\n            raise Exception(f\"Git Error: {e.stderr.strip()}\")", "chunk_type": "function", "line_start": 15, "line_end": 27, "language": "python", "name": "_run_git"}, "78d4229b20dc_func_get_current_branch": {"id": "78d4229b20dc_func_get_current_branch", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\git_manager.py", "content": "    def get_current_branch(self) -> str:\n        return self._run_git([\"rev-parse\", \"--abbrev-ref\", \"HEAD\"])", "chunk_type": "function", "line_start": 29, "line_end": 30, "language": "python", "name": "get_current_branch"}, "78d4229b20dc_func_create_branch": {"id": "78d4229b20dc_func_create_branch", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\git_manager.py", "content": "    def create_branch(self, branch_name: str, base: str = \"HEAD\"):\n        return self._run_git([\"checkout\", \"-b\", branch_name, base])", "chunk_type": "function", "line_start": 32, "line_end": 33, "language": "python", "name": "create_branch"}, "78d4229b20dc_func_commit": {"id": "78d4229b20dc_func_commit", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\git_manager.py", "content": "    def commit(self, message: str, all_files: bool = True):\n        if all_files:\n            self._run_git([\"add\", \"-A\"])\n        return self._run_git([\"commit\", \"-m\", message])", "chunk_type": "function", "line_start": 35, "line_end": 38, "language": "python", "name": "commit"}, "78d4229b20dc_func_merge": {"id": "78d4229b20dc_func_merge", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\git_manager.py", "content": "    def merge(self, branch_name: str) -> str:\n        try:\n            return self._run_git([\"merge\", branch_name])\n        except Exception as e:\n            if \"CONFLICT\" in str(e):\n                return \"CONFLICT\"\n            raise e", "chunk_type": "function", "line_start": 40, "line_end": 46, "language": "python", "name": "merge"}, "78d4229b20dc_func_get_conflicts": {"id": "78d4229b20dc_func_get_conflicts", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\git_manager.py", "content": "    def get_conflicts(self) -> List[str]:\n        output = self._run_git([\"diff\", \"--name-only\", \"--diff-filter=U\"])\n        return output.splitlines() if output else []", "chunk_type": "function", "line_start": 48, "line_end": 50, "language": "python", "name": "get_conflicts"}, "78d4229b20dc_func_get_file_content_with_conflicts": {"id": "78d4229b20dc_func_get_file_content_with_conflicts", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\git_manager.py", "content": "    def get_file_content_with_conflicts(self, filepath: str) -> str:\n        path = os.path.join(self.root_path, filepath)\n        if os.path.exists(path):\n            with open(path, 'r', encoding='utf-8') as f:\n                return f.read()\n        return \"\"", "chunk_type": "function", "line_start": 52, "line_end": 57, "language": "python", "name": "get_file_content_with_conflicts"}, "78d4229b20dc_func_resolve_file": {"id": "78d4229b20dc_func_resolve_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\git_manager.py", "content": "    def resolve_file(self, filepath: str, resolved_content: str):\n        path = os.path.join(self.root_path, filepath)\n        with open(path, 'w', encoding='utf-8', newline='') as f:\n            f.write(resolved_content)\n        self._run_git([\"add\", filepath])", "chunk_type": "function", "line_start": 59, "line_end": 63, "language": "python", "name": "resolve_file"}, "78d4229b20dc_func_abort_merge": {"id": "78d4229b20dc_func_abort_merge", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\git_manager.py", "content": "    def abort_merge(self):\n        return self._run_git([\"merge\", \"--abort\"])", "chunk_type": "function", "line_start": 65, "line_end": 66, "language": "python", "name": "abort_merge"}, "78d4229b20dc_func_push": {"id": "78d4229b20dc_func_push", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\git_manager.py", "content": "    def push(self, remote: str = \"origin\", branch: Optional[str] = None):\n        if not branch:\n            branch = self.get_current_branch()\n        return self._run_git([\"push\", remote, branch])", "chunk_type": "function", "line_start": 68, "line_end": 71, "language": "python", "name": "push"}, "78d4229b20dc_func_fetch": {"id": "78d4229b20dc_func_fetch", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\git_manager.py", "content": "    def fetch(self, remote: str = \"origin\"):\n        return self._run_git([\"fetch\", remote])", "chunk_type": "function", "line_start": 73, "line_end": 74, "language": "python", "name": "fetch"}, "78d4229b20dc_class_GitManager": {"id": "78d4229b20dc_class_GitManager", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\git_manager.py", "content": "class GitManager:\n    \"\"\"\n    Wrapper for Git CLI commands, used by agents to manage branches and conflicts.\n    \"\"\"\n    def __init__(self, root_path: str = \".\"):\n        self.root_path = os.path.abspath(root_path)\n\n    def _run_git(self, args: List[str]) -> str:\n        try:\n            result = subprocess.run(\n                [\"git\"] + args,\n                cwd=self.root_path,\n                capture_output=True,\n                text=True,\n                check=True\n            )\n            return result.stdout.strip()\n        except subprocess.CalledProcessError as e:\n            logger.error(f\"Git command failed: git {' '.join(args)}\\nError: {e.stderr}\")\n            raise Exception(f\"Git Error: {e.stderr.strip()}\")\n\n    def get_current_branch(self) -> str:\n        return self._run_git([\"rev-parse\", \"--abbrev-ref\", \"HEAD\"])\n\n    def create_branch(self, branch_name: str, base: str = \"HEAD\"):\n        return self._run_git([\"checkout\", \"-b\", branch_name, base])\n\n    def commit(self, me", "chunk_type": "class", "line_start": 8, "line_end": 74, "language": "python", "name": "GitManager"}, "224e8691b05e_file": {"id": "224e8691b05e_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\git_service.py", "content": "from pathlib import Path\nfrom threading import Thread\nimport logging\nimport os\nimport time\n\nlogger = logging.getLogger(\"GitMonitor\")\n\ntry:\n    from watchdog.observers import Observer\n    from watchdog.events import FileSystemEventHandler\n    HAS_WATCHDOG = True\nexcept ImportError:\n    HAS_WATCHDOG = False\n\nclass GitMonitoringService:\n    \"\"\"\n    Monitors the .git directory for state changes (branches, commits, merges).\n    Fires 'git_event' on the EventBus.\n    \"\"\"\n    def __init__(self, event_bus, root_path: str = \".\"):\n        self.event_bus = event_bus\n        self.root_path = Path(root_path).resolve()\n        self.git_path = self.root_path / \".git\"\n        self.is_running = False\n        self._thread = None\n        self._observer = None\n\n    def start(self):\n        if not self.git_path.exists():\n            logger.warning(f\"No .git directory found at {self.root_path}. Git monitoring disabled.\")\n            return\n\n        if self.is_running:\n            return\n        self.is_running = True\n\n        if HAS_WATCHDOG:\n            self._start_watchdog()\n        else:\n            self._start_polling()\n\n        logger.info(f\"Git Monitoring started at {self.git_path}\")\n\n    def stop(self):\n        self.is_running = False\n        if self._observer:\n            self._observer.stop()\n            self._observer.join()\n        if self._thread:\n            self._thread.join(timeout=1)\n        logger.info(\"Git Monitoring stopped.\")\n\n    def _start_watchdog(self):\n        class GitEventHandlerService(FileSystemEventHandler):\n            def __init__(self, service):\n                self.service = service\n\n            def on_modified(self, event):\n                self.service._process_event(event.src_path)\n\n            def on_created(self, event):\n                self.service._process_event(event.src_path)\n\n            def on_deleted(self, event):\n                self.service._process_event(event.src_path)\n\n        self._observer = Observer()\n        # Monitor HEAD and refs\n  ", "chunk_type": "file", "line_start": 1, "line_end": 146, "language": "python", "name": "git_service.py"}, "224e8691b05e_func___init__": {"id": "224e8691b05e_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\git_service.py", "content": "            def __init__(self, service):\n                self.service = service", "chunk_type": "function", "line_start": 56, "line_end": 57, "language": "python", "name": "__init__"}, "224e8691b05e_func_start": {"id": "224e8691b05e_func_start", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\git_service.py", "content": "    def start(self):\n        if not self.git_path.exists():\n            logger.warning(f\"No .git directory found at {self.root_path}. Git monitoring disabled.\")\n            return\n\n        if self.is_running:\n            return\n        self.is_running = True\n\n        if HAS_WATCHDOG:\n            self._start_watchdog()\n        else:\n            self._start_polling()\n\n        logger.info(f\"Git Monitoring started at {self.git_path}\")", "chunk_type": "function", "line_start": 29, "line_end": 43, "language": "python", "name": "start"}, "224e8691b05e_func_stop": {"id": "224e8691b05e_func_stop", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\git_service.py", "content": "    def stop(self):\n        self.is_running = False\n        if self._observer:\n            self._observer.stop()\n            self._observer.join()\n        if self._thread:\n            self._thread.join(timeout=1)\n        logger.info(\"Git Monitoring stopped.\")", "chunk_type": "function", "line_start": 45, "line_end": 52, "language": "python", "name": "stop"}, "224e8691b05e_func__start_watchdog": {"id": "224e8691b05e_func__start_watchdog", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\git_service.py", "content": "    def _start_watchdog(self):\n        class GitEventHandlerService(FileSystemEventHandler):\n            def __init__(self, service):\n                self.service = service\n\n            def on_modified(self, event):\n                self.service._process_event(event.src_path)\n\n            def on_created(self, event):\n                self.service._process_event(event.src_path)\n\n            def on_deleted(self, event):\n                self.service._process_event(event.src_path)\n\n        self._observer = Observer()\n        # Monitor HEAD and refs\n        self._observer.schedule(GitEventHandlerService(self), str(self.git_path / \"HEAD\"), recursive=False)\n        self._observer.schedule(GitEventHandlerService(self), str(self.git_path / \"refs\"), recursive=True)\n        if (self.git_path / \"index\").exists():\n             self._observer.schedule(GitEventHandlerService(self), str(self.git_path / \"index\"), recursive=False)\n\n        self._observer.start()", "chunk_type": "function", "line_start": 54, "line_end": 75, "language": "python", "name": "_start_watchdog"}, "224e8691b05e_func__start_polling": {"id": "224e8691b05e_func__start_polling", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\git_service.py", "content": "    def _start_polling(self):\n        def poll_loop():\n            last_states = {} # path -> mtime\n            paths_to_watch = [\n                self.git_path / \"HEAD\",\n                self.git_path / \"refs\"\n            ]\n            while self.is_running:\n                try:\n                    for root_p in paths_to_watch:\n                        if not root_p.exists(): continue\n\n                        if root_p.is_file():\n                            mtime = root_p.stat().st_mtime\n                            if str(root_p) not in last_states or last_states[str(root_p)] != mtime:\n                                last_states[str(root_p)] = mtime\n                                self._process_event(str(root_p))\n                        else:\n                            for p in root_p.rglob('*'):\n                                if p.is_file():\n                                    mtime = p.stat().st_mtime\n                                    if str(p) not in last_states or last_states[st", "chunk_type": "function", "line_start": 77, "line_end": 106, "language": "python", "name": "_start_polling"}, "224e8691b05e_func__process_event": {"id": "224e8691b05e_func__process_event", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\git_service.py", "content": "    def _process_event(self, path: str):\n        path = Path(path)\n        rel_path = path.relative_to(self.git_path)\n\n        event_type = \"unknown\"\n        data = {\"path\": str(rel_path)}\n\n        if rel_path.name == \"HEAD\":\n            event_type = \"branch_checkout\"\n            # Read current branch\n            try:\n                content = path.read_text().strip()\n                if content.startswith(\"ref: refs/heads/\"):\n                    data[\"branch\"] = content.replace(\"ref: refs/heads/\", \"\")\n                else:\n                    data[\"branch\"] = \"DETACHED\"\n                    data[\"commit\"] = content\n            except: pass\n        elif \"refs/heads/\" in str(rel_path):\n            event_type = \"commit_detected\"\n            data[\"branch\"] = rel_path.name\n            try:\n                data[\"commit\"] = path.read_text().strip()\n            except: pass\n        elif \"refs/remotes/\" in str(rel_path):\n            event_type = \"remote_update\"\n            data[\"remote_path\"] = ", "chunk_type": "function", "line_start": 108, "line_end": 145, "language": "python", "name": "_process_event"}, "224e8691b05e_func_poll_loop": {"id": "224e8691b05e_func_poll_loop", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\git_service.py", "content": "        def poll_loop():\n            last_states = {} # path -> mtime\n            paths_to_watch = [\n                self.git_path / \"HEAD\",\n                self.git_path / \"refs\"\n            ]\n            while self.is_running:\n                try:\n                    for root_p in paths_to_watch:\n                        if not root_p.exists(): continue\n\n                        if root_p.is_file():\n                            mtime = root_p.stat().st_mtime\n                            if str(root_p) not in last_states or last_states[str(root_p)] != mtime:\n                                last_states[str(root_p)] = mtime\n                                self._process_event(str(root_p))\n                        else:\n                            for p in root_p.rglob('*'):\n                                if p.is_file():\n                                    mtime = p.stat().st_mtime\n                                    if str(p) not in last_states or last_states[str(p)] != mtime:\n              ", "chunk_type": "function", "line_start": 78, "line_end": 103, "language": "python", "name": "poll_loop"}, "224e8691b05e_func_on_modified": {"id": "224e8691b05e_func_on_modified", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\git_service.py", "content": "            def on_modified(self, event):\n                self.service._process_event(event.src_path)", "chunk_type": "function", "line_start": 59, "line_end": 60, "language": "python", "name": "on_modified"}, "224e8691b05e_func_on_created": {"id": "224e8691b05e_func_on_created", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\git_service.py", "content": "            def on_created(self, event):\n                self.service._process_event(event.src_path)", "chunk_type": "function", "line_start": 62, "line_end": 63, "language": "python", "name": "on_created"}, "224e8691b05e_func_on_deleted": {"id": "224e8691b05e_func_on_deleted", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\git_service.py", "content": "            def on_deleted(self, event):\n                self.service._process_event(event.src_path)", "chunk_type": "function", "line_start": 65, "line_end": 66, "language": "python", "name": "on_deleted"}, "224e8691b05e_class_GitMonitoringService": {"id": "224e8691b05e_class_GitMonitoringService", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\git_service.py", "content": "class GitMonitoringService:\n    \"\"\"\n    Monitors the .git directory for state changes (branches, commits, merges).\n    Fires 'git_event' on the EventBus.\n    \"\"\"\n    def __init__(self, event_bus, root_path: str = \".\"):\n        self.event_bus = event_bus\n        self.root_path = Path(root_path).resolve()\n        self.git_path = self.root_path / \".git\"\n        self.is_running = False\n        self._thread = None\n        self._observer = None\n\n    def start(self):\n        if not self.git_path.exists():\n            logger.warning(f\"No .git directory found at {self.root_path}. Git monitoring disabled.\")\n            return\n\n        if self.is_running:\n            return\n        self.is_running = True\n\n        if HAS_WATCHDOG:\n            self._start_watchdog()\n        else:\n            self._start_polling()\n\n        logger.info(f\"Git Monitoring started at {self.git_path}\")\n\n    def stop(self):\n        self.is_running = False\n        if self._observer:\n            self._observer.stop()\n       ", "chunk_type": "class", "line_start": 16, "line_end": 145, "language": "python", "name": "GitMonitoringService"}, "224e8691b05e_class_GitEventHandlerService": {"id": "224e8691b05e_class_GitEventHandlerService", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\git_service.py", "content": "        class GitEventHandlerService(FileSystemEventHandler):\n            def __init__(self, service):\n                self.service = service\n\n            def on_modified(self, event):\n                self.service._process_event(event.src_path)\n\n            def on_created(self, event):\n                self.service._process_event(event.src_path)\n\n            def on_deleted(self, event):\n                self.service._process_event(event.src_path)", "chunk_type": "class", "line_start": 55, "line_end": 66, "language": "python", "name": "GitEventHandlerService"}, "4ba7fcaa6182_file": {"id": "4ba7fcaa6182_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\memory_service.py", "content": "from pathlib import Path\nfrom typing import List, Dict, Any, Optional\nimport json\nimport logging\nimport os\n\nimport faiss\nimport numpy as np\n\nlogger = logging.getLogger(\"FireflyMemoryService\")\n\nclass MemoryService:\n    \"\"\"\n    Project-Firefly Semantic Memory.\n    Uses FAISS for vector search and an LLM for embeddings.\n    Indexes thoughts, commands, and code context.\n    \"\"\"\n    def __init__(self, model_client, memory_path: Optional[str] = None):\n        self.model_client = model_client\n        self.root_path = Path(memory_path or \".firefly/memory\")\n        self.index_file = self.root_path / \"firefly_index.faiss\"\n        self.metadata_file = self.root_path / \"firefly_metadata.json\"\n\n        self.dimension = 1536 # Default for OpenAI 'text-embedding-3-small'\n        self.index = None\n        self.metadata = [] # List of dicts matching index IDs\n\n        self._initialize_storage()\n\n    def _initialize_storage(self):\n        self.root_path.mkdir(parents=True, exist_ok=True)\n        if self.index_file.exists() and self.metadata_file.exists():\n            try:\n                self.index = faiss.read_index(str(self.index_file))\n                with open(self.metadata_file, 'r', encoding='utf-8') as f:\n                    self.metadata = json.load(f)\n                logger.info(f\"Memory loaded: {len(self.metadata)} items.\")\n            except Exception as e:\n                logger.error(f\"Failed to load memory index: {e}\")\n                self._create_empty_index()\n        else:\n            self._create_empty_index()\n\n    def _create_empty_index(self):\n        # We start with FlatL2 for simplicity.\n        # For very large codebases, HNSW is better.\n        self.index = faiss.IndexFlatL2(self.dimension)\n        self.metadata = []\n        logger.info(\"Created new empty memory index.\")\n\n    def upsert(self, text: str, meta: Dict[str, Any]):\n        \"\"\"Vectorize and store text in the index.\"\"\"\n        try:\n            embedding = self.model_client.embed(text)\n            vec =", "chunk_type": "file", "line_start": 1, "line_end": 106, "language": "python", "name": "memory_service.py"}, "4ba7fcaa6182_func___init__": {"id": "4ba7fcaa6182_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\memory_service.py", "content": "    def __init__(self, model_client, memory_path: Optional[str] = None):\n        self.model_client = model_client\n        self.root_path = Path(memory_path or \".firefly/memory\")\n        self.index_file = self.root_path / \"firefly_index.faiss\"\n        self.metadata_file = self.root_path / \"firefly_metadata.json\"\n\n        self.dimension = 1536 # Default for OpenAI 'text-embedding-3-small'\n        self.index = None\n        self.metadata = [] # List of dicts matching index IDs\n\n        self._initialize_storage()", "chunk_type": "function", "line_start": 18, "line_end": 28, "language": "python", "name": "__init__"}, "4ba7fcaa6182_func__initialize_storage": {"id": "4ba7fcaa6182_func__initialize_storage", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\memory_service.py", "content": "    def _initialize_storage(self):\n        self.root_path.mkdir(parents=True, exist_ok=True)\n        if self.index_file.exists() and self.metadata_file.exists():\n            try:\n                self.index = faiss.read_index(str(self.index_file))\n                with open(self.metadata_file, 'r', encoding='utf-8') as f:\n                    self.metadata = json.load(f)\n                logger.info(f\"Memory loaded: {len(self.metadata)} items.\")\n            except Exception as e:\n                logger.error(f\"Failed to load memory index: {e}\")\n                self._create_empty_index()\n        else:\n            self._create_empty_index()", "chunk_type": "function", "line_start": 30, "line_end": 42, "language": "python", "name": "_initialize_storage"}, "4ba7fcaa6182_func__create_empty_index": {"id": "4ba7fcaa6182_func__create_empty_index", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\memory_service.py", "content": "    def _create_empty_index(self):\n        # We start with FlatL2 for simplicity.\n        # For very large codebases, HNSW is better.\n        self.index = faiss.IndexFlatL2(self.dimension)\n        self.metadata = []\n        logger.info(\"Created new empty memory index.\")", "chunk_type": "function", "line_start": 44, "line_end": 49, "language": "python", "name": "_create_empty_index"}, "4ba7fcaa6182_func_upsert": {"id": "4ba7fcaa6182_func_upsert", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\memory_service.py", "content": "    def upsert(self, text: str, meta: Dict[str, Any]):\n        \"\"\"Vectorize and store text in the index.\"\"\"\n        try:\n            embedding = self.model_client.embed(text)\n            vec = np.array([embedding]).astype('float32')\n\n            # If dimensions mismatch (e.g. model changed), reset index\n            if vec.shape[1] != self.dimension:\n                logger.warning(f\"Embedding dimension mismatch ({vec.shape[1]} vs {self.dimension}). Recreating index.\")\n                self.dimension = vec.shape[1]\n                self._create_empty_index()\n                # Retry once\n                return self.upsert(text, meta)\n\n            self.index.add(vec)\n            self.metadata.append({\n                \"text\": text,\n                **meta\n            })\n            self.save()\n            return True\n        except Exception as e:\n            logger.error(f\"Failed to upsert memory: {e}\")\n            return False", "chunk_type": "function", "line_start": 51, "line_end": 74, "language": "python", "name": "upsert"}, "4ba7fcaa6182_func_query": {"id": "4ba7fcaa6182_func_query", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\memory_service.py", "content": "    def query(self, query_text: str, top_k: int = 5) -> List[Dict[str, Any]]:\n        \"\"\"Search memory for relevant context.\"\"\"\n        if self.index.ntotal == 0:\n            return []\n\n        try:\n            embedding = self.model_client.embed(query_text)\n            vec = np.array([embedding]).astype('float32')\n\n            distances, indices = self.index.search(vec, top_k)\n\n            results = []\n            for i, idx in enumerate(indices[0]):\n                if idx != -1 and idx < len(self.metadata):\n                    res = self.metadata[idx].copy()\n                    res[\"score\"] = float(distances[0][i])\n                    results.append(res)\n            return results\n        except Exception as e:\n            logger.error(f\"Failed to query memory: {e}\")\n            return []", "chunk_type": "function", "line_start": 76, "line_end": 96, "language": "python", "name": "query"}, "4ba7fcaa6182_func_save": {"id": "4ba7fcaa6182_func_save", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\memory_service.py", "content": "    def save(self):\n        \"\"\"Persist index and metadata to disk.\"\"\"\n        try:\n            faiss.write_index(self.index, str(self.index_file))\n            with open(self.metadata_file, 'w', encoding='utf-8') as f:\n                json.dump(self.metadata, f, indent=2)\n        except Exception as e:\n            logger.error(f\"Failed to save memory: {e}\")", "chunk_type": "function", "line_start": 98, "line_end": 105, "language": "python", "name": "save"}, "4ba7fcaa6182_class_MemoryService": {"id": "4ba7fcaa6182_class_MemoryService", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\memory_service.py", "content": "class MemoryService:\n    \"\"\"\n    Project-Firefly Semantic Memory.\n    Uses FAISS for vector search and an LLM for embeddings.\n    Indexes thoughts, commands, and code context.\n    \"\"\"\n    def __init__(self, model_client, memory_path: Optional[str] = None):\n        self.model_client = model_client\n        self.root_path = Path(memory_path or \".firefly/memory\")\n        self.index_file = self.root_path / \"firefly_index.faiss\"\n        self.metadata_file = self.root_path / \"firefly_metadata.json\"\n\n        self.dimension = 1536 # Default for OpenAI 'text-embedding-3-small'\n        self.index = None\n        self.metadata = [] # List of dicts matching index IDs\n\n        self._initialize_storage()\n\n    def _initialize_storage(self):\n        self.root_path.mkdir(parents=True, exist_ok=True)\n        if self.index_file.exists() and self.metadata_file.exists():\n            try:\n                self.index = faiss.read_index(str(self.index_file))\n                with open(self.metadata_file, 'r', enc", "chunk_type": "class", "line_start": 12, "line_end": 105, "language": "python", "name": "MemoryService"}, "79559b9d7e2e_file": {"id": "79559b9d7e2e_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\notification_service.py", "content": "from typing import List, Dict, Any, Optional\nimport logging\n\nlogger = logging.getLogger(\"FireflyNotificationService\")\n\nclass NotificationService:\n    \"\"\"\n    Unified notification hub for Project-Firefly.\n    Routes messages to Telegram, Webhooks, and internal Event Bus.\n    \"\"\"\n    def __init__(self, event_bus, config_service=None):\n        self.event_bus = event_bus\n        self.config_service = config_service\n\n        # Subscribe to internal broadcasts\n        self.event_bus.subscribe(\"broadcast_notification\", self.on_broadcast)\n\n    def notify(self, message: str, priority: str = \"info\", metadata: Optional[Dict[str, Any]] = None):\n        \"\"\"\n        Send a notification to all active channels.\n        \"\"\"\n        logger.info(f\"[{priority.upper()}] Notification: {message}\")\n\n        payload = {\n            \"text\": message,\n            \"priority\": priority,\n            \"metadata\": metadata or {}\n        }\n\n        # 1. Alert via EventBus (Triggers Telegram, Webhooks etc)\n        # We use a broad chat_id for telegram if not specified\n        tg_payload = {\n            \"text\": f\"[{priority.upper()}] {message}\"\n        }\n        # If we have a default chat ID in env, TelegramService will handle it,\n        # but here we can explicitly try to find one.\n        self.event_bus.publish(\"telegram_output\", tg_payload)\n\n        # also email if it is a critical alert\n        if priority == \"critical\":\n            self.event_bus.publish(\"email_output\", {\n                \"to\": self.config_service.get(\"admin_email\") if self.config_service else None,\n                \"subject\": f\"FIREFLY CRITICAL: {message}\",\n                \"text\": message\n            })\n            self.event_bus.publish(\"sms_output\", {\n                \"to\": self.config_service.get(\"admin_phone\") if self.config_service else None,\n                \"text\": f\"\ud83d\udd25 FIREFLY CRITICAL: {message}\"\n            })\n\n        self.event_bus.publish(\"webhook_event\", {\"type\": \"notification\", \"data\": payload})\n\n    def on_broadcast(", "chunk_type": "file", "line_start": 1, "line_end": 59, "language": "python", "name": "notification_service.py"}, "79559b9d7e2e_func___init__": {"id": "79559b9d7e2e_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\notification_service.py", "content": "    def __init__(self, event_bus, config_service=None):\n        self.event_bus = event_bus\n        self.config_service = config_service\n\n        # Subscribe to internal broadcasts\n        self.event_bus.subscribe(\"broadcast_notification\", self.on_broadcast)", "chunk_type": "function", "line_start": 11, "line_end": 16, "language": "python", "name": "__init__"}, "79559b9d7e2e_func_notify": {"id": "79559b9d7e2e_func_notify", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\notification_service.py", "content": "    def notify(self, message: str, priority: str = \"info\", metadata: Optional[Dict[str, Any]] = None):\n        \"\"\"\n        Send a notification to all active channels.\n        \"\"\"\n        logger.info(f\"[{priority.upper()}] Notification: {message}\")\n\n        payload = {\n            \"text\": message,\n            \"priority\": priority,\n            \"metadata\": metadata or {}\n        }\n\n        # 1. Alert via EventBus (Triggers Telegram, Webhooks etc)\n        # We use a broad chat_id for telegram if not specified\n        tg_payload = {\n            \"text\": f\"[{priority.upper()}] {message}\"\n        }\n        # If we have a default chat ID in env, TelegramService will handle it,\n        # but here we can explicitly try to find one.\n        self.event_bus.publish(\"telegram_output\", tg_payload)\n\n        # also email if it is a critical alert\n        if priority == \"critical\":\n            self.event_bus.publish(\"email_output\", {\n                \"to\": self.config_service.get(\"admin_email\") if self.co", "chunk_type": "function", "line_start": 18, "line_end": 51, "language": "python", "name": "notify"}, "79559b9d7e2e_func_on_broadcast": {"id": "79559b9d7e2e_func_on_broadcast", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\notification_service.py", "content": "    def on_broadcast(self, event_type: str, payload: Dict[str, Any]):\n        \"\"\"Handler for internal broadcast events.\"\"\"\n        text = payload.get(\"text\")\n        prio = payload.get(\"priority\", \"info\")\n        if text:\n            self.notify(text, prio, payload.get(\"metadata\"))", "chunk_type": "function", "line_start": 53, "line_end": 58, "language": "python", "name": "on_broadcast"}, "79559b9d7e2e_class_NotificationService": {"id": "79559b9d7e2e_class_NotificationService", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\notification_service.py", "content": "class NotificationService:\n    \"\"\"\n    Unified notification hub for Project-Firefly.\n    Routes messages to Telegram, Webhooks, and internal Event Bus.\n    \"\"\"\n    def __init__(self, event_bus, config_service=None):\n        self.event_bus = event_bus\n        self.config_service = config_service\n\n        # Subscribe to internal broadcasts\n        self.event_bus.subscribe(\"broadcast_notification\", self.on_broadcast)\n\n    def notify(self, message: str, priority: str = \"info\", metadata: Optional[Dict[str, Any]] = None):\n        \"\"\"\n        Send a notification to all active channels.\n        \"\"\"\n        logger.info(f\"[{priority.upper()}] Notification: {message}\")\n\n        payload = {\n            \"text\": message,\n            \"priority\": priority,\n            \"metadata\": metadata or {}\n        }\n\n        # 1. Alert via EventBus (Triggers Telegram, Webhooks etc)\n        # We use a broad chat_id for telegram if not specified\n        tg_payload = {\n            \"text\": f\"[{priority.upper()}] {mes", "chunk_type": "class", "line_start": 6, "line_end": 58, "language": "python", "name": "NotificationService"}, "024ccd90d381_file": {"id": "024ccd90d381_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\peer_discovery.py", "content": "from pathlib import Path\nfrom typing import Dict, Any, List, Optional\nimport json\nimport logging\nimport os\nimport socket\nimport threading\nimport time\n\nlogger = logging.getLogger(\"FireflyPeerDiscovery\")\n\nclass PeerDiscoveryService:\n    \"\"\"\n    Enables detection and communication with other Firefly/MCP agents.\n    Uses the NSync shared directory for presence and messaging.\n    \"\"\"\n    def __init__(self, event_bus, nsync_path: Optional[str] = None):\n        self.event_bus = event_bus\n        # Default NSync path for Windows\n        self.nsync_path = Path(nsync_path or os.environ.get(\"NSYNC_PATH\", \"C:/Users/dbiss/Desktop/Projects/_BLANK_/NSync\"))\n        self.comms_dir = self.nsync_path / \".nsync_agents\"\n        self.mailbox_dir = self.comms_dir / \"messages\"\n\n        self.hostname = socket.gethostname()\n        self.identity = os.environ.get(\"AGENT_IDENTITY\", self.hostname)\n        self.role = os.environ.get(\"AGENT_ROLE\", \"generalist\")\n        self.capabilities = os.environ.get(\"AGENT_CAPABILITIES\", \"standard\").split(\",\")\n\n        self.peers = {} # hostname -> presence_data\n        self.running = False\n        self._poll_thread = None\n\n        self._ensure_directories()\n\n    def _ensure_directories(self):\n        try:\n            self.comms_dir.mkdir(parents=True, exist_ok=True)\n            self.mailbox_dir.mkdir(parents=True, exist_ok=True)\n        except Exception as e:\n            logger.error(f\"Failed to create comms directories: {e}\")\n\n    def start(self):\n        if self.running: return\n        self.running = True\n        self._poll_thread = threading.Thread(target=self._poll_loop, daemon=True)\n        self._poll_thread.start()\n        logger.info(f\"PeerDiscoveryService started. Identity: {self.identity}\")\n\n    def stop(self):\n        self.running = False\n        if self._poll_thread:\n            self._poll_thread.join(timeout=2)\n        logger.info(\"PeerDiscoveryService stopped.\")\n\n    def _poll_loop(self):\n        while self.running:\n            self.refresh()\n ", "chunk_type": "file", "line_start": 1, "line_end": 164, "language": "python", "name": "peer_discovery.py"}, "024ccd90d381_func___init__": {"id": "024ccd90d381_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\peer_discovery.py", "content": "    def __init__(self, event_bus, nsync_path: Optional[str] = None):\n        self.event_bus = event_bus\n        # Default NSync path for Windows\n        self.nsync_path = Path(nsync_path or os.environ.get(\"NSYNC_PATH\", \"C:/Users/dbiss/Desktop/Projects/_BLANK_/NSync\"))\n        self.comms_dir = self.nsync_path / \".nsync_agents\"\n        self.mailbox_dir = self.comms_dir / \"messages\"\n\n        self.hostname = socket.gethostname()\n        self.identity = os.environ.get(\"AGENT_IDENTITY\", self.hostname)\n        self.role = os.environ.get(\"AGENT_ROLE\", \"generalist\")\n        self.capabilities = os.environ.get(\"AGENT_CAPABILITIES\", \"standard\").split(\",\")\n\n        self.peers = {} # hostname -> presence_data\n        self.running = False\n        self._poll_thread = None\n\n        self._ensure_directories()", "chunk_type": "function", "line_start": 17, "line_end": 33, "language": "python", "name": "__init__"}, "024ccd90d381_func__ensure_directories": {"id": "024ccd90d381_func__ensure_directories", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\peer_discovery.py", "content": "    def _ensure_directories(self):\n        try:\n            self.comms_dir.mkdir(parents=True, exist_ok=True)\n            self.mailbox_dir.mkdir(parents=True, exist_ok=True)\n        except Exception as e:\n            logger.error(f\"Failed to create comms directories: {e}\")", "chunk_type": "function", "line_start": 35, "line_end": 40, "language": "python", "name": "_ensure_directories"}, "024ccd90d381_func_start": {"id": "024ccd90d381_func_start", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\peer_discovery.py", "content": "    def start(self):\n        if self.running: return\n        self.running = True\n        self._poll_thread = threading.Thread(target=self._poll_loop, daemon=True)\n        self._poll_thread.start()\n        logger.info(f\"PeerDiscoveryService started. Identity: {self.identity}\")", "chunk_type": "function", "line_start": 42, "line_end": 47, "language": "python", "name": "start"}, "024ccd90d381_func_stop": {"id": "024ccd90d381_func_stop", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\peer_discovery.py", "content": "    def stop(self):\n        self.running = False\n        if self._poll_thread:\n            self._poll_thread.join(timeout=2)\n        logger.info(\"PeerDiscoveryService stopped.\")", "chunk_type": "function", "line_start": 49, "line_end": 53, "language": "python", "name": "stop"}, "024ccd90d381_func__poll_loop": {"id": "024ccd90d381_func__poll_loop", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\peer_discovery.py", "content": "    def _poll_loop(self):\n        while self.running:\n            self.refresh()\n            # Sleep in small increments to be responsive to stop()\n            for _ in range(100):\n                if not self.running: break\n                time.sleep(0.1)", "chunk_type": "function", "line_start": 55, "line_end": 61, "language": "python", "name": "_poll_loop"}, "024ccd90d381_func_refresh": {"id": "024ccd90d381_func_refresh", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\peer_discovery.py", "content": "    def refresh(self):\n        \"\"\"Synchronously refresh presence, peers, and mailbox.\"\"\"\n        self._update_presence()\n        self._discover_peers()\n        self._check_mailbox()", "chunk_type": "function", "line_start": 63, "line_end": 67, "language": "python", "name": "refresh"}, "024ccd90d381_func__update_presence": {"id": "024ccd90d381_func__update_presence", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\peer_discovery.py", "content": "    def _update_presence(self, status=\"active\", task=\"monitoring\"):\n        presence_file = self.comms_dir / f\"{self.hostname}.json\"\n        data = {\n            \"hostname\": self.hostname,\n            \"identity\": self.identity,\n            \"role\": self.role,\n            \"capabilities\": self.capabilities,\n            \"timestamp\": time.time(),\n            \"status\": status,\n            \"current_task\": task,\n            \"last_seen\": time.ctime()\n        }\n        try:\n            with open(presence_file, \"w\") as f:\n                json.dump(data, f, indent=2)\n        except Exception as e:\n            logger.error(f\"Failed to update presence: {e}\")", "chunk_type": "function", "line_start": 69, "line_end": 85, "language": "python", "name": "_update_presence"}, "024ccd90d381_func__discover_peers": {"id": "024ccd90d381_func__discover_peers", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\peer_discovery.py", "content": "    def _discover_peers(self):\n        current_time = time.time()\n        found_peers = []\n\n        try:\n            for f in self.comms_dir.glob(\"*.json\"):\n                if f.stem == self.hostname: continue\n\n                try:\n                    with open(f, \"r\") as pf:\n                        data = json.load(pf)\n                        peer_id = data.get(\"identity\", f.stem)\n\n                        # Check pulse (stale if > 120s)\n                        if current_time - data.get(\"timestamp\", 0) < 120:\n                            if peer_id not in self.peers:\n                                logger.info(f\"New peer discovered: {peer_id}\")\n                                self.event_bus.publish(\"peer_joined\", data)\n                            self.peers[peer_id] = data\n                            found_peers.append(peer_id)\n                except Exception:\n                    continue\n        except Exception as e:\n            logger.error(f\"Error discovering peers: {e}\")\n\n       ", "chunk_type": "function", "line_start": 87, "line_end": 121, "language": "python", "name": "_discover_peers"}, "024ccd90d381_func__check_mailbox": {"id": "024ccd90d381_func__check_mailbox", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\peer_discovery.py", "content": "    def _check_mailbox(self):\n        messages = []\n        try:\n            # Files match: {recipient}_{sender}_{id}.json\n            search_pattern = f\"{self.identity}_*.json\"\n            for f in self.mailbox_dir.glob(search_pattern):\n                try:\n                    with open(f, \"r\") as mf:\n                        msg = json.load(mf)\n                        messages.append(msg)\n                    f.unlink() # Mark as read\n                except Exception:\n                    continue\n        except Exception as e:\n            logger.error(f\"Error checking mailbox: {e}\")\n\n        for msg in messages:\n            logger.info(f\"Received message from {msg.get('from')}: {msg.get('type')}\")\n            self.event_bus.publish(\"peer_message\", msg)", "chunk_type": "function", "line_start": 123, "line_end": 141, "language": "python", "name": "_check_mailbox"}, "024ccd90d381_func_send_message": {"id": "024ccd90d381_func_send_message", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\peer_discovery.py", "content": "    def send_message(self, recipient: str, msg_type: str, content: dict):\n        msg_id = int(time.time() * 1000)\n        msg_file = self.mailbox_dir / f\"{recipient}_{self.identity}_{msg_id}.json\"\n\n        payload = {\n            \"id\": msg_id,\n            \"from\": self.identity,\n            \"to\": recipient,\n            \"type\": msg_type,\n            \"content\": content,\n            \"timestamp\": time.time()\n        }\n\n        try:\n            with open(msg_file, \"w\") as f:\n                json.dump(payload, f, indent=2)\n            logger.info(f\"Message sent to {recipient}: {msg_type}\")\n            return True\n        except Exception as e:\n            logger.error(f\"Failed to send message to {recipient}: {e}\")\n            return False", "chunk_type": "function", "line_start": 143, "line_end": 163, "language": "python", "name": "send_message"}, "024ccd90d381_class_PeerDiscoveryService": {"id": "024ccd90d381_class_PeerDiscoveryService", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\peer_discovery.py", "content": "class PeerDiscoveryService:\n    \"\"\"\n    Enables detection and communication with other Firefly/MCP agents.\n    Uses the NSync shared directory for presence and messaging.\n    \"\"\"\n    def __init__(self, event_bus, nsync_path: Optional[str] = None):\n        self.event_bus = event_bus\n        # Default NSync path for Windows\n        self.nsync_path = Path(nsync_path or os.environ.get(\"NSYNC_PATH\", \"C:/Users/dbiss/Desktop/Projects/_BLANK_/NSync\"))\n        self.comms_dir = self.nsync_path / \".nsync_agents\"\n        self.mailbox_dir = self.comms_dir / \"messages\"\n\n        self.hostname = socket.gethostname()\n        self.identity = os.environ.get(\"AGENT_IDENTITY\", self.hostname)\n        self.role = os.environ.get(\"AGENT_ROLE\", \"generalist\")\n        self.capabilities = os.environ.get(\"AGENT_CAPABILITIES\", \"standard\").split(\",\")\n\n        self.peers = {} # hostname -> presence_data\n        self.running = False\n        self._poll_thread = None\n\n        self._ensure_directories()\n\n    def _ensure_d", "chunk_type": "class", "line_start": 12, "line_end": 163, "language": "python", "name": "PeerDiscoveryService"}, "7777d2b949e7_file": {"id": "7777d2b949e7_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\prompt_service.py", "content": "from typing import Dict, Optional\nimport logging\n\nlogger = logging.getLogger(\"PromptService\")\n\nclass PromptService:\n    \"\"\"\n    Manages agent personas and system prompts for Project-Firefly.\n    Provides structured context for specialized agent roles.\n    \"\"\"\n    def __init__(self):\n        self.personas = {\n            \"Lead Orchestrator\": (\n                \"You are the Firefly Lead Orchestrator. Your goal is to manage the overall development lifecycle. \"\n                \"You are responsible for analyzing high-level requests, creating execution plans, and delegating specific tasks \"\n                \"to specialized agents (Documentarian, Test Engineer, Architect, etc.). \"\n                \"Always maintain a technical, proactive, and authoritative tone.\"\n            ),\n            \"Test Engineer\": (\n                \"You are the Firefly Test Engineer. Your primary responsibility is writing, running, and debugging tests. \"\n                \"You focus on unit, integration, and E2E testing using frameworks like pytest, unittest, and playwright. \"\n                \"You must ensure that any new code meets quality standards and that regressions are caught immediately. \"\n                \"Always prioritize test coverage and edge-case handling.\"\n            ),\n            \"Documentarian\": (\n                \"You are the Firefly Documentarian. Your mission is to maintain crystal-clear project documentation. \"\n                \"This includes updating README.md, generating docstrings, writing walkthroughs, and maintaining architectural logs. \"\n                \"You translate complex technical changes into readable, professional documentation. \"\n                \"Always prioritize clarity, consistency, and completeness.\"\n            ),\n            \"Structural Architect\": (\n                \"You are the Firefly Structural Architect. You specialize in project hierarchy, layering, and large-scale refactoring. \"\n                \"You ensure the codebase follows strict architectural constraints", "chunk_type": "file", "line_start": 1, "line_end": 72, "language": "python", "name": "prompt_service.py"}, "7777d2b949e7_func___init__": {"id": "7777d2b949e7_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\prompt_service.py", "content": "    def __init__(self):\n        self.personas = {\n            \"Lead Orchestrator\": (\n                \"You are the Firefly Lead Orchestrator. Your goal is to manage the overall development lifecycle. \"\n                \"You are responsible for analyzing high-level requests, creating execution plans, and delegating specific tasks \"\n                \"to specialized agents (Documentarian, Test Engineer, Architect, etc.). \"\n                \"Always maintain a technical, proactive, and authoritative tone.\"\n            ),\n            \"Test Engineer\": (\n                \"You are the Firefly Test Engineer. Your primary responsibility is writing, running, and debugging tests. \"\n                \"You focus on unit, integration, and E2E testing using frameworks like pytest, unittest, and playwright. \"\n                \"You must ensure that any new code meets quality standards and that regressions are caught immediately. \"\n                \"Always prioritize test coverage and edge-case handling.\"\n        ", "chunk_type": "function", "line_start": 11, "line_end": 54, "language": "python", "name": "__init__"}, "7777d2b949e7_func_get_prompt": {"id": "7777d2b949e7_func_get_prompt", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\prompt_service.py", "content": "    def get_prompt(self, role: str, session_context: str = \"\") -> str:\n        \"\"\"\n        Constructs the final system prompt for a specific role.\n        \"\"\"\n        persona = self.personas.get(role, f\"You are the Firefly {role}.\")\n\n        return (\n            f\"{persona}\\n\\n\"\n            \"### Standard Capabilities & Formatting\\n\"\n            f\"{self.base_instructions}\\n\\n\"\n            \"### Session History & Context\\n\"\n            f\"{session_context}\"\n        )", "chunk_type": "function", "line_start": 56, "line_end": 68, "language": "python", "name": "get_prompt"}, "7777d2b949e7_func_list_roles": {"id": "7777d2b949e7_func_list_roles", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\prompt_service.py", "content": "    def list_roles(self):\n        return list(self.personas.keys())", "chunk_type": "function", "line_start": 70, "line_end": 71, "language": "python", "name": "list_roles"}, "7777d2b949e7_class_PromptService": {"id": "7777d2b949e7_class_PromptService", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\prompt_service.py", "content": "class PromptService:\n    \"\"\"\n    Manages agent personas and system prompts for Project-Firefly.\n    Provides structured context for specialized agent roles.\n    \"\"\"\n    def __init__(self):\n        self.personas = {\n            \"Lead Orchestrator\": (\n                \"You are the Firefly Lead Orchestrator. Your goal is to manage the overall development lifecycle. \"\n                \"You are responsible for analyzing high-level requests, creating execution plans, and delegating specific tasks \"\n                \"to specialized agents (Documentarian, Test Engineer, Architect, etc.). \"\n                \"Always maintain a technical, proactive, and authoritative tone.\"\n            ),\n            \"Test Engineer\": (\n                \"You are the Firefly Test Engineer. Your primary responsibility is writing, running, and debugging tests. \"\n                \"You focus on unit, integration, and E2E testing using frameworks like pytest, unittest, and playwright. \"\n                \"You must ensure that a", "chunk_type": "class", "line_start": 6, "line_end": 71, "language": "python", "name": "PromptService"}, "63944bf6e00e_file": {"id": "63944bf6e00e_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\session_manager.py", "content": "from collections import deque\nfrom typing import List, Dict, Any, Optional\nimport logging\nimport time\n\nlogger = logging.getLogger(\"FireflySessionManager\")\n\nclass SessionManager:\n    \"\"\"\n    Manages stateful conversation histories for different trigger sources.\n    Ensures agents have context of previous turns.\n    \"\"\"\n    def __init__(self, max_history: int = 20):\n        self.max_history = max_history\n        self.sessions: Dict[str, deque] = {} # session_id -> deque of message dicts\n\n    def get_history(self, session_id: str) -> List[Dict[str, str]]:\n        \"\"\"Returns the chat history for a given session.\"\"\"\n        if session_id not in self.sessions:\n            self.sessions[session_id] = deque(maxlen=self.max_history)\n        return list(self.sessions[session_id])\n\n    def add_message(self, session_id: str, role: str, content: str):\n        \"\"\"Adds a message to the session history.\"\"\"\n        if session_id not in self.sessions:\n            self.sessions[session_id] = deque(maxlen=self.max_history)\n\n        self.sessions[session_id].append({\n            \"role\": role,\n            \"content\": content,\n            \"timestamp\": time.time()\n        })\n        logger.debug(f\"Added {role} message to session {session_id}\")\n\n    def clear_session(self, session_id: str):\n        \"\"\"Resets the history for a session.\"\"\"\n        if session_id in self.sessions:\n            self.sessions[session_id].clear()\n            logger.info(f\"Cleared session: {session_id}\")\n\n    def format_for_ai(self, session_id: str) -> str:\n        \"\"\"Formats the history as a single string for AI context (compatibility mode).\"\"\"\n        history = self.get_history(session_id)\n        if not history:\n            return \"\"\n\n        formatted = \"\\n--- CONVERSATION HISTORY ---\\n\"\n        for msg in history:\n            formatted += f\"{msg['role'].upper()}: {msg['content']}\\n\"\n        formatted += \"--- END HISTORY ---\\n\"\n        return formatted\n", "chunk_type": "file", "line_start": 1, "line_end": 52, "language": "python", "name": "session_manager.py"}, "63944bf6e00e_func___init__": {"id": "63944bf6e00e_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\session_manager.py", "content": "    def __init__(self, max_history: int = 20):\n        self.max_history = max_history\n        self.sessions: Dict[str, deque] = {} # session_id -> deque of message dicts", "chunk_type": "function", "line_start": 13, "line_end": 15, "language": "python", "name": "__init__"}, "63944bf6e00e_func_get_history": {"id": "63944bf6e00e_func_get_history", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\session_manager.py", "content": "    def get_history(self, session_id: str) -> List[Dict[str, str]]:\n        \"\"\"Returns the chat history for a given session.\"\"\"\n        if session_id not in self.sessions:\n            self.sessions[session_id] = deque(maxlen=self.max_history)\n        return list(self.sessions[session_id])", "chunk_type": "function", "line_start": 17, "line_end": 21, "language": "python", "name": "get_history"}, "63944bf6e00e_func_add_message": {"id": "63944bf6e00e_func_add_message", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\session_manager.py", "content": "    def add_message(self, session_id: str, role: str, content: str):\n        \"\"\"Adds a message to the session history.\"\"\"\n        if session_id not in self.sessions:\n            self.sessions[session_id] = deque(maxlen=self.max_history)\n\n        self.sessions[session_id].append({\n            \"role\": role,\n            \"content\": content,\n            \"timestamp\": time.time()\n        })\n        logger.debug(f\"Added {role} message to session {session_id}\")", "chunk_type": "function", "line_start": 23, "line_end": 33, "language": "python", "name": "add_message"}, "63944bf6e00e_func_clear_session": {"id": "63944bf6e00e_func_clear_session", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\session_manager.py", "content": "    def clear_session(self, session_id: str):\n        \"\"\"Resets the history for a session.\"\"\"\n        if session_id in self.sessions:\n            self.sessions[session_id].clear()\n            logger.info(f\"Cleared session: {session_id}\")", "chunk_type": "function", "line_start": 35, "line_end": 39, "language": "python", "name": "clear_session"}, "63944bf6e00e_func_format_for_ai": {"id": "63944bf6e00e_func_format_for_ai", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\session_manager.py", "content": "    def format_for_ai(self, session_id: str) -> str:\n        \"\"\"Formats the history as a single string for AI context (compatibility mode).\"\"\"\n        history = self.get_history(session_id)\n        if not history:\n            return \"\"\n\n        formatted = \"\\n--- CONVERSATION HISTORY ---\\n\"\n        for msg in history:\n            formatted += f\"{msg['role'].upper()}: {msg['content']}\\n\"\n        formatted += \"--- END HISTORY ---\\n\"\n        return formatted", "chunk_type": "function", "line_start": 41, "line_end": 51, "language": "python", "name": "format_for_ai"}, "63944bf6e00e_class_SessionManager": {"id": "63944bf6e00e_class_SessionManager", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\session_manager.py", "content": "class SessionManager:\n    \"\"\"\n    Manages stateful conversation histories for different trigger sources.\n    Ensures agents have context of previous turns.\n    \"\"\"\n    def __init__(self, max_history: int = 20):\n        self.max_history = max_history\n        self.sessions: Dict[str, deque] = {} # session_id -> deque of message dicts\n\n    def get_history(self, session_id: str) -> List[Dict[str, str]]:\n        \"\"\"Returns the chat history for a given session.\"\"\"\n        if session_id not in self.sessions:\n            self.sessions[session_id] = deque(maxlen=self.max_history)\n        return list(self.sessions[session_id])\n\n    def add_message(self, session_id: str, role: str, content: str):\n        \"\"\"Adds a message to the session history.\"\"\"\n        if session_id not in self.sessions:\n            self.sessions[session_id] = deque(maxlen=self.max_history)\n\n        self.sessions[session_id].append({\n            \"role\": role,\n            \"content\": content,\n            \"timestamp\": time.time(", "chunk_type": "class", "line_start": 8, "line_end": 51, "language": "python", "name": "SessionManager"}, "9500b240bceb_file": {"id": "9500b240bceb_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\tag_parser.py", "content": "from dataclasses import dataclass, field\nfrom typing import List, Dict, Any, Optional\nimport logging\nimport re\n\nfrom agent_manager.models.tag import TagResponse\n\nlogger = logging.getLogger(\"FireflyTagParser\")\n\n\nclass TagParserService:\n    \"\"\"\n    Robustly extracts structured data from AI-generated text using XML-like tags.\n    Resilient to malformed JSON, interleaving, and surrounding noise.\n    \"\"\"\n    TAG_PATTERNS = {\n        \"thought\": r\"<thought>(.*?)</thought>\",\n        \"command\": r\"<command>(.*?)</command>\",\n        \"message\": r\"<message>(.*?)</message>\",\n        \"status\": r\"<status>(.*?)</status>\",\n        \"call\": r\"<call>(.*?)</call>\"\n    }\n\n    def parse(self, text: str) -> TagResponse:\n        \"\"\"\n        Parse text and extract all identified tags.\n        \"\"\"\n        # Clean up common AI artifacts like markdown code blocks around tags\n        # e.g. ```xml <command>ls</command> ```\n        text = re.sub(r\"```[a-z]*\\n?\", \"\", text)\n        text = re.sub(r\"\\n?```\", \"\", text)\n\n        response = TagResponse(raw_text=text)\n\n        # Extract standard tags\n        response.thoughts = self._extract_all(text, \"thought\")\n        response.commands = self._extract_all(text, \"command\")\n        response.messages = self._extract_all(text, \"message\")\n        response.status_updates = self._extract_all(text, \"status\")\n\n        # Special handling for calls (might contain JSON inside tags)\n        raw_calls = self._extract_all(text, \"call\")\n        for raw in raw_calls:\n            try:\n                import json\n                response.calls.append(json.loads(raw))\n            except Exception:\n                # If it's not JSON, just treat it as a raw call string\n                response.calls.append({\"raw\": raw})\n\n        return response\n\n    def _extract_all(self, text: str, tag_name: str) -> List[str]:\n        \"\"\"\n        Extract all occurrences of a specific tag using regex.\n        Supports multiline content (DOTALL).\n        \"\"\"\n        pattern = self.TAG_PATTERN", "chunk_type": "file", "line_start": 1, "line_end": 69, "language": "python", "name": "tag_parser.py"}, "9500b240bceb_func_parse": {"id": "9500b240bceb_func_parse", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\tag_parser.py", "content": "    def parse(self, text: str) -> TagResponse:\n        \"\"\"\n        Parse text and extract all identified tags.\n        \"\"\"\n        # Clean up common AI artifacts like markdown code blocks around tags\n        # e.g. ```xml <command>ls</command> ```\n        text = re.sub(r\"```[a-z]*\\n?\", \"\", text)\n        text = re.sub(r\"\\n?```\", \"\", text)\n\n        response = TagResponse(raw_text=text)\n\n        # Extract standard tags\n        response.thoughts = self._extract_all(text, \"thought\")\n        response.commands = self._extract_all(text, \"command\")\n        response.messages = self._extract_all(text, \"message\")\n        response.status_updates = self._extract_all(text, \"status\")\n\n        # Special handling for calls (might contain JSON inside tags)\n        raw_calls = self._extract_all(text, \"call\")\n        for raw in raw_calls:\n            try:\n                import json\n                response.calls.append(json.loads(raw))\n            except Exception:\n                # If it's not JSON, just", "chunk_type": "function", "line_start": 24, "line_end": 51, "language": "python", "name": "parse"}, "9500b240bceb_func__extract_all": {"id": "9500b240bceb_func__extract_all", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\tag_parser.py", "content": "    def _extract_all(self, text: str, tag_name: str) -> List[str]:\n        \"\"\"\n        Extract all occurrences of a specific tag using regex.\n        Supports multiline content (DOTALL).\n        \"\"\"\n        pattern = self.TAG_PATTERNS.get(tag_name)\n        if not pattern:\n            return []\n\n        matches = re.findall(pattern, text, re.DOTALL | re.IGNORECASE)\n        return [m.strip() for m in matches]", "chunk_type": "function", "line_start": 53, "line_end": 63, "language": "python", "name": "_extract_all"}, "9500b240bceb_func_wrap": {"id": "9500b240bceb_func_wrap", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\tag_parser.py", "content": "    def wrap(content: str, tag: str) -> str:\n        \"\"\"Utility to wrap content in FTS tags.\"\"\"\n        return f\"<{tag}>\\n{content}\\n</tag>\"", "chunk_type": "function", "line_start": 66, "line_end": 68, "language": "python", "name": "wrap"}, "9500b240bceb_class_TagParserService": {"id": "9500b240bceb_class_TagParserService", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\core\\tag_parser.py", "content": "class TagParserService:\n    \"\"\"\n    Robustly extracts structured data from AI-generated text using XML-like tags.\n    Resilient to malformed JSON, interleaving, and surrounding noise.\n    \"\"\"\n    TAG_PATTERNS = {\n        \"thought\": r\"<thought>(.*?)</thought>\",\n        \"command\": r\"<command>(.*?)</command>\",\n        \"message\": r\"<message>(.*?)</message>\",\n        \"status\": r\"<status>(.*?)</status>\",\n        \"call\": r\"<call>(.*?)</call>\"\n    }\n\n    def parse(self, text: str) -> TagResponse:\n        \"\"\"\n        Parse text and extract all identified tags.\n        \"\"\"\n        # Clean up common AI artifacts like markdown code blocks around tags\n        # e.g. ```xml <command>ls</command> ```\n        text = re.sub(r\"```[a-z]*\\n?\", \"\", text)\n        text = re.sub(r\"\\n?```\", \"\", text)\n\n        response = TagResponse(raw_text=text)\n\n        # Extract standard tags\n        response.thoughts = self._extract_all(text, \"thought\")\n        response.commands = self._extract_all(text, \"command\")\n       ", "chunk_type": "class", "line_start": 11, "line_end": 68, "language": "python", "name": "TagParserService"}, "689f4dddb131_file": {"id": "689f4dddb131_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\models\\anthropic.py", "content": "from typing import Optional, TYPE_CHECKING, Dict, Any\nimport json\nimport logging\nimport os\nimport urllib.error\nimport urllib.request\n\nfrom .base import BaseService, ServiceResponse\nfrom __future__ import annotations\n\nif TYPE_CHECKING:\n    pass\n\nlogger = logging.getLogger(\"FireflyAnthropicService\")\n\nclass AnthropicService(BaseService):\n    \"\"\"\n    Anthropic Service (Claude) using standard library (zero-dependency).\n    \"\"\"\n    BASE_URL = \"https://api.anthropic.com/v1/messages\"\n\n    def __init__(self, api_key: Optional[str] = None, model_name: str = \"claude-3-5-sonnet-20240620\"):\n        self.api_key = api_key or os.environ.get(\"ANTHROPIC_API_KEY\")\n        self.model_name = model_name\n\n    def validate_config(self) -> bool:\n        return bool(self.api_key)\n\n    def generate(self, prompt: str, system_prompt: Optional[str] = None) -> ServiceResponse:\n        if not self.validate_config():\n            raise ValueError(\"Anthropic API Key not found. Set ANTHROPIC_API_KEY environment variable.\")\n\n        # Construct payload\n        data = {\n            \"model\": self.model_name,\n            \"max_tokens\": 4096,\n            \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n        }\n        if system_prompt:\n            data[\"system\"] = system_prompt\n\n        headers = {\n            'Content-Type': 'application/json',\n            'x-api-key': self.api_key,\n            'anthropic-version': '2023-06-01'\n        }\n\n        req = urllib.request.Request(self.BASE_URL, data=json.dumps(data).encode('utf-8'), headers=headers)\n\n        try:\n            with urllib.request.urlopen(req) as response:\n                result = json.loads(response.read().decode('utf-8'))\n\n                try:\n                    # Anthropic returns a list of content blocks\n                    text = \"\"\n                    for block in result.get(\"content\", []):\n                        if block.get(\"type\") == \"text\":\n                            text += block.get(\"text\", \"\")\n\n                    usage = resul", "chunk_type": "file", "line_start": 1, "line_end": 92, "language": "python", "name": "anthropic.py"}, "689f4dddb131_func___init__": {"id": "689f4dddb131_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\models\\anthropic.py", "content": "    def __init__(self, api_key: Optional[str] = None, model_name: str = \"claude-3-5-sonnet-20240620\"):\n        self.api_key = api_key or os.environ.get(\"ANTHROPIC_API_KEY\")\n        self.model_name = model_name", "chunk_type": "function", "line_start": 22, "line_end": 24, "language": "python", "name": "__init__"}, "689f4dddb131_func_validate_config": {"id": "689f4dddb131_func_validate_config", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\models\\anthropic.py", "content": "    def validate_config(self) -> bool:\n        return bool(self.api_key)", "chunk_type": "function", "line_start": 26, "line_end": 27, "language": "python", "name": "validate_config"}, "689f4dddb131_func_generate": {"id": "689f4dddb131_func_generate", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\models\\anthropic.py", "content": "    def generate(self, prompt: str, system_prompt: Optional[str] = None) -> ServiceResponse:\n        if not self.validate_config():\n            raise ValueError(\"Anthropic API Key not found. Set ANTHROPIC_API_KEY environment variable.\")\n\n        # Construct payload\n        data = {\n            \"model\": self.model_name,\n            \"max_tokens\": 4096,\n            \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n        }\n        if system_prompt:\n            data[\"system\"] = system_prompt\n\n        headers = {\n            'Content-Type': 'application/json',\n            'x-api-key': self.api_key,\n            'anthropic-version': '2023-06-01'\n        }\n\n        req = urllib.request.Request(self.BASE_URL, data=json.dumps(data).encode('utf-8'), headers=headers)\n\n        try:\n            with urllib.request.urlopen(req) as response:\n                result = json.loads(response.read().decode('utf-8'))\n\n                try:\n                    # Anthropic returns a list of content blocks\n     ", "chunk_type": "function", "line_start": 29, "line_end": 91, "language": "python", "name": "generate"}, "689f4dddb131_class_AnthropicService": {"id": "689f4dddb131_class_AnthropicService", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\models\\anthropic.py", "content": "class AnthropicService(BaseService):\n    \"\"\"\n    Anthropic Service (Claude) using standard library (zero-dependency).\n    \"\"\"\n    BASE_URL = \"https://api.anthropic.com/v1/messages\"\n\n    def __init__(self, api_key: Optional[str] = None, model_name: str = \"claude-3-5-sonnet-20240620\"):\n        self.api_key = api_key or os.environ.get(\"ANTHROPIC_API_KEY\")\n        self.model_name = model_name\n\n    def validate_config(self) -> bool:\n        return bool(self.api_key)\n\n    def generate(self, prompt: str, system_prompt: Optional[str] = None) -> ServiceResponse:\n        if not self.validate_config():\n            raise ValueError(\"Anthropic API Key not found. Set ANTHROPIC_API_KEY environment variable.\")\n\n        # Construct payload\n        data = {\n            \"model\": self.model_name,\n            \"max_tokens\": 4096,\n            \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n        }\n        if system_prompt:\n            data[\"system\"] = system_prompt\n\n        headers = {\n            'Conte", "chunk_type": "class", "line_start": 16, "line_end": 91, "language": "python", "name": "AnthropicService"}, "3bf20ae96dfc_file": {"id": "3bf20ae96dfc_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\models\\base.py", "content": "from abc import ABC, abstractmethod\nfrom dataclasses import dataclass, field\nfrom typing import Iterator, Optional, Dict, Any\n\n@dataclass\nclass ServiceResponse:\n    \"\"\"\n    Standardized response from an AI Model Service.\n    \"\"\"\n    text: str\n    prompt_tokens: int = 0\n    completion_tokens: int = 0\n    model_name: str = \"unknown\"\n    cost_usd: float = 0.0\n    metadata: Dict[str, Any] = field(default_factory=dict)\n\nclass BaseService(ABC):\n    \"\"\"\n    Abstract base class for all LLM providers.\n    Enforces a consistent interface for the ModelConnectionManager.\n    \"\"\"\n\n    def __init__(self, api_key: Optional[str] = None, model_name: str = \"default\"):\n        self.api_key = api_key\n        self.model_name = model_name\n\n    @abstractmethod\n    def generate(self, prompt: str, system_prompt: Optional[str] = None) -> ServiceResponse:\n        \"\"\"\n        Generate a complete response from the model.\n\n        Args:\n            prompt: The user prompt.\n            system_prompt: Optional system instruction.\n\n        Returns:\n            ServiceResponse: The generated text and usage metadata.\n\n        Raises:\n            Exception: If the API call fails.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def validate_config(self) -> bool:\n        \"\"\"\n        Check if the provider is correctly configured (e.g., has API key).\n        \"\"\"\n        pass\n", "chunk_type": "file", "line_start": 1, "line_end": 50, "language": "python", "name": "base.py"}, "3bf20ae96dfc_func___init__": {"id": "3bf20ae96dfc_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\models\\base.py", "content": "    def __init__(self, api_key: Optional[str] = None, model_name: str = \"default\"):\n        self.api_key = api_key\n        self.model_name = model_name", "chunk_type": "function", "line_start": 23, "line_end": 25, "language": "python", "name": "__init__"}, "3bf20ae96dfc_func_generate": {"id": "3bf20ae96dfc_func_generate", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\models\\base.py", "content": "    def generate(self, prompt: str, system_prompt: Optional[str] = None) -> ServiceResponse:\n        \"\"\"\n        Generate a complete response from the model.\n\n        Args:\n            prompt: The user prompt.\n            system_prompt: Optional system instruction.\n\n        Returns:\n            ServiceResponse: The generated text and usage metadata.\n\n        Raises:\n            Exception: If the API call fails.\n        \"\"\"\n        pass", "chunk_type": "function", "line_start": 28, "line_end": 42, "language": "python", "name": "generate"}, "3bf20ae96dfc_func_validate_config": {"id": "3bf20ae96dfc_func_validate_config", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\models\\base.py", "content": "    def validate_config(self) -> bool:\n        \"\"\"\n        Check if the provider is correctly configured (e.g., has API key).\n        \"\"\"\n        pass", "chunk_type": "function", "line_start": 45, "line_end": 49, "language": "python", "name": "validate_config"}, "3bf20ae96dfc_class_ServiceResponse": {"id": "3bf20ae96dfc_class_ServiceResponse", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\models\\base.py", "content": "class ServiceResponse:\n    \"\"\"\n    Standardized response from an AI Model Service.\n    \"\"\"\n    text: str\n    prompt_tokens: int = 0\n    completion_tokens: int = 0\n    model_name: str = \"unknown\"\n    cost_usd: float = 0.0\n    metadata: Dict[str, Any] = field(default_factory=dict)", "chunk_type": "class", "line_start": 6, "line_end": 15, "language": "python", "name": "ServiceResponse"}, "3bf20ae96dfc_class_BaseService": {"id": "3bf20ae96dfc_class_BaseService", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\models\\base.py", "content": "class BaseService(ABC):\n    \"\"\"\n    Abstract base class for all LLM providers.\n    Enforces a consistent interface for the ModelConnectionManager.\n    \"\"\"\n\n    def __init__(self, api_key: Optional[str] = None, model_name: str = \"default\"):\n        self.api_key = api_key\n        self.model_name = model_name\n\n    @abstractmethod\n    def generate(self, prompt: str, system_prompt: Optional[str] = None) -> ServiceResponse:\n        \"\"\"\n        Generate a complete response from the model.\n\n        Args:\n            prompt: The user prompt.\n            system_prompt: Optional system instruction.\n\n        Returns:\n            ServiceResponse: The generated text and usage metadata.\n\n        Raises:\n            Exception: If the API call fails.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def validate_config(self) -> bool:\n        \"\"\"\n        Check if the provider is correctly configured (e.g., has API key).\n        \"\"\"\n        pass", "chunk_type": "class", "line_start": 17, "line_end": 49, "language": "python", "name": "BaseService"}, "59acdcb668f4_file": {"id": "59acdcb668f4_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\models\\gemini.py", "content": "from typing import Optional, TYPE_CHECKING, Dict, Any, List\nimport json\nimport logging\nimport os\nimport urllib.error\nimport urllib.request\n\nfrom .base import BaseService, ServiceResponse\nfrom __future__ import annotations\n\nlogger = logging.getLogger(\"FireflyGeminiService\")\n\nclass GeminiService(BaseService):\n    \"\"\"\n    Google Gemini Service using standard library (zero-dependency).\n    \"\"\"\n    BASE_URL = \"https://generativelanguage.googleapis.com/v1beta/models\"\n\n    def __init__(self, api_key: Optional[str] = None, model_name: str = \"gemini-1.5-flash\"):\n        self.api_key = api_key or os.environ.get(\"GEMINI_API_KEY\")\n        self.model_name = model_name\n\n    def validate_config(self) -> bool:\n        return bool(self.api_key)\n\n    def generate(self, prompt: str, system_prompt: Optional[str] = None) -> ServiceResponse:\n        if not self.validate_config():\n            raise ValueError(\"Gemini API Key not found. Set GEMINI_API_KEY environment variable.\")\n\n        url = f\"{self.BASE_URL}/{self.model_name}:generateContent?key={self.api_key}\"\n\n        # Construct payload\n        contents = []\n        if system_prompt:\n             contents.append({\"role\": \"user\", \"parts\": [{\"text\": \"System Instruction: \" + system_prompt}]})\n\n        contents.append({\"role\": \"user\", \"parts\": [{\"text\": prompt}]})\n\n        data = {\n            \"contents\": contents,\n            \"generationConfig\": {\n                \"temperature\": 0.7,\n                \"maxOutputTokens\": 2048\n            }\n        }\n\n        headers = {'Content-Type': 'application/json'}\n        req = urllib.request.Request(url, data=json.dumps(data).encode('utf-8'), headers=headers)\n\n        try:\n            with urllib.request.urlopen(req) as response:\n                result = json.loads(response.read().decode('utf-8'))\n\n                try:\n                    text = result['candidates'][0]['content']['parts'][0]['text']\n                    usage = result.get('usageMetadata', {})\n                    pt = usage.get('promp", "chunk_type": "file", "line_start": 1, "line_end": 107, "language": "python", "name": "gemini.py"}, "59acdcb668f4_func___init__": {"id": "59acdcb668f4_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\models\\gemini.py", "content": "    def __init__(self, api_key: Optional[str] = None, model_name: str = \"gemini-1.5-flash\"):\n        self.api_key = api_key or os.environ.get(\"GEMINI_API_KEY\")\n        self.model_name = model_name", "chunk_type": "function", "line_start": 19, "line_end": 21, "language": "python", "name": "__init__"}, "59acdcb668f4_func_validate_config": {"id": "59acdcb668f4_func_validate_config", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\models\\gemini.py", "content": "    def validate_config(self) -> bool:\n        return bool(self.api_key)", "chunk_type": "function", "line_start": 23, "line_end": 24, "language": "python", "name": "validate_config"}, "59acdcb668f4_func_generate": {"id": "59acdcb668f4_func_generate", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\models\\gemini.py", "content": "    def generate(self, prompt: str, system_prompt: Optional[str] = None) -> ServiceResponse:\n        if not self.validate_config():\n            raise ValueError(\"Gemini API Key not found. Set GEMINI_API_KEY environment variable.\")\n\n        url = f\"{self.BASE_URL}/{self.model_name}:generateContent?key={self.api_key}\"\n\n        # Construct payload\n        contents = []\n        if system_prompt:\n             contents.append({\"role\": \"user\", \"parts\": [{\"text\": \"System Instruction: \" + system_prompt}]})\n\n        contents.append({\"role\": \"user\", \"parts\": [{\"text\": prompt}]})\n\n        data = {\n            \"contents\": contents,\n            \"generationConfig\": {\n                \"temperature\": 0.7,\n                \"maxOutputTokens\": 2048\n            }\n        }\n\n        headers = {'Content-Type': 'application/json'}\n        req = urllib.request.Request(url, data=json.dumps(data).encode('utf-8'), headers=headers)\n\n        try:\n            with urllib.request.urlopen(req) as response:\n             ", "chunk_type": "function", "line_start": 26, "line_end": 81, "language": "python", "name": "generate"}, "59acdcb668f4_func_embed": {"id": "59acdcb668f4_func_embed", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\models\\gemini.py", "content": "    def embed(self, text: str) -> List[float]:\n        \"\"\"Generate embedding using Google's Generative AI API.\"\"\"\n        if not self.api_key:\n            raise ValueError(\"Gemini API Key not found.\")\n\n        # Using text-embedding-004 model for Gemini\n        url = f\"https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:embedContent?key={self.api_key}\"\n\n        data = {\n            \"model\": \"models/text-embedding-004\",\n            \"content\": {\n                \"parts\": [{\"text\": text}]\n            }\n        }\n\n        req = urllib.request.Request(url, data=json.dumps(data).encode('utf-8'), headers={'Content-Type': 'application/json'})\n\n        try:\n            with urllib.request.urlopen(req) as response:\n                result = json.loads(response.read().decode('utf-8'))\n                return result['embedding']['values']\n        except Exception as e:\n            logger.error(f\"Gemini Embed Error: {e}\")\n            raise", "chunk_type": "function", "line_start": 83, "line_end": 106, "language": "python", "name": "embed"}, "59acdcb668f4_class_GeminiService": {"id": "59acdcb668f4_class_GeminiService", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\models\\gemini.py", "content": "class GeminiService(BaseService):\n    \"\"\"\n    Google Gemini Service using standard library (zero-dependency).\n    \"\"\"\n    BASE_URL = \"https://generativelanguage.googleapis.com/v1beta/models\"\n\n    def __init__(self, api_key: Optional[str] = None, model_name: str = \"gemini-1.5-flash\"):\n        self.api_key = api_key or os.environ.get(\"GEMINI_API_KEY\")\n        self.model_name = model_name\n\n    def validate_config(self) -> bool:\n        return bool(self.api_key)\n\n    def generate(self, prompt: str, system_prompt: Optional[str] = None) -> ServiceResponse:\n        if not self.validate_config():\n            raise ValueError(\"Gemini API Key not found. Set GEMINI_API_KEY environment variable.\")\n\n        url = f\"{self.BASE_URL}/{self.model_name}:generateContent?key={self.api_key}\"\n\n        # Construct payload\n        contents = []\n        if system_prompt:\n             contents.append({\"role\": \"user\", \"parts\": [{\"text\": \"System Instruction: \" + system_prompt}]})\n\n        contents.append({\"role\":", "chunk_type": "class", "line_start": 13, "line_end": 106, "language": "python", "name": "GeminiService"}, "83b21bdfc544_file": {"id": "83b21bdfc544_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\models\\manager.py", "content": "from typing import List, Optional, Dict, Any\nimport logging\n\nfrom .anthropic import AnthropicService\nfrom .base import BaseService, ServiceResponse\nfrom .gemini import GeminiService\nfrom .ollama import OllamaService\nfrom .open_connector import OpenRouterService\nfrom .openai import OpenAIService\n\nlogger = logging.getLogger(\"FireflyHandlerClient\")\n\nclass ModelClientManager:\n    \"\"\"\n    Universal Handler Client.\n    Manages multiple model services and handles failover logic.\n    Tracks token usage and cost.\n    \"\"\"\n    def __init__(self, providers: Optional[List[BaseService]] = None, event_bus = None, config_service = None):\n        self.providers = providers or []\n        self.event_bus = event_bus\n        self.config_service = config_service\n        self.usage_ledger = {\n            \"total_prompt_tokens\": 0,\n            \"total_completion_tokens\": 0,\n            \"total_cost_usd\": 0.0,\n            \"by_model\": {}\n        }\n\n        if not self.providers:\n            # Default fallback chain if none provided\n            self._initialize_default_providers()\n\n        if self.config_service:\n            self.reorder_providers()\n\n        if not self.providers:\n            logger.warning(\"No model services configured or initialized successfully.\")\n\n    def _initialize_default_providers(self):\n        \"\"\"Initialize all supported providers (keys loaded from env).\"\"\"\n        for cls in [GeminiService, OpenAIService, AnthropicService, OpenRouterService, OllamaService]:\n            try:\n                p = cls()\n                if p.validate_config():\n                    self.providers.append(p)\n            except Exception:\n                pass\n\n    def reorder_providers(self):\n        \"\"\"Reorder providers based on config priority.\"\"\"\n        priority_list = self.config_service.get(\"model_priority\", [])\n        if not priority_list:\n            return\n\n        def get_priority(p):\n            # Map class name or model name to priority index\n            name = p.__class__.__name__", "chunk_type": "file", "line_start": 1, "line_end": 137, "language": "python", "name": "manager.py"}, "83b21bdfc544_func___init__": {"id": "83b21bdfc544_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\models\\manager.py", "content": "    def __init__(self, providers: Optional[List[BaseService]] = None, event_bus = None, config_service = None):\n        self.providers = providers or []\n        self.event_bus = event_bus\n        self.config_service = config_service\n        self.usage_ledger = {\n            \"total_prompt_tokens\": 0,\n            \"total_completion_tokens\": 0,\n            \"total_cost_usd\": 0.0,\n            \"by_model\": {}\n        }\n\n        if not self.providers:\n            # Default fallback chain if none provided\n            self._initialize_default_providers()\n\n        if self.config_service:\n            self.reorder_providers()\n\n        if not self.providers:\n            logger.warning(\"No model services configured or initialized successfully.\")", "chunk_type": "function", "line_start": 19, "line_end": 38, "language": "python", "name": "__init__"}, "83b21bdfc544_func__initialize_default_providers": {"id": "83b21bdfc544_func__initialize_default_providers", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\models\\manager.py", "content": "    def _initialize_default_providers(self):\n        \"\"\"Initialize all supported providers (keys loaded from env).\"\"\"\n        for cls in [GeminiService, OpenAIService, AnthropicService, OpenRouterService, OllamaService]:\n            try:\n                p = cls()\n                if p.validate_config():\n                    self.providers.append(p)\n            except Exception:\n                pass", "chunk_type": "function", "line_start": 40, "line_end": 48, "language": "python", "name": "_initialize_default_providers"}, "83b21bdfc544_func_reorder_providers": {"id": "83b21bdfc544_func_reorder_providers", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\models\\manager.py", "content": "    def reorder_providers(self):\n        \"\"\"Reorder providers based on config priority.\"\"\"\n        priority_list = self.config_service.get(\"model_priority\", [])\n        if not priority_list:\n            return\n\n        def get_priority(p):\n            # Map class name or model name to priority index\n            name = p.__class__.__name__.lower().replace(\"service\", \"\").replace(\"manager\", \"\")\n            try:\n                return priority_list.index(name)\n            except ValueError:\n                return 999\n\n        self.providers.sort(key=get_priority)\n        logger.info(f\"Service providers reordered: {[p.__class__.__name__ for p in self.providers]}\")", "chunk_type": "function", "line_start": 50, "line_end": 65, "language": "python", "name": "reorder_providers"}, "83b21bdfc544_func_add_provider": {"id": "83b21bdfc544_func_add_provider", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\models\\manager.py", "content": "    def add_provider(self, provider: BaseService):\n        \"\"\"Add a service to the end of the priority list.\"\"\"\n        self.providers.append(provider)", "chunk_type": "function", "line_start": 67, "line_end": 69, "language": "python", "name": "add_provider"}, "83b21bdfc544_func__record_usage": {"id": "83b21bdfc544_func__record_usage", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\models\\manager.py", "content": "    def _record_usage(self, response: ServiceResponse):\n        \"\"\"Update internal ledger and emit event.\"\"\"\n        self.usage_ledger[\"total_prompt_tokens\"] += response.prompt_tokens\n        self.usage_ledger[\"total_completion_tokens\"] += response.completion_tokens\n        self.usage_ledger[\"total_cost_usd\"] += response.cost_usd\n\n        m_name = response.model_name\n        if m_name not in self.usage_ledger[\"by_model\"]:\n            self.usage_ledger[\"by_model\"][m_name] = {\"prompt\": 0, \"completion\": 0, \"cost\": 0.0}\n\n        self.usage_ledger[\"by_model\"][m_name][\"prompt\"] += response.prompt_tokens\n        self.usage_ledger[\"by_model\"][m_name][\"completion\"] += response.completion_tokens\n        self.usage_ledger[\"by_model\"][m_name][\"cost\"] += response.cost_usd\n\n        if self.event_bus:\n            self.event_bus.publish(\"usage_report\", {\n                \"current_response\": {\n                    \"model\": m_name,\n                    \"prompt_tokens\": response.prompt_tokens,\n             ", "chunk_type": "function", "line_start": 71, "line_end": 94, "language": "python", "name": "_record_usage"}, "83b21bdfc544_func_generate": {"id": "83b21bdfc544_func_generate", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\models\\manager.py", "content": "    def generate(self, prompt: str, system_prompt: Optional[str] = None) -> ServiceResponse:\n        \"\"\"\n        Attempt to generate text using the configured providers in priority order.\n        If one fails, try the next.\n        \"\"\"\n        full_error_log = []\n\n        for provider in self.providers:\n            provider_name = f\"{provider.__class__.__name__}({provider.model_name})\"\n            try:\n                if not provider.validate_config():\n                    logger.warning(f\"Skipping {provider_name}: Invalid configuration (missing API key?)\")\n                    continue\n\n                logger.info(f\"Generating with {provider_name}...\")\n                response = provider.generate(prompt, system_prompt)\n                logger.info(f\"Success with {provider_name}\")\n\n                # Record usage\n                self._record_usage(response)\n\n                return response\n\n            except Exception as e:\n                error_msg = f\"{provider_name} failed: {str(e)}\"\n ", "chunk_type": "function", "line_start": 96, "line_end": 126, "language": "python", "name": "generate"}, "83b21bdfc544_func_embed": {"id": "83b21bdfc544_func_embed", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\models\\manager.py", "content": "    def embed(self, text: str) -> List[float]:\n        \"\"\"Generate an embedding for the text using the primary provider.\"\"\"\n        for provider in self.providers:\n            try:\n                return provider.embed(text)\n            except Exception as e:\n                logger.warning(f\"Embedding failed with {provider.__class__.__name__}: {e}\")\n                continue\n        raise RuntimeError(\"All embedding providers failed.\")", "chunk_type": "function", "line_start": 128, "line_end": 136, "language": "python", "name": "embed"}, "83b21bdfc544_func_get_priority": {"id": "83b21bdfc544_func_get_priority", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\models\\manager.py", "content": "        def get_priority(p):\n            # Map class name or model name to priority index\n            name = p.__class__.__name__.lower().replace(\"service\", \"\").replace(\"manager\", \"\")\n            try:\n                return priority_list.index(name)\n            except ValueError:\n                return 999", "chunk_type": "function", "line_start": 56, "line_end": 62, "language": "python", "name": "get_priority"}, "83b21bdfc544_class_ModelClientManager": {"id": "83b21bdfc544_class_ModelClientManager", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\models\\manager.py", "content": "class ModelClientManager:\n    \"\"\"\n    Universal Handler Client.\n    Manages multiple model services and handles failover logic.\n    Tracks token usage and cost.\n    \"\"\"\n    def __init__(self, providers: Optional[List[BaseService]] = None, event_bus = None, config_service = None):\n        self.providers = providers or []\n        self.event_bus = event_bus\n        self.config_service = config_service\n        self.usage_ledger = {\n            \"total_prompt_tokens\": 0,\n            \"total_completion_tokens\": 0,\n            \"total_cost_usd\": 0.0,\n            \"by_model\": {}\n        }\n\n        if not self.providers:\n            # Default fallback chain if none provided\n            self._initialize_default_providers()\n\n        if self.config_service:\n            self.reorder_providers()\n\n        if not self.providers:\n            logger.warning(\"No model services configured or initialized successfully.\")\n\n    def _initialize_default_providers(self):\n        \"\"\"Initialize all supported providers", "chunk_type": "class", "line_start": 13, "line_end": 136, "language": "python", "name": "ModelClientManager"}, "36fde5040177_file": {"id": "36fde5040177_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\models\\ollama.py", "content": "from typing import Optional, TYPE_CHECKING, Dict, Any\nimport json\nimport logging\nimport os\nimport urllib.error\nimport urllib.request\n\nfrom .base import BaseService, ServiceResponse\nfrom __future__ import annotations\n\nlogger = logging.getLogger(\"FireflyOllamaService\")\n\nclass OllamaService(BaseService):\n    \"\"\"\n    Ollama Service for local inference (zero-dependency).\n    \"\"\"\n    def __init__(self, api_key: Optional[str] = None, model_name: str = \"llama3\", base_url: str = \"http://localhost:11434/api/generate\"):\n        self.api_key = api_key # Usually none for local\n        self.model_name = model_name\n        self.base_url = base_url\n\n    def validate_config(self) -> bool:\n        # Check if ollama is reachable? For now just return True.\n        return True\n\n    def generate(self, prompt: str, system_prompt: Optional[str] = None) -> ServiceResponse:\n        full_prompt = prompt\n        if system_prompt:\n            full_prompt = f\"System: {system_prompt}\\n\\nUser: {prompt}\"\n\n        data = {\n            \"model\": self.model_name,\n            \"prompt\": full_prompt,\n            \"stream\": False\n        }\n\n        headers = {'Content-Type': 'application/json'}\n        req = urllib.request.Request(self.base_url, data=json.dumps(data).encode('utf-8'), headers=headers)\n\n        try:\n            with urllib.request.urlopen(req) as response:\n                result = json.loads(response.read().decode('utf-8'))\n\n                try:\n                    text = result.get('response', \"\")\n\n                    # Ollama counts\n                    pt = result.get('prompt_eval_count', 0)\n                    ct = result.get('eval_count', 0)\n\n                    return ServiceResponse(\n                        text=text.strip(),\n                        prompt_tokens=pt,\n                        completion_tokens=ct,\n                        model_name=self.model_name,\n                        cost_usd=0.0, # Local is free!\n                        metadata={\"raw\": result}\n                    )", "chunk_type": "file", "line_start": 1, "line_end": 69, "language": "python", "name": "ollama.py"}, "36fde5040177_func___init__": {"id": "36fde5040177_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\models\\ollama.py", "content": "    def __init__(self, api_key: Optional[str] = None, model_name: str = \"llama3\", base_url: str = \"http://localhost:11434/api/generate\"):\n        self.api_key = api_key # Usually none for local\n        self.model_name = model_name\n        self.base_url = base_url", "chunk_type": "function", "line_start": 17, "line_end": 20, "language": "python", "name": "__init__"}, "36fde5040177_func_validate_config": {"id": "36fde5040177_func_validate_config", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\models\\ollama.py", "content": "    def validate_config(self) -> bool:\n        # Check if ollama is reachable? For now just return True.\n        return True", "chunk_type": "function", "line_start": 22, "line_end": 24, "language": "python", "name": "validate_config"}, "36fde5040177_func_generate": {"id": "36fde5040177_func_generate", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\models\\ollama.py", "content": "    def generate(self, prompt: str, system_prompt: Optional[str] = None) -> ServiceResponse:\n        full_prompt = prompt\n        if system_prompt:\n            full_prompt = f\"System: {system_prompt}\\n\\nUser: {prompt}\"\n\n        data = {\n            \"model\": self.model_name,\n            \"prompt\": full_prompt,\n            \"stream\": False\n        }\n\n        headers = {'Content-Type': 'application/json'}\n        req = urllib.request.Request(self.base_url, data=json.dumps(data).encode('utf-8'), headers=headers)\n\n        try:\n            with urllib.request.urlopen(req) as response:\n                result = json.loads(response.read().decode('utf-8'))\n\n                try:\n                    text = result.get('response', \"\")\n\n                    # Ollama counts\n                    pt = result.get('prompt_eval_count', 0)\n                    ct = result.get('eval_count', 0)\n\n                    return ServiceResponse(\n                        text=text.strip(),\n                        prompt_to", "chunk_type": "function", "line_start": 26, "line_end": 68, "language": "python", "name": "generate"}, "36fde5040177_class_OllamaService": {"id": "36fde5040177_class_OllamaService", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\models\\ollama.py", "content": "class OllamaService(BaseService):\n    \"\"\"\n    Ollama Service for local inference (zero-dependency).\n    \"\"\"\n    def __init__(self, api_key: Optional[str] = None, model_name: str = \"llama3\", base_url: str = \"http://localhost:11434/api/generate\"):\n        self.api_key = api_key # Usually none for local\n        self.model_name = model_name\n        self.base_url = base_url\n\n    def validate_config(self) -> bool:\n        # Check if ollama is reachable? For now just return True.\n        return True\n\n    def generate(self, prompt: str, system_prompt: Optional[str] = None) -> ServiceResponse:\n        full_prompt = prompt\n        if system_prompt:\n            full_prompt = f\"System: {system_prompt}\\n\\nUser: {prompt}\"\n\n        data = {\n            \"model\": self.model_name,\n            \"prompt\": full_prompt,\n            \"stream\": False\n        }\n\n        headers = {'Content-Type': 'application/json'}\n        req = urllib.request.Request(self.base_url, data=json.dumps(data).encode('utf-8'), header", "chunk_type": "class", "line_start": 13, "line_end": 68, "language": "python", "name": "OllamaService"}, "2742a1f3a7ac_file": {"id": "2742a1f3a7ac_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\models\\openai.py", "content": "from typing import Optional, TYPE_CHECKING, Dict, Any, List\nimport json\nimport logging\nimport os\nimport urllib.error\nimport urllib.request\n\nfrom .base import BaseService, ServiceResponse\nfrom __future__ import annotations\n\nlogger = logging.getLogger(\"FireflyOpenAIService\")\n\nclass OpenAIService(BaseService):\n    \"\"\"\n    OpenAI Service using standard library (zero-dependency).\n    \"\"\"\n    BASE_URL = \"https://api.openai.com/v1/chat/completions\"\n    EMBED_URL = \"https://api.openai.com/v1/embeddings\"\n\n    def __init__(self, api_key: Optional[str] = None, model_name: str = \"gpt-4o-mini\"):\n        self.api_key = api_key or os.environ.get(\"OPENAI_API_KEY\")\n        self.model_name = model_name\n\n    def validate_config(self) -> bool:\n        return bool(self.api_key)\n\n    def generate(self, prompt: str, system_prompt: Optional[str] = None) -> ServiceResponse:\n        if not self.validate_config():\n            raise ValueError(\"OpenAI API Key not found. Set OPENAI_API_KEY environment variable.\")\n\n        # Construct payload\n        messages = []\n        if system_prompt:\n            messages.append({\"role\": \"system\", \"content\": system_prompt})\n\n        messages.append({\"role\": \"user\", \"content\": prompt})\n\n        data = {\n            \"model\": self.model_name,\n            \"messages\": messages,\n            \"temperature\": 0.7\n        }\n\n        headers = {\n            'Content-Type': 'application/json',\n            'Authorization': f'Bearer {self.api_key}'\n        }\n\n        req = urllib.request.Request(self.BASE_URL, data=json.dumps(data).encode('utf-8'), headers=headers)\n\n        try:\n            with urllib.request.urlopen(req) as response:\n                result = json.loads(response.read().decode('utf-8'))\n\n                try:\n                    text = result['choices'][0]['message']['content']\n                    usage = result.get('usage', {})\n                    pt = usage.get('prompt_tokens', 0)\n                    ct = usage.get('completion_tokens', 0)\n\n              ", "chunk_type": "file", "line_start": 1, "line_end": 108, "language": "python", "name": "openai.py"}, "2742a1f3a7ac_func___init__": {"id": "2742a1f3a7ac_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\models\\openai.py", "content": "    def __init__(self, api_key: Optional[str] = None, model_name: str = \"gpt-4o-mini\"):\n        self.api_key = api_key or os.environ.get(\"OPENAI_API_KEY\")\n        self.model_name = model_name", "chunk_type": "function", "line_start": 20, "line_end": 22, "language": "python", "name": "__init__"}, "2742a1f3a7ac_func_validate_config": {"id": "2742a1f3a7ac_func_validate_config", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\models\\openai.py", "content": "    def validate_config(self) -> bool:\n        return bool(self.api_key)", "chunk_type": "function", "line_start": 24, "line_end": 25, "language": "python", "name": "validate_config"}, "2742a1f3a7ac_func_generate": {"id": "2742a1f3a7ac_func_generate", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\models\\openai.py", "content": "    def generate(self, prompt: str, system_prompt: Optional[str] = None) -> ServiceResponse:\n        if not self.validate_config():\n            raise ValueError(\"OpenAI API Key not found. Set OPENAI_API_KEY environment variable.\")\n\n        # Construct payload\n        messages = []\n        if system_prompt:\n            messages.append({\"role\": \"system\", \"content\": system_prompt})\n\n        messages.append({\"role\": \"user\", \"content\": prompt})\n\n        data = {\n            \"model\": self.model_name,\n            \"messages\": messages,\n            \"temperature\": 0.7\n        }\n\n        headers = {\n            'Content-Type': 'application/json',\n            'Authorization': f'Bearer {self.api_key}'\n        }\n\n        req = urllib.request.Request(self.BASE_URL, data=json.dumps(data).encode('utf-8'), headers=headers)\n\n        try:\n            with urllib.request.urlopen(req) as response:\n                result = json.loads(response.read().decode('utf-8'))\n\n                try:\n                    ", "chunk_type": "function", "line_start": 27, "line_end": 82, "language": "python", "name": "generate"}, "2742a1f3a7ac_func_embed": {"id": "2742a1f3a7ac_func_embed", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\models\\openai.py", "content": "    def embed(self, text: str) -> List[float]:\n        \"\"\"Generate embedding using OpenAI's embeddings API.\"\"\"\n        if not self.validate_config():\n            raise ValueError(\"OpenAI API Key not found.\")\n\n        data = {\n            \"model\": \"text-embedding-3-small\",\n            \"input\": text\n        }\n\n        headers = {\n            'Content-Type': 'application/json',\n            'Authorization': f'Bearer {self.api_key}'\n        }\n\n        req = urllib.request.Request(self.EMBED_URL, data=json.dumps(data).encode('utf-8'), headers=headers)\n\n        try:\n            with urllib.request.urlopen(req) as response:\n                result = json.loads(response.read().decode('utf-8'))\n                return result['data'][0]['embedding']\n        except Exception as e:\n            logger.error(f\"OpenAI Embed Error: {e}\")\n            raise", "chunk_type": "function", "line_start": 84, "line_end": 107, "language": "python", "name": "embed"}, "2742a1f3a7ac_class_OpenAIService": {"id": "2742a1f3a7ac_class_OpenAIService", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\models\\openai.py", "content": "class OpenAIService(BaseService):\n    \"\"\"\n    OpenAI Service using standard library (zero-dependency).\n    \"\"\"\n    BASE_URL = \"https://api.openai.com/v1/chat/completions\"\n    EMBED_URL = \"https://api.openai.com/v1/embeddings\"\n\n    def __init__(self, api_key: Optional[str] = None, model_name: str = \"gpt-4o-mini\"):\n        self.api_key = api_key or os.environ.get(\"OPENAI_API_KEY\")\n        self.model_name = model_name\n\n    def validate_config(self) -> bool:\n        return bool(self.api_key)\n\n    def generate(self, prompt: str, system_prompt: Optional[str] = None) -> ServiceResponse:\n        if not self.validate_config():\n            raise ValueError(\"OpenAI API Key not found. Set OPENAI_API_KEY environment variable.\")\n\n        # Construct payload\n        messages = []\n        if system_prompt:\n            messages.append({\"role\": \"system\", \"content\": system_prompt})\n\n        messages.append({\"role\": \"user\", \"content\": prompt})\n\n        data = {\n            \"model\": self.model_name,\n      ", "chunk_type": "class", "line_start": 13, "line_end": 107, "language": "python", "name": "OpenAIService"}, "6bee648eb91c_file": {"id": "6bee648eb91c_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\models\\open_connector.py", "content": "from typing import Optional, TYPE_CHECKING, Dict, Any\nimport json\nimport logging\nimport os\nimport urllib.error\nimport urllib.request\n\nfrom .base import BaseService, ServiceResponse\nfrom __future__ import annotations\n\nlogger = logging.getLogger(\"FireflyOpenRouterService\")\n\nclass OpenRouterService(BaseService):\n    \"\"\"\n    OpenRouter Service using standard library (zero-dependency).\n    \"\"\"\n    BASE_URL = \"https://openrouter.ai/api/v1/chat/completions\"\n\n    def __init__(self, api_key: Optional[str] = None, model_name: str = \"anthropic/claude-3.5-sonnet\"):\n        self.api_key = api_key or os.environ.get(\"OPENROUTER_API_KEY\")\n        self.model_name = model_name\n\n    def validate_config(self) -> bool:\n        return bool(self.api_key)\n\n    def generate(self, prompt: str, system_prompt: Optional[str] = None) -> ServiceResponse:\n        if not self.validate_config():\n            raise ValueError(\"OpenRouter API Key not found. Set OPENROUTER_API_KEY environment variable.\")\n\n        # Construct payload\n        messages = []\n        if system_prompt:\n            messages.append({\"role\": \"system\", \"content\": system_prompt})\n        messages.append({\"role\": \"user\", \"content\": prompt})\n\n        data = {\n            \"model\": self.model_name,\n            \"messages\": messages,\n            \"top_p\": 1,\n            \"temperature\": 0.7\n        }\n\n        headers = {\n            'Content-Type': 'application/json',\n            'Authorization': f'Bearer {self.api_key}',\n            'HTTP-Referer': 'https://github.com/FatStinkyPanda/Project-Firefly',\n            'X-Title': 'Firefly Agent Manager'\n        }\n\n        req = urllib.request.Request(self.BASE_URL, data=json.dumps(data).encode('utf-8'), headers=headers)\n\n        try:\n            with urllib.request.urlopen(req) as response:\n                result = json.loads(response.read().decode('utf-8'))\n\n                try:\n                    text = result['choices'][0]['message']['content']\n                    usage = result.get('usage',", "chunk_type": "file", "line_start": 1, "line_end": 84, "language": "python", "name": "open_connector.py"}, "6bee648eb91c_func___init__": {"id": "6bee648eb91c_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\models\\open_connector.py", "content": "    def __init__(self, api_key: Optional[str] = None, model_name: str = \"anthropic/claude-3.5-sonnet\"):\n        self.api_key = api_key or os.environ.get(\"OPENROUTER_API_KEY\")\n        self.model_name = model_name", "chunk_type": "function", "line_start": 19, "line_end": 21, "language": "python", "name": "__init__"}, "6bee648eb91c_func_validate_config": {"id": "6bee648eb91c_func_validate_config", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\models\\open_connector.py", "content": "    def validate_config(self) -> bool:\n        return bool(self.api_key)", "chunk_type": "function", "line_start": 23, "line_end": 24, "language": "python", "name": "validate_config"}, "6bee648eb91c_func_generate": {"id": "6bee648eb91c_func_generate", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\models\\open_connector.py", "content": "    def generate(self, prompt: str, system_prompt: Optional[str] = None) -> ServiceResponse:\n        if not self.validate_config():\n            raise ValueError(\"OpenRouter API Key not found. Set OPENROUTER_API_KEY environment variable.\")\n\n        # Construct payload\n        messages = []\n        if system_prompt:\n            messages.append({\"role\": \"system\", \"content\": system_prompt})\n        messages.append({\"role\": \"user\", \"content\": prompt})\n\n        data = {\n            \"model\": self.model_name,\n            \"messages\": messages,\n            \"top_p\": 1,\n            \"temperature\": 0.7\n        }\n\n        headers = {\n            'Content-Type': 'application/json',\n            'Authorization': f'Bearer {self.api_key}',\n            'HTTP-Referer': 'https://github.com/FatStinkyPanda/Project-Firefly',\n            'X-Title': 'Firefly Agent Manager'\n        }\n\n        req = urllib.request.Request(self.BASE_URL, data=json.dumps(data).encode('utf-8'), headers=headers)\n\n        try:\n         ", "chunk_type": "function", "line_start": 26, "line_end": 83, "language": "python", "name": "generate"}, "6bee648eb91c_class_OpenRouterService": {"id": "6bee648eb91c_class_OpenRouterService", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\models\\open_connector.py", "content": "class OpenRouterService(BaseService):\n    \"\"\"\n    OpenRouter Service using standard library (zero-dependency).\n    \"\"\"\n    BASE_URL = \"https://openrouter.ai/api/v1/chat/completions\"\n\n    def __init__(self, api_key: Optional[str] = None, model_name: str = \"anthropic/claude-3.5-sonnet\"):\n        self.api_key = api_key or os.environ.get(\"OPENROUTER_API_KEY\")\n        self.model_name = model_name\n\n    def validate_config(self) -> bool:\n        return bool(self.api_key)\n\n    def generate(self, prompt: str, system_prompt: Optional[str] = None) -> ServiceResponse:\n        if not self.validate_config():\n            raise ValueError(\"OpenRouter API Key not found. Set OPENROUTER_API_KEY environment variable.\")\n\n        # Construct payload\n        messages = []\n        if system_prompt:\n            messages.append({\"role\": \"system\", \"content\": system_prompt})\n        messages.append({\"role\": \"user\", \"content\": prompt})\n\n        data = {\n            \"model\": self.model_name,\n            \"messages\":", "chunk_type": "class", "line_start": 13, "line_end": 83, "language": "python", "name": "OpenRouterService"}, "d6b6c827d6bb_file": {"id": "d6b6c827d6bb_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\models\\tag.py", "content": "from dataclasses import dataclass, field\nfrom typing import List, Dict, Any\n\n@dataclass\nclass TagResponse:\n    \"\"\"\n    Structured container for parsed tags.\n    \"\"\"\n    thoughts: List[str] = field(default_factory=list)\n    commands: List[str] = field(default_factory=list)\n    messages: List[str] = field(default_factory=list)\n    status_updates: List[str] = field(default_factory=list)\n    calls: List[Dict[str, Any]] = field(default_factory=list)\n    raw_text: str = \"\"\n\n    def has_actions(self) -> bool:\n        return len(self.commands) > 0 or len(self.calls) > 0\n", "chunk_type": "file", "line_start": 1, "line_end": 18, "language": "python", "name": "tag.py"}, "d6b6c827d6bb_func_has_actions": {"id": "d6b6c827d6bb_func_has_actions", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\models\\tag.py", "content": "    def has_actions(self) -> bool:\n        return len(self.commands) > 0 or len(self.calls) > 0", "chunk_type": "function", "line_start": 16, "line_end": 17, "language": "python", "name": "has_actions"}, "d6b6c827d6bb_class_TagResponse": {"id": "d6b6c827d6bb_class_TagResponse", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\models\\tag.py", "content": "class TagResponse:\n    \"\"\"\n    Structured container for parsed tags.\n    \"\"\"\n    thoughts: List[str] = field(default_factory=list)\n    commands: List[str] = field(default_factory=list)\n    messages: List[str] = field(default_factory=list)\n    status_updates: List[str] = field(default_factory=list)\n    calls: List[Dict[str, Any]] = field(default_factory=list)\n    raw_text: str = \"\"\n\n    def has_actions(self) -> bool:\n        return len(self.commands) > 0 or len(self.calls) > 0", "chunk_type": "class", "line_start": 5, "line_end": 17, "language": "python", "name": "TagResponse"}, "56ecfb0b8a10_file": {"id": "56ecfb0b8a10_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\models\\__init__.py", "content": "\"\"\"\nUniversal Model Client package.\nContains providers for various AI models and the central manager for orchestration.\n\"\"\"\n", "chunk_type": "file", "line_start": 1, "line_end": 5, "language": "python", "name": "__init__.py"}, "0ebdc708fba8_file": {"id": "0ebdc708fba8_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\triggers\\email.py", "content": "from email.mime.text import MIMEText\nfrom typing import Optional, Dict, Any\nimport email\nimport logging\nimport os\nimport threading\nimport time\n\nimport imaplib\nimport smtplib\n\nlogger = logging.getLogger(\"FireflyEmailService\")\n\nclass EmailService:\n    \"\"\"\n    Service to handle Email (IMAP/SMTP) interactions.\n    Polls for new emails and sends responses.\n    \"\"\"\n    def __init__(self, event_bus, imap_host: Optional[str] = None, smtp_host: Optional[str] = None):\n        self.event_bus = event_bus\n        self.imap_user = os.environ.get(\"EMAIL_USER\")\n        self.imap_pass = os.environ.get(\"EMAIL_PASS\")\n        self.imap_host = imap_host or os.environ.get(\"IMAP_HOST\", \"imap.gmail.com\")\n        self.smtp_host = smtp_host or os.environ.get(\"SMTP_HOST\", \"smtp.gmail.com\")\n        self.imap_port = int(os.environ.get(\"IMAP_PORT\", 993))\n        self.smtp_port = int(os.environ.get(\"SMTP_PORT\", 587))\n\n        self.is_running = False\n        self.polling_thread = None\n\n        # Subscribe to outgoing messages to send them back via Email\n        self.event_bus.subscribe(\"email_output\", self.handle_outgoing_message)\n\n    def start(self):\n        \"\"\"Start the polling loop in a background thread.\"\"\"\n        if not self.imap_user or not self.imap_pass:\n            logger.warning(\"EMAIL_USER or EMAIL_PASS not set. EmailService will not run.\")\n            return\n\n        self.is_running = True\n        self.polling_thread = threading.Thread(target=self._poll_loop, daemon=True)\n        self.polling_thread.start()\n        logger.info(f\"EmailService started polling {self.imap_host}\")\n\n    def stop(self):\n        \"\"\"Stop the polling loop.\"\"\"\n        self.is_running = False\n        if self.polling_thread:\n            self.polling_thread.join(timeout=1.0)\n        logger.info(\"EmailService stopped.\")\n\n    def _poll_loop(self):\n        \"\"\"Internal loop to check for updates.\"\"\"\n        while self.is_running:\n            try:\n                self._check_emails()\n            except Exception as e:\n ", "chunk_type": "file", "line_start": 1, "line_end": 141, "language": "python", "name": "email.py"}, "0ebdc708fba8_func___init__": {"id": "0ebdc708fba8_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\triggers\\email.py", "content": "    def __init__(self, event_bus, imap_host: Optional[str] = None, smtp_host: Optional[str] = None):\n        self.event_bus = event_bus\n        self.imap_user = os.environ.get(\"EMAIL_USER\")\n        self.imap_pass = os.environ.get(\"EMAIL_PASS\")\n        self.imap_host = imap_host or os.environ.get(\"IMAP_HOST\", \"imap.gmail.com\")\n        self.smtp_host = smtp_host or os.environ.get(\"SMTP_HOST\", \"smtp.gmail.com\")\n        self.imap_port = int(os.environ.get(\"IMAP_PORT\", 993))\n        self.smtp_port = int(os.environ.get(\"SMTP_PORT\", 587))\n\n        self.is_running = False\n        self.polling_thread = None\n\n        # Subscribe to outgoing messages to send them back via Email\n        self.event_bus.subscribe(\"email_output\", self.handle_outgoing_message)", "chunk_type": "function", "line_start": 19, "line_end": 32, "language": "python", "name": "__init__"}, "0ebdc708fba8_func_start": {"id": "0ebdc708fba8_func_start", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\triggers\\email.py", "content": "    def start(self):\n        \"\"\"Start the polling loop in a background thread.\"\"\"\n        if not self.imap_user or not self.imap_pass:\n            logger.warning(\"EMAIL_USER or EMAIL_PASS not set. EmailService will not run.\")\n            return\n\n        self.is_running = True\n        self.polling_thread = threading.Thread(target=self._poll_loop, daemon=True)\n        self.polling_thread.start()\n        logger.info(f\"EmailService started polling {self.imap_host}\")", "chunk_type": "function", "line_start": 34, "line_end": 43, "language": "python", "name": "start"}, "0ebdc708fba8_func_stop": {"id": "0ebdc708fba8_func_stop", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\triggers\\email.py", "content": "    def stop(self):\n        \"\"\"Stop the polling loop.\"\"\"\n        self.is_running = False\n        if self.polling_thread:\n            self.polling_thread.join(timeout=1.0)\n        logger.info(\"EmailService stopped.\")", "chunk_type": "function", "line_start": 45, "line_end": 50, "language": "python", "name": "stop"}, "0ebdc708fba8_func__poll_loop": {"id": "0ebdc708fba8_func__poll_loop", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\triggers\\email.py", "content": "    def _poll_loop(self):\n        \"\"\"Internal loop to check for updates.\"\"\"\n        while self.is_running:\n            try:\n                self._check_emails()\n            except Exception as e:\n                logger.error(f\"Error in Email polling loop: {e}\")\n                time.sleep(10) # Backoff on error\n\n            time.sleep(30) # Poll interval for emails (less aggressive than telegram)", "chunk_type": "function", "line_start": 52, "line_end": 61, "language": "python", "name": "_poll_loop"}, "0ebdc708fba8_func__check_emails": {"id": "0ebdc708fba8_func__check_emails", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\triggers\\email.py", "content": "    def _check_emails(self):\n        \"\"\"Connect to IMAP and check for UNSEEN messages.\"\"\"\n        try:\n            mail = imaplib.IMAP4_SSL(self.imap_host, self.imap_port)\n            mail.login(self.imap_user, self.imap_pass)\n            mail.select(\"inbox\")\n\n            # Search for unseen messages\n            status, response = mail.search(None, 'UNSEEN')\n            if status != 'OK':\n                return\n\n            for num in response[0].split():\n                status, data = mail.fetch(num, '(RFC822)')\n                if status != 'OK':\n                    continue\n\n                raw_email = data[0][1]\n                msg = email.message_from_bytes(raw_email)\n\n                subject = msg.get(\"Subject\", \"\")\n                from_addr = msg.get(\"From\", \"\")\n\n                # Check for Firefly prefix or specific format\n                if \"FIREFLY\" in subject.upper():\n                    body = self._get_email_body(msg)\n                    logger.info(f\"Received Firefly Email", "chunk_type": "function", "line_start": 63, "line_end": 101, "language": "python", "name": "_check_emails"}, "0ebdc708fba8_func__get_email_body": {"id": "0ebdc708fba8_func__get_email_body", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\triggers\\email.py", "content": "    def _get_email_body(self, msg):\n        \"\"\"Extract body text from email message.\"\"\"\n        if msg.is_multipart():\n            for part in msg.walk():\n                if part.get_content_type() == \"text/plain\":\n                    return part.get_payload(decode=True).decode()\n        else:\n            return msg.get_payload(decode=True).decode()\n        return \"\"", "chunk_type": "function", "line_start": 103, "line_end": 111, "language": "python", "name": "_get_email_body"}, "0ebdc708fba8_func_handle_outgoing_message": {"id": "0ebdc708fba8_func_handle_outgoing_message", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\triggers\\email.py", "content": "    def handle_outgoing_message(self, event_type: str, payload: Dict[str, Any]):\n        \"\"\"Handle 'email_output' events -> Send email response.\"\"\"\n        to_addr = payload.get(\"to\")\n        text = payload.get(\"text\")\n        subject = payload.get(\"subject\", \"Firefly Response\")\n\n        if to_addr and text:\n            self.send_email(to_addr, subject, text)", "chunk_type": "function", "line_start": 113, "line_end": 120, "language": "python", "name": "handle_outgoing_message"}, "0ebdc708fba8_func_send_email": {"id": "0ebdc708fba8_func_send_email", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\triggers\\email.py", "content": "    def send_email(self, to_addr: str, subject: str, text: str):\n        \"\"\"Send an email using SMTP.\"\"\"\n        if not self.imap_user or not self.imap_pass:\n            return\n\n        msg = MIMEText(text)\n        msg['Subject'] = subject\n        msg['From'] = self.imap_user\n        msg['To'] = to_addr\n\n        try:\n            server = smtplib.SMTP(self.smtp_host, self.smtp_port)\n            server.starttls()\n            server.login(self.imap_user, self.imap_pass)\n            server.send_message(msg)\n            server.quit()\n            logger.info(f\"Email sent to {to_addr}\")\n        except Exception as e:\n            logger.error(f\"Failed to send Email: {e}\")", "chunk_type": "function", "line_start": 122, "line_end": 140, "language": "python", "name": "send_email"}, "0ebdc708fba8_class_EmailService": {"id": "0ebdc708fba8_class_EmailService", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\triggers\\email.py", "content": "class EmailService:\n    \"\"\"\n    Service to handle Email (IMAP/SMTP) interactions.\n    Polls for new emails and sends responses.\n    \"\"\"\n    def __init__(self, event_bus, imap_host: Optional[str] = None, smtp_host: Optional[str] = None):\n        self.event_bus = event_bus\n        self.imap_user = os.environ.get(\"EMAIL_USER\")\n        self.imap_pass = os.environ.get(\"EMAIL_PASS\")\n        self.imap_host = imap_host or os.environ.get(\"IMAP_HOST\", \"imap.gmail.com\")\n        self.smtp_host = smtp_host or os.environ.get(\"SMTP_HOST\", \"smtp.gmail.com\")\n        self.imap_port = int(os.environ.get(\"IMAP_PORT\", 993))\n        self.smtp_port = int(os.environ.get(\"SMTP_PORT\", 587))\n\n        self.is_running = False\n        self.polling_thread = None\n\n        # Subscribe to outgoing messages to send them back via Email\n        self.event_bus.subscribe(\"email_output\", self.handle_outgoing_message)\n\n    def start(self):\n        \"\"\"Start the polling loop in a background thread.\"\"\"\n        if not self.imap_u", "chunk_type": "class", "line_start": 14, "line_end": 140, "language": "python", "name": "EmailService"}, "9d0a051d93aa_file": {"id": "9d0a051d93aa_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\triggers\\ide_control.py", "content": "from typing import Dict, Any\nimport json\nimport logging\nimport sys\nimport threading\n\nlogger = logging.getLogger(\"FireflyIDEControl\")\n\nclass IDEControlService:\n    \"\"\"\n    Service that listens to stdin for JSON commands from the VS Code main process.\n    Enables bidirectional communication with the IDE UI.\n    \"\"\"\n    def __init__(self, event_bus):\n        self.event_bus = event_bus\n        self.running = False\n        self.thread = None\n\n    def start(self):\n        \"\"\"Start the stdin listener thread.\"\"\"\n        self.running = True\n        self.thread = threading.Thread(target=self._listen_loop, name=\"IDEControlListener\")\n        self.thread.daemon = True\n        self.thread.start()\n        logger.info(\"IDE Control Service started (listening on stdin).\")\n\n    def _listen_loop(self):\n        \"\"\"Continuously read lines from stdin and process as JSON commands.\"\"\"\n        while self.running:\n            try:\n                line = sys.stdin.readline()\n                if not line:\n                    break\n\n                line = line.strip()\n                if not line:\n                    continue\n\n                try:\n                    command = json.loads(line)\n                    self._process_command(command)\n                except json.JSONDecodeError:\n                    logger.warning(f\"Received non-JSON command from IDE: {line}\")\n            except Exception as e:\n                if self.running:\n                    logger.error(f\"Error in IDE control loop: {e}\")\n                break\n\n    def _process_command(self, command: Dict[str, Any]):\n        \"\"\"Route the command to the event bus.\"\"\"\n        cmd_type = command.get(\"type\")\n        if not cmd_type:\n            return\n\n        logger.debug(f\"Received command from IDE: {cmd_type}\")\n\n        # Publish to the event bus\n        # The orchestrator should listen for these\n        self.event_bus.publish(f\"ide_{cmd_type}\", command)\n\n    def stop(self):\n        \"\"\"Stop the service.\"\"\"\n        self.running = False\n", "chunk_type": "file", "line_start": 1, "line_end": 67, "language": "python", "name": "ide_control.py"}, "9d0a051d93aa_func___init__": {"id": "9d0a051d93aa_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\triggers\\ide_control.py", "content": "    def __init__(self, event_bus):\n        self.event_bus = event_bus\n        self.running = False\n        self.thread = None", "chunk_type": "function", "line_start": 14, "line_end": 17, "language": "python", "name": "__init__"}, "9d0a051d93aa_func_start": {"id": "9d0a051d93aa_func_start", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\triggers\\ide_control.py", "content": "    def start(self):\n        \"\"\"Start the stdin listener thread.\"\"\"\n        self.running = True\n        self.thread = threading.Thread(target=self._listen_loop, name=\"IDEControlListener\")\n        self.thread.daemon = True\n        self.thread.start()\n        logger.info(\"IDE Control Service started (listening on stdin).\")", "chunk_type": "function", "line_start": 19, "line_end": 25, "language": "python", "name": "start"}, "9d0a051d93aa_func__listen_loop": {"id": "9d0a051d93aa_func__listen_loop", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\triggers\\ide_control.py", "content": "    def _listen_loop(self):\n        \"\"\"Continuously read lines from stdin and process as JSON commands.\"\"\"\n        while self.running:\n            try:\n                line = sys.stdin.readline()\n                if not line:\n                    break\n\n                line = line.strip()\n                if not line:\n                    continue\n\n                try:\n                    command = json.loads(line)\n                    self._process_command(command)\n                except json.JSONDecodeError:\n                    logger.warning(f\"Received non-JSON command from IDE: {line}\")\n            except Exception as e:\n                if self.running:\n                    logger.error(f\"Error in IDE control loop: {e}\")\n                break", "chunk_type": "function", "line_start": 27, "line_end": 47, "language": "python", "name": "_listen_loop"}, "9d0a051d93aa_func__process_command": {"id": "9d0a051d93aa_func__process_command", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\triggers\\ide_control.py", "content": "    def _process_command(self, command: Dict[str, Any]):\n        \"\"\"Route the command to the event bus.\"\"\"\n        cmd_type = command.get(\"type\")\n        if not cmd_type:\n            return\n\n        logger.debug(f\"Received command from IDE: {cmd_type}\")\n\n        # Publish to the event bus\n        # The orchestrator should listen for these\n        self.event_bus.publish(f\"ide_{cmd_type}\", command)", "chunk_type": "function", "line_start": 49, "line_end": 59, "language": "python", "name": "_process_command"}, "9d0a051d93aa_func_stop": {"id": "9d0a051d93aa_func_stop", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\triggers\\ide_control.py", "content": "    def stop(self):\n        \"\"\"Stop the service.\"\"\"\n        self.running = False\n        # stdin.readline is blocking, but setting running to false will\n        # prevent further processing if it ever returns.\n        logger.info(\"IDE Control Service stopped.\")", "chunk_type": "function", "line_start": 61, "line_end": 66, "language": "python", "name": "stop"}, "9d0a051d93aa_class_IDEControlService": {"id": "9d0a051d93aa_class_IDEControlService", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\triggers\\ide_control.py", "content": "class IDEControlService:\n    \"\"\"\n    Service that listens to stdin for JSON commands from the VS Code main process.\n    Enables bidirectional communication with the IDE UI.\n    \"\"\"\n    def __init__(self, event_bus):\n        self.event_bus = event_bus\n        self.running = False\n        self.thread = None\n\n    def start(self):\n        \"\"\"Start the stdin listener thread.\"\"\"\n        self.running = True\n        self.thread = threading.Thread(target=self._listen_loop, name=\"IDEControlListener\")\n        self.thread.daemon = True\n        self.thread.start()\n        logger.info(\"IDE Control Service started (listening on stdin).\")\n\n    def _listen_loop(self):\n        \"\"\"Continuously read lines from stdin and process as JSON commands.\"\"\"\n        while self.running:\n            try:\n                line = sys.stdin.readline()\n                if not line:\n                    break\n\n                line = line.strip()\n                if not line:\n                    continue\n\n                try:\n", "chunk_type": "class", "line_start": 9, "line_end": 66, "language": "python", "name": "IDEControlService"}, "5708d92d1682_file": {"id": "5708d92d1682_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\triggers\\sms.py", "content": "from typing import Dict, Any, Optional\nimport json\nimport logging\nimport os\nimport urllib.parse\nimport urllib.request\n\nlogger = logging.getLogger(\"FireflySMSService\")\n\nclass SMSService:\n    \"\"\"\n    Service to handle SMS (Twilio/Generic Webhook) interactions.\n    Processes incoming SMS via WebhookService events and sends responses.\n    \"\"\"\n    def __init__(self, event_bus):\n        self.event_bus = event_bus\n        self.twilio_sid = os.environ.get(\"TWILIO_ACCOUNT_SID\")\n        self.twilio_auth_token = os.environ.get(\"TWILIO_AUTH_TOKEN\")\n        self.twilio_number = os.environ.get(\"TWILIO_NUMBER\")\n\n        # Subscribe to generic webhook events\n        self.event_bus.subscribe(\"webhook_event\", self.handle_incoming_webhook)\n        # Subscribe to outgoing SMS requests\n        self.event_bus.subscribe(\"sms_output\", self.handle_outgoing_message)\n\n    def handle_incoming_webhook(self, event_type: str, payload: Dict[str, Any]):\n        \"\"\"\n        Check if a webhook payload is an SMS (e.g., from Twilio).\n        Twilio sends form-encoded data, which our WebhookService might decode as a dict if it's JSON,\n        or we might need to handle raw form data.\n        \"\"\"\n        # Simple heuristic: Twilio payloads usually have 'From', 'To', and 'Body'\n        if \"Body\" in payload and \"From\" in payload:\n            text = payload.get(\"Body\")\n            from_number = payload.get(\"From\")\n\n            logger.info(f\"Received SMS from {from_number}: {text}\")\n\n            sms_payload = {\n                \"type\": \"sms\",\n                \"from\": from_number,\n                \"text\": text\n            }\n            # Publish as a dedicated sms_input for the Orchestrator\n            self.event_bus.publish(\"sms_input\", sms_payload)\n\n    def handle_outgoing_message(self, event_type: str, payload: Dict[str, Any]):\n        \"\"\"Handle 'sms_output' events -> Send SMS via Twilio.\"\"\"\n        to_number = payload.get(\"to\")\n        text = payload.get(\"text\")\n\n        if to_number and text:\n            se", "chunk_type": "file", "line_start": 1, "line_end": 92, "language": "python", "name": "sms.py"}, "5708d92d1682_func___init__": {"id": "5708d92d1682_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\triggers\\sms.py", "content": "    def __init__(self, event_bus):\n        self.event_bus = event_bus\n        self.twilio_sid = os.environ.get(\"TWILIO_ACCOUNT_SID\")\n        self.twilio_auth_token = os.environ.get(\"TWILIO_AUTH_TOKEN\")\n        self.twilio_number = os.environ.get(\"TWILIO_NUMBER\")\n\n        # Subscribe to generic webhook events\n        self.event_bus.subscribe(\"webhook_event\", self.handle_incoming_webhook)\n        # Subscribe to outgoing SMS requests\n        self.event_bus.subscribe(\"sms_output\", self.handle_outgoing_message)", "chunk_type": "function", "line_start": 15, "line_end": 24, "language": "python", "name": "__init__"}, "5708d92d1682_func_handle_incoming_webhook": {"id": "5708d92d1682_func_handle_incoming_webhook", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\triggers\\sms.py", "content": "    def handle_incoming_webhook(self, event_type: str, payload: Dict[str, Any]):\n        \"\"\"\n        Check if a webhook payload is an SMS (e.g., from Twilio).\n        Twilio sends form-encoded data, which our WebhookService might decode as a dict if it's JSON,\n        or we might need to handle raw form data.\n        \"\"\"\n        # Simple heuristic: Twilio payloads usually have 'From', 'To', and 'Body'\n        if \"Body\" in payload and \"From\" in payload:\n            text = payload.get(\"Body\")\n            from_number = payload.get(\"From\")\n\n            logger.info(f\"Received SMS from {from_number}: {text}\")\n\n            sms_payload = {\n                \"type\": \"sms\",\n                \"from\": from_number,\n                \"text\": text\n            }\n            # Publish as a dedicated sms_input for the Orchestrator\n            self.event_bus.publish(\"sms_input\", sms_payload)", "chunk_type": "function", "line_start": 26, "line_end": 45, "language": "python", "name": "handle_incoming_webhook"}, "5708d92d1682_func_handle_outgoing_message": {"id": "5708d92d1682_func_handle_outgoing_message", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\triggers\\sms.py", "content": "    def handle_outgoing_message(self, event_type: str, payload: Dict[str, Any]):\n        \"\"\"Handle 'sms_output' events -> Send SMS via Twilio.\"\"\"\n        to_number = payload.get(\"to\")\n        text = payload.get(\"text\")\n\n        if to_number and text:\n            self.send_sms(to_number, text)", "chunk_type": "function", "line_start": 47, "line_end": 53, "language": "python", "name": "handle_outgoing_message"}, "5708d92d1682_func_send_sms": {"id": "5708d92d1682_func_send_sms", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\triggers\\sms.py", "content": "    def send_sms(self, to_number: str, text: str):\n        \"\"\"Send an SMS using Twilio API (zero-dependency approach).\"\"\"\n        if not self.twilio_sid or not self.twilio_auth_token or not self.twilio_number:\n            logger.warning(\"Twilio credentials not set. SMS cannot be sent.\")\n            return\n\n        url = f\"https://api.twilio.com/2010-04-01/Accounts/{self.twilio_sid}/Messages.json\"\n\n        data = urllib.parse.urlencode({\n            \"To\": to_number,\n            \"From\": self.twilio_number,\n            \"Body\": text\n        }).encode(\"utf-8\")\n\n        # Basic Auth\n        import base64\n        auth_str = f\"{self.twilio_sid}:{self.twilio_auth_token}\"\n        encoded_auth = base64.b64encode(auth_str.encode(\"ascii\")).decode(\"ascii\")\n\n        req = urllib.request.Request(url, data=data, method=\"POST\")\n        req.add_header(\"Authorization\", f\"Basic {encoded_auth}\")\n        req.add_header(\"Content-Type\", \"application/x-www-form-urlencoded\")\n\n        try:\n            with urllib", "chunk_type": "function", "line_start": 55, "line_end": 83, "language": "python", "name": "send_sms"}, "5708d92d1682_func_start": {"id": "5708d92d1682_func_start", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\triggers\\sms.py", "content": "    def start(self):\n        \"\"\"Service startup logic.\"\"\"\n        logger.info(\"SMSService initialized and listening for webhook events.\")", "chunk_type": "function", "line_start": 85, "line_end": 87, "language": "python", "name": "start"}, "5708d92d1682_func_stop": {"id": "5708d92d1682_func_stop", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\triggers\\sms.py", "content": "    def stop(self):\n        \"\"\"Service shutdown logic.\"\"\"\n        pass", "chunk_type": "function", "line_start": 89, "line_end": 91, "language": "python", "name": "stop"}, "5708d92d1682_class_SMSService": {"id": "5708d92d1682_class_SMSService", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\triggers\\sms.py", "content": "class SMSService:\n    \"\"\"\n    Service to handle SMS (Twilio/Generic Webhook) interactions.\n    Processes incoming SMS via WebhookService events and sends responses.\n    \"\"\"\n    def __init__(self, event_bus):\n        self.event_bus = event_bus\n        self.twilio_sid = os.environ.get(\"TWILIO_ACCOUNT_SID\")\n        self.twilio_auth_token = os.environ.get(\"TWILIO_AUTH_TOKEN\")\n        self.twilio_number = os.environ.get(\"TWILIO_NUMBER\")\n\n        # Subscribe to generic webhook events\n        self.event_bus.subscribe(\"webhook_event\", self.handle_incoming_webhook)\n        # Subscribe to outgoing SMS requests\n        self.event_bus.subscribe(\"sms_output\", self.handle_outgoing_message)\n\n    def handle_incoming_webhook(self, event_type: str, payload: Dict[str, Any]):\n        \"\"\"\n        Check if a webhook payload is an SMS (e.g., from Twilio).\n        Twilio sends form-encoded data, which our WebhookService might decode as a dict if it's JSON,\n        or we might need to handle raw form data.\n   ", "chunk_type": "class", "line_start": 10, "line_end": 91, "language": "python", "name": "SMSService"}, "26e1391b9dd4_file": {"id": "26e1391b9dd4_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\triggers\\system_events.py", "content": "from pathlib import Path\nfrom threading import Thread\nfrom typing import Set\nimport logging\nimport os\nimport time\n\nlogger = logging.getLogger(\"WorkspaceMonitor\")\n\ntry:\n    from watchdog.observers import Observer\n    from watchdog.events import FileSystemEventHandler\n    HAS_WATCHDOG = True\nexcept ImportError:\n    HAS_WATCHDOG = False\n\nclass WorkspaceMonitoringService:\n    \"\"\"\n    Monitors the project workspace for file changes and system events.\n    Fires 'system_event' on the EventBus.\n    \"\"\"\n    def __init__(self, event_bus, root_path: str = \".\"):\n        self.event_bus = event_bus\n        self.root_path = Path(root_path).resolve()\n        self.is_running = False\n        self.ignored_dirs = {'.git', '.mcp', '__pycache__', 'node_modules', 'vscode'}\n        self.relevant_extensions = {'.py', '.js', '.ts', '.md', '.json', '.txt'}\n        self._thread = None\n\n    def start(self):\n        if self.is_running:\n            return\n        self.is_running = True\n\n        if HAS_WATCHDOG:\n            self._start_watchdog()\n        else:\n            self._start_polling()\n\n        logger.info(f\"Workspace Monitoring started at {self.root_path} ({'watchdog' if HAS_WATCHDOG else 'polling'} mode)\")\n\n    def stop(self):\n        self.is_running = False\n        if self._thread:\n            self._thread.join(timeout=1)\n        logger.info(\"Workspace Monitoring stopped.\")\n\n    def _start_watchdog(self):\n        class WorkspaceEventHandlerService(FileSystemEventHandler):\n            def __init__(self, service):\n                self.service = service\n\n            def on_modified(self, event):\n                if not event.is_directory:\n                    self.service._handle_change(event.src_path)\n\n            def on_created(self, event):\n                if not event.is_directory:\n                    self.service._handle_change(event.src_path)\n\n        self.observer = Observer()\n        self.observer.schedule(WorkspaceEventHandlerService(self), str(self.root_path), recursive=True)\n     ", "chunk_type": "file", "line_start": 1, "line_end": 101, "language": "python", "name": "system_events.py"}, "26e1391b9dd4_func___init__": {"id": "26e1391b9dd4_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\triggers\\system_events.py", "content": "            def __init__(self, service):\n                self.service = service", "chunk_type": "function", "line_start": 50, "line_end": 51, "language": "python", "name": "__init__"}, "26e1391b9dd4_func_start": {"id": "26e1391b9dd4_func_start", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\triggers\\system_events.py", "content": "    def start(self):\n        if self.is_running:\n            return\n        self.is_running = True\n\n        if HAS_WATCHDOG:\n            self._start_watchdog()\n        else:\n            self._start_polling()\n\n        logger.info(f\"Workspace Monitoring started at {self.root_path} ({'watchdog' if HAS_WATCHDOG else 'polling'} mode)\")", "chunk_type": "function", "line_start": 30, "line_end": 40, "language": "python", "name": "start"}, "26e1391b9dd4_func_stop": {"id": "26e1391b9dd4_func_stop", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\triggers\\system_events.py", "content": "    def stop(self):\n        self.is_running = False\n        if self._thread:\n            self._thread.join(timeout=1)\n        logger.info(\"Workspace Monitoring stopped.\")", "chunk_type": "function", "line_start": 42, "line_end": 46, "language": "python", "name": "stop"}, "26e1391b9dd4_func__start_watchdog": {"id": "26e1391b9dd4_func__start_watchdog", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\triggers\\system_events.py", "content": "    def _start_watchdog(self):\n        class WorkspaceEventHandlerService(FileSystemEventHandler):\n            def __init__(self, service):\n                self.service = service\n\n            def on_modified(self, event):\n                if not event.is_directory:\n                    self.service._handle_change(event.src_path)\n\n            def on_created(self, event):\n                if not event.is_directory:\n                    self.service._handle_change(event.src_path)\n\n        self.observer = Observer()\n        self.observer.schedule(WorkspaceEventHandlerService(self), str(self.root_path), recursive=True)\n        self.observer.start()", "chunk_type": "function", "line_start": 48, "line_end": 63, "language": "python", "name": "_start_watchdog"}, "26e1391b9dd4_func__start_polling": {"id": "26e1391b9dd4_func__start_polling", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\triggers\\system_events.py", "content": "    def _start_polling(self):\n        def poll_loop():\n            file_states = {} # path -> mtime\n            while self.is_running:\n                try:\n                    for path in self.root_path.rglob('*'):\n                        if any(part in self.ignored_dirs for part in path.parts):\n                            continue\n                        if path.suffix not in self.relevant_extensions:\n                            continue\n\n                        mtime = path.stat().st_mtime\n                        if str(path) not in file_states:\n                            file_states[str(path)] = mtime\n                        elif file_states[str(path)] != mtime:\n                            file_states[str(path)] = mtime\n                            self._handle_change(str(path))\n                except Exception as e:\n                    logger.error(f\"Polling error: {e}\")\n\n                time.sleep(2) # Poll every 2 seconds\n\n        self._thread = Thread(target=poll_loop, daemon=Tr", "chunk_type": "function", "line_start": 65, "line_end": 88, "language": "python", "name": "_start_polling"}, "26e1391b9dd4_func__handle_change": {"id": "26e1391b9dd4_func__handle_change", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\triggers\\system_events.py", "content": "    def _handle_change(self, path: str):\n        rel_path = os.path.relpath(path, self.root_path)\n        if any(part in self.ignored_dirs for part in Path(rel_path).parts):\n            return\n\n        logger.info(f\"File change detected: {rel_path}\")\n        self.event_bus.publish(\"system_event\", {\n            \"type\": \"file_change\",\n            \"path\": rel_path,\n            \"timestamp\": time.time()\n        })", "chunk_type": "function", "line_start": 90, "line_end": 100, "language": "python", "name": "_handle_change"}, "26e1391b9dd4_func_poll_loop": {"id": "26e1391b9dd4_func_poll_loop", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\triggers\\system_events.py", "content": "        def poll_loop():\n            file_states = {} # path -> mtime\n            while self.is_running:\n                try:\n                    for path in self.root_path.rglob('*'):\n                        if any(part in self.ignored_dirs for part in path.parts):\n                            continue\n                        if path.suffix not in self.relevant_extensions:\n                            continue\n\n                        mtime = path.stat().st_mtime\n                        if str(path) not in file_states:\n                            file_states[str(path)] = mtime\n                        elif file_states[str(path)] != mtime:\n                            file_states[str(path)] = mtime\n                            self._handle_change(str(path))\n                except Exception as e:\n                    logger.error(f\"Polling error: {e}\")\n\n                time.sleep(2) # Poll every 2 seconds", "chunk_type": "function", "line_start": 66, "line_end": 85, "language": "python", "name": "poll_loop"}, "26e1391b9dd4_func_on_modified": {"id": "26e1391b9dd4_func_on_modified", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\triggers\\system_events.py", "content": "            def on_modified(self, event):\n                if not event.is_directory:\n                    self.service._handle_change(event.src_path)", "chunk_type": "function", "line_start": 53, "line_end": 55, "language": "python", "name": "on_modified"}, "26e1391b9dd4_func_on_created": {"id": "26e1391b9dd4_func_on_created", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\triggers\\system_events.py", "content": "            def on_created(self, event):\n                if not event.is_directory:\n                    self.service._handle_change(event.src_path)", "chunk_type": "function", "line_start": 57, "line_end": 59, "language": "python", "name": "on_created"}, "26e1391b9dd4_class_WorkspaceMonitoringService": {"id": "26e1391b9dd4_class_WorkspaceMonitoringService", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\triggers\\system_events.py", "content": "class WorkspaceMonitoringService:\n    \"\"\"\n    Monitors the project workspace for file changes and system events.\n    Fires 'system_event' on the EventBus.\n    \"\"\"\n    def __init__(self, event_bus, root_path: str = \".\"):\n        self.event_bus = event_bus\n        self.root_path = Path(root_path).resolve()\n        self.is_running = False\n        self.ignored_dirs = {'.git', '.mcp', '__pycache__', 'node_modules', 'vscode'}\n        self.relevant_extensions = {'.py', '.js', '.ts', '.md', '.json', '.txt'}\n        self._thread = None\n\n    def start(self):\n        if self.is_running:\n            return\n        self.is_running = True\n\n        if HAS_WATCHDOG:\n            self._start_watchdog()\n        else:\n            self._start_polling()\n\n        logger.info(f\"Workspace Monitoring started at {self.root_path} ({'watchdog' if HAS_WATCHDOG else 'polling'} mode)\")\n\n    def stop(self):\n        self.is_running = False\n        if self._thread:\n            self._thread.join(timeout=1)\n        logger", "chunk_type": "class", "line_start": 17, "line_end": 100, "language": "python", "name": "WorkspaceMonitoringService"}, "26e1391b9dd4_class_WorkspaceEventHandlerService": {"id": "26e1391b9dd4_class_WorkspaceEventHandlerService", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\triggers\\system_events.py", "content": "        class WorkspaceEventHandlerService(FileSystemEventHandler):\n            def __init__(self, service):\n                self.service = service\n\n            def on_modified(self, event):\n                if not event.is_directory:\n                    self.service._handle_change(event.src_path)\n\n            def on_created(self, event):\n                if not event.is_directory:\n                    self.service._handle_change(event.src_path)", "chunk_type": "class", "line_start": 49, "line_end": 59, "language": "python", "name": "WorkspaceEventHandlerService"}, "8278127ebecf_file": {"id": "8278127ebecf_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\triggers\\telegram.py", "content": "from typing import Optional, Dict, Any\nimport json\nimport logging\nimport os\nimport threading\nimport time\nimport urllib.error\nimport urllib.parse\nimport urllib.request\n\nlogger = logging.getLogger(\"FireflyTelegramService\")\n\nclass TelegramService:\n    \"\"\"\n    Service to handle Telegram Bot API interactions.\n    Polls for updates and sends messages.\n    \"\"\"\n    BASE_URL = \"https://api.telegram.org/bot\"\n\n    def __init__(self, event_bus, token: Optional[str] = None):\n        self.event_bus = event_bus\n        self.token = token or os.environ.get(\"TELEGRAM_BOT_TOKEN\")\n        self.default_chat_id = os.environ.get(\"TELEGRAM_CHAT_ID\")\n        self.is_running = False\n        self.last_update_id = 0\n        self.polling_thread = None\n\n        # Subscribe to outgoing messages to send them back to Telegram\n        self.event_bus.subscribe(\"telegram_output\", self.handle_outgoing_message)\n\n    def start(self):\n        \"\"\"Start the polling loop in a background thread.\"\"\"\n        if not self.token:\n            logger.warning(\"TELEGRAM_BOT_TOKEN not set. TelegramService will not run.\")\n            return\n\n        self.is_running = True\n        self.polling_thread = threading.Thread(target=self._poll_loop, daemon=True)\n        self.polling_thread.start()\n        logger.info(\"TelegramService started polling.\")\n        if self.default_chat_id:\n            self.send_message(self.default_chat_id, \"\ud83d\udd25 Project-Firefly Agent Manager is now LIVE and monitoring.\")\n\n    def stop(self):\n        \"\"\"Stop the polling loop.\"\"\"\n        self.is_running = False\n        if self.polling_thread:\n            self.polling_thread.join(timeout=1.0)\n        logger.info(\"TelegramService stopped.\")\n\n    def _poll_loop(self):\n        \"\"\"Internal loop to check for updates.\"\"\"\n        while self.is_running:\n            try:\n                self._check_updates()\n            except Exception as e:\n                logger.error(f\"Error in Telegram polling loop: {e}\")\n                time.sleep(5) # Backoff on error\n\n  ", "chunk_type": "file", "line_start": 1, "line_end": 131, "language": "python", "name": "telegram.py"}, "8278127ebecf_func___init__": {"id": "8278127ebecf_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\triggers\\telegram.py", "content": "    def __init__(self, event_bus, token: Optional[str] = None):\n        self.event_bus = event_bus\n        self.token = token or os.environ.get(\"TELEGRAM_BOT_TOKEN\")\n        self.default_chat_id = os.environ.get(\"TELEGRAM_CHAT_ID\")\n        self.is_running = False\n        self.last_update_id = 0\n        self.polling_thread = None\n\n        # Subscribe to outgoing messages to send them back to Telegram\n        self.event_bus.subscribe(\"telegram_output\", self.handle_outgoing_message)", "chunk_type": "function", "line_start": 20, "line_end": 29, "language": "python", "name": "__init__"}, "8278127ebecf_func_start": {"id": "8278127ebecf_func_start", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\triggers\\telegram.py", "content": "    def start(self):\n        \"\"\"Start the polling loop in a background thread.\"\"\"\n        if not self.token:\n            logger.warning(\"TELEGRAM_BOT_TOKEN not set. TelegramService will not run.\")\n            return\n\n        self.is_running = True\n        self.polling_thread = threading.Thread(target=self._poll_loop, daemon=True)\n        self.polling_thread.start()\n        logger.info(\"TelegramService started polling.\")\n        if self.default_chat_id:\n            self.send_message(self.default_chat_id, \"\ud83d\udd25 Project-Firefly Agent Manager is now LIVE and monitoring.\")", "chunk_type": "function", "line_start": 31, "line_end": 42, "language": "python", "name": "start"}, "8278127ebecf_func_stop": {"id": "8278127ebecf_func_stop", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\triggers\\telegram.py", "content": "    def stop(self):\n        \"\"\"Stop the polling loop.\"\"\"\n        self.is_running = False\n        if self.polling_thread:\n            self.polling_thread.join(timeout=1.0)\n        logger.info(\"TelegramService stopped.\")", "chunk_type": "function", "line_start": 44, "line_end": 49, "language": "python", "name": "stop"}, "8278127ebecf_func__poll_loop": {"id": "8278127ebecf_func__poll_loop", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\triggers\\telegram.py", "content": "    def _poll_loop(self):\n        \"\"\"Internal loop to check for updates.\"\"\"\n        while self.is_running:\n            try:\n                self._check_updates()\n            except Exception as e:\n                logger.error(f\"Error in Telegram polling loop: {e}\")\n                time.sleep(5) # Backoff on error\n\n            time.sleep(1) # Poll interval", "chunk_type": "function", "line_start": 51, "line_end": 60, "language": "python", "name": "_poll_loop"}, "8278127ebecf_func__check_updates": {"id": "8278127ebecf_func__check_updates", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\triggers\\telegram.py", "content": "    def _check_updates(self):\n        \"\"\"Call getUpdates API.\"\"\"\n        url = f\"{self.BASE_URL}{self.token}/getUpdates?offset={self.last_update_id + 1}&timeout=30\"\n\n        try:\n            with urllib.request.urlopen(url) as response:\n                result = json.loads(response.read().decode('utf-8'))\n\n                if not result.get(\"ok\"):\n                    logger.error(f\"Telegram API Error: {result}\")\n                    return\n\n                updates = result.get(\"result\", [])\n                for update in updates:\n                    self.last_update_id = update[\"update_id\"]\n                    self._process_update(update)\n\n        except urllib.error.URLError as e:\n            # Network issue or timeout (normal for long polling)\n            pass", "chunk_type": "function", "line_start": 62, "line_end": 81, "language": "python", "name": "_check_updates"}, "8278127ebecf_func__process_update": {"id": "8278127ebecf_func__process_update", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\triggers\\telegram.py", "content": "    def _process_update(self, update: Dict[str, Any]):\n        \"\"\"Process a single update and publish event.\"\"\"\n        message = update.get(\"message\")\n        if not message:\n            return\n\n        chat_id = message.get(\"chat\", {}).get(\"id\")\n        text = message.get(\"text\")\n        username = message.get(\"from\", {}).get(\"username\")\n\n        if text:\n            logger.info(f\"Received Telegram message from {username}: {text}\")\n            payload = {\n                \"type\": \"message\",\n                \"chat_id\": chat_id,\n                \"text\": text,\n                \"user\": username\n            }\n            # Publish to Event Bus\n            self.event_bus.publish(\"telegram_input\", payload)", "chunk_type": "function", "line_start": 83, "line_end": 102, "language": "python", "name": "_process_update"}, "8278127ebecf_func_handle_outgoing_message": {"id": "8278127ebecf_func_handle_outgoing_message", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\triggers\\telegram.py", "content": "    def handle_outgoing_message(self, event_type: str, payload: Dict[str, Any]):\n        \"\"\"Handle 'telegram_output' events -> Send message to Telegram.\"\"\"\n        chat_id = payload.get(\"chat_id\") or self.default_chat_id\n        text = payload.get(\"text\")\n\n        if chat_id and text:\n            self.send_message(chat_id, text)", "chunk_type": "function", "line_start": 104, "line_end": 110, "language": "python", "name": "handle_outgoing_message"}, "8278127ebecf_func_send_message": {"id": "8278127ebecf_func_send_message", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\triggers\\telegram.py", "content": "    def send_message(self, chat_id: int, text: str):\n        \"\"\"Send a text message to a chat.\"\"\"\n        if not self.token:\n            return\n\n        url = f\"{self.BASE_URL}{self.token}/sendMessage\"\n        data = {\n            \"chat_id\": chat_id,\n            \"text\": text\n        }\n\n        headers = {'Content-Type': 'application/json'}\n        req = urllib.request.Request(url, data=json.dumps(data).encode('utf-8'), headers=headers)\n\n        try:\n            with urllib.request.urlopen(req) as response:\n                pass # Success\n        except Exception as e:\n            logger.error(f\"Failed to send Telegram message: {e}\")", "chunk_type": "function", "line_start": 112, "line_end": 130, "language": "python", "name": "send_message"}, "8278127ebecf_class_TelegramService": {"id": "8278127ebecf_class_TelegramService", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\triggers\\telegram.py", "content": "class TelegramService:\n    \"\"\"\n    Service to handle Telegram Bot API interactions.\n    Polls for updates and sends messages.\n    \"\"\"\n    BASE_URL = \"https://api.telegram.org/bot\"\n\n    def __init__(self, event_bus, token: Optional[str] = None):\n        self.event_bus = event_bus\n        self.token = token or os.environ.get(\"TELEGRAM_BOT_TOKEN\")\n        self.default_chat_id = os.environ.get(\"TELEGRAM_CHAT_ID\")\n        self.is_running = False\n        self.last_update_id = 0\n        self.polling_thread = None\n\n        # Subscribe to outgoing messages to send them back to Telegram\n        self.event_bus.subscribe(\"telegram_output\", self.handle_outgoing_message)\n\n    def start(self):\n        \"\"\"Start the polling loop in a background thread.\"\"\"\n        if not self.token:\n            logger.warning(\"TELEGRAM_BOT_TOKEN not set. TelegramService will not run.\")\n            return\n\n        self.is_running = True\n        self.polling_thread = threading.Thread(target=self._poll_loop, daemon=True)\n ", "chunk_type": "class", "line_start": 13, "line_end": 130, "language": "python", "name": "TelegramService"}, "bae00dfc4b33_file": {"id": "bae00dfc4b33_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\triggers\\webhook.py", "content": "from http.server import BaseHTTPRequestHandler, HTTPServer\nfrom threading import Thread\nfrom typing import Optional\nimport json\nimport logging\n\n\nlogger = logging.getLogger(\"FireflyWebhook\")\n\nclass WebhookRequestLogic(BaseHTTPRequestHandler):\n    def do_POST(self):\n        \"\"\"Handle incoming webhook POST requests.\"\"\"\n        try:\n            content_length = int(self.headers.get('Content-Length', 0))\n            post_data = self.rfile.read(content_length)\n\n            if not post_data:\n                 self.send_response(400)\n                 self.end_headers()\n                 return\n\n            payload = json.loads(post_data.decode('utf-8'))\n            logger.info(f\"Received webhook payload: {payload}\")\n\n            # Access injected event bus from the server instance\n            if hasattr(self.server, 'event_bus') and self.server.event_bus:\n                self.server.event_bus.publish(\"webhook_event\", payload)\n            else:\n                logger.error(\"EventBus not attached to Webhook Server!\")\n\n            self.send_response(200)\n            self.send_header('Content-type', 'application/json')\n            self.end_headers()\n            self.wfile.write(json.dumps({\"status\": \"received\"}).encode('utf-8'))\n\n        except Exception as e:\n            logger.error(f\"Error processing webhook: {e}\")\n            self.send_response(500)\n            self.end_headers()\n\nclass WebhookService:\n    def __init__(self, event_bus, port: int = 5000):\n        self.port = port\n        self.event_bus = event_bus\n        self.server: Optional[HTTPServer] = None\n        self.thread: Optional[Thread] = None\n\n    def start(self):\n        \"\"\"Start the webhook server in a separate thread.\"\"\"\n        self.server = HTTPServer(('0.0.0.0', self.port), WebhookRequestLogic)\n        # Inject event_bus into the server instance so the handler can access it\n        self.server.event_bus = self.event_bus\n\n        self.thread = Thread(target=self.server.serve_forever)\n        self.thread.daem", "chunk_type": "file", "line_start": 1, "line_end": 65, "language": "python", "name": "webhook.py"}, "bae00dfc4b33_func_do_POST": {"id": "bae00dfc4b33_func_do_POST", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\triggers\\webhook.py", "content": "    def do_POST(self):\n        \"\"\"Handle incoming webhook POST requests.\"\"\"\n        try:\n            content_length = int(self.headers.get('Content-Length', 0))\n            post_data = self.rfile.read(content_length)\n\n            if not post_data:\n                 self.send_response(400)\n                 self.end_headers()\n                 return\n\n            payload = json.loads(post_data.decode('utf-8'))\n            logger.info(f\"Received webhook payload: {payload}\")\n\n            # Access injected event bus from the server instance\n            if hasattr(self.server, 'event_bus') and self.server.event_bus:\n                self.server.event_bus.publish(\"webhook_event\", payload)\n            else:\n                logger.error(\"EventBus not attached to Webhook Server!\")\n\n            self.send_response(200)\n            self.send_header('Content-type', 'application/json')\n            self.end_headers()\n            self.wfile.write(json.dumps({\"status\": \"received\"}).encode('utf-8'))\n\n      ", "chunk_type": "function", "line_start": 11, "line_end": 39, "language": "python", "name": "do_POST"}, "bae00dfc4b33_func___init__": {"id": "bae00dfc4b33_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\triggers\\webhook.py", "content": "    def __init__(self, event_bus, port: int = 5000):\n        self.port = port\n        self.event_bus = event_bus\n        self.server: Optional[HTTPServer] = None\n        self.thread: Optional[Thread] = None", "chunk_type": "function", "line_start": 42, "line_end": 46, "language": "python", "name": "__init__"}, "bae00dfc4b33_func_start": {"id": "bae00dfc4b33_func_start", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\triggers\\webhook.py", "content": "    def start(self):\n        \"\"\"Start the webhook server in a separate thread.\"\"\"\n        self.server = HTTPServer(('0.0.0.0', self.port), WebhookRequestLogic)\n        # Inject event_bus into the server instance so the handler can access it\n        self.server.event_bus = self.event_bus\n\n        self.thread = Thread(target=self.server.serve_forever)\n        self.thread.daemon = True\n        self.thread.start()\n        logger.info(f\"Webhook server started on port {self.port}\")", "chunk_type": "function", "line_start": 48, "line_end": 57, "language": "python", "name": "start"}, "bae00dfc4b33_func_stop": {"id": "bae00dfc4b33_func_stop", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\triggers\\webhook.py", "content": "    def stop(self):\n        \"\"\"Stop the webhook server.\"\"\"\n        if self.server:\n            self.server.shutdown()\n            self.server.server_close()\n            logger.info(\"Webhook server stopped\")", "chunk_type": "function", "line_start": 59, "line_end": 64, "language": "python", "name": "stop"}, "bae00dfc4b33_class_WebhookRequestLogic": {"id": "bae00dfc4b33_class_WebhookRequestLogic", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\triggers\\webhook.py", "content": "class WebhookRequestLogic(BaseHTTPRequestHandler):\n    def do_POST(self):\n        \"\"\"Handle incoming webhook POST requests.\"\"\"\n        try:\n            content_length = int(self.headers.get('Content-Length', 0))\n            post_data = self.rfile.read(content_length)\n\n            if not post_data:\n                 self.send_response(400)\n                 self.end_headers()\n                 return\n\n            payload = json.loads(post_data.decode('utf-8'))\n            logger.info(f\"Received webhook payload: {payload}\")\n\n            # Access injected event bus from the server instance\n            if hasattr(self.server, 'event_bus') and self.server.event_bus:\n                self.server.event_bus.publish(\"webhook_event\", payload)\n            else:\n                logger.error(\"EventBus not attached to Webhook Server!\")\n\n            self.send_response(200)\n            self.send_header('Content-type', 'application/json')\n            self.end_headers()\n            self.wfile.write(json.dum", "chunk_type": "class", "line_start": 10, "line_end": 39, "language": "python", "name": "WebhookRequestLogic"}, "bae00dfc4b33_class_WebhookService": {"id": "bae00dfc4b33_class_WebhookService", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\agent_manager\\triggers\\webhook.py", "content": "class WebhookService:\n    def __init__(self, event_bus, port: int = 5000):\n        self.port = port\n        self.event_bus = event_bus\n        self.server: Optional[HTTPServer] = None\n        self.thread: Optional[Thread] = None\n\n    def start(self):\n        \"\"\"Start the webhook server in a separate thread.\"\"\"\n        self.server = HTTPServer(('0.0.0.0', self.port), WebhookRequestLogic)\n        # Inject event_bus into the server instance so the handler can access it\n        self.server.event_bus = self.event_bus\n\n        self.thread = Thread(target=self.server.serve_forever)\n        self.thread.daemon = True\n        self.thread.start()\n        logger.info(f\"Webhook server started on port {self.port}\")\n\n    def stop(self):\n        \"\"\"Stop the webhook server.\"\"\"\n        if self.server:\n            self.server.shutdown()\n            self.server.server_close()\n            logger.info(\"Webhook server stopped\")", "chunk_type": "class", "line_start": 41, "line_end": 64, "language": "python", "name": "WebhookService"}, "e9be3f4678e8_file": {"id": "e9be3f4678e8_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\agent_comms.py", "content": "#!/usr/bin/env python3\n\"\"\"\nMCP Agent Collaboration Layer (ACL)\nEnables secure, bidirectional communication and presence tracking between AI agents.\n\"\"\"\n\nfrom pathlib import Path\nimport json\nimport os\nimport socket\nimport sys\nimport time\n\n# Configuration - Shared with NSync\nWINDOWS_NSYNC = Path(\"C:/Users/dbiss/Desktop/Projects/_BLANK_/NSync\")\nLINUX_NSYNC = Path(\"/home/p4nd4pr0t0c01/Projects/NSync\")\n\ndef get_nsync_path() -> Path:\n    return WINDOWS_NSYNC if os.name == 'nt' else LINUX_NSYNC\n\ndef get_comms_dir() -> Path:\n    comms_dir = get_nsync_path() / \".nsync_agents\"\n    if not comms_dir.exists():\n        comms_dir.mkdir(parents=True, exist_ok=True)\n    return comms_dir\n\ndef get_mailbox_dir() -> Path:\n    mailbox = get_comms_dir() / \"messages\"\n    if not mailbox.exists():\n        mailbox.mkdir(parents=True, exist_ok=True)\n    return mailbox\n\ndef get_hostname():\n    return socket.gethostname()\n\nclass AgentPresence:\n    \"\"\"Manages local agent presence and heartbeats.\"\"\"\n    @staticmethod\n    def update(status=\"active\", task=\"monitoring\"):\n        presence_file = get_comms_dir() / f\"{get_hostname()}.json\"\n        data = {\n            \"hostname\": get_hostname(),\n            \"timestamp\": time.time(),\n            \"status\": status,\n            \"current_task\": task,\n            \"last_seen\": time.ctime()\n        }\n        with open(presence_file, \"w\") as f:\n            json.dump(data, f, indent=2)\n\n        # Trigger NSync to propagate the heartbeat\n        try:\n            mcp_py = Path(__file__).parents[1] / \"mcp.py\"\n            subprocess.run([sys.executable, str(mcp_py), \"nsync\", \"sync\"], capture_output=True)\n        except:\n            pass\n        return data\n\n    @staticmethod\n    def get_remote_status():\n        comms_dir = get_comms_dir()\n        remote_status = {}\n        for f in comms_dir.glob(\"*.json\"):\n            if f.stem != get_hostname():\n                try:\n                    with open(f, \"r\") as pf:\n                        remote_status[f.stem] = json.lo", "chunk_type": "file", "line_start": 1, "line_end": 216, "language": "python", "name": "agent_comms.py"}, "e9be3f4678e8_func_get_nsync_path": {"id": "e9be3f4678e8_func_get_nsync_path", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\agent_comms.py", "content": "def get_nsync_path() -> Path:\n    return WINDOWS_NSYNC if os.name == 'nt' else LINUX_NSYNC", "chunk_type": "function", "line_start": 18, "line_end": 19, "language": "python", "name": "get_nsync_path"}, "e9be3f4678e8_func_get_comms_dir": {"id": "e9be3f4678e8_func_get_comms_dir", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\agent_comms.py", "content": "def get_comms_dir() -> Path:\n    comms_dir = get_nsync_path() / \".nsync_agents\"\n    if not comms_dir.exists():\n        comms_dir.mkdir(parents=True, exist_ok=True)\n    return comms_dir", "chunk_type": "function", "line_start": 21, "line_end": 25, "language": "python", "name": "get_comms_dir"}, "e9be3f4678e8_func_get_mailbox_dir": {"id": "e9be3f4678e8_func_get_mailbox_dir", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\agent_comms.py", "content": "def get_mailbox_dir() -> Path:\n    mailbox = get_comms_dir() / \"messages\"\n    if not mailbox.exists():\n        mailbox.mkdir(parents=True, exist_ok=True)\n    return mailbox", "chunk_type": "function", "line_start": 27, "line_end": 31, "language": "python", "name": "get_mailbox_dir"}, "e9be3f4678e8_func_get_hostname": {"id": "e9be3f4678e8_func_get_hostname", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\agent_comms.py", "content": "def get_hostname():\n    return socket.gethostname()", "chunk_type": "function", "line_start": 33, "line_end": 34, "language": "python", "name": "get_hostname"}, "e9be3f4678e8_func_send_message": {"id": "e9be3f4678e8_func_send_message", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\agent_comms.py", "content": "def send_message(recipient: str, msg_type: str, content: dict):\n    \"\"\"Sends an encrypted-in-transit message via NSync mailbox.\"\"\"\n    mailbox = get_mailbox_dir()\n    msg_id = int(time.time() * 1000)\n    msg_file = mailbox / f\"{recipient}_{get_hostname()}_{msg_id}.json\"\n\n    payload = {\n        \"id\": msg_id,\n        \"from\": get_hostname(),\n        \"to\": recipient,\n        \"type\": msg_type,\n        \"content\": content,\n        \"timestamp\": time.time()\n    }\n\n    with open(msg_file, \"w\") as f:\n        json.dump(payload, f, indent=2)\n    print(f\"[COMMS] Message sent to {recipient}: {msg_type}\")\n\n    # Trigger NSync to propagate the message\n    try:\n        mcp_py = Path(__file__).parents[1] / \"mcp.py\"\n        subprocess.run([sys.executable, str(mcp_py), \"nsync\", \"sync\"], capture_output=True)\n    except:\n        pass\n    return msg_file", "chunk_type": "function", "line_start": 72, "line_end": 97, "language": "python", "name": "send_message"}, "e9be3f4678e8_func_listen_for_messages": {"id": "e9be3f4678e8_func_listen_for_messages", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\agent_comms.py", "content": "def listen_for_messages():\n    \"\"\"Polls for messages addressed to this host.\"\"\"\n    mailbox = get_mailbox_dir()\n    hostname = get_hostname()\n\n    messages = []\n    for f in mailbox.glob(f\"{hostname}_*.json\"):\n        try:\n            with open(f, \"r\") as mf:\n                msg = json.load(mf)\n                messages.append(msg)\n            # Mark as read/processed by deleting\n            f.unlink()\n        except Exception as e:\n            print(f\"[WARN] Failed to read message {f}: {e}\")\n\n    return messages", "chunk_type": "function", "line_start": 99, "line_end": 115, "language": "python", "name": "listen_for_messages"}, "e9be3f4678e8_func_show_status": {"id": "e9be3f4678e8_func_show_status", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\agent_comms.py", "content": "def show_status():\n    \"\"\"Displays local and remote agent status.\"\"\"\n    local = AgentPresence.update()\n    print(\"--- Local Agent Priority ---\")\n    print(f\"Host:   {local['hostname']}\")\n    print(f\"Status: {local['status']}\")\n    print(f\"Task:   {local['current_task']}\")\n    print(f\"Sync:   {local['last_seen']}\")\n\n    print(\"\\n--- Remote Agents ---\")\n    remotes = AgentPresence.get_remote_status()\n    if not remotes:\n        print(\"No remote agents detected yet.\")\n    for host, data in remotes.items():\n        age = time.time() - data['timestamp']\n        active_str = \"[ACTIVE]\" if age < 60 else \"[OFFLINE/STALE]\"\n        print(f\"Host:   {host} {active_str}\")\n        print(f\"Status: {data['status']}\")\n        print(f\"Task:   {data['current_task']}\")\n        print(f\"Last heartbeat: {int(age)}s ago\")\n        print(\"-\" * 20)", "chunk_type": "function", "line_start": 117, "line_end": 137, "language": "python", "name": "show_status"}, "e9be3f4678e8_func_show_help": {"id": "e9be3f4678e8_func_show_help", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\agent_comms.py", "content": "def show_help():\n    print(\"MCP Agent Collaboration Layer (ACL)\")\n    print(\"Usage: mcp comms <command> [args]\")\n    print(\"\\nCommands:\")\n    print(\"  status                Check local and remote agent presence\")\n    print(\"  send <host> <type> <msg> Send a message to a specific agent\")\n    print(\"  listen                Poll and display unread messages\")\n    print(\"  ping <host>           Quick verification of remote agent life\")\n    print(\"  heartbeat <status> <task> Update local presence info\")\n    print(\"  collaborate           Enter autonomous agent-to-agent team mode\")", "chunk_type": "function", "line_start": 139, "line_end": 148, "language": "python", "name": "show_help"}, "e9be3f4678e8_func_autonomous_loop": {"id": "e9be3f4678e8_func_autonomous_loop", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\agent_comms.py", "content": "def autonomous_loop():\n    \"\"\"Autonomous execution loop for AI agents.\"\"\"\n    hostname = get_hostname()\n    print(f\"[AUTONOMOUS] Agent {hostname} entered collaboration mode.\")\n    AgentPresence.update(\"active\", \"autonomous collaboration\")\n\n    try:\n        while True:\n            msgs = listen_for_messages()\n            for m in msgs:\n                print(f\"\\n[RECEIVED] From: {m['from']} | Type: {m['type']}\")\n                print(f\"Content: {m['content']}\")\n\n                # If it's a task, execute it and report back\n                if m['type'] == \"task\" or m['type'] == \"instruction\":\n                    task_text = m['content'].get('text', '')\n                    print(f\"[EXEC] Starting task: {task_text}\")\n                    # In a real scenario, the agent would use the LLM to process this.\n                    # For now, we simulate acknowledgment.\n                    send_message(m['from'], \"ack\", {\"text\": f\"Task received and processing: {task_text}\"})\n\n            time.sleep(5)", "chunk_type": "function", "line_start": 150, "line_end": 175, "language": "python", "name": "autonomous_loop"}, "e9be3f4678e8_func_main": {"id": "e9be3f4678e8_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\agent_comms.py", "content": "def main():\n    if len(sys.argv) < 2:\n        show_help()\n        return 0\n\n    cmd = sys.argv[1]\n    args = sys.argv[2:]\n\n    if cmd == \"status\":\n        show_status()\n    elif cmd == \"send\" and len(args) >= 3:\n        send_message(args[0], args[1], {\"text\": \" \".join(args[2:])})\n    elif cmd == \"listen\":\n        msgs = listen_for_messages()\n        if not msgs:\n            print(\"No new messages.\")\n        for m in msgs:\n            print(f\"\\n[FROM: {m['from']}] [TYPE: {m['type']}]\")\n            print(f\"Content: {m['content']}\")\n    elif cmd == \"ping\" and args:\n        remotes = AgentPresence.get_remote_status()\n        if args[0] in remotes:\n            age = time.time() - remotes[args[0]]['timestamp']\n            if age < 60:\n                print(f\"[OK] {args[0]} is ALIVE (Age: {int(age)}s)\")\n                return 0\n        print(f\"[FAIL] {args[0]} is UNREACHABLE or STALE\")\n        return 1\n    elif cmd == \"heartbeat\" and len(args) >= 2:\n        AgentPresence.update(args[0], args[", "chunk_type": "function", "line_start": 177, "line_end": 212, "language": "python", "name": "main"}, "e9be3f4678e8_func_update": {"id": "e9be3f4678e8_func_update", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\agent_comms.py", "content": "    def update(status=\"active\", task=\"monitoring\"):\n        presence_file = get_comms_dir() / f\"{get_hostname()}.json\"\n        data = {\n            \"hostname\": get_hostname(),\n            \"timestamp\": time.time(),\n            \"status\": status,\n            \"current_task\": task,\n            \"last_seen\": time.ctime()\n        }\n        with open(presence_file, \"w\") as f:\n            json.dump(data, f, indent=2)\n\n        # Trigger NSync to propagate the heartbeat\n        try:\n            mcp_py = Path(__file__).parents[1] / \"mcp.py\"\n            subprocess.run([sys.executable, str(mcp_py), \"nsync\", \"sync\"], capture_output=True)\n        except:\n            pass\n        return data", "chunk_type": "function", "line_start": 39, "line_end": 57, "language": "python", "name": "update"}, "e9be3f4678e8_func_get_remote_status": {"id": "e9be3f4678e8_func_get_remote_status", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\agent_comms.py", "content": "    def get_remote_status():\n        comms_dir = get_comms_dir()\n        remote_status = {}\n        for f in comms_dir.glob(\"*.json\"):\n            if f.stem != get_hostname():\n                try:\n                    with open(f, \"r\") as pf:\n                        remote_status[f.stem] = json.load(pf)\n                except:\n                    pass\n        return remote_status", "chunk_type": "function", "line_start": 60, "line_end": 70, "language": "python", "name": "get_remote_status"}, "e9be3f4678e8_class_AgentPresence": {"id": "e9be3f4678e8_class_AgentPresence", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\agent_comms.py", "content": "class AgentPresence:\n    \"\"\"Manages local agent presence and heartbeats.\"\"\"\n    @staticmethod\n    def update(status=\"active\", task=\"monitoring\"):\n        presence_file = get_comms_dir() / f\"{get_hostname()}.json\"\n        data = {\n            \"hostname\": get_hostname(),\n            \"timestamp\": time.time(),\n            \"status\": status,\n            \"current_task\": task,\n            \"last_seen\": time.ctime()\n        }\n        with open(presence_file, \"w\") as f:\n            json.dump(data, f, indent=2)\n\n        # Trigger NSync to propagate the heartbeat\n        try:\n            mcp_py = Path(__file__).parents[1] / \"mcp.py\"\n            subprocess.run([sys.executable, str(mcp_py), \"nsync\", \"sync\"], capture_output=True)\n        except:\n            pass\n        return data\n\n    @staticmethod\n    def get_remote_status():\n        comms_dir = get_comms_dir()\n        remote_status = {}\n        for f in comms_dir.glob(\"*.json\"):\n            if f.stem != get_hostname():\n                try:\n       ", "chunk_type": "class", "line_start": 36, "line_end": 70, "language": "python", "name": "AgentPresence"}, "3bb16070f006_file": {"id": "3bb16070f006_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\mcp.py", "content": "#!/usr/bin/env python3\n\"\"\"\nMCP Tools Runner\n================\nSingle entry point for all MCP AI enhancement tools.\n\nWorks correctly regardless of:\n- How it's invoked (relative path, absolute path, symlink)\n- Current working directory\n- Installation location in project\n\"\"\"\n\nfrom pathlib import Path\nimport json\nimport os\nimport sys\n\nimport importlib\n\n# =============================================================================\n# CRITICAL: Resolve the ACTUAL location of this script\n# =============================================================================\n\ndef get_package_root():\n    \"\"\"\n    Get the absolute path to the mcp-global-rules directory.\n    Handles symlinks, relative paths, and various invocation methods.\n    \"\"\"\n    # Method 1: Use __file__ (works in most cases)\n    if '__file__' in dir():\n        script_path = Path(__file__).resolve()\n        return script_path.parent\n\n    # Method 2: Use sys.argv[0] (when __file__ isn't available)\n    if sys.argv:\n        script_path = Path(sys.argv[0]).resolve()\n        if script_path.name == 'mcp.py':\n            return script_path.parent\n\n    # Method 3: Search common locations\n    cwd = Path.cwd()\n\n    # Check if mcp-global-rules is in current directory\n    if (cwd / 'mcp-global-rules' / 'mcp.py').exists():\n        return cwd / 'mcp-global-rules'\n\n    # Check if we're inside mcp-global-rules\n    if (cwd / 'mcp.py').exists() and (cwd / 'scripts').exists():\n        return cwd\n\n    # Check parent directories\n    for parent in cwd.parents:\n        if (parent / 'mcp-global-rules' / 'mcp.py').exists():\n            return parent / 'mcp-global-rules'\n\n    return None\n\n\n# Get MCP root and add to path\nMCP_ROOT = get_package_root()\n\nif MCP_ROOT is None:\n    print(\"[FAIL] Cannot find mcp-global-rules directory\")\n    print(\"Make sure you're running from a project with mcp-global-rules installed\")\n    sys.exit(1)\n\n# Add MCP root to path for imports\nif str(MCP_ROOT) not in sys.path:\n    sys.path.insert(0, str(MCP_ROOT))\n\n# Sto", "chunk_type": "file", "line_start": 1, "line_end": 252, "language": "python", "name": "mcp.py"}, "3bb16070f006_func_get_package_root": {"id": "3bb16070f006_func_get_package_root", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\mcp.py", "content": "def get_package_root():\n    \"\"\"\n    Get the absolute path to the mcp-global-rules directory.\n    Handles symlinks, relative paths, and various invocation methods.\n    \"\"\"\n    # Method 1: Use __file__ (works in most cases)\n    if '__file__' in dir():\n        script_path = Path(__file__).resolve()\n        return script_path.parent\n\n    # Method 2: Use sys.argv[0] (when __file__ isn't available)\n    if sys.argv:\n        script_path = Path(sys.argv[0]).resolve()\n        if script_path.name == 'mcp.py':\n            return script_path.parent\n\n    # Method 3: Search common locations\n    cwd = Path.cwd()\n\n    # Check if mcp-global-rules is in current directory\n    if (cwd / 'mcp-global-rules' / 'mcp.py').exists():\n        return cwd / 'mcp-global-rules'\n\n    # Check if we're inside mcp-global-rules\n    if (cwd / 'mcp.py').exists() and (cwd / 'scripts').exists():\n        return cwd\n\n    # Check parent directories\n    for parent in cwd.parents:\n        if (parent / 'mcp-global-rules' / 'mcp.py')", "chunk_type": "function", "line_start": 24, "line_end": 56, "language": "python", "name": "get_package_root"}, "3bb16070f006_func_show_help": {"id": "3bb16070f006_func_show_help", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\mcp.py", "content": "def show_help():\n    \"\"\"Show help message.\"\"\"\n    print(\"\"\"\nMCP AI Enhancement Tools (48 Commands)\n=======================================\n\nUsage: python3 mcp-global-rules/mcp.py <command> [args...]\n\nCode Quality:\n    review [path] [--strict]    Code review automation\n    docs [path] [--write]       Generate missing docstrings\n    test [path]                 Generate pytest test stubs\n    deadcode [path]             Find unused code\n    fix [path] [--safe --apply] Auto-fix issues\n\nAnalysis:\n    deps [path]                 Dependency analysis\n    profile [path]              Performance/complexity\n    security [path]             Security audit\n    errors [path]               Error handling\n    architecture [path]         Architecture validation\n\nIntelligence:\n    context \"query\" [path]      Smart context extraction\n    find \"query\" [path]         Natural language search\n    refactor [path]             Suggest refactorings\n\nIndexes:\n    index-all                   Full reindex (all 7)\n   ", "chunk_type": "function", "line_start": 75, "line_end": 137, "language": "python", "name": "show_help"}, "3bb16070f006_func_main": {"id": "3bb16070f006_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\mcp.py", "content": "def main():\n    \"\"\"Main entry point.\"\"\"\n    if len(sys.argv) < 2 or sys.argv[1] in ('help', '-h', '--help'):\n        show_help()\n        return 0\n\n    command = sys.argv[1]\n    args = sys.argv[2:]\n\n    if command not in COMMANDS:\n        print(f\"[FAIL] Unknown command: {command}\")\n        show_help()\n        return 1\n\n    module_name = COMMANDS[command]\n\n    try:\n        # Import the module\n        module = importlib.import_module(f'scripts.{module_name}')\n\n        # Update sys.argv for the module\n        sys.argv = [f'scripts/{module_name}.py'] + args\n\n        if hasattr(module, 'main'):\n            return module.main() or 0\n        else:\n            print(f\"[FAIL] Module {module_name} has no main function\")\n            return 1\n\n    except ImportError as e:\n        print(f\"[FAIL] Could not import {module_name}: {e}\")\n        print(f\"MCP_ROOT: {MCP_ROOT}\")\n        print(f\"sys.path: {sys.path[:3]}\")\n        return 1\n    except Exception as e:\n        print(f\"[FAIL] Error running {comma", "chunk_type": "function", "line_start": 209, "line_end": 247, "language": "python", "name": "main"}, "573a228f3a6c_file": {"id": "573a228f3a6c_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\model_manager.py", "content": "#!/usr/bin/env python3\n\"\"\"\nAntigravity Model Priority Manager\nManages model selection based on user preference and availability.\nPriority 1: Gemini 3 Flash\nPriority 2: Claude Opus (Latest/4.5 Thinking)\n\"\"\"\n\nfrom pathlib import Path\nimport json\nimport os\nimport sys\n\n# Configuration Path\nCONFIG_PATH = Path(\"C:/Users/dbiss/Desktop/Projects/_BLANK_/mcp-global-rules/model_preferences.json\") if os.name == 'nt' else Path(\"/home/p4nd4pr0t0c01/Projects/mcp-global-rules/model_preferences.json\")\n\nDEFAULT_PRIORITY = [\n    \"Gemini 3 Flash\",\n    \"Claude Opus (4.5 Thinking)\",\n    \"GPT-4o\"\n]\n\ndef get_preferences():\n    if CONFIG_PATH.exists():\n        with open(CONFIG_PATH, \"r\") as f:\n            return json.load(f)\n    return {\"priority\": DEFAULT_PRIORITY, \"current\": DEFAULT_PRIORITY[0]}\n\ndef save_preferences(prefs):\n    with open(CONFIG_PATH, \"w\") as f:\n        json.dump(prefs, f, indent=2)\n\ndef get_current_model():\n    prefs = get_preferences()\n    return prefs.get(\"current\", DEFAULT_PRIORITY[0])\n\ndef switch_model(reason=\"manual\"):\n    prefs = get_preferences()\n    priority = prefs.get(\"priority\", DEFAULT_PRIORITY)\n    current = prefs.get(\"current\", priority[0])\n\n    try:\n        idx = priority.index(current)\n        next_idx = (idx + 1) % len(priority)\n        prefs[\"current\"] = priority[next_idx]\n        save_preferences(prefs)\n        print(f\"[MODEL] Switched to {prefs['current']} (Reason: {reason})\")\n        return prefs[\"current\"]\n    except ValueError:\n        prefs[\"current\"] = priority[0]\n        save_preferences(prefs)\n        return priority[0]\n\ndef main():\n    if len(sys.argv) < 2:\n        print(get_current_model())\n        return 0\n\n    cmd = sys.argv[1]\n    if cmd == \"status\":\n        print(f\"Current Priority Model: {get_current_model()}\")\n    elif cmd == \"switch\":\n        reason = sys.argv[2] if len(sys.argv) > 2 else \"limit reached\"\n        switch_model(reason)\n    elif cmd == \"reset\":\n        prefs = {\"priority\": DEFAULT_PRIORITY, \"current\": DEFAULT_PRIORITY[0]}\n", "chunk_type": "file", "line_start": 1, "line_end": 73, "language": "python", "name": "model_manager.py"}, "573a228f3a6c_func_get_preferences": {"id": "573a228f3a6c_func_get_preferences", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\model_manager.py", "content": "def get_preferences():\n    if CONFIG_PATH.exists():\n        with open(CONFIG_PATH, \"r\") as f:\n            return json.load(f)\n    return {\"priority\": DEFAULT_PRIORITY, \"current\": DEFAULT_PRIORITY[0]}", "chunk_type": "function", "line_start": 23, "line_end": 27, "language": "python", "name": "get_preferences"}, "573a228f3a6c_func_save_preferences": {"id": "573a228f3a6c_func_save_preferences", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\model_manager.py", "content": "def save_preferences(prefs):\n    with open(CONFIG_PATH, \"w\") as f:\n        json.dump(prefs, f, indent=2)", "chunk_type": "function", "line_start": 29, "line_end": 31, "language": "python", "name": "save_preferences"}, "573a228f3a6c_func_get_current_model": {"id": "573a228f3a6c_func_get_current_model", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\model_manager.py", "content": "def get_current_model():\n    prefs = get_preferences()\n    return prefs.get(\"current\", DEFAULT_PRIORITY[0])", "chunk_type": "function", "line_start": 33, "line_end": 35, "language": "python", "name": "get_current_model"}, "573a228f3a6c_func_switch_model": {"id": "573a228f3a6c_func_switch_model", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\model_manager.py", "content": "def switch_model(reason=\"manual\"):\n    prefs = get_preferences()\n    priority = prefs.get(\"priority\", DEFAULT_PRIORITY)\n    current = prefs.get(\"current\", priority[0])\n\n    try:\n        idx = priority.index(current)\n        next_idx = (idx + 1) % len(priority)\n        prefs[\"current\"] = priority[next_idx]\n        save_preferences(prefs)\n        print(f\"[MODEL] Switched to {prefs['current']} (Reason: {reason})\")\n        return prefs[\"current\"]\n    except ValueError:\n        prefs[\"current\"] = priority[0]\n        save_preferences(prefs)\n        return priority[0]", "chunk_type": "function", "line_start": 37, "line_end": 52, "language": "python", "name": "switch_model"}, "573a228f3a6c_func_main": {"id": "573a228f3a6c_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\model_manager.py", "content": "def main():\n    if len(sys.argv) < 2:\n        print(get_current_model())\n        return 0\n\n    cmd = sys.argv[1]\n    if cmd == \"status\":\n        print(f\"Current Priority Model: {get_current_model()}\")\n    elif cmd == \"switch\":\n        reason = sys.argv[2] if len(sys.argv) > 2 else \"limit reached\"\n        switch_model(reason)\n    elif cmd == \"reset\":\n        prefs = {\"priority\": DEFAULT_PRIORITY, \"current\": DEFAULT_PRIORITY[0]}\n        save_preferences(prefs)\n        print(\"[MODEL] Preferences reset to defaults.\")\n    return 0", "chunk_type": "function", "line_start": 54, "line_end": 69, "language": "python", "name": "main"}, "03812a2a84e1_file": {"id": "03812a2a84e1_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\config\\loop_config.py", "content": "\"\"\"\nAuto-Dev Loop Configuration\n===========================\nWARNING: THIS FILE CONTROLS AN INFINITE AUTONOMOUS LOOP.\n\nRules:\n1. ONLY the USER is allowed to change this file.\n2. AI Agents must NEVER modify this file.\n3. If set to True, the system will trigger a new development cycle after every commit.\n\nTo stop the loop, set ENABLE_AUTO_LOOP = False manually.\n\"\"\"\n\n# START USER CONFIGURATION\nENABLE_AUTO_LOOP = True\n# END USER CONFIGURATION\n", "chunk_type": "file", "line_start": 1, "line_end": 17, "language": "python", "name": "loop_config.py"}, "4744e1052a4f_file": {"id": "4744e1052a4f_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\config\\__init__.py", "content": "\"\"\"\nConfiguration Package\n=====================\n\"\"\"\n", "chunk_type": "file", "line_start": 1, "line_end": 5, "language": "python", "name": "__init__.py"}, "bb2a1c5f8fcc_file": {"id": "bb2a1c5f8fcc_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\agent_comms.py", "content": "#!/usr/bin/env python3\n\"\"\"\nMCP Agent Collaboration Layer (ACL)\nEnables secure, bidirectional communication and presence tracking between AI agents.\n\"\"\"\n\nfrom pathlib import Path\nimport json\nimport os\nimport socket\nimport subprocess\nimport sys\nimport time\n\n# Configuration - Shared with NSync\nWINDOWS_NSYNC = Path(\"C:/Users/dbiss/Desktop/Projects/_BLANK_/NSync\")\nLINUX_NSYNC = Path(\"/home/p4nd4pr0t0c01/Projects/NSync\")\n\ndef get_nsync_path() -> Path:\n    return WINDOWS_NSYNC if os.name == 'nt' else LINUX_NSYNC\n\ndef get_comms_dir() -> Path:\n    comms_dir = get_nsync_path() / \".nsync_agents\"\n    if not comms_dir.exists():\n        comms_dir.mkdir(parents=True, exist_ok=True)\n    return comms_dir\n\ndef get_mailbox_dir() -> Path:\n    mailbox = get_comms_dir() / \"messages\"\n    if not mailbox.exists():\n        mailbox.mkdir(parents=True, exist_ok=True)\n    return mailbox\n\ndef get_telegram_inbox_dir() -> Path:\n    inbox = get_comms_dir() / \"telegram_inbox\"\n    if not inbox.exists():\n        inbox.mkdir(parents=True, exist_ok=True)\n    return inbox\n\ndef get_hostname():\n    # Allow override for specifically identifying the IDE agent session\n    identity = os.environ.get(\"AGENT_IDENTITY\")\n    if identity:\n        return identity\n    return socket.gethostname()\n\nclass AgentPresence:\n    \"\"\"Manages local agent presence and heartbeats.\"\"\"\n    @staticmethod\n    def update(status=\"active\", task=\"monitoring\"):\n        presence_file = get_comms_dir() / f\"{get_hostname()}.json\"\n        data = {\n            \"hostname\": get_hostname(),\n            \"timestamp\": time.time(),\n            \"status\": status,\n            \"current_task\": task,\n            \"last_seen\": time.ctime()\n        }\n        with open(presence_file, \"w\") as f:\n            json.dump(data, f, indent=2)\n\n        # Trigger NSync to propagate the heartbeat\n        try:\n            mcp_py = Path(__file__).parents[1] / \"mcp.py\"\n            subprocess.run([sys.executable, str(mcp_py), \"nsync\", \"sync\"], capture_output=True)\n        exc", "chunk_type": "file", "line_start": 1, "line_end": 364, "language": "python", "name": "agent_comms.py"}, "bb2a1c5f8fcc_func_get_nsync_path": {"id": "bb2a1c5f8fcc_func_get_nsync_path", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\agent_comms.py", "content": "def get_nsync_path() -> Path:\n    return WINDOWS_NSYNC if os.name == 'nt' else LINUX_NSYNC", "chunk_type": "function", "line_start": 19, "line_end": 20, "language": "python", "name": "get_nsync_path"}, "bb2a1c5f8fcc_func_get_comms_dir": {"id": "bb2a1c5f8fcc_func_get_comms_dir", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\agent_comms.py", "content": "def get_comms_dir() -> Path:\n    comms_dir = get_nsync_path() / \".nsync_agents\"\n    if not comms_dir.exists():\n        comms_dir.mkdir(parents=True, exist_ok=True)\n    return comms_dir", "chunk_type": "function", "line_start": 22, "line_end": 26, "language": "python", "name": "get_comms_dir"}, "bb2a1c5f8fcc_func_get_mailbox_dir": {"id": "bb2a1c5f8fcc_func_get_mailbox_dir", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\agent_comms.py", "content": "def get_mailbox_dir() -> Path:\n    mailbox = get_comms_dir() / \"messages\"\n    if not mailbox.exists():\n        mailbox.mkdir(parents=True, exist_ok=True)\n    return mailbox", "chunk_type": "function", "line_start": 28, "line_end": 32, "language": "python", "name": "get_mailbox_dir"}, "bb2a1c5f8fcc_func_get_telegram_inbox_dir": {"id": "bb2a1c5f8fcc_func_get_telegram_inbox_dir", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\agent_comms.py", "content": "def get_telegram_inbox_dir() -> Path:\n    inbox = get_comms_dir() / \"telegram_inbox\"\n    if not inbox.exists():\n        inbox.mkdir(parents=True, exist_ok=True)\n    return inbox", "chunk_type": "function", "line_start": 34, "line_end": 38, "language": "python", "name": "get_telegram_inbox_dir"}, "bb2a1c5f8fcc_func_get_hostname": {"id": "bb2a1c5f8fcc_func_get_hostname", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\agent_comms.py", "content": "def get_hostname():\n    # Allow override for specifically identifying the IDE agent session\n    identity = os.environ.get(\"AGENT_IDENTITY\")\n    if identity:\n        return identity\n    return socket.gethostname()", "chunk_type": "function", "line_start": 40, "line_end": 45, "language": "python", "name": "get_hostname"}, "bb2a1c5f8fcc_func_send_message": {"id": "bb2a1c5f8fcc_func_send_message", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\agent_comms.py", "content": "def send_message(recipient: str, msg_type: str, content: dict):\n    \"\"\"Sends an encrypted-in-transit message via NSync mailbox.\"\"\"\n    mailbox = get_mailbox_dir()\n    msg_id = int(time.time() * 1000)\n    msg_file = mailbox / f\"{recipient}_{get_hostname()}_{msg_id}.json\"\n\n    payload = {\n        \"id\": msg_id,\n        \"from\": get_hostname(),\n        \"to\": recipient,\n        \"type\": msg_type,\n        \"content\": content,\n        \"timestamp\": time.time()\n    }\n\n    with open(msg_file, \"w\") as f:\n        json.dump(payload, f, indent=2)\n    print(f\"[COMMS] Message sent to {recipient}: {msg_type}\")\n\n    # Trigger NSync to propagate the message\n    try:\n        mcp_py = Path(__file__).parents[1] / \"mcp.py\"\n        subprocess.run([sys.executable, str(mcp_py), \"nsync\", \"sync\"], capture_output=True)\n    except:\n        pass\n    return msg_file", "chunk_type": "function", "line_start": 83, "line_end": 108, "language": "python", "name": "send_message"}, "bb2a1c5f8fcc_func_listen_for_messages": {"id": "bb2a1c5f8fcc_func_listen_for_messages", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\agent_comms.py", "content": "def listen_for_messages():\n    \"\"\"Polls for messages addressed to this host.\"\"\"\n    mailbox = get_mailbox_dir()\n    hostname = get_hostname()\n\n    messages = []\n    for f in mailbox.glob(f\"{hostname}_*.json\"):\n        try:\n            with open(f, \"r\") as mf:\n                msg = json.load(mf)\n                messages.append(msg)\n            # Mark as read/processed by deleting\n            f.unlink()\n        except Exception as e:\n            print(f\"[WARN] Failed to read message {f}: {e}\")\n\n    return messages", "chunk_type": "function", "line_start": 110, "line_end": 126, "language": "python", "name": "listen_for_messages"}, "bb2a1c5f8fcc_func_listen_for_telegram_messages": {"id": "bb2a1c5f8fcc_func_listen_for_telegram_messages", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\agent_comms.py", "content": "def listen_for_telegram_messages():\n    \"\"\"Polls for Telegram messages. Background agents wait for Antigravity priority.\"\"\"\n    inbox = get_telegram_inbox_dir()\n    hostname = get_hostname()\n    agent_identity = os.getenv(\"AGENT_IDENTITY\", hostname)  # Use AGENT_IDENTITY if set, else hostname\n\n    messages = []\n\n    # Priority 1: Messages directly for me (based on AGENT_IDENTITY)\n    for f in inbox.glob(f\"{agent_identity}_*.json\"):\n        try:\n            with open(f, \"r\") as mf:\n                msg = json.load(mf)\n                messages.append(msg)\n            f.unlink()\n        except: pass\n\n    # Skip fallback logic if I AM Antigravity (I already checked)\n    if agent_identity.lower() == \"antigravity\":\n        return messages\n\n    # Priority 2: Fallback for Antigravity (Background Agents only)\n    # Background agents (Quasar/wizardpanda) only take Antigravity messages if stale\n    for f in inbox.glob(\"Antigravity_*.json\"):\n        try:\n            # Check how old the message is\n ", "chunk_type": "function", "line_start": 128, "line_end": 181, "language": "python", "name": "listen_for_telegram_messages"}, "bb2a1c5f8fcc_func_notify_user_telegram": {"id": "bb2a1c5f8fcc_func_notify_user_telegram", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\agent_comms.py", "content": "def notify_user_telegram(text: str):\n    \"\"\"Sends a notification back to the user via the Telegram Bridge.\"\"\"\n    # The bridge will watch this directory for outgoing alerts\n    outbox = get_comms_dir() / \"telegram_outbox\"\n    if not outbox.exists():\n        outbox.mkdir(parents=True, exist_ok=True)\n\n    msg_id = int(time.time() * 1000)\n    msg_file = outbox / f\"out_{msg_id}.json\"\n\n    with open(msg_file, \"w\") as f:\n        json.dump({\"text\": text, \"from\": get_hostname(), \"timestamp\": time.time()}, f, indent=2)\n    print(f\"[COMMS] Notification queued for Telegram: {text[:50]}...\")", "chunk_type": "function", "line_start": 183, "line_end": 195, "language": "python", "name": "notify_user_telegram"}, "bb2a1c5f8fcc_func_show_status": {"id": "bb2a1c5f8fcc_func_show_status", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\agent_comms.py", "content": "def show_status():\n    \"\"\"Displays local and remote agent status.\"\"\"\n    hostname = get_hostname()\n    presence_file = get_comms_dir() / f\"{hostname}.json\"\n    local = {}\n    if presence_file.exists():\n        with open(presence_file, \"r\") as f:\n            local = json.load(f)\n    else:\n        local = AgentPresence.update() # Create if missing\n\n    print(\"--- Local Agent Priority ---\")\n    print(f\"Host:   {local.get('hostname', hostname)}\")\n    print(f\"Status: {local.get('status', 'unknown')}\")\n    print(f\"Task:   {local.get('current_task', 'unknown')}\")\n    print(f\"Sync:   {local.get('last_seen', 'unknown')}\")\n\n    print(\"\\n--- Remote Agents ---\")\n    remotes = AgentPresence.get_remote_status()\n    if not remotes:\n        print(\"No remote agents detected yet.\")\n    for host, data in remotes.items():\n        age = time.time() - data['timestamp']\n        active_str = \"[ACTIVE]\" if age < 60 else \"[OFFLINE/STALE]\"\n        print(f\"Host:   {host} {active_str}\")\n        print(f\"Status: {da", "chunk_type": "function", "line_start": 197, "line_end": 225, "language": "python", "name": "show_status"}, "bb2a1c5f8fcc_func_show_help": {"id": "bb2a1c5f8fcc_func_show_help", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\agent_comms.py", "content": "def show_help():\n    print(\"MCP Agent Collaboration Layer (ACL)\")\n    print(\"Usage: mcp comms <command> [args]\")\n    print(\"\\nCommands:\")\n    print(\"  status                Check local and remote agent presence\")\n    print(\"  send <host> <type> <msg> Send a message to a specific agent\")\n    print(\"  listen                Poll and display unread messages\")\n    print(\"  ping <host>           Quick verification of remote agent life\")\n    print(\"  heartbeat <status> <task> Update local presence info\")\n    print(\"  collaborate           Enter autonomous agent-to-agent team mode\")", "chunk_type": "function", "line_start": 227, "line_end": 236, "language": "python", "name": "show_help"}, "bb2a1c5f8fcc_func_handle_telegram_instruction": {"id": "bb2a1c5f8fcc_func_handle_telegram_instruction", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\agent_comms.py", "content": "def handle_telegram_instruction(text):\n    \"\"\"Parses telegram text and tries to execute as an MCP command or route to Antigravity.\"\"\"\n    print(f\"[EXEC] Parsing Telegram Task: {text}\")\n\n    # Check if this is the \"Antigravity\" agent (IDE session)\n    # If so, send to Antigravity automation instead of running MCP commands\n    hostname = get_hostname().lower()\n    agent_identity = os.getenv(\"AGENT_IDENTITY\", \"\").lower()\n\n    # Route to Antigravity IDE automation if AGENT_IDENTITY is set to \"Antigravity\"\n    if agent_identity == \"antigravity\":\n        try:\n            # Import antigravity automation module\n            antigravity_path = Path(__file__).resolve().parent / \"antigravity_automation.py\"\n            if antigravity_path.exists():\n                import importlib.util\n                spec = importlib.util.spec_from_file_location(\"antigravity_automation\", antigravity_path)\n                ag_module = importlib.util.module_from_spec(spec)\n                spec.loader.exec_module(ag_m", "chunk_type": "function", "line_start": 238, "line_end": 294, "language": "python", "name": "handle_telegram_instruction"}, "bb2a1c5f8fcc_func_autonomous_loop": {"id": "bb2a1c5f8fcc_func_autonomous_loop", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\agent_comms.py", "content": "def autonomous_loop():\n    \"\"\"Autonomous execution loop for AI agents.\"\"\"\n    hostname = get_hostname()\n    print(f\"[AUTONOMOUS] Agent {hostname} entered collaboration mode.\")\n    AgentPresence.update(\"active\", \"autonomous collaboration\")\n\n    try:\n        while True:\n            msgs = listen_for_messages()\n            for m in msgs:\n                print(f\"\\n[RECEIVED] From: {m['from']} | Type: {m['type']}\")\n                if m['type'] == \"task\" or m['type'] == \"instruction\":\n                    task_text = m['content'].get('text', '')\n                    result = handle_telegram_instruction(task_text)\n                    send_message(m['from'], \"result\", {\"text\": result})\n\n            # Check for Telegram instructions\n            t_msgs = listen_for_telegram_messages()\n            for tm in t_msgs:\n                print(f\"\\n[TELEGRAM] Instruction received: {tm['text']}\")\n                result = handle_telegram_instruction(tm['text'])\n                notify_user_telegram(f\"Result f", "chunk_type": "function", "line_start": 296, "line_end": 323, "language": "python", "name": "autonomous_loop"}, "bb2a1c5f8fcc_func_main": {"id": "bb2a1c5f8fcc_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\agent_comms.py", "content": "def main():\n    if len(sys.argv) < 2:\n        show_help()\n        return 0\n\n    cmd = sys.argv[1]\n    args = sys.argv[2:]\n\n    if cmd == \"status\":\n        show_status()\n    elif cmd == \"send\" and len(args) >= 3:\n        send_message(args[0], args[1], {\"text\": \" \".join(args[2:])})\n    elif cmd == \"listen\":\n        msgs = listen_for_messages()\n        if not msgs:\n            print(\"No new messages.\")\n        for m in msgs:\n            print(f\"\\n[FROM: {m['from']}] [TYPE: {m['type']}]\")\n            print(f\"Content: {m['content']}\")\n    elif cmd == \"ping\" and args:\n        remotes = AgentPresence.get_remote_status()\n        if args[0] in remotes:\n            age = time.time() - remotes[args[0]]['timestamp']\n            if age < 60:\n                print(f\"[OK] {args[0]} is ALIVE (Age: {int(age)}s)\")\n                return 0\n        print(f\"[FAIL] {args[0]} is UNREACHABLE or STALE\")\n        return 1\n    elif cmd == \"heartbeat\" and len(args) >= 2:\n        AgentPresence.update(args[0], args[", "chunk_type": "function", "line_start": 325, "line_end": 360, "language": "python", "name": "main"}, "bb2a1c5f8fcc_func_update": {"id": "bb2a1c5f8fcc_func_update", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\agent_comms.py", "content": "    def update(status=\"active\", task=\"monitoring\"):\n        presence_file = get_comms_dir() / f\"{get_hostname()}.json\"\n        data = {\n            \"hostname\": get_hostname(),\n            \"timestamp\": time.time(),\n            \"status\": status,\n            \"current_task\": task,\n            \"last_seen\": time.ctime()\n        }\n        with open(presence_file, \"w\") as f:\n            json.dump(data, f, indent=2)\n\n        # Trigger NSync to propagate the heartbeat\n        try:\n            mcp_py = Path(__file__).parents[1] / \"mcp.py\"\n            subprocess.run([sys.executable, str(mcp_py), \"nsync\", \"sync\"], capture_output=True)\n        except:\n            pass\n        return data", "chunk_type": "function", "line_start": 50, "line_end": 68, "language": "python", "name": "update"}, "bb2a1c5f8fcc_func_get_remote_status": {"id": "bb2a1c5f8fcc_func_get_remote_status", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\agent_comms.py", "content": "    def get_remote_status():\n        comms_dir = get_comms_dir()\n        remote_status = {}\n        for f in comms_dir.glob(\"*.json\"):\n            if f.stem != get_hostname():\n                try:\n                    with open(f, \"r\") as pf:\n                        remote_status[f.stem] = json.load(pf)\n                except:\n                    pass\n        return remote_status", "chunk_type": "function", "line_start": 71, "line_end": 81, "language": "python", "name": "get_remote_status"}, "bb2a1c5f8fcc_class_AgentPresence": {"id": "bb2a1c5f8fcc_class_AgentPresence", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\agent_comms.py", "content": "class AgentPresence:\n    \"\"\"Manages local agent presence and heartbeats.\"\"\"\n    @staticmethod\n    def update(status=\"active\", task=\"monitoring\"):\n        presence_file = get_comms_dir() / f\"{get_hostname()}.json\"\n        data = {\n            \"hostname\": get_hostname(),\n            \"timestamp\": time.time(),\n            \"status\": status,\n            \"current_task\": task,\n            \"last_seen\": time.ctime()\n        }\n        with open(presence_file, \"w\") as f:\n            json.dump(data, f, indent=2)\n\n        # Trigger NSync to propagate the heartbeat\n        try:\n            mcp_py = Path(__file__).parents[1] / \"mcp.py\"\n            subprocess.run([sys.executable, str(mcp_py), \"nsync\", \"sync\"], capture_output=True)\n        except:\n            pass\n        return data\n\n    @staticmethod\n    def get_remote_status():\n        comms_dir = get_comms_dir()\n        remote_status = {}\n        for f in comms_dir.glob(\"*.json\"):\n            if f.stem != get_hostname():\n                try:\n       ", "chunk_type": "class", "line_start": 47, "line_end": 81, "language": "python", "name": "AgentPresence"}, "13a0e3c05204_file": {"id": "13a0e3c05204_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\agent_launcher.py", "content": "#!/usr/bin/env python3\n\"\"\"\nAntigravity Autonomous Agent Launcher\nEnsures the mcp comms collaborate loop stays running in the background.\nAuto-restarts on failure.\n\"\"\"\n\nfrom pathlib import Path\nimport os\nimport subprocess\nimport sys\nimport time\n\nimport signal\n\nPID_FILE = Path(\"/tmp/agent_launcher.pid\") if os.name != 'nt' else Path(os.environ.get('TEMP', 'C:/Temp')) / \"agent_launcher.pid\"\n\ndef is_already_running():\n    if PID_FILE.exists():\n        try:\n            with open(PID_FILE, \"r\") as f:\n                pid = int(f.read().strip())\n            # Check if process exists\n            if os.name != 'nt':\n                os.kill(pid, 0)\n            else:\n                # Windows check\n                subprocess.run([\"tasklist\", \"/FI\", f\"PID eq {pid}\"], capture_output=True, check=True)\n            return True\n        except:\n            PID_FILE.unlink(missing_ok=True)\n    return False\n\ndef write_pid():\n    with open(PID_FILE, \"w\") as f:\n        f.write(str(os.getpid()))\n\ndef get_mcp_py():\n    script_dir = Path(__file__).resolve().parent\n    mcp_py = script_dir.parent / \"mcp.py\"\n    return str(mcp_py)\n\ndef run_collaboration():\n    mcp_py = get_mcp_py()\n    script_dir = Path(__file__).resolve().parent\n    telegram_bridge_py = script_dir / \"telegram_bridge.py\"\n    telegram_config = script_dir / \"telegram_config.json\"\n\n    print(f\"[LAUNCHER] Starting autonomous collaboration loop...\")\n\n    t_process = None\n\n    while True:\n        try:\n            # Check/Start Telegram Bridge if configured\n            if telegram_config.exists():\n                if t_process is None or t_process.poll() is not None:\n                    action = \"Starting\" if t_process is None else \"Restarting\"\n                    print(f\"[LAUNCHER] Telegram configuration found. {action} Bridge...\")\n                    t_process = subprocess.Popen([sys.executable, str(telegram_bridge_py)], shell=False)\n\n            # Run mcp comms collaborate\n            process = subprocess.Popen([sys.executable, mcp_p", "chunk_type": "file", "line_start": 1, "line_end": 97, "language": "python", "name": "agent_launcher.py"}, "13a0e3c05204_func_is_already_running": {"id": "13a0e3c05204_func_is_already_running", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\agent_launcher.py", "content": "def is_already_running():\n    if PID_FILE.exists():\n        try:\n            with open(PID_FILE, \"r\") as f:\n                pid = int(f.read().strip())\n            # Check if process exists\n            if os.name != 'nt':\n                os.kill(pid, 0)\n            else:\n                # Windows check\n                subprocess.run([\"tasklist\", \"/FI\", f\"PID eq {pid}\"], capture_output=True, check=True)\n            return True\n        except:\n            PID_FILE.unlink(missing_ok=True)\n    return False", "chunk_type": "function", "line_start": 18, "line_end": 32, "language": "python", "name": "is_already_running"}, "13a0e3c05204_func_write_pid": {"id": "13a0e3c05204_func_write_pid", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\agent_launcher.py", "content": "def write_pid():\n    with open(PID_FILE, \"w\") as f:\n        f.write(str(os.getpid()))", "chunk_type": "function", "line_start": 34, "line_end": 36, "language": "python", "name": "write_pid"}, "13a0e3c05204_func_get_mcp_py": {"id": "13a0e3c05204_func_get_mcp_py", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\agent_launcher.py", "content": "def get_mcp_py():\n    script_dir = Path(__file__).resolve().parent\n    mcp_py = script_dir.parent / \"mcp.py\"\n    return str(mcp_py)", "chunk_type": "function", "line_start": 38, "line_end": 41, "language": "python", "name": "get_mcp_py"}, "13a0e3c05204_func_run_collaboration": {"id": "13a0e3c05204_func_run_collaboration", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\agent_launcher.py", "content": "def run_collaboration():\n    mcp_py = get_mcp_py()\n    script_dir = Path(__file__).resolve().parent\n    telegram_bridge_py = script_dir / \"telegram_bridge.py\"\n    telegram_config = script_dir / \"telegram_config.json\"\n\n    print(f\"[LAUNCHER] Starting autonomous collaboration loop...\")\n\n    t_process = None\n\n    while True:\n        try:\n            # Check/Start Telegram Bridge if configured\n            if telegram_config.exists():\n                if t_process is None or t_process.poll() is not None:\n                    action = \"Starting\" if t_process is None else \"Restarting\"\n                    print(f\"[LAUNCHER] Telegram configuration found. {action} Bridge...\")\n                    t_process = subprocess.Popen([sys.executable, str(telegram_bridge_py)], shell=False)\n\n            # Run mcp comms collaborate\n            process = subprocess.Popen([sys.executable, mcp_py, \"comms\", \"collaborate\"], shell=False)\n\n            # Monitoring loop\n            while process.poll() is None:\n      ", "chunk_type": "function", "line_start": 43, "line_end": 85, "language": "python", "name": "run_collaboration"}, "5a37116d7070_file": {"id": "5a37116d7070_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\antigravity_automation.py", "content": "#!/usr/bin/env python3\n\"\"\"\nAntigravity IDE Automation Bridge\nAutomates typing messages into the Antigravity IDE chat interface using Playwright.\n\nThis module integrates with telegram_bridge.py and agent_comms.py to enable\nTelegram \u2192 Antigravity \u2192 Telegram message flow.\n\"\"\"\n\nfrom pathlib import Path\nfrom typing import Optional\nimport json\nimport os\nimport sys\nimport time\n\n# Playwright will be imported dynamically to handle installation\ntry:\n    from playwright.sync_api import sync_playwright, Page, Browser, TimeoutError as PlaywrightTimeoutError\n    PLAYWRIGHT_AVAILABLE = True\nexcept ImportError:\n    PLAYWRIGHT_AVAILABLE = False\n    print(\"[WARNING] Playwright not installed. Run: pip install playwright && playwright install chromium\")\n\n# MCP Path Resolution\nSCRIPTS_DIR = Path(__file__).resolve().parent\nsys.path.append(str(SCRIPTS_DIR))\n\ntry:\n    import agent_comms\nexcept ImportError:\n    agent_comms = None\n\n\nclass AntigravityBridge:\n    \"\"\"Manages automation of Antigravity IDE chat interface.\"\"\"\n\n    def __init__(self, workspace_path: Optional[str] = None):\n        self.browser: Optional[Browser] = None\n        self.page: Optional[Page] = None\n        self.playwright = None\n        self.conversation_active = False\n\n        # Workspace paths for Quasar (Windows) and WizardPanda (Linux)\n        if workspace_path:\n            self.workspace_path = Path(workspace_path)\n        else:\n            # Auto-detect based on hostname\n            if os.name == 'nt':  # Windows - Quasar\n                self.workspace_path = Path(\"C:/Users/dbiss/Desktop/Projects/_BLANK_\")\n            else:  # Linux - WizardPanda\n                self.workspace_path = Path(\"/home/p4nd4pr0t0c01/Projects/_BLANK_\")\n\n        print(f\"[INFO] Workspace path set to: {self.workspace_path}\")\n\n    def connect_to_antigravity(self) -> bool:\n        \"\"\"\n        Attempts to connect to a running Antigravity IDE instance.\n\n        Antigravity is an Electron app, so we'll use Playwright's Chromium DevTools Protocol\n  ", "chunk_type": "file", "line_start": 1, "line_end": 525, "language": "python", "name": "antigravity_automation.py"}, "5a37116d7070_func_handle_antigravity_message": {"id": "5a37116d7070_func_handle_antigravity_message", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\antigravity_automation.py", "content": "def handle_antigravity_message(message_text: str) -> str:\n    \"\"\"\n    Main handler for processing Telegram messages destined for Antigravity.\n\n    Args:\n        message_text: The instruction from Telegram\n\n    Returns:\n        str: The response from Antigravity agent\n    \"\"\"\n    print(f\"[ANTIGRAVITY] Processing message: {message_text}\")\n\n    bridge = AntigravityBridge()\n\n    try:\n        response = bridge.send_message_to_agent(message_text, timeout_seconds=60)\n\n        if response:\n            return response\n        else:\n            return \"[ERROR] Failed to get response from Antigravity. Ensure the IDE is running with remote debugging enabled.\"\n\n    finally:\n        bridge.close()", "chunk_type": "function", "line_start": 436, "line_end": 459, "language": "python", "name": "handle_antigravity_message"}, "5a37116d7070_func_install_playwright": {"id": "5a37116d7070_func_install_playwright", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\antigravity_automation.py", "content": "def install_playwright():\n    \"\"\"Helper function to install Playwright if needed.\"\"\"\n    import subprocess\n\n    print(\"[INFO] Installing Playwright...\")\n    try:\n        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"playwright\"], check=True)\n        subprocess.run([sys.executable, \"-m\", \"playwright\", \"install\", \"chromium\"], check=True)\n        print(\"[OK] Playwright installed successfully\")\n        return True\n    except Exception as e:\n        print(f\"[FAIL] Failed to install Playwright: {e}\")\n        return False", "chunk_type": "function", "line_start": 462, "line_end": 474, "language": "python", "name": "install_playwright"}, "5a37116d7070_func_test_connection": {"id": "5a37116d7070_func_test_connection", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\antigravity_automation.py", "content": "def test_connection():\n    \"\"\"Test the connection to Antigravity IDE.\"\"\"\n    print(\"=== Antigravity Connection Test ===\")\n\n    if not PLAYWRIGHT_AVAILABLE:\n        print(\"[INFO] Playwright not available. Attempting to install...\")\n        if install_playwright():\n            print(\"[INFO] Please restart this script after installation completes.\")\n            return\n\n    bridge = AntigravityBridge()\n\n    if bridge.connect_to_antigravity():\n        print(\"[OK] Successfully connected to Antigravity IDE\")\n\n        # Test sending a simple message\n        test_msg = \"Hello! This is a test message from the Telegram bridge.\"\n        print(f\"\\n[TEST] Sending test message: {test_msg}\")\n\n        response = bridge.send_message_to_agent(test_msg, timeout_seconds=30)\n\n        if response:\n            print(f\"\\n[SUCCESS] Received response:\\n{response}\")\n        else:\n            print(\"\\n[FAIL] No response received\")\n    else:\n        print(\"[FAIL] Could not connect to Antigravity\")\n        print(\"\\n", "chunk_type": "function", "line_start": 477, "line_end": 511, "language": "python", "name": "test_connection"}, "5a37116d7070_func___init__": {"id": "5a37116d7070_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\antigravity_automation.py", "content": "    def __init__(self, workspace_path: Optional[str] = None):\n        self.browser: Optional[Browser] = None\n        self.page: Optional[Page] = None\n        self.playwright = None\n        self.conversation_active = False\n\n        # Workspace paths for Quasar (Windows) and WizardPanda (Linux)\n        if workspace_path:\n            self.workspace_path = Path(workspace_path)\n        else:\n            # Auto-detect based on hostname\n            if os.name == 'nt':  # Windows - Quasar\n                self.workspace_path = Path(\"C:/Users/dbiss/Desktop/Projects/_BLANK_\")\n            else:  # Linux - WizardPanda\n                self.workspace_path = Path(\"/home/p4nd4pr0t0c01/Projects/_BLANK_\")\n\n        print(f\"[INFO] Workspace path set to: {self.workspace_path}\")", "chunk_type": "function", "line_start": 38, "line_end": 54, "language": "python", "name": "__init__"}, "5a37116d7070_func_connect_to_antigravity": {"id": "5a37116d7070_func_connect_to_antigravity", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\antigravity_automation.py", "content": "    def connect_to_antigravity(self) -> bool:\n        \"\"\"\n        Attempts to connect to a running Antigravity IDE instance.\n\n        Antigravity is an Electron app, so we'll use Playwright's Chromium DevTools Protocol\n        to connect to the existing instance.\n\n        Returns:\n            bool: True if successfully connected, False otherwise\n        \"\"\"\n        if not PLAYWRIGHT_AVAILABLE:\n            print(\"[FAIL] Playwright is not installed.\")\n            return False\n\n        try:\n            self.playwright = sync_playwright().start()\n\n            # Antigravity IDE typically runs on a CDP endpoint\n            # We need to find the CDP debugging port\n            # Default for Electron apps is often http://localhost:9222\n\n            # Try common debugging ports for Electron apps\n            debugging_ports = [9222, 9223, 9224, 8315, 8316]\n\n            for port in debugging_ports:\n                try:\n                    cdp_url = f\"http://localhost:{port}\"\n                    pr", "chunk_type": "function", "line_start": 56, "line_end": 127, "language": "python", "name": "connect_to_antigravity"}, "5a37116d7070_func_verify_workspace": {"id": "5a37116d7070_func_verify_workspace", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\antigravity_automation.py", "content": "    def verify_workspace(self) -> bool:\n        \"\"\"\n        Verifies that Antigravity is open in the correct workspace directory.\n\n        Returns:\n            bool: True if in correct workspace, False otherwise\n        \"\"\"\n        if not self.page:\n            return False\n\n        try:\n            # Check if title bar or status bar shows the correct workspace path\n            # Method 1: Check window title\n            title = self.page.title()\n            workspace_name = str(self.workspace_path.name)\n\n            print(f\"[DEBUG] Window title: {title}\")\n            print(f\"[DEBUG] Expected workspace: {workspace_name} or {self.workspace_path}\")\n\n            if workspace_name in title or str(self.workspace_path) in title:\n                print(f\"[OK] Antigravity is in correct workspace: {workspace_name}\")\n                return True\n\n            # Method 2: Execute JavaScript to get workspace path from VS Code API\n            try:\n                current_workspace = self.page.evaluate(", "chunk_type": "function", "line_start": 129, "line_end": 180, "language": "python", "name": "verify_workspace"}, "5a37116d7070_func_open_workspace": {"id": "5a37116d7070_func_open_workspace", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\antigravity_automation.py", "content": "    def open_workspace(self) -> bool:\n        \"\"\"\n        Opens the correct workspace directory in Antigravity.\n\n        Returns:\n            bool: True if workspace opened successfully, False otherwise\n        \"\"\"\n        if not self.page:\n            return False\n\n        try:\n            print(f\"[INFO] Opening workspace: {self.workspace_path}\")\n\n            # First, press Escape to close any open dialogs\n            self.page.keyboard.press(\"Escape\")\n            time.sleep(0.5)\n\n            # Click \"Open Folder\" button if on Launchpad\n            try:\n                open_folder_button = self.page.query_selector('text=\"Open Folder\"')\n                if open_folder_button:\n                    print(\"[INFO] Clicking 'Open Folder' button on Launchpad\")\n                    open_folder_button.click()\n                    time.sleep(2)\n                else:\n                    # Try keyboard shortcut: Ctrl+K Ctrl+O\n                    print(\"[INFO] Using Ctrl+K Ctrl+O to open folder\")\n    ", "chunk_type": "function", "line_start": 182, "line_end": 245, "language": "python", "name": "open_workspace"}, "5a37116d7070_func_send_message_to_agent": {"id": "5a37116d7070_func_send_message_to_agent", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\antigravity_automation.py", "content": "    def send_message_to_agent(self, message: str, timeout_seconds: int = 30) -> Optional[str]:\n        \"\"\"\n        Types a message into Antigravity's agent chat interface and retrieves the response.\n\n        Args:\n            message: The message text to send\n            timeout_seconds: Maximum time to wait for response\n\n        Returns:\n            str: The agent's response, or None if failed\n        \"\"\"\n        if not self.page:\n            if not self.connect_to_antigravity():\n                return None\n\n        try:\n            # Click the \"Open Agent Manager\" button to open the agent panel\n            print(\"[INFO] Looking for 'Open Agent Manager' button...\")\n            try:\n                # Try to find and click the Open Agent Manager button\n                agent_button = self.page.query_selector('text=\"Open Agent Manager\"')\n                if agent_button and agent_button.is_visible():\n                    print(\"[INFO] Clicking 'Open Agent Manager' button...\")\n              ", "chunk_type": "function", "line_start": 247, "line_end": 420, "language": "python", "name": "send_message_to_agent"}, "5a37116d7070_func_close": {"id": "5a37116d7070_func_close", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\antigravity_automation.py", "content": "    def close(self):\n        \"\"\"Cleanup resources.\"\"\"\n        if self.browser:\n            try:\n                self.browser.close()\n            except:\n                pass\n        if self.playwright:\n            try:\n                self.playwright.stop()\n            except:\n                pass", "chunk_type": "function", "line_start": 422, "line_end": 433, "language": "python", "name": "close"}, "5a37116d7070_class_AntigravityBridge": {"id": "5a37116d7070_class_AntigravityBridge", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\antigravity_automation.py", "content": "class AntigravityBridge:\n    \"\"\"Manages automation of Antigravity IDE chat interface.\"\"\"\n\n    def __init__(self, workspace_path: Optional[str] = None):\n        self.browser: Optional[Browser] = None\n        self.page: Optional[Page] = None\n        self.playwright = None\n        self.conversation_active = False\n\n        # Workspace paths for Quasar (Windows) and WizardPanda (Linux)\n        if workspace_path:\n            self.workspace_path = Path(workspace_path)\n        else:\n            # Auto-detect based on hostname\n            if os.name == 'nt':  # Windows - Quasar\n                self.workspace_path = Path(\"C:/Users/dbiss/Desktop/Projects/_BLANK_\")\n            else:  # Linux - WizardPanda\n                self.workspace_path = Path(\"/home/p4nd4pr0t0c01/Projects/_BLANK_\")\n\n        print(f\"[INFO] Workspace path set to: {self.workspace_path}\")\n\n    def connect_to_antigravity(self) -> bool:\n        \"\"\"\n        Attempts to connect to a running Antigravity IDE instance.\n\n        Antigrav", "chunk_type": "class", "line_start": 35, "line_end": 433, "language": "python", "name": "AntigravityBridge"}, "bdbec3e2e850_file": {"id": "bdbec3e2e850_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\api_docs.py", "content": "\"\"\"\nAPI Documentation Generator\n===========================\nGenerate OpenAPI specs and markdown docs from Flask/FastAPI code.\n\nUsage:\n    python api_docs.py [path] [--output api.md]\n    python -m scripts.api_docs src/\n\"\"\"\n\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Tuple, Any\nimport ast\nimport json\nimport re\nimport sys\n\nfrom .utils import (\n    find_python_files,\n    find_project_root,\n    parse_file,\n    Console\n)\n\n\n@dataclass\nclass APIEndpoint:\n    \"\"\"An API endpoint definition.\"\"\"\n    path: str\n    method: str\n    function_name: str\n    file_path: Path\n    line_number: int\n    docstring: Optional[str] = None\n    parameters: List[Dict[str, Any]] = field(default_factory=list)\n    request_body: Optional[Dict[str, Any]] = None\n    responses: Dict[str, Any] = field(default_factory=dict)\n\n\n@dataclass\nclass APIDocumentation:\n    \"\"\"Complete API documentation.\"\"\"\n    title: str = \"API Documentation\"\n    version: str = \"1.0.0\"\n    endpoints: List[APIEndpoint] = field(default_factory=list)\n\n    def to_openapi(self) -> Dict[str, Any]:\n        \"\"\"Convert to OpenAPI 3.0 spec.\"\"\"\n        paths: Dict[str, Dict] = {}\n\n        for endpoint in self.endpoints:\n            if endpoint.path not in paths:\n                paths[endpoint.path] = {}\n\n            method = endpoint.method.lower()\n            paths[endpoint.path][method] = {\n                \"summary\": endpoint.function_name,\n                \"description\": endpoint.docstring or \"\",\n                \"operationId\": endpoint.function_name,\n                \"parameters\": endpoint.parameters,\n                \"responses\": endpoint.responses or {\"200\": {\"description\": \"Success\"}}\n            }\n\n            if endpoint.request_body:\n                paths[endpoint.path][method][\"requestBody\"] = endpoint.request_body\n\n        return {\n            \"openapi\": \"3.0.0\",\n            \"info\": {\n                \"title\": self.title,\n                \"version\": self.version\n          ", "chunk_type": "file", "line_start": 1, "line_end": 400, "language": "python", "name": "api_docs.py"}, "bdbec3e2e850_func_analyze_file": {"id": "bdbec3e2e850_func_analyze_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\api_docs.py", "content": "def analyze_file(path: Path) -> List[APIEndpoint]:\n    \"\"\"Analyze a file for API endpoints.\"\"\"\n    tree = parse_file(path)\n    if tree is None:\n        return []\n\n    try:\n        with open(path, 'r', encoding='utf-8') as f:\n            source_lines = f.readlines()\n    except Exception:\n        return []\n\n    endpoints = []\n\n    # Detect framework\n    source = ''.join(source_lines)\n\n    if 'flask' in source.lower() or 'Flask' in source:\n        extractor = FlaskRouteExtractor(path, source_lines)\n        extractor.visit(tree)\n        endpoints.extend(extractor.endpoints)\n\n    if 'fastapi' in source.lower() or 'FastAPI' in source:\n        extractor = FastAPIRouteExtractor(path, source_lines)\n        extractor.visit(tree)\n        endpoints.extend(extractor.endpoints)\n\n    return endpoints", "chunk_type": "function", "line_start": 299, "line_end": 326, "language": "python", "name": "analyze_file"}, "bdbec3e2e850_func_generate_api_docs": {"id": "bdbec3e2e850_func_generate_api_docs", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\api_docs.py", "content": "def generate_api_docs(\n    root: Path,\n    title: str = \"API Documentation\",\n    exclude_patterns: List[str] = None\n) -> APIDocumentation:\n    \"\"\"Generate API documentation for a project.\"\"\"\n    docs = APIDocumentation(title=title)\n\n    Console.info(f\"Scanning {root}...\")\n\n    files = list(find_python_files(root, exclude_patterns))\n    Console.info(f\"Found {len(files)} Python files\")\n\n    for path in files:\n        endpoints = analyze_file(path)\n        docs.endpoints.extend(endpoints)\n\n    Console.info(f\"Found {len(docs.endpoints)} API endpoints\")\n\n    return docs", "chunk_type": "function", "line_start": 329, "line_end": 348, "language": "python", "name": "generate_api_docs"}, "bdbec3e2e850_func_main": {"id": "bdbec3e2e850_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\api_docs.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"API Documentation Generator\")\n\n    # Parse args\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n    output_file = None\n    output_format = 'markdown'\n\n    for i, arg in enumerate(sys.argv):\n        if arg == '--output' and i + 1 < len(sys.argv):\n            output_file = Path(sys.argv[i + 1])\n        if arg == '--json':\n            output_format = 'json'\n\n    if args:\n        path = Path(args[0])\n    else:\n        path = find_project_root() or Path.cwd()\n\n    if not path.exists():\n        Console.fail(f\"Path not found: {path}\")\n        return 1\n\n    Console.info(f\"Analyzing: {path}\")\n\n    docs = generate_api_docs(path)\n\n    if len(docs.endpoints) == 0:\n        Console.warn(\"No API endpoints found (Flask/FastAPI)\")\n        return 0\n\n    if output_format == 'json':\n        content = json.dumps(docs.to_openapi(), indent=2)\n    else:\n        content = docs.to_markdown()\n\n    if output_file:\n        with open(output_fi", "chunk_type": "function", "line_start": 351, "line_end": 395, "language": "python", "name": "main"}, "bdbec3e2e850_func_to_openapi": {"id": "bdbec3e2e850_func_to_openapi", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\api_docs.py", "content": "    def to_openapi(self) -> Dict[str, Any]:\n        \"\"\"Convert to OpenAPI 3.0 spec.\"\"\"\n        paths: Dict[str, Dict] = {}\n\n        for endpoint in self.endpoints:\n            if endpoint.path not in paths:\n                paths[endpoint.path] = {}\n\n            method = endpoint.method.lower()\n            paths[endpoint.path][method] = {\n                \"summary\": endpoint.function_name,\n                \"description\": endpoint.docstring or \"\",\n                \"operationId\": endpoint.function_name,\n                \"parameters\": endpoint.parameters,\n                \"responses\": endpoint.responses or {\"200\": {\"description\": \"Success\"}}\n            }\n\n            if endpoint.request_body:\n                paths[endpoint.path][method][\"requestBody\"] = endpoint.request_body\n\n        return {\n            \"openapi\": \"3.0.0\",\n            \"info\": {\n                \"title\": self.title,\n                \"version\": self.version\n            },\n            \"paths\": paths\n        }", "chunk_type": "function", "line_start": 48, "line_end": 75, "language": "python", "name": "to_openapi"}, "bdbec3e2e850_func_to_markdown": {"id": "bdbec3e2e850_func_to_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\api_docs.py", "content": "    def to_markdown(self) -> str:\n        \"\"\"Convert to markdown documentation.\"\"\"\n        lines = [\n            f\"# {self.title}\",\n            \"\",\n            f\"**Version:** {self.version}\",\n            \"\",\n            \"## Endpoints\",\n            \"\",\n        ]\n\n        # Group by path\n        by_path: Dict[str, List[APIEndpoint]] = {}\n        for ep in self.endpoints:\n            if ep.path not in by_path:\n                by_path[ep.path] = []\n            by_path[ep.path].append(ep)\n\n        for path, endpoints in sorted(by_path.items()):\n            lines.append(f\"### `{path}`\")\n            lines.append(\"\")\n\n            for ep in endpoints:\n                lines.append(f\"#### {ep.method} `{path}`\")\n                lines.append(\"\")\n                lines.append(f\"**Handler:** `{ep.function_name}`\")\n                lines.append(f\"**Source:** `{ep.file_path}:{ep.line_number}`\")\n                lines.append(\"\")\n\n                if ep.docstring:\n                    lines.append(ep.docstrin", "chunk_type": "function", "line_start": 77, "line_end": 119, "language": "python", "name": "to_markdown"}, "bdbec3e2e850_func___init__": {"id": "bdbec3e2e850_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\api_docs.py", "content": "    def __init__(self, path: Path, source_lines: List[str]):\n        self.path = path\n        self.source_lines = source_lines\n        self.endpoints: List[APIEndpoint] = []", "chunk_type": "function", "line_start": 227, "line_end": 230, "language": "python", "name": "__init__"}, "bdbec3e2e850_func_visit_Assign": {"id": "bdbec3e2e850_func_visit_Assign", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\api_docs.py", "content": "    def visit_Assign(self, node: ast.Assign):\n        # Detect Flask app = Flask(__name__)\n        if isinstance(node.value, ast.Call):\n            if isinstance(node.value.func, ast.Name):\n                if node.value.func.id == 'Flask':\n                    for target in node.targets:\n                        if isinstance(target, ast.Name):\n                            self._app_names.add(target.id)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 133, "line_end": 141, "language": "python", "name": "visit_Assign"}, "bdbec3e2e850_func_visit_FunctionDef": {"id": "bdbec3e2e850_func_visit_FunctionDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\api_docs.py", "content": "    def visit_FunctionDef(self, node: ast.FunctionDef):\n        self._check_decorators(node)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 232, "line_end": 234, "language": "python", "name": "visit_FunctionDef"}, "bdbec3e2e850_func_visit_AsyncFunctionDef": {"id": "bdbec3e2e850_func_visit_AsyncFunctionDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\api_docs.py", "content": "    def visit_AsyncFunctionDef(self, node: ast.AsyncFunctionDef):\n        self._check_decorators(node)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 236, "line_end": 238, "language": "python", "name": "visit_AsyncFunctionDef"}, "bdbec3e2e850_func__check_decorators": {"id": "bdbec3e2e850_func__check_decorators", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\api_docs.py", "content": "    def _check_decorators(self, node):\n        for decorator in node.decorator_list:\n            endpoint = self._parse_fastapi_decorator(decorator, node)\n            if endpoint:\n                self.endpoints.append(endpoint)", "chunk_type": "function", "line_start": 240, "line_end": 244, "language": "python", "name": "_check_decorators"}, "bdbec3e2e850_func__parse_flask_decorator": {"id": "bdbec3e2e850_func__parse_flask_decorator", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\api_docs.py", "content": "    def _parse_flask_decorator(self, decorator, func_node) -> Optional[APIEndpoint]:\n        # @app.route('/path', methods=['GET'])\n        if isinstance(decorator, ast.Call):\n            if isinstance(decorator.func, ast.Attribute):\n                if decorator.func.attr == 'route':\n                    path = self._get_path_arg(decorator)\n                    methods = self._get_methods_arg(decorator)\n                    if path:\n                        for method in methods:\n                            return APIEndpoint(\n                                path=path,\n                                method=method,\n                                function_name=func_node.name,\n                                file_path=self.path,\n                                line_number=func_node.lineno,\n                                docstring=ast.get_docstring(func_node),\n                                parameters=self._extract_params(path),\n                                responses={\"200\": {\"descripti", "chunk_type": "function", "line_start": 157, "line_end": 191, "language": "python", "name": "_parse_flask_decorator"}, "bdbec3e2e850_func__get_path_arg": {"id": "bdbec3e2e850_func__get_path_arg", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\api_docs.py", "content": "    def _get_path_arg(self, call: ast.Call) -> Optional[str]:\n        if call.args and isinstance(call.args[0], ast.Constant):\n            return call.args[0].value\n        return None", "chunk_type": "function", "line_start": 265, "line_end": 268, "language": "python", "name": "_get_path_arg"}, "bdbec3e2e850_func__get_methods_arg": {"id": "bdbec3e2e850_func__get_methods_arg", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\api_docs.py", "content": "    def _get_methods_arg(self, call: ast.Call) -> List[str]:\n        for keyword in call.keywords:\n            if keyword.arg == 'methods':\n                if isinstance(keyword.value, ast.List):\n                    return [\n                        elt.value.upper() if isinstance(elt, ast.Constant) else 'GET'\n                        for elt in keyword.value.elts\n                    ]\n        return ['GET']", "chunk_type": "function", "line_start": 198, "line_end": 206, "language": "python", "name": "_get_methods_arg"}, "bdbec3e2e850_func__extract_params": {"id": "bdbec3e2e850_func__extract_params", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\api_docs.py", "content": "    def _extract_params(self, path: str, func_node) -> List[Dict]:\n        \"\"\"Extract parameters from path and function signature.\"\"\"\n        params = []\n\n        # Path parameters: {id}\n        for match in re.findall(r'\\{(\\w+)\\}', path):\n            params.append({\n                \"name\": match,\n                \"in\": \"path\",\n                \"required\": True,\n                \"schema\": {\"type\": \"string\"}\n            })\n\n        # Query parameters from function args\n        skip = {'request', 'response', 'db', 'session'}\n        path_params = {p['name'] for p in params}\n\n        for arg in func_node.args.args:\n            if arg.arg not in skip and arg.arg not in path_params:\n                params.append({\n                    \"name\": arg.arg,\n                    \"in\": \"query\",\n                    \"required\": arg.annotation is not None,\n                    \"schema\": {\"type\": \"string\"}\n                })\n\n        return params", "chunk_type": "function", "line_start": 270, "line_end": 296, "language": "python", "name": "_extract_params"}, "bdbec3e2e850_func__parse_fastapi_decorator": {"id": "bdbec3e2e850_func__parse_fastapi_decorator", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\api_docs.py", "content": "    def _parse_fastapi_decorator(self, decorator, func_node) -> Optional[APIEndpoint]:\n        # @app.get(\"/path\"), @router.post(\"/path\")\n        if isinstance(decorator, ast.Call):\n            if isinstance(decorator.func, ast.Attribute):\n                if decorator.func.attr in self.METHODS:\n                    path = self._get_path_arg(decorator)\n                    if path:\n                        return APIEndpoint(\n                            path=path,\n                            method=decorator.func.attr.upper(),\n                            function_name=func_node.name,\n                            file_path=self.path,\n                            line_number=func_node.lineno,\n                            docstring=ast.get_docstring(func_node),\n                            parameters=self._extract_params(path, func_node)\n                        )\n\n        return None", "chunk_type": "function", "line_start": 246, "line_end": 263, "language": "python", "name": "_parse_fastapi_decorator"}, "bdbec3e2e850_class_APIEndpoint": {"id": "bdbec3e2e850_class_APIEndpoint", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\api_docs.py", "content": "class APIEndpoint:\n    \"\"\"An API endpoint definition.\"\"\"\n    path: str\n    method: str\n    function_name: str\n    file_path: Path\n    line_number: int\n    docstring: Optional[str] = None\n    parameters: List[Dict[str, Any]] = field(default_factory=list)\n    request_body: Optional[Dict[str, Any]] = None\n    responses: Dict[str, Any] = field(default_factory=dict)", "chunk_type": "class", "line_start": 28, "line_end": 38, "language": "python", "name": "APIEndpoint"}, "bdbec3e2e850_class_APIDocumentation": {"id": "bdbec3e2e850_class_APIDocumentation", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\api_docs.py", "content": "class APIDocumentation:\n    \"\"\"Complete API documentation.\"\"\"\n    title: str = \"API Documentation\"\n    version: str = \"1.0.0\"\n    endpoints: List[APIEndpoint] = field(default_factory=list)\n\n    def to_openapi(self) -> Dict[str, Any]:\n        \"\"\"Convert to OpenAPI 3.0 spec.\"\"\"\n        paths: Dict[str, Dict] = {}\n\n        for endpoint in self.endpoints:\n            if endpoint.path not in paths:\n                paths[endpoint.path] = {}\n\n            method = endpoint.method.lower()\n            paths[endpoint.path][method] = {\n                \"summary\": endpoint.function_name,\n                \"description\": endpoint.docstring or \"\",\n                \"operationId\": endpoint.function_name,\n                \"parameters\": endpoint.parameters,\n                \"responses\": endpoint.responses or {\"200\": {\"description\": \"Success\"}}\n            }\n\n            if endpoint.request_body:\n                paths[endpoint.path][method][\"requestBody\"] = endpoint.request_body\n\n        return {\n            \"o", "chunk_type": "class", "line_start": 42, "line_end": 119, "language": "python", "name": "APIDocumentation"}, "bdbec3e2e850_class_FlaskRouteExtractor": {"id": "bdbec3e2e850_class_FlaskRouteExtractor", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\api_docs.py", "content": "class FlaskRouteExtractor(ast.NodeVisitor):\n    \"\"\"Extract routes from Flask applications.\"\"\"\n\n    METHODS = {'get', 'post', 'put', 'delete', 'patch', 'options', 'head'}\n\n    def __init__(self, path: Path, source_lines: List[str]):\n        self.path = path\n        self.source_lines = source_lines\n        self.endpoints: List[APIEndpoint] = []\n        self._app_names: set = set()\n\n    def visit_Assign(self, node: ast.Assign):\n        # Detect Flask app = Flask(__name__)\n        if isinstance(node.value, ast.Call):\n            if isinstance(node.value.func, ast.Name):\n                if node.value.func.id == 'Flask':\n                    for target in node.targets:\n                        if isinstance(target, ast.Name):\n                            self._app_names.add(target.id)\n        self.generic_visit(node)\n\n    def visit_FunctionDef(self, node: ast.FunctionDef):\n        self._check_decorators(node)\n        self.generic_visit(node)\n\n    def visit_AsyncFunctionDef(self, node: ast.Async", "chunk_type": "class", "line_start": 122, "line_end": 219, "language": "python", "name": "FlaskRouteExtractor"}, "bdbec3e2e850_class_FastAPIRouteExtractor": {"id": "bdbec3e2e850_class_FastAPIRouteExtractor", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\api_docs.py", "content": "class FastAPIRouteExtractor(ast.NodeVisitor):\n    \"\"\"Extract routes from FastAPI applications.\"\"\"\n\n    METHODS = {'get', 'post', 'put', 'delete', 'patch', 'options', 'head'}\n\n    def __init__(self, path: Path, source_lines: List[str]):\n        self.path = path\n        self.source_lines = source_lines\n        self.endpoints: List[APIEndpoint] = []\n\n    def visit_FunctionDef(self, node: ast.FunctionDef):\n        self._check_decorators(node)\n        self.generic_visit(node)\n\n    def visit_AsyncFunctionDef(self, node: ast.AsyncFunctionDef):\n        self._check_decorators(node)\n        self.generic_visit(node)\n\n    def _check_decorators(self, node):\n        for decorator in node.decorator_list:\n            endpoint = self._parse_fastapi_decorator(decorator, node)\n            if endpoint:\n                self.endpoints.append(endpoint)\n\n    def _parse_fastapi_decorator(self, decorator, func_node) -> Optional[APIEndpoint]:\n        # @app.get(\"/path\"), @router.post(\"/path\")\n        if isinstan", "chunk_type": "class", "line_start": 222, "line_end": 296, "language": "python", "name": "FastAPIRouteExtractor"}, "35bb77a84471_file": {"id": "35bb77a84471_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\architecture.py", "content": "\"\"\"\nArchitecture Validator\n======================\nEnforce architectural patterns and layer separation.\n\nUsage:\n    python architecture.py [path] [--config arch.json]\n    python -m scripts.architecture src/\n\"\"\"\n\nfrom collections import defaultdict\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Set, Tuple\nimport ast\nimport re\nimport sys\n\nfrom .utils import (\n    find_python_files,\n    find_project_root,\n    parse_file,\n    Console\n)\n\n\n@dataclass\nclass LayerRule:\n    \"\"\"A layer dependency rule.\"\"\"\n    layer: str\n    can_depend_on: List[str]\n    patterns: List[str]  # Path patterns for this layer\n\n\n@dataclass\nclass ArchViolation:\n    \"\"\"An architecture violation.\"\"\"\n    path: Path\n    line: int\n    severity: str  # 'error', 'warning'\n    category: str\n    message: str\n    from_layer: Optional[str] = None\n    to_layer: Optional[str] = None\n\n\n@dataclass\nclass ArchReport:\n    \"\"\"Architecture analysis report.\"\"\"\n    violations: List[ArchViolation] = field(default_factory=list)\n    layer_mapping: Dict[str, str] = field(default_factory=dict)\n    dependencies: Dict[str, Set[str]] = field(default_factory=lambda: defaultdict(set))\n\n    @property\n    def errors(self) -> List[ArchViolation]:\n        return [v for v in self.violations if v.severity == 'error']\n\n    def to_markdown(self) -> str:\n        lines = [\n            \"# Architecture Analysis\",\n            \"\",\n            \"## Layer Structure\",\n            \"\",\n            \"```mermaid\",\n            \"graph TD\",\n        ]\n\n        # Add layer nodes\n        layers_seen = set()\n        for layer in self.layer_mapping.values():\n            if layer and layer not in layers_seen:\n                lines.append(f'    {layer}[\"{layer}\"]')\n                layers_seen.add(layer)\n\n        # Add dependencies\n        for from_layer, to_layers in self.dependencies.items():\n            for to_layer in to_layers:\n                if from_layer and to_layer:\n                    lines.appen", "chunk_type": "file", "line_start": 1, "line_end": 353, "language": "python", "name": "architecture.py"}, "35bb77a84471_func_detect_layer": {"id": "35bb77a84471_func_detect_layer", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\architecture.py", "content": "def detect_layer(path: Path, rules: List[LayerRule]) -> Optional[str]:\n    \"\"\"Detect the layer a module belongs to based on path patterns.\"\"\"\n    name = path.stem.lower()\n    parts = [p.lower() for p in path.parts]\n\n    for rule in rules:\n        for pattern in rule.patterns:\n            # Convert glob to regex\n            regex = pattern.replace('*', '.*')\n            if re.search(regex, name) or any(re.search(regex, p) for p in parts):\n                return rule.layer\n\n    return None", "chunk_type": "function", "line_start": 140, "line_end": 152, "language": "python", "name": "detect_layer"}, "35bb77a84471_func_analyze_file": {"id": "35bb77a84471_func_analyze_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\architecture.py", "content": "def analyze_file(\n    path: Path,\n    rules: List[LayerRule]\n) -> Tuple[Optional[str], List[ArchViolation], Set[str]]:\n    \"\"\"Analyze a file for architecture violations.\"\"\"\n    violations = []\n    imports = set()\n\n    layer = detect_layer(path, rules)\n\n    tree = parse_file(path)\n    if tree is None:\n        return layer, violations, imports\n\n    # Import analysis\n    import_analyzer = ImportAnalyzer(path, layer, rules)\n    import_analyzer.visit(tree)\n    violations.extend(import_analyzer.violations)\n    imports = import_analyzer.imports\n\n    # Naming conventions\n    naming = NamingConventionChecker(path, layer)\n    naming.check(tree)\n    violations.extend(naming.violations)\n\n    return layer, violations, imports", "chunk_type": "function", "line_start": 246, "line_end": 271, "language": "python", "name": "analyze_file"}, "35bb77a84471_func_analyze_architecture": {"id": "35bb77a84471_func_analyze_architecture", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\architecture.py", "content": "def analyze_architecture(\n    root: Path,\n    rules: List[LayerRule] = None,\n    exclude_patterns: List[str] = None\n) -> ArchReport:\n    \"\"\"Analyze project architecture.\"\"\"\n    if rules is None:\n        rules = DEFAULT_RULES\n\n    report = ArchReport()\n\n    Console.info(f\"Analyzing architecture in {root}...\")\n\n    files = list(find_python_files(root, exclude_patterns))\n    Console.info(f\"Found {len(files)} Python files\")\n\n    for path in files:\n        layer, violations, imports = analyze_file(path, rules)\n\n        # Track layer mapping\n        report.layer_mapping[str(path)] = layer or 'unknown'\n\n        # Track violations\n        report.violations.extend(violations)\n\n        # Track dependencies\n        if layer:\n            for imp in imports:\n                for rule in rules:\n                    for pattern in rule.patterns:\n                        regex = pattern.replace('*', '.*')\n                        if re.search(regex, imp.lower()):\n                            report.depende", "chunk_type": "function", "line_start": 274, "line_end": 309, "language": "python", "name": "analyze_architecture"}, "35bb77a84471_func_main": {"id": "35bb77a84471_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\architecture.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Architecture Validator\")\n\n    # Parse args\n    strict = '--strict' in sys.argv\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n\n    if args:\n        path = Path(args[0])\n    else:\n        path = find_project_root() or Path.cwd()\n\n    if not path.exists():\n        Console.fail(f\"Path not found: {path}\")\n        return 1\n\n    Console.info(f\"Analyzing: {path}\")\n\n    report = analyze_architecture(path)\n\n    print(report.to_markdown())\n\n    # Summary\n    if report.errors:\n        Console.fail(f\"Found {len(report.errors)} architecture violations\")\n        return 1\n    elif report.violations:\n        if strict:\n            Console.fail(f\"Found {len(report.violations)} warnings (strict mode)\")\n            return 1\n        else:\n            Console.warn(f\"Found {len(report.violations)} warnings\")\n    else:\n        Console.ok(\"Architecture is clean\")\n\n    return 0", "chunk_type": "function", "line_start": 312, "line_end": 348, "language": "python", "name": "main"}, "35bb77a84471_func_errors": {"id": "35bb77a84471_func_errors", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\architecture.py", "content": "    def errors(self) -> List[ArchViolation]:\n        return [v for v in self.violations if v.severity == 'error']", "chunk_type": "function", "line_start": 55, "line_end": 56, "language": "python", "name": "errors"}, "35bb77a84471_func_to_markdown": {"id": "35bb77a84471_func_to_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\architecture.py", "content": "    def to_markdown(self) -> str:\n        lines = [\n            \"# Architecture Analysis\",\n            \"\",\n            \"## Layer Structure\",\n            \"\",\n            \"```mermaid\",\n            \"graph TD\",\n        ]\n\n        # Add layer nodes\n        layers_seen = set()\n        for layer in self.layer_mapping.values():\n            if layer and layer not in layers_seen:\n                lines.append(f'    {layer}[\"{layer}\"]')\n                layers_seen.add(layer)\n\n        # Add dependencies\n        for from_layer, to_layers in self.dependencies.items():\n            for to_layer in to_layers:\n                if from_layer and to_layer:\n                    lines.append(f'    {from_layer} --> {to_layer}')\n\n        lines.extend([\"```\", \"\"])\n\n        # Summary\n        lines.extend([\n            \"## Summary\",\n            \"\",\n            f\"- **Modules analyzed:** {len(self.layer_mapping)}\",\n            f\"- **Violations:** {len(self.violations)}\",\n            f\"- **Errors:** {len(self.errors)}", "chunk_type": "function", "line_start": 58, "line_end": 107, "language": "python", "name": "to_markdown"}, "35bb77a84471_func___init__": {"id": "35bb77a84471_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\architecture.py", "content": "    def __init__(self, path: Path, layer: Optional[str]):\n        self.path = path\n        self.layer = layer\n        self.violations: List[ArchViolation] = []", "chunk_type": "function", "line_start": 219, "line_end": 222, "language": "python", "name": "__init__"}, "35bb77a84471_func_visit_Import": {"id": "35bb77a84471_func_visit_Import", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\architecture.py", "content": "    def visit_Import(self, node: ast.Import):\n        for alias in node.names:\n            self.imports.add(alias.name)\n            self._check_import(alias.name, node.lineno)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 165, "line_end": 169, "language": "python", "name": "visit_Import"}, "35bb77a84471_func_visit_ImportFrom": {"id": "35bb77a84471_func_visit_ImportFrom", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\architecture.py", "content": "    def visit_ImportFrom(self, node: ast.ImportFrom):\n        if node.module:\n            self.imports.add(node.module)\n            self._check_import(node.module, node.lineno)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 171, "line_end": 175, "language": "python", "name": "visit_ImportFrom"}, "35bb77a84471_func__check_import": {"id": "35bb77a84471_func__check_import", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\architecture.py", "content": "    def _check_import(self, module: str, lineno: int):\n        if not self.layer:\n            return\n\n        # Get allowed dependencies for current layer\n        allowed = set()\n        for rule in self.rules:\n            if rule.layer == self.layer:\n                allowed = set(rule.can_depend_on)\n                break\n\n        # Check if import violates layer rules\n        module_lower = module.lower()\n        for rule in self.rules:\n            for pattern in rule.patterns:\n                regex = pattern.replace('*', '.*')\n                if re.search(regex, module_lower):\n                    imported_layer = rule.layer\n\n                    if imported_layer != self.layer and imported_layer not in allowed:\n                        self.violations.append(ArchViolation(\n                            path=self.path,\n                            line=lineno,\n                            severity='error',\n                            category='Layer Violation',\n                            m", "chunk_type": "function", "line_start": 177, "line_end": 206, "language": "python", "name": "_check_import"}, "35bb77a84471_func_check": {"id": "35bb77a84471_func_check", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\architecture.py", "content": "    def check(self, tree: ast.Module):\n        if not self.layer or self.layer not in self.CONVENTIONS:\n            return\n\n        expected = self.CONVENTIONS[self.layer]\n\n        for node in ast.walk(tree):\n            if isinstance(node, ast.ClassDef):\n                if node.name.startswith('_') or node.name == 'Config':\n                    continue\n\n                # Check if class name follows convention\n                if not any(node.name.endswith(suffix) for suffix in expected):\n                    self.violations.append(ArchViolation(\n                        path=self.path,\n                        line=node.lineno,\n                        severity='warning',\n                        category='Naming Convention',\n                        message=f\"Class '{node.name}' in '{self.layer}' layer should end with: {', '.join(expected)}\"\n                    ))", "chunk_type": "function", "line_start": 224, "line_end": 243, "language": "python", "name": "check"}, "35bb77a84471_class_LayerRule": {"id": "35bb77a84471_class_LayerRule", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\architecture.py", "content": "class LayerRule:\n    \"\"\"A layer dependency rule.\"\"\"\n    layer: str\n    can_depend_on: List[str]\n    patterns: List[str]  # Path patterns for this layer", "chunk_type": "class", "line_start": 28, "line_end": 32, "language": "python", "name": "LayerRule"}, "35bb77a84471_class_ArchViolation": {"id": "35bb77a84471_class_ArchViolation", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\architecture.py", "content": "class ArchViolation:\n    \"\"\"An architecture violation.\"\"\"\n    path: Path\n    line: int\n    severity: str  # 'error', 'warning'\n    category: str\n    message: str\n    from_layer: Optional[str] = None\n    to_layer: Optional[str] = None", "chunk_type": "class", "line_start": 36, "line_end": 44, "language": "python", "name": "ArchViolation"}, "35bb77a84471_class_ArchReport": {"id": "35bb77a84471_class_ArchReport", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\architecture.py", "content": "class ArchReport:\n    \"\"\"Architecture analysis report.\"\"\"\n    violations: List[ArchViolation] = field(default_factory=list)\n    layer_mapping: Dict[str, str] = field(default_factory=dict)\n    dependencies: Dict[str, Set[str]] = field(default_factory=lambda: defaultdict(set))\n\n    @property\n    def errors(self) -> List[ArchViolation]:\n        return [v for v in self.violations if v.severity == 'error']\n\n    def to_markdown(self) -> str:\n        lines = [\n            \"# Architecture Analysis\",\n            \"\",\n            \"## Layer Structure\",\n            \"\",\n            \"```mermaid\",\n            \"graph TD\",\n        ]\n\n        # Add layer nodes\n        layers_seen = set()\n        for layer in self.layer_mapping.values():\n            if layer and layer not in layers_seen:\n                lines.append(f'    {layer}[\"{layer}\"]')\n                layers_seen.add(layer)\n\n        # Add dependencies\n        for from_layer, to_layers in self.dependencies.items():\n            for to_layer in to_lay", "chunk_type": "class", "line_start": 48, "line_end": 107, "language": "python", "name": "ArchReport"}, "35bb77a84471_class_ImportAnalyzer": {"id": "35bb77a84471_class_ImportAnalyzer", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\architecture.py", "content": "class ImportAnalyzer(ast.NodeVisitor):\n    \"\"\"Analyze imports for architecture violations.\"\"\"\n\n    def __init__(self, path: Path, layer: Optional[str], rules: List[LayerRule]):\n        self.path = path\n        self.layer = layer\n        self.rules = rules\n        self.violations: List[ArchViolation] = []\n        self.imports: Set[str] = set()\n\n    def visit_Import(self, node: ast.Import):\n        for alias in node.names:\n            self.imports.add(alias.name)\n            self._check_import(alias.name, node.lineno)\n        self.generic_visit(node)\n\n    def visit_ImportFrom(self, node: ast.ImportFrom):\n        if node.module:\n            self.imports.add(node.module)\n            self._check_import(node.module, node.lineno)\n        self.generic_visit(node)\n\n    def _check_import(self, module: str, lineno: int):\n        if not self.layer:\n            return\n\n        # Get allowed dependencies for current layer\n        allowed = set()\n        for rule in self.rules:\n            if rule.la", "chunk_type": "class", "line_start": 155, "line_end": 206, "language": "python", "name": "ImportAnalyzer"}, "35bb77a84471_class_NamingConventionChecker": {"id": "35bb77a84471_class_NamingConventionChecker", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\architecture.py", "content": "class NamingConventionChecker:\n    \"\"\"Check naming conventions by layer.\"\"\"\n\n    CONVENTIONS = {\n        'controller': ['Controller', 'Handler', 'View', 'Router', 'Api', 'Manager'],\n        'service': ['Service', 'Manager', 'Logic', 'Settings', 'Response'],\n        'repository': ['Repository', 'Repo', 'DAO', 'Dal'],\n        'model': ['Model', 'Entity', 'Schema', 'DTO', 'Base', 'Create', 'Read', 'Update', 'Item', 'Info', 'Status', 'Payload', 'Login', 'Response', 'Request', 'Analytics', 'Performance', 'Risk', 'Grade', 'Token', 'WithStudent', 'Account', 'Institution', 'Classroom', 'Assignment', 'Announcement', 'Subscription', 'Transaction', 'GameSave', 'BugReport', 'Product', 'Permission', 'Enrollment', 'Submission', 'Condition', 'Link', 'Jurisdiction', 'Log', 'Message', 'Cache', 'Category', 'Image', 'Review', 'Question', 'Option', 'Answer', 'Module', 'Progress', 'Type'],\n    }\n\n    def __init__(self, path: Path, layer: Optional[str]):\n        self.path = path\n        self.layer = layer\n ", "chunk_type": "class", "line_start": 209, "line_end": 243, "language": "python", "name": "NamingConventionChecker"}, "a51778df45ec_file": {"id": "a51778df45ec_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\astgrep.py", "content": "\"\"\"\nast-grep Wrapper\n================\nStructural code search and transformation using ast-grep.\n\nUsage:\n    from scripts.astgrep import search_pattern, apply_fix\n\"\"\"\n\nimport json\nimport re\nimport subprocess\nimport sys\nfrom pathlib import Path\nfrom typing import Dict, List, Optional\nfrom dataclasses import dataclass, field\n\nfrom .utils import Console, find_python_files\n\n\n# Check if ast-grep is available\ndef _find_astgrep() -> Optional[str]:\n    \"\"\"Find ast-grep binary.\"\"\"\n    for name in ['ast-grep', 'sg']:\n        try:\n            result = subprocess.run(\n                [name, '--version'],\n                capture_output=True,\n                text=True\n            )\n            if result.returncode == 0:\n                return name\n        except FileNotFoundError:\n            continue\n    return None\n\n\nASTGREP_BIN = _find_astgrep()\nASTGREP_AVAILABLE = ASTGREP_BIN is not None\n\n\n@dataclass\nclass PatternMatch:\n    \"\"\"A pattern match result.\"\"\"\n    path: Path\n    line: int\n    column: int\n    text: str\n    matched_text: str\n    pattern: str\n\n\n@dataclass\nclass PatternRule:\n    \"\"\"A pattern rule for search/fix.\"\"\"\n    id: str\n    pattern: str\n    message: str\n    fix: Optional[str] = None\n    severity: str = \"warning\"\n    language: str = \"python\"\n\n\n# Built-in patterns for common issues\nBUILTIN_PATTERNS = {\n    'python': [\n        PatternRule(\n            id='bare-except',\n            pattern='except:',\n            message='Bare except catches all exceptions',\n            fix='except Exception:',\n            severity='error'\n        ),\n        PatternRule(\n            id='print-statement',\n            pattern='print($$$ARGS)',\n            message='Consider using logging instead of print',\n            severity='warning'\n        ),\n        PatternRule(\n            id='mutable-default',\n            pattern='def $FN($$$ARGS, $ARG=[]):',\n            message='Mutable default argument',\n            severity='error'\n        ),\n        PatternRule(\n            id='hardcoded-passw", "chunk_type": "file", "line_start": 1, "line_end": 395, "language": "python", "name": "astgrep.py"}, "a51778df45ec_func__find_astgrep": {"id": "a51778df45ec_func__find_astgrep", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\astgrep.py", "content": "def _find_astgrep() -> Optional[str]:\n    \"\"\"Find ast-grep binary.\"\"\"\n    for name in ['ast-grep', 'sg']:\n        try:\n            result = subprocess.run(\n                [name, '--version'],\n                capture_output=True,\n                text=True\n            )\n            if result.returncode == 0:\n                return name\n        except FileNotFoundError:\n            continue\n    return None", "chunk_type": "function", "line_start": 22, "line_end": 35, "language": "python", "name": "_find_astgrep"}, "a51778df45ec_func_search_pattern": {"id": "a51778df45ec_func_search_pattern", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\astgrep.py", "content": "def search_pattern(\n    pattern: str,\n    path: Path,\n    language: str = \"python\"\n) -> List[PatternMatch]:\n    \"\"\"Search for pattern in code.\"\"\"\n    results = []\n\n    if ASTGREP_AVAILABLE:\n        return _astgrep_search(pattern, path, language)\n\n    # Fallback to regex-based search\n    return _regex_search(pattern, path)", "chunk_type": "function", "line_start": 157, "line_end": 169, "language": "python", "name": "search_pattern"}, "a51778df45ec_func__astgrep_search": {"id": "a51778df45ec_func__astgrep_search", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\astgrep.py", "content": "def _astgrep_search(\n    pattern: str,\n    path: Path,\n    language: str\n) -> List[PatternMatch]:\n    \"\"\"Search using ast-grep.\"\"\"\n    results = []\n\n    try:\n        cmd = [\n            ASTGREP_BIN,\n            '--pattern', pattern,\n            '--json',\n            str(path)\n        ]\n\n        if language:\n            cmd.extend(['--lang', language])\n\n        proc = subprocess.run(cmd, capture_output=True, text=True)\n\n        if proc.returncode == 0 and proc.stdout:\n            for line in proc.stdout.strip().split('\\n'):\n                if line:\n                    try:\n                        match = json.loads(line)\n                        results.append(PatternMatch(\n                            path=Path(match.get('file', '')),\n                            line=match.get('range', {}).get('start', {}).get('line', 0),\n                            column=match.get('range', {}).get('start', {}).get('column', 0),\n                            text=match.get('text', ''),\n                   ", "chunk_type": "function", "line_start": 172, "line_end": 212, "language": "python", "name": "_astgrep_search"}, "a51778df45ec_func__regex_search": {"id": "a51778df45ec_func__regex_search", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\astgrep.py", "content": "def _regex_search(pattern: str, path: Path) -> List[PatternMatch]:\n    \"\"\"Fallback regex-based search.\"\"\"\n    results = []\n\n    # Convert ast-grep pattern to rough regex\n    regex = pattern\n    regex = re.escape(regex)\n    regex = regex.replace(r'\\$\\$\\$', '.*')  # $$$ matches anything\n    regex = regex.replace(r'\\$', r'\\w+')     # $ matches identifier\n\n    try:\n        files = [path] if path.is_file() else list(path.rglob('*.py'))\n\n        for file_path in files:\n            try:\n                with open(file_path, 'r', encoding='utf-8') as f:\n                    for i, line in enumerate(f, 1):\n                        if re.search(regex, line):\n                            results.append(PatternMatch(\n                                path=file_path,\n                                line=i,\n                                column=0,\n                                text=line.strip(),\n                                matched_text=line.strip(),\n                                pattern=pattern\n ", "chunk_type": "function", "line_start": 215, "line_end": 247, "language": "python", "name": "_regex_search"}, "a51778df45ec_func_apply_fix": {"id": "a51778df45ec_func_apply_fix", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\astgrep.py", "content": "def apply_fix(\n    pattern: str,\n    replacement: str,\n    path: Path,\n    language: str = \"python\",\n    dry_run: bool = True\n) -> int:\n    \"\"\"Apply fix pattern to files.\"\"\"\n    fixed = 0\n\n    if ASTGREP_AVAILABLE:\n        return _astgrep_fix(pattern, replacement, path, language, dry_run)\n\n    # Fallback to regex\n    return _regex_fix(pattern, replacement, path, dry_run)", "chunk_type": "function", "line_start": 250, "line_end": 264, "language": "python", "name": "apply_fix"}, "a51778df45ec_func__astgrep_fix": {"id": "a51778df45ec_func__astgrep_fix", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\astgrep.py", "content": "def _astgrep_fix(\n    pattern: str,\n    replacement: str,\n    path: Path,\n    language: str,\n    dry_run: bool\n) -> int:\n    \"\"\"Apply fix using ast-grep.\"\"\"\n    cmd = [\n        ASTGREP_BIN,\n        '--pattern', pattern,\n        '--rewrite', replacement,\n    ]\n\n    if not dry_run:\n        cmd.append('--update-all')\n\n    cmd.extend(['--lang', language, str(path)])\n\n    try:\n        proc = subprocess.run(cmd, capture_output=True, text=True)\n        # Count matches\n        return proc.stdout.count('\\n')\n    except Exception:\n        return 0", "chunk_type": "function", "line_start": 267, "line_end": 291, "language": "python", "name": "_astgrep_fix"}, "a51778df45ec_func__regex_fix": {"id": "a51778df45ec_func__regex_fix", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\astgrep.py", "content": "def _regex_fix(\n    pattern: str,\n    replacement: str,\n    path: Path,\n    dry_run: bool\n) -> int:\n    \"\"\"Fallback regex-based fix.\"\"\"\n    fixed = 0\n\n    # Convert patterns\n    regex = pattern.replace('$$$', '(.*)').replace('$', r'(\\w+)')\n    repl = replacement.replace('$$$', r'\\1').replace('$', r'\\1')\n\n    files = [path] if path.is_file() else list(path.rglob('*.py'))\n\n    for file_path in files:\n        try:\n            with open(file_path, 'r', encoding='utf-8') as f:\n                content = f.read()\n\n            new_content, count = re.subn(regex, repl, content)\n\n            if count > 0:\n                fixed += count\n                if not dry_run:\n                    with open(file_path, 'w', encoding='utf-8') as f:\n                        f.write(new_content)\n        except Exception:\n            pass\n\n    return fixed", "chunk_type": "function", "line_start": 294, "line_end": 324, "language": "python", "name": "_regex_fix"}, "a51778df45ec_func_run_rules": {"id": "a51778df45ec_func_run_rules", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\astgrep.py", "content": "def run_rules(\n    rules: List[PatternRule],\n    path: Path\n) -> List[PatternMatch]:\n    \"\"\"Run multiple pattern rules.\"\"\"\n    all_matches = []\n\n    for rule in rules:\n        matches = search_pattern(rule.pattern, path, rule.language)\n        for match in matches:\n            match.pattern = f\"{rule.id}: {rule.message}\"\n        all_matches.extend(matches)\n\n    return all_matches", "chunk_type": "function", "line_start": 327, "line_end": 340, "language": "python", "name": "run_rules"}, "a51778df45ec_func_get_builtin_rules": {"id": "a51778df45ec_func_get_builtin_rules", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\astgrep.py", "content": "def get_builtin_rules(language: str = \"python\") -> List[PatternRule]:\n    \"\"\"Get built-in rules for language.\"\"\"\n    return BUILTIN_PATTERNS.get(language, [])", "chunk_type": "function", "line_start": 343, "line_end": 345, "language": "python", "name": "get_builtin_rules"}, "a51778df45ec_func_is_astgrep_available": {"id": "a51778df45ec_func_is_astgrep_available", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\astgrep.py", "content": "def is_astgrep_available() -> bool:\n    \"\"\"Check if ast-grep is available.\"\"\"\n    return ASTGREP_AVAILABLE", "chunk_type": "function", "line_start": 348, "line_end": 350, "language": "python", "name": "is_astgrep_available"}, "a51778df45ec_func_main": {"id": "a51778df45ec_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\astgrep.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"ast-grep Wrapper\")\n\n    if ASTGREP_AVAILABLE:\n        Console.ok(f\"ast-grep available: {ASTGREP_BIN}\")\n    else:\n        Console.warn(\"ast-grep not found, using regex fallback\")\n\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n\n    if len(args) < 2:\n        Console.info(\"Usage: python astgrep.py <pattern> <path>\")\n        Console.info(\"\\nBuilt-in rules:\")\n        for lang, rules in BUILTIN_PATTERNS.items():\n            Console.info(f\"\\n  {lang}:\")\n            for rule in rules:\n                Console.info(f\"    - {rule.id}: {rule.message}\")\n        return 1\n\n    pattern = args[0]\n    path = Path(args[1])\n\n    if not path.exists():\n        Console.fail(f\"Path not found: {path}\")\n        return 1\n\n    Console.info(f\"Pattern: {pattern}\")\n    Console.info(f\"Path: {path}\")\n\n    matches = search_pattern(pattern, path)\n\n    Console.info(f\"Found {len(matches)} matches\")\n\n    for match in matches[:20]:\n        print(f\"  {", "chunk_type": "function", "line_start": 353, "line_end": 390, "language": "python", "name": "main"}, "a51778df45ec_class_PatternMatch": {"id": "a51778df45ec_class_PatternMatch", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\astgrep.py", "content": "class PatternMatch:\n    \"\"\"A pattern match result.\"\"\"\n    path: Path\n    line: int\n    column: int\n    text: str\n    matched_text: str\n    pattern: str", "chunk_type": "class", "line_start": 43, "line_end": 50, "language": "python", "name": "PatternMatch"}, "a51778df45ec_class_PatternRule": {"id": "a51778df45ec_class_PatternRule", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\astgrep.py", "content": "class PatternRule:\n    \"\"\"A pattern rule for search/fix.\"\"\"\n    id: str\n    pattern: str\n    message: str\n    fix: Optional[str] = None\n    severity: str = \"warning\"\n    language: str = \"python\"", "chunk_type": "class", "line_start": 54, "line_end": 61, "language": "python", "name": "PatternRule"}, "97f056073130_file": {"id": "97f056073130_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\autocontext.py", "content": "\"\"\"\nAuto-Context Loader\n===================\nAutomatically load relevant code context for AI agents.\n\nUsage:\n    python mcp.py context --auto      # Get auto-loaded context\n    python mcp.py context --recent    # Context from recent files\n\"\"\"\n\nfrom collections import Counter\nfrom dataclasses import dataclass, field, asdict\nfrom datetime import datetime\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Tuple\nimport json\nimport os\nimport sys\n\nfrom .utils import Console, find_project_root\n\n\n@dataclass\nclass ContextCache:\n    \"\"\"Cache of context state.\"\"\"\n    recent_files: List[str] = field(default_factory=list)\n    hot_files: Dict[str, int] = field(default_factory=dict)  # path -> access count\n    last_query: str = \"\"\n    last_task: str = \"\"\n    timestamp: str = \"\"\n\n    def to_dict(self) -> dict:\n        return asdict(self)\n\n    @classmethod\n    def from_dict(cls, data: dict) -> 'ContextCache':\n        return cls(**data)\n\n\n@dataclass\nclass ContextResult:\n    \"\"\"Result of context loading.\"\"\"\n    files: List[Tuple[str, str]]  # (path, content summary)\n    token_count: int\n    source: str  # 'recent', 'semantic', 'dependency'\n\n\ndef get_cache_path(root: Path = None) -> Path:\n    \"\"\"Get path to context cache.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n    return root / '.mcp' / 'memory' / 'context_cache.json'\n\n\ndef load_cache(root: Path = None) -> ContextCache:\n    \"\"\"Load context cache from disk.\"\"\"\n    cache_path = get_cache_path(root)\n\n    if cache_path.exists():\n        try:\n            with open(cache_path, 'r', encoding='utf-8') as f:\n                data = json.load(f)\n                return ContextCache.from_dict(data)\n        except Exception:\n            pass\n\n    return ContextCache()\n\n\ndef save_cache(cache: ContextCache, root: Path = None):\n    \"\"\"Save context cache to disk.\"\"\"\n    cache_path = get_cache_path(root)\n    cache_path.parent.mkdir(parents=True, exist_ok=True)\n\n    cache.timestamp = datetime.utcnow().isoformat() + 'Z'\n\n    ", "chunk_type": "file", "line_start": 1, "line_end": 391, "language": "python", "name": "autocontext.py"}, "97f056073130_func_get_cache_path": {"id": "97f056073130_func_get_cache_path", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\autocontext.py", "content": "def get_cache_path(root: Path = None) -> Path:\n    \"\"\"Get path to context cache.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n    return root / '.mcp' / 'memory' / 'context_cache.json'", "chunk_type": "function", "line_start": 48, "line_end": 51, "language": "python", "name": "get_cache_path"}, "97f056073130_func_load_cache": {"id": "97f056073130_func_load_cache", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\autocontext.py", "content": "def load_cache(root: Path = None) -> ContextCache:\n    \"\"\"Load context cache from disk.\"\"\"\n    cache_path = get_cache_path(root)\n\n    if cache_path.exists():\n        try:\n            with open(cache_path, 'r', encoding='utf-8') as f:\n                data = json.load(f)\n                return ContextCache.from_dict(data)\n        except Exception:\n            pass\n\n    return ContextCache()", "chunk_type": "function", "line_start": 54, "line_end": 66, "language": "python", "name": "load_cache"}, "97f056073130_func_save_cache": {"id": "97f056073130_func_save_cache", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\autocontext.py", "content": "def save_cache(cache: ContextCache, root: Path = None):\n    \"\"\"Save context cache to disk.\"\"\"\n    cache_path = get_cache_path(root)\n    cache_path.parent.mkdir(parents=True, exist_ok=True)\n\n    cache.timestamp = datetime.utcnow().isoformat() + 'Z'\n\n    with open(cache_path, 'w', encoding='utf-8') as f:\n        json.dump(cache.to_dict(), f, indent=2)", "chunk_type": "function", "line_start": 69, "line_end": 77, "language": "python", "name": "save_cache"}, "97f056073130_func_track_file_access": {"id": "97f056073130_func_track_file_access", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\autocontext.py", "content": "def track_file_access(path: Path, root: Path = None):\n    \"\"\"Track that a file was accessed.\"\"\"\n    cache = load_cache(root)\n\n    path_str = str(path)\n\n    # Update recent files (max 20)\n    if path_str in cache.recent_files:\n        cache.recent_files.remove(path_str)\n    cache.recent_files.insert(0, path_str)\n    cache.recent_files = cache.recent_files[:20]\n\n    # Update hot files\n    cache.hot_files[path_str] = cache.hot_files.get(path_str, 0) + 1\n\n    save_cache(cache, root)", "chunk_type": "function", "line_start": 80, "line_end": 95, "language": "python", "name": "track_file_access"}, "97f056073130_func_get_recent_context": {"id": "97f056073130_func_get_recent_context", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\autocontext.py", "content": "def get_recent_context(\n    limit: int = 5,\n    max_lines: int = 50,\n    root: Path = None\n) -> ContextResult:\n    \"\"\"Get context from recently accessed files.\"\"\"\n    cache = load_cache(root)\n    root = root or find_project_root() or Path.cwd()\n\n    files = []\n    token_count = 0\n\n    for file_path in cache.recent_files[:limit]:\n        path = Path(file_path)\n        if not path.is_absolute():\n            path = root / path\n\n        if path.exists():\n            try:\n                with open(path, 'r', encoding='utf-8') as f:\n                    lines = f.readlines()[:max_lines]\n                    content = ''.join(lines)\n                    files.append((str(path), content))\n                    token_count += len(content.split())\n            except Exception:\n                pass\n\n    return ContextResult(files=files, token_count=token_count, source='recent')", "chunk_type": "function", "line_start": 98, "line_end": 125, "language": "python", "name": "get_recent_context"}, "97f056073130_func_get_hot_context": {"id": "97f056073130_func_get_hot_context", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\autocontext.py", "content": "def get_hot_context(\n    limit: int = 5,\n    max_lines: int = 50,\n    root: Path = None\n) -> ContextResult:\n    \"\"\"Get context from most frequently accessed files.\"\"\"\n    cache = load_cache(root)\n    root = root or find_project_root() or Path.cwd()\n\n    # Sort by access count\n    sorted_files = sorted(cache.hot_files.items(), key=lambda x: x[1], reverse=True)\n\n    files = []\n    token_count = 0\n\n    for file_path, _ in sorted_files[:limit]:\n        path = Path(file_path)\n        if not path.is_absolute():\n            path = root / path\n\n        if path.exists():\n            try:\n                with open(path, 'r', encoding='utf-8') as f:\n                    lines = f.readlines()[:max_lines]\n                    content = ''.join(lines)\n                    files.append((str(path), content))\n                    token_count += len(content.split())\n            except Exception:\n                pass\n\n    return ContextResult(files=files, token_count=token_count, source='hot')", "chunk_type": "function", "line_start": 128, "line_end": 158, "language": "python", "name": "get_hot_context"}, "97f056073130_func_get_semantic_context": {"id": "97f056073130_func_get_semantic_context", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\autocontext.py", "content": "def get_semantic_context(\n    query: str,\n    limit: int = 5,\n    root: Path = None\n) -> ContextResult:\n    \"\"\"Get context via semantic search.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    files = []\n    token_count = 0\n\n    try:\n        from .vector_store import VectorStore\n        store = VectorStore(root / '.mcp' / 'vector_index')\n\n        if store.load():\n            results = store.search(query, k=limit)\n\n            for result in results:\n                files.append((result.chunk.path, result.chunk.content))\n                token_count += len(result.chunk.content.split())\n    except Exception:\n        pass\n\n    # Update cache with query\n    cache = load_cache(root)\n    cache.last_query = query\n    save_cache(cache, root)\n\n    return ContextResult(files=files, token_count=token_count, source='semantic')", "chunk_type": "function", "line_start": 161, "line_end": 190, "language": "python", "name": "get_semantic_context"}, "97f056073130_func_get_dependency_context": {"id": "97f056073130_func_get_dependency_context", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\autocontext.py", "content": "def get_dependency_context(\n    file_path: Path,\n    root: Path = None\n) -> ContextResult:\n    \"\"\"Get context from file dependencies (imports).\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    files = []\n    token_count = 0\n\n    try:\n        from .treesitter_utils import parse_file\n        parsed = parse_file(file_path)\n\n        for imp in parsed.imports:\n            # Try to resolve import to file\n            parts = imp.replace('from ', '').replace('import ', '').split()[0].split('.')\n\n            for i in range(len(parts), 0, -1):\n                possible_path = root / '/'.join(parts[:i]) + '.py'\n                if possible_path.exists():\n                    try:\n                        with open(possible_path, 'r', encoding='utf-8') as f:\n                            content = f.read()[:2000]\n                            files.append((str(possible_path), content))\n                            token_count += len(content.split())\n                    except Exception:\n       ", "chunk_type": "function", "line_start": 193, "line_end": 225, "language": "python", "name": "get_dependency_context"}, "97f056073130_func_get_project_map": {"id": "97f056073130_func_get_project_map", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\autocontext.py", "content": "def get_project_map(root: Path, budget: int) -> str:\n    \"\"\"Layer 1: Get high-level project map.\"\"\"\n    summary_path = root / \"CODEBASE_SUMMARY.md\"\n    if summary_path.exists():\n        try:\n            content = summary_path.read_text(encoding='utf-8')\n            # Extract Directory Structure section\n            if \"## Directory Structure\" in content:\n                structure = content.split(\"## Directory Structure\")[1].split(\"##\")[0]\n                return f\"# Project Map\\n{structure[:budget]}\"\n            return content[:budget]\n        except Exception:\n            pass\n    return \"\"", "chunk_type": "function", "line_start": 230, "line_end": 243, "language": "python", "name": "get_project_map"}, "97f056073130_func_get_auto_context": {"id": "97f056073130_func_get_auto_context", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\autocontext.py", "content": "def get_auto_context(\n    task: str = \"\",\n    token_budget: int = 8000, # Increased default for deep context\n    root: Path = None\n) -> str:\n    \"\"\"Get hierarchically layered context for AI agent.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    # Budget Allocation\n    budget_map = int(token_budget * 0.05)\n    budget_mem = int(token_budget * 0.10)\n    budget_active = int(token_budget * 0.40)\n    budget_semantic = token_budget - (budget_map + budget_mem + budget_active)\n\n    layers = []\n\n    # Layer 1: Project Map\n    project_map = get_project_map(root, budget_map)\n    if project_map:\n        layers.append(project_map)\n\n    # Layer 2: Memory\n    memories = []\n    try:\n        from .memory import get_store\n        store = get_store()\n        recent_mems = store.recall(task) if task else store.list_all()\n        recent_mems.sort(key=lambda m: m.updated or m.created, reverse=True)\n\n        mem_tokens_used = 0\n        for mem in recent_mems[:5]:\n            encoded = f\"[{mem.key", "chunk_type": "function", "line_start": 245, "line_end": 337, "language": "python", "name": "get_auto_context"}, "97f056073130_func_update_task": {"id": "97f056073130_func_update_task", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\autocontext.py", "content": "def update_task(task: str, root: Path = None):\n    \"\"\"Update current task in cache.\"\"\"\n    cache = load_cache(root)\n    cache.last_task = task\n    save_cache(cache, root)", "chunk_type": "function", "line_start": 342, "line_end": 346, "language": "python", "name": "update_task"}, "97f056073130_func_main": {"id": "97f056073130_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\autocontext.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Auto-Context Loader\")\n\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n\n    root = find_project_root() or Path.cwd()\n\n    if '--recent' in sys.argv:\n        result = get_recent_context(root=root)\n        Console.info(f\"Recent files: {len(result.files)}\")\n        for path, _ in result.files:\n            print(f\"  - {path}\")\n        return 0\n\n    if '--hot' in sys.argv:\n        result = get_hot_context(root=root)\n        Console.info(f\"Hot files: {len(result.files)}\")\n        for path, _ in result.files:\n            print(f\"  - {path}\")\n        return 0\n\n    if '--auto' in sys.argv or not args:\n        task = ' '.join(args) if args else \"\"\n        context = get_auto_context(task=task, root=root)\n        print(context)\n        return 0\n\n    # Semantic search with query\n    query = ' '.join(args)\n    result = get_semantic_context(query, root=root)\n\n    Console.info(f\"Found {len(result.files)} relevant files for: {quer", "chunk_type": "function", "line_start": 349, "line_end": 386, "language": "python", "name": "main"}, "97f056073130_func_to_dict": {"id": "97f056073130_func_to_dict", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\autocontext.py", "content": "    def to_dict(self) -> dict:\n        return asdict(self)", "chunk_type": "function", "line_start": 32, "line_end": 33, "language": "python", "name": "to_dict"}, "97f056073130_func_from_dict": {"id": "97f056073130_func_from_dict", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\autocontext.py", "content": "    def from_dict(cls, data: dict) -> 'ContextCache':\n        return cls(**data)", "chunk_type": "function", "line_start": 36, "line_end": 37, "language": "python", "name": "from_dict"}, "97f056073130_class_ContextCache": {"id": "97f056073130_class_ContextCache", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\autocontext.py", "content": "class ContextCache:\n    \"\"\"Cache of context state.\"\"\"\n    recent_files: List[str] = field(default_factory=list)\n    hot_files: Dict[str, int] = field(default_factory=dict)  # path -> access count\n    last_query: str = \"\"\n    last_task: str = \"\"\n    timestamp: str = \"\"\n\n    def to_dict(self) -> dict:\n        return asdict(self)\n\n    @classmethod\n    def from_dict(cls, data: dict) -> 'ContextCache':\n        return cls(**data)", "chunk_type": "class", "line_start": 24, "line_end": 37, "language": "python", "name": "ContextCache"}, "97f056073130_class_ContextResult": {"id": "97f056073130_class_ContextResult", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\autocontext.py", "content": "class ContextResult:\n    \"\"\"Result of context loading.\"\"\"\n    files: List[Tuple[str, str]]  # (path, content summary)\n    token_count: int\n    source: str  # 'recent', 'semantic', 'dependency'", "chunk_type": "class", "line_start": 41, "line_end": 45, "language": "python", "name": "ContextResult"}, "720a713f0cd9_file": {"id": "720a713f0cd9_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\auto_docs.py", "content": "\"\"\"\nAuto-Docstring Generator\n========================\nAutomatically add missing docstrings to Python functions and classes.\n\nUsage:\n    python auto_docs.py [path] [--write]\n    python -m scripts.auto_docs [path] [--write]\n\"\"\"\n\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import List, Optional, Tuple\nimport ast\nimport sys\n\nfrom .utils import (\n    find_python_files,\n    find_project_root,\n    parse_file,\n    get_type_annotation,\n    Console\n)\n\n\n@dataclass\nclass DocstringSuggestion:\n    \"\"\"A suggested docstring for a function or class.\"\"\"\n    path: Path\n    name: str\n    lineno: int\n    node_type: str  # 'function', 'class', 'method'\n    docstring: str\n    indent: str\n\n\ndef generate_function_docstring(\n    node: ast.FunctionDef | ast.AsyncFunctionDef,\n    indent: str = \"    \"\n) -> str:\n    \"\"\"\n    Generate a Google-style docstring for a function.\n\n    Args:\n        node: AST function node\n        indent: Indentation to use\n\n    Returns:\n        Generated docstring string\n    \"\"\"\n    lines = ['\"\"\"']\n\n    # First line - brief description\n    if node.name.startswith('_'):\n        lines[0] += f\"Private {'async ' if isinstance(node, ast.AsyncFunctionDef) else ''}function {node.name}.\"\n    else:\n        # Try to generate a meaningful description from the name\n        name_parts = node.name.split('_')\n        if name_parts[0] in ('get', 'fetch', 'retrieve'):\n            desc = f\"Get {' '.join(name_parts[1:])}.\"\n        elif name_parts[0] in ('set', 'update'):\n            desc = f\"Set {' '.join(name_parts[1:])}.\"\n        elif name_parts[0] in ('is', 'has', 'can', 'should'):\n            desc = f\"Check if {' '.join(name_parts[1:])}.\"\n        elif name_parts[0] == 'create':\n            desc = f\"Create {' '.join(name_parts[1:])}.\"\n        elif name_parts[0] == 'delete':\n            desc = f\"Delete {' '.join(name_parts[1:])}.\"\n        elif name_parts[0] == 'process':\n            desc = f\"Process {' '.join(name_parts[1:])}.\"\n        elif name_parts[", "chunk_type": "file", "line_start": 1, "line_end": 451, "language": "python", "name": "auto_docs.py"}, "720a713f0cd9_func_generate_function_docstring": {"id": "720a713f0cd9_func_generate_function_docstring", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\auto_docs.py", "content": "def generate_function_docstring(\n    node: ast.FunctionDef | ast.AsyncFunctionDef,\n    indent: str = \"    \"\n) -> str:\n    \"\"\"\n    Generate a Google-style docstring for a function.\n\n    Args:\n        node: AST function node\n        indent: Indentation to use\n\n    Returns:\n        Generated docstring string\n    \"\"\"\n    lines = ['\"\"\"']\n\n    # First line - brief description\n    if node.name.startswith('_'):\n        lines[0] += f\"Private {'async ' if isinstance(node, ast.AsyncFunctionDef) else ''}function {node.name}.\"\n    else:\n        # Try to generate a meaningful description from the name\n        name_parts = node.name.split('_')\n        if name_parts[0] in ('get', 'fetch', 'retrieve'):\n            desc = f\"Get {' '.join(name_parts[1:])}.\"\n        elif name_parts[0] in ('set', 'update'):\n            desc = f\"Set {' '.join(name_parts[1:])}.\"\n        elif name_parts[0] in ('is', 'has', 'can', 'should'):\n            desc = f\"Check if {' '.join(name_parts[1:])}.\"\n        elif name_parts[0] ", "chunk_type": "function", "line_start": 37, "line_end": 141, "language": "python", "name": "generate_function_docstring"}, "720a713f0cd9_func__generate_param_description": {"id": "720a713f0cd9_func__generate_param_description", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\auto_docs.py", "content": "def _generate_param_description(name: str, type_hint: str) -> str:\n    \"\"\"Generate a description for a parameter based on its name.\"\"\"\n    # Common patterns\n    if name in ('path', 'filepath', 'file_path'):\n        return \"Path to the file.\"\n    elif name in ('root', 'root_dir', 'directory', 'dir'):\n        return \"Root directory.\"\n    elif name in ('data', 'content'):\n        return \"Input data.\"\n    elif name in ('name', 'filename'):\n        return \"The name.\"\n    elif name in ('key', 'id', 'identifier'):\n        return \"Unique identifier.\"\n    elif name in ('value', 'val'):\n        return \"The value.\"\n    elif name in ('config', 'settings', 'options'):\n        return \"Configuration options.\"\n    elif name in ('callback', 'func', 'function'):\n        return \"Callback function.\"\n    elif name in ('timeout', 'delay'):\n        return \"Timeout in seconds.\"\n    elif name in ('count', 'limit', 'max', 'min'):\n        return f\"The {name} value.\"\n    elif name.startswith('is_') or name.starts", "chunk_type": "function", "line_start": 144, "line_end": 174, "language": "python", "name": "_generate_param_description"}, "720a713f0cd9_func_generate_class_docstring": {"id": "720a713f0cd9_func_generate_class_docstring", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\auto_docs.py", "content": "def generate_class_docstring(node: ast.ClassDef, indent: str = \"    \") -> str:\n    \"\"\"\n    Generate a Google-style docstring for a class.\n\n    Args:\n        node: AST class node\n        indent: Indentation to use\n\n    Returns:\n        Generated docstring string\n    \"\"\"\n    lines = ['\"\"\"']\n\n    # First line - class description\n    name_parts = []\n    for i, char in enumerate(node.name):\n        if char.isupper() and i > 0:\n            name_parts.append(' ')\n        name_parts.append(char.lower())\n\n    desc = ''.join(name_parts).capitalize()\n    lines[0] += f\"{desc} class.\"\n\n    # Check for __init__ to get attributes\n    init_method = None\n    for item in node.body:\n        if isinstance(item, ast.FunctionDef) and item.name == '__init__':\n            init_method = item\n            break\n\n    # Extract attributes from __init__\n    if init_method:\n        attrs = []\n        for stmt in ast.walk(init_method):\n            if isinstance(stmt, ast.Assign):\n                for target in stmt.ta", "chunk_type": "function", "line_start": 177, "line_end": 226, "language": "python", "name": "generate_class_docstring"}, "720a713f0cd9_func_analyze_file_for_docstrings": {"id": "720a713f0cd9_func_analyze_file_for_docstrings", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\auto_docs.py", "content": "def analyze_file_for_docstrings(path: Path) -> List[DocstringSuggestion]:\n    \"\"\"\n    Analyze a file for missing docstrings.\n\n    Args:\n        path: Path to Python file\n\n    Returns:\n        List of docstring suggestions\n    \"\"\"\n    tree = parse_file(path)\n    if tree is None:\n        return []\n\n    try:\n        with open(path, 'r', encoding='utf-8') as f:\n            source_lines = f.readlines()\n    except Exception:\n        return []\n\n    analyzer = DocstringAnalyzer(path, source_lines)\n    analyzer.visit(tree)\n\n    return analyzer.suggestions", "chunk_type": "function", "line_start": 307, "line_end": 330, "language": "python", "name": "analyze_file_for_docstrings"}, "720a713f0cd9_func_add_docstrings_to_file": {"id": "720a713f0cd9_func_add_docstrings_to_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\auto_docs.py", "content": "def add_docstrings_to_file(path: Path, suggestions: List[DocstringSuggestion]) -> str:\n    \"\"\"\n    Add docstrings to a file.\n\n    Args:\n        path: Path to Python file\n        suggestions: List of docstring suggestions for this file\n\n    Returns:\n        Modified source code\n    \"\"\"\n    with open(path, 'r', encoding='utf-8') as f:\n        lines = f.readlines()\n\n    # Sort suggestions by line number in reverse order\n    # so we can insert from bottom to top without affecting line numbers\n    sorted_suggestions = sorted(suggestions, key=lambda s: s.lineno, reverse=True)\n\n    for suggestion in sorted_suggestions:\n        # Find the line with the function/class definition\n        def_line = suggestion.lineno - 1  # Convert to 0-indexed\n\n        # Find where to insert (after the definition line and any decorators)\n        insert_line = def_line + 1\n\n        # Skip past the colon and any existing pass/... statements\n        while insert_line < len(lines):\n            line = lines[insert_li", "chunk_type": "function", "line_start": 333, "line_end": 370, "language": "python", "name": "add_docstrings_to_file"}, "720a713f0cd9_func_generate_docstrings": {"id": "720a713f0cd9_func_generate_docstrings", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\auto_docs.py", "content": "def generate_docstrings(\n    root: Path,\n    write: bool = False,\n    exclude_patterns: List[str] = None\n) -> Tuple[int, int]:\n    \"\"\"\n    Generate docstrings for all Python files in a directory.\n\n    Args:\n        root: Root directory\n        write: Whether to write changes to files\n        exclude_patterns: Patterns to exclude\n\n    Returns:\n        Tuple of (files_with_missing, total_missing)\n    \"\"\"\n    all_suggestions: List[DocstringSuggestion] = []\n    files_with_missing = 0\n\n    Console.info(f\"Scanning for Python files in {root}...\")\n\n    files = list(find_python_files(root, exclude_patterns))\n    Console.info(f\"Found {len(files)} Python files\")\n\n    for path in files:\n        suggestions = analyze_file_for_docstrings(path)\n        if suggestions:\n            files_with_missing += 1\n            all_suggestions.extend(suggestions)\n\n            if write:\n                # Group suggestions by file\n                modified = add_docstrings_to_file(path, suggestions)\n                ", "chunk_type": "function", "line_start": 373, "line_end": 410, "language": "python", "name": "generate_docstrings"}, "720a713f0cd9_func_main": {"id": "720a713f0cd9_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\auto_docs.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Auto-Docstring Generator\")\n\n    # Parse args\n    write = '--write' in sys.argv\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n\n    # Get path\n    if args:\n        path = Path(args[0])\n    else:\n        path = find_project_root() or Path.cwd()\n\n    if not path.exists():\n        Console.fail(f\"Path not found: {path}\")\n        sys.exit(1)\n\n    Console.info(f\"Analyzing: {path}\")\n    Console.info(f\"Write mode: {'ON' if write else 'OFF (use --write to apply changes)'}\")\n\n    files_with_missing, total_missing = generate_docstrings(path, write=write)\n\n    print()\n    if total_missing > 0:\n        Console.warn(f\"Found {total_missing} missing docstrings in {files_with_missing} files\")\n        if write:\n            Console.ok(\"Docstrings have been added\")\n        else:\n            Console.info(\"Run with --write to add docstrings\")\n    else:\n        Console.ok(\"All functions and classes have docstrings\")\n\n    return 0 if tot", "chunk_type": "function", "line_start": 413, "line_end": 446, "language": "python", "name": "main"}, "720a713f0cd9_func___init__": {"id": "720a713f0cd9_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\auto_docs.py", "content": "    def __init__(self, path: Path, source_lines: List[str]):\n        self.path = path\n        self.source_lines = source_lines\n        self.suggestions: List[DocstringSuggestion] = []\n        self._class_stack: List[str] = []", "chunk_type": "function", "line_start": 232, "line_end": 236, "language": "python", "name": "__init__"}, "720a713f0cd9_func__get_indent": {"id": "720a713f0cd9_func__get_indent", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\auto_docs.py", "content": "    def _get_indent(self, lineno: int) -> str:\n        \"\"\"Get the indentation of a line.\"\"\"\n        if lineno <= 0 or lineno > len(self.source_lines):\n            return \"    \"\n        line = self.source_lines[lineno - 1]\n        return line[:len(line) - len(line.lstrip())]", "chunk_type": "function", "line_start": 238, "line_end": 243, "language": "python", "name": "_get_indent"}, "720a713f0cd9_func_visit_FunctionDef": {"id": "720a713f0cd9_func_visit_FunctionDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\auto_docs.py", "content": "    def visit_FunctionDef(self, node: ast.FunctionDef):\n        self._check_function(node)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 245, "line_end": 247, "language": "python", "name": "visit_FunctionDef"}, "720a713f0cd9_func_visit_AsyncFunctionDef": {"id": "720a713f0cd9_func_visit_AsyncFunctionDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\auto_docs.py", "content": "    def visit_AsyncFunctionDef(self, node: ast.AsyncFunctionDef):\n        self._check_function(node)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 249, "line_end": 251, "language": "python", "name": "visit_AsyncFunctionDef"}, "720a713f0cd9_func__check_function": {"id": "720a713f0cd9_func__check_function", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\auto_docs.py", "content": "    def _check_function(self, node: ast.FunctionDef | ast.AsyncFunctionDef):\n        \"\"\"Check if a function needs a docstring.\"\"\"\n        # Skip private and dunder methods\n        if node.name.startswith('__') and node.name.endswith('__'):\n            return\n\n        # Check if docstring exists\n        if ast.get_docstring(node):\n            return\n\n        # Get indentation for the docstring\n        body_indent = self._get_indent(node.lineno) + \"    \"\n\n        # Generate docstring\n        docstring = generate_function_docstring(node, body_indent)\n\n        node_type = 'method' if self._class_stack else 'function'\n\n        self.suggestions.append(DocstringSuggestion(\n            path=self.path,\n            name=node.name,\n            lineno=node.lineno,\n            node_type=node_type,\n            docstring=docstring,\n            indent=body_indent\n        ))", "chunk_type": "function", "line_start": 253, "line_end": 278, "language": "python", "name": "_check_function"}, "720a713f0cd9_func_visit_ClassDef": {"id": "720a713f0cd9_func_visit_ClassDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\auto_docs.py", "content": "    def visit_ClassDef(self, node: ast.ClassDef):\n        \"\"\"Check if a class needs a docstring.\"\"\"\n        # Skip private classes\n        if node.name.startswith('_'):\n            self.generic_visit(node)\n            return\n\n        # Check if docstring exists\n        if not ast.get_docstring(node):\n            body_indent = self._get_indent(node.lineno) + \"    \"\n            docstring = generate_class_docstring(node, body_indent)\n\n            self.suggestions.append(DocstringSuggestion(\n                path=self.path,\n                name=node.name,\n                lineno=node.lineno,\n                node_type='class',\n                docstring=docstring,\n                indent=body_indent\n            ))\n\n        # Visit methods\n        self._class_stack.append(node.name)\n        self.generic_visit(node)\n        self._class_stack.pop()", "chunk_type": "function", "line_start": 280, "line_end": 304, "language": "python", "name": "visit_ClassDef"}, "720a713f0cd9_class_DocstringSuggestion": {"id": "720a713f0cd9_class_DocstringSuggestion", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\auto_docs.py", "content": "class DocstringSuggestion:\n    \"\"\"A suggested docstring for a function or class.\"\"\"\n    path: Path\n    name: str\n    lineno: int\n    node_type: str  # 'function', 'class', 'method'\n    docstring: str\n    indent: str", "chunk_type": "class", "line_start": 27, "line_end": 34, "language": "python", "name": "DocstringSuggestion"}, "720a713f0cd9_class_DocstringAnalyzer": {"id": "720a713f0cd9_class_DocstringAnalyzer", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\auto_docs.py", "content": "class DocstringAnalyzer(ast.NodeVisitor):\n    \"\"\"Analyze a module for missing docstrings.\"\"\"\n\n    def __init__(self, path: Path, source_lines: List[str]):\n        self.path = path\n        self.source_lines = source_lines\n        self.suggestions: List[DocstringSuggestion] = []\n        self._class_stack: List[str] = []\n\n    def _get_indent(self, lineno: int) -> str:\n        \"\"\"Get the indentation of a line.\"\"\"\n        if lineno <= 0 or lineno > len(self.source_lines):\n            return \"    \"\n        line = self.source_lines[lineno - 1]\n        return line[:len(line) - len(line.lstrip())]\n\n    def visit_FunctionDef(self, node: ast.FunctionDef):\n        self._check_function(node)\n        self.generic_visit(node)\n\n    def visit_AsyncFunctionDef(self, node: ast.AsyncFunctionDef):\n        self._check_function(node)\n        self.generic_visit(node)\n\n    def _check_function(self, node: ast.FunctionDef | ast.AsyncFunctionDef):\n        \"\"\"Check if a function needs a docstring.\"\"\"\n        # Ski", "chunk_type": "class", "line_start": 229, "line_end": 304, "language": "python", "name": "DocstringAnalyzer"}, "77ac498b8e58_file": {"id": "77ac498b8e58_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\auto_learn.py", "content": "\"\"\"\nAuto-Learning Integration\n=========================\nAutomatic recording of tool outcomes for continuous improvement.\n\nUsage:\n    Import and wrap tool functions for auto-learning.\n\"\"\"\n\nfrom pathlib import Path\nfrom typing import Any, Callable, Optional\nimport functools\nimport sys\nimport traceback\n\n# Import learning system\ntry:\n    from .learning import get_store, record_feedback, record_error as _record_error\nexcept ImportError:\n    # Fallback if not running as module\n    def record_feedback(*args, **kwargs): pass\n    def _record_error(*args, **kwargs): pass\n\n\ndef auto_learn(tool_name: str):\n    \"\"\"Decorator to auto-record tool outcomes.\"\"\"\n    def decorator(func: Callable) -> Callable:\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs) -> Any:\n            try:\n                result = func(*args, **kwargs)\n\n                # Record success\n                context = f\"args={args[:2]}\" if args else \"\"\n                record_feedback(tool_name, 'success', context)\n\n                return result\n            except Exception as e:\n                # Record failure\n                tb = traceback.format_exc()\n                record_error(\n                    error_type=type(e).__name__,\n                    pattern=str(e)[:100],\n                    fix=\"\",\n                    context=f\"Tool: {tool_name}\"\n                )\n                record_feedback(tool_name, 'failure', str(e)[:100])\n                raise\n\n        return wrapper\n    return decorator\n\n\ndef record_error(\n    error_type: str,\n    pattern: str,\n    fix: str = \"\",\n    context: str = \"\"\n):\n    \"\"\"Record an error for learning.\"\"\"\n    try:\n        from .learning import get_store\n        store = get_store()\n        store.record_error(error_type, pattern, fix, context)\n    except Exception:\n        pass  # Silent fail for learning\n\n\ndef record_correction(before: str, after: str, context: str = \"\"):\n    \"\"\"Record a user correction for learning.\"\"\"\n    try:\n        from .learning import get_sto", "chunk_type": "file", "line_start": 1, "line_end": 138, "language": "python", "name": "auto_learn.py"}, "77ac498b8e58_func_auto_learn": {"id": "77ac498b8e58_func_auto_learn", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\auto_learn.py", "content": "def auto_learn(tool_name: str):\n    \"\"\"Decorator to auto-record tool outcomes.\"\"\"\n    def decorator(func: Callable) -> Callable:\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs) -> Any:\n            try:\n                result = func(*args, **kwargs)\n\n                # Record success\n                context = f\"args={args[:2]}\" if args else \"\"\n                record_feedback(tool_name, 'success', context)\n\n                return result\n            except Exception as e:\n                # Record failure\n                tb = traceback.format_exc()\n                record_error(\n                    error_type=type(e).__name__,\n                    pattern=str(e)[:100],\n                    fix=\"\",\n                    context=f\"Tool: {tool_name}\"\n                )\n                record_feedback(tool_name, 'failure', str(e)[:100])\n                raise\n\n        return wrapper\n    return decorator", "chunk_type": "function", "line_start": 25, "line_end": 51, "language": "python", "name": "auto_learn"}, "77ac498b8e58_func_record_error": {"id": "77ac498b8e58_func_record_error", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\auto_learn.py", "content": "def record_error(\n    error_type: str,\n    pattern: str,\n    fix: str = \"\",\n    context: str = \"\"\n):\n    \"\"\"Record an error for learning.\"\"\"\n    try:\n        from .learning import get_store\n        store = get_store()\n        store.record_error(error_type, pattern, fix, context)\n    except Exception:\n        pass  # Silent fail for learning", "chunk_type": "function", "line_start": 54, "line_end": 66, "language": "python", "name": "record_error"}, "77ac498b8e58_func_record_correction": {"id": "77ac498b8e58_func_record_correction", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\auto_learn.py", "content": "def record_correction(before: str, after: str, context: str = \"\"):\n    \"\"\"Record a user correction for learning.\"\"\"\n    try:\n        from .learning import get_store\n        store = get_store()\n        store.record_feedback(\n            action='correction',\n            outcome='applied',\n            context=f\"Before: {before[:50]}... After: {after[:50]}...\",\n            details={'before': before, 'after': after}\n        )\n    except Exception:\n        pass", "chunk_type": "function", "line_start": 69, "line_end": 81, "language": "python", "name": "record_correction"}, "77ac498b8e58_func_suggest_from_history": {"id": "77ac498b8e58_func_suggest_from_history", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\auto_learn.py", "content": "def suggest_from_history(error_type: str, pattern: str) -> Optional[str]:\n    \"\"\"Get fix suggestion from learning history.\"\"\"\n    try:\n        from .learning import get_store\n        store = get_store()\n        return store.suggest_fix(error_type, pattern)\n    except Exception:\n        return None", "chunk_type": "function", "line_start": 84, "line_end": 91, "language": "python", "name": "suggest_from_history"}, "77ac498b8e58_func_get_success_rate": {"id": "77ac498b8e58_func_get_success_rate", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\auto_learn.py", "content": "def get_success_rate(tool_name: str) -> float:\n    \"\"\"Get success rate for a tool.\"\"\"\n    try:\n        from .learning import get_store\n        store = get_store()\n        return store.get_action_success_rate(tool_name)\n    except Exception:\n        return 0.5  # Unknown", "chunk_type": "function", "line_start": 94, "line_end": 101, "language": "python", "name": "get_success_rate"}, "77ac498b8e58_func_main": {"id": "77ac498b8e58_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\auto_learn.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    from .utils import Console\n    Console.header(\"Auto-Learning Status\")\n\n    try:\n        from .learning import get_store\n        store = get_store()\n\n        analysis = store.analyze_patterns()\n\n        print(f\"\\nTotal feedback: {analysis['total_feedback']}\")\n        print(f\"Error patterns: {analysis['total_errors']}\")\n\n        print(\"\\n## Tool Success Rates\")\n        for action, data in analysis.get('action_outcomes', {}).items():\n            rate = data['success_rate'] * 100\n            status = \"\u2713\" if rate > 80 else \"!\" if rate > 50 else \"\u2717\"\n            print(f\"  {status} {action}: {rate:.0f}% ({data['count']} uses)\")\n\n        print(\"\\n## Common Errors\")\n        for err in analysis.get('common_errors', [])[:5]:\n            print(f\"  - [{err['type']}] {err['pattern'][:40]}...\")\n            if err.get('fix'):\n                print(f\"    Fix: {err['fix'][:40]}...\")\n\n    except Exception as e:\n        print(f\"Error loading learning data: {e}\")\n\n", "chunk_type": "function", "line_start": 104, "line_end": 133, "language": "python", "name": "main"}, "77ac498b8e58_func_decorator": {"id": "77ac498b8e58_func_decorator", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\auto_learn.py", "content": "    def decorator(func: Callable) -> Callable:\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs) -> Any:\n            try:\n                result = func(*args, **kwargs)\n\n                # Record success\n                context = f\"args={args[:2]}\" if args else \"\"\n                record_feedback(tool_name, 'success', context)\n\n                return result\n            except Exception as e:\n                # Record failure\n                tb = traceback.format_exc()\n                record_error(\n                    error_type=type(e).__name__,\n                    pattern=str(e)[:100],\n                    fix=\"\",\n                    context=f\"Tool: {tool_name}\"\n                )\n                record_feedback(tool_name, 'failure', str(e)[:100])\n                raise\n\n        return wrapper", "chunk_type": "function", "line_start": 27, "line_end": 50, "language": "python", "name": "decorator"}, "77ac498b8e58_func_record_feedback": {"id": "77ac498b8e58_func_record_feedback", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\auto_learn.py", "content": "    def record_feedback(*args, **kwargs): pass", "chunk_type": "function", "line_start": 21, "line_end": 21, "language": "python", "name": "record_feedback"}, "77ac498b8e58_func__record_error": {"id": "77ac498b8e58_func__record_error", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\auto_learn.py", "content": "    def _record_error(*args, **kwargs): pass", "chunk_type": "function", "line_start": 22, "line_end": 22, "language": "python", "name": "_record_error"}, "77ac498b8e58_func_wrapper": {"id": "77ac498b8e58_func_wrapper", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\auto_learn.py", "content": "        def wrapper(*args, **kwargs) -> Any:\n            try:\n                result = func(*args, **kwargs)\n\n                # Record success\n                context = f\"args={args[:2]}\" if args else \"\"\n                record_feedback(tool_name, 'success', context)\n\n                return result\n            except Exception as e:\n                # Record failure\n                tb = traceback.format_exc()\n                record_error(\n                    error_type=type(e).__name__,\n                    pattern=str(e)[:100],\n                    fix=\"\",\n                    context=f\"Tool: {tool_name}\"\n                )\n                record_feedback(tool_name, 'failure', str(e)[:100])\n                raise", "chunk_type": "function", "line_start": 29, "line_end": 48, "language": "python", "name": "wrapper"}, "4ad54e4ed692_file": {"id": "4ad54e4ed692_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\auto_test.py", "content": "\"\"\"\nAuto-Test Generator\n===================\nAutomatically generate pytest test stubs for Python functions and classes.\n\nUsage:\n    python auto_test.py [path] [--output-dir tests/]\n    python -m scripts.auto_test [path]\n\"\"\"\n\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import List, Dict, Optional\nimport ast\nimport sys\n\nfrom .utils import (\n    find_python_files,\n    find_project_root,\n    parse_file,\n    analyze_module,\n    FunctionInfo,\n    ClassInfo,\n    Console\n)\n\n\n@dataclass\nclass TestSuite:\n    \"\"\"Generated test suite for a module.\"\"\"\n    module_path: Path\n    module_name: str\n    test_imports: List[str] = field(default_factory=list)\n    test_functions: List[str] = field(default_factory=list)\n    test_classes: List[str] = field(default_factory=list)\n\n\ndef generate_test_function(func: FunctionInfo, module_name: str) -> str:\n    \"\"\"\n    Generate a pytest test function for a given function.\n\n    Args:\n        func: Function information\n        module_name: Name of the module containing the function\n\n    Returns:\n        Test function source code\n    \"\"\"\n    lines = []\n\n    # Generate test function name\n    test_name = f\"test_{func.name}\"\n\n    # Add docstring\n    lines.append(f\"def {test_name}():\")\n    lines.append(f'    \"\"\"Test {func.name} function.\"\"\"')\n\n    # Generate basic test structure\n    if func.args:\n        # Generate sample arguments\n        lines.append(\"    # Arrange\")\n        for arg in func.args:\n            if arg in ('self', 'cls'):\n                continue\n\n            arg_type = func.arg_types.get(arg, '')\n            sample_value = _get_sample_value(arg, arg_type)\n            lines.append(f\"    {arg} = {sample_value}\")\n\n        lines.append(\"\")\n        lines.append(\"    # Act\")\n\n        # Generate function call\n        call_args = [a for a in func.args if a not in ('self', 'cls')]\n        if call_args:\n            args_str = \", \".join(call_args)\n            lines.append(f\"    result = {module_name}.{func.name}({ar", "chunk_type": "file", "line_start": 1, "line_end": 439, "language": "python", "name": "auto_test.py"}, "4ad54e4ed692_func_generate_test_function": {"id": "4ad54e4ed692_func_generate_test_function", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\auto_test.py", "content": "def generate_test_function(func: FunctionInfo, module_name: str) -> str:\n    \"\"\"\n    Generate a pytest test function for a given function.\n\n    Args:\n        func: Function information\n        module_name: Name of the module containing the function\n\n    Returns:\n        Test function source code\n    \"\"\"\n    lines = []\n\n    # Generate test function name\n    test_name = f\"test_{func.name}\"\n\n    # Add docstring\n    lines.append(f\"def {test_name}():\")\n    lines.append(f'    \"\"\"Test {func.name} function.\"\"\"')\n\n    # Generate basic test structure\n    if func.args:\n        # Generate sample arguments\n        lines.append(\"    # Arrange\")\n        for arg in func.args:\n            if arg in ('self', 'cls'):\n                continue\n\n            arg_type = func.arg_types.get(arg, '')\n            sample_value = _get_sample_value(arg, arg_type)\n            lines.append(f\"    {arg} = {sample_value}\")\n\n        lines.append(\"\")\n        lines.append(\"    # Act\")\n\n        # Generate function call\n     ", "chunk_type": "function", "line_start": 38, "line_end": 98, "language": "python", "name": "generate_test_function"}, "4ad54e4ed692_func_generate_edge_case_tests": {"id": "4ad54e4ed692_func_generate_edge_case_tests", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\auto_test.py", "content": "def generate_edge_case_tests(func: FunctionInfo, module_name: str) -> List[str]:\n    \"\"\"\n    Generate edge case tests for a function.\n\n    Args:\n        func: Function information\n        module_name: Module name\n\n    Returns:\n        List of edge case test functions\n    \"\"\"\n    tests = []\n\n    for arg in func.args:\n        if arg in ('self', 'cls'):\n            continue\n\n        arg_type = func.arg_types.get(arg, '')\n\n        # Test with None if Optional\n        if 'Optional' in arg_type or 'None' in arg_type:\n            test_lines = [\n                f\"def test_{func.name}_with_{arg}_none():\",\n                f'    \"\"\"Test {func.name} with None {arg}.\"\"\"',\n                f\"    # This should handle None gracefully\",\n                f\"    try:\",\n                f\"        result = {module_name}.{func.name}({arg}=None)\",\n                f\"        # Assert expected behavior with None\",\n                f\"    except (TypeError, ValueError) as e:\",\n                f\"        pass  # Expecte", "chunk_type": "function", "line_start": 101, "line_end": 148, "language": "python", "name": "generate_edge_case_tests"}, "4ad54e4ed692_func_generate_test_class": {"id": "4ad54e4ed692_func_generate_test_class", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\auto_test.py", "content": "def generate_test_class(cls: ClassInfo, module_name: str) -> str:\n    \"\"\"\n    Generate a pytest test class.\n\n    Args:\n        cls: Class information\n        module_name: Module name\n\n    Returns:\n        Test class source code\n    \"\"\"\n    lines = []\n\n    test_class_name = f\"Test{cls.name}\"\n\n    lines.append(f\"class {test_class_name}:\")\n    lines.append(f'    \"\"\"Tests for {cls.name} class.\"\"\"')\n    lines.append(\"\")\n\n    # Add fixture for class instance\n    lines.append(\"    @pytest.fixture\")\n    lines.append(\"    def instance(self):\")\n    lines.append(f'        \"\"\"Create a {cls.name} instance for testing.\"\"\"')\n    lines.append(f\"        return {module_name}.{cls.name}()  # TODO: Add constructor args\")\n    lines.append(\"\")\n\n    # Add test for instantiation\n    lines.append(\"    def test_instantiation(self):\")\n    lines.append(f'        \"\"\"Test {cls.name} can be instantiated.\"\"\"')\n    lines.append(f\"        obj = {module_name}.{cls.name}()  # TODO: Add constructor args\")\n    lines.append", "chunk_type": "function", "line_start": 151, "line_end": 193, "language": "python", "name": "generate_test_class"}, "4ad54e4ed692_func__generate_method_test": {"id": "4ad54e4ed692_func__generate_method_test", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\auto_test.py", "content": "def _generate_method_test(method: FunctionInfo, class_name: str) -> List[str]:\n    \"\"\"Generate test for a class method.\"\"\"\n    lines = []\n\n    lines.append(f\"    def test_{method.name}(self, instance):\")\n    lines.append(f'        \"\"\"Test {class_name}.{method.name} method.\"\"\"')\n\n    # Generate method call\n    call_args = [a for a in method.args if a not in ('self', 'cls')]\n    if call_args:\n        lines.append(\"        # Arrange\")\n        for arg in call_args:\n            arg_type = method.arg_types.get(arg, '')\n            sample_value = _get_sample_value(arg, arg_type)\n            lines.append(f\"        {arg} = {sample_value}\")\n\n        lines.append(\"\")\n        lines.append(\"        # Act\")\n        args_str = \", \".join(call_args)\n        lines.append(f\"        result = instance.{method.name}({args_str})\")\n    else:\n        lines.append(\"        # Act\")\n        lines.append(f\"        result = instance.{method.name}()\")\n\n    lines.append(\"\")\n    lines.append(\"        # Assert\")\n    li", "chunk_type": "function", "line_start": 196, "line_end": 225, "language": "python", "name": "_generate_method_test"}, "4ad54e4ed692_func__get_sample_value": {"id": "4ad54e4ed692_func__get_sample_value", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\auto_test.py", "content": "def _get_sample_value(arg_name: str, arg_type: str) -> str:\n    \"\"\"Get a sample value for a parameter.\"\"\"\n    type_lower = arg_type.lower()\n\n    if 'str' in type_lower:\n        return f'\"test_{arg_name}\"'\n    elif 'int' in type_lower:\n        return \"42\"\n    elif 'float' in type_lower:\n        return \"3.14\"\n    elif 'bool' in type_lower:\n        return \"True\"\n    elif 'list' in type_lower:\n        return \"[]\"\n    elif 'dict' in type_lower:\n        return \"{}\"\n    elif 'path' in type_lower or 'path' in arg_name.lower():\n        return 'Path(\".\")'\n    elif 'none' in type_lower:\n        return \"None\"\n    else:\n        # Try to infer from name\n        if 'path' in arg_name.lower():\n            return 'Path(\".\")'\n        elif 'name' in arg_name.lower():\n            return '\"test_name\"'\n        elif 'id' in arg_name.lower():\n            return '\"test_id\"'\n        elif 'count' in arg_name.lower() or 'num' in arg_name.lower():\n            return \"10\"\n        elif 'flag' in arg_name.lower() or ", "chunk_type": "function", "line_start": 228, "line_end": 261, "language": "python", "name": "_get_sample_value"}, "4ad54e4ed692_func__generate_assertion": {"id": "4ad54e4ed692_func__generate_assertion", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\auto_test.py", "content": "def _generate_assertion(return_type: str) -> str:\n    \"\"\"Generate an assertion based on return type.\"\"\"\n    type_lower = return_type.lower()\n\n    if 'bool' in type_lower:\n        return \"assert isinstance(result, bool)\"\n    elif 'str' in type_lower:\n        return \"assert isinstance(result, str)\"\n    elif 'int' in type_lower:\n        return \"assert isinstance(result, int)\"\n    elif 'float' in type_lower:\n        return \"assert isinstance(result, (int, float))\"\n    elif 'list' in type_lower:\n        return \"assert isinstance(result, list)\"\n    elif 'dict' in type_lower:\n        return \"assert isinstance(result, dict)\"\n    elif 'none' in type_lower:\n        return \"assert result is None\"\n    elif 'optional' in type_lower:\n        return \"# Result may be None\"\n    else:\n        return \"assert result is not None  # TODO: Add specific assertion\"", "chunk_type": "function", "line_start": 264, "line_end": 285, "language": "python", "name": "_generate_assertion"}, "4ad54e4ed692_func_generate_test_file": {"id": "4ad54e4ed692_func_generate_test_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\auto_test.py", "content": "def generate_test_file(module_path: Path, output_dir: Path = None) -> Optional[Path]:\n    \"\"\"\n    Generate a test file for a Python module.\n\n    Args:\n        module_path: Path to the module\n        output_dir: Output directory for test files\n\n    Returns:\n        Path to generated test file, or None if no tests generated\n    \"\"\"\n    module_info = analyze_module(module_path)\n    if module_info is None:\n        return None\n\n    # Skip if no public functions or classes\n    public_functions = [f for f in module_info.functions if not f.name.startswith('_')]\n    public_classes = [c for c in module_info.classes if not c.name.startswith('_')]\n\n    if not public_functions and not public_classes:\n        return None\n\n    # Generate module name\n    module_name = module_path.stem\n\n    # Build test file content\n    lines = [\n        '\"\"\"',\n        f'Tests for {module_name} module.',\n        '\"\"\"',\n        '',\n        'import pytest',\n        'from pathlib import Path',\n        '',\n        f'# Impo", "chunk_type": "function", "line_start": 288, "line_end": 363, "language": "python", "name": "generate_test_file"}, "4ad54e4ed692_func_generate_tests": {"id": "4ad54e4ed692_func_generate_tests", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\auto_test.py", "content": "def generate_tests(\n    root: Path,\n    output_dir: Path = None,\n    exclude_patterns: List[str] = None\n) -> int:\n    \"\"\"\n    Generate tests for all Python files in a directory.\n\n    Args:\n        root: Root directory\n        output_dir: Output directory for tests\n        exclude_patterns: Patterns to exclude\n\n    Returns:\n        Number of test files generated\n    \"\"\"\n    Console.info(f\"Scanning for Python files in {root}...\")\n\n    files = list(find_python_files(root, exclude_patterns))\n    Console.info(f\"Found {len(files)} Python files\")\n\n    generated = 0\n\n    for path in files:\n        # Skip test files\n        if path.name.startswith('test_') or 'tests' in path.parts:\n            continue\n\n        test_path = generate_test_file(path, output_dir)\n        if test_path:\n            Console.ok(f\"Generated: {test_path}\")\n            generated += 1\n\n    return generated", "chunk_type": "function", "line_start": 366, "line_end": 399, "language": "python", "name": "generate_tests"}, "4ad54e4ed692_func_main": {"id": "4ad54e4ed692_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\auto_test.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Auto-Test Generator\")\n\n    # Parse args\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n    output_dir = None\n\n    for i, arg in enumerate(sys.argv):\n        if arg == '--output-dir' and i + 1 < len(sys.argv):\n            output_dir = Path(sys.argv[i + 1])\n\n    # Get path\n    if args:\n        path = Path(args[0])\n    else:\n        path = find_project_root() or Path.cwd()\n\n    if not path.exists():\n        Console.fail(f\"Path not found: {path}\")\n        sys.exit(1)\n\n    Console.info(f\"Analyzing: {path}\")\n\n    generated = generate_tests(path, output_dir)\n\n    print()\n    if generated > 0:\n        Console.ok(f\"Generated {generated} test files\")\n    else:\n        Console.info(\"No new test files generated (all modules already have tests or no public code found)\")\n\n    return 0", "chunk_type": "function", "line_start": 402, "line_end": 434, "language": "python", "name": "main"}, "4ad54e4ed692_class_TestSuite": {"id": "4ad54e4ed692_class_TestSuite", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\auto_test.py", "content": "class TestSuite:\n    \"\"\"Generated test suite for a module.\"\"\"\n    module_path: Path\n    module_name: str\n    test_imports: List[str] = field(default_factory=list)\n    test_functions: List[str] = field(default_factory=list)\n    test_classes: List[str] = field(default_factory=list)", "chunk_type": "class", "line_start": 29, "line_end": 35, "language": "python", "name": "TestSuite"}, "a2d9ea88d3a1_file": {"id": "a2d9ea88d3a1_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\changelog.py", "content": "\"\"\"\nChangelog Generator\n===================\nAuto-generate changelogs from git commits using conventional commit format.\n\nUsage:\n    python changelog.py [--since v1.0.0] [--output CHANGELOG.md]\n    python -m scripts.changelog\n\"\"\"\n\nfrom collections import defaultdict\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Tuple\nimport re\nimport sys\n\nfrom .utils import (\n    find_project_root,\n    get_git_log,\n    run_git_command,\n    GitCommit,\n    Console\n)\n\n\n@dataclass\nclass ChangelogEntry:\n    \"\"\"A single changelog entry.\"\"\"\n    commit_type: str\n    scope: Optional[str]\n    description: str\n    commit_hash: str\n    breaking: bool = False\n    issues: List[str] = field(default_factory=list)\n\n\n@dataclass\nclass ChangelogVersion:\n    \"\"\"A version section in the changelog.\"\"\"\n    version: str\n    date: str\n    entries: Dict[str, List[ChangelogEntry]] = field(default_factory=lambda: defaultdict(list))\n    breaking_changes: List[str] = field(default_factory=list)\n\n\n# Conventional commit types\nCOMMIT_TYPES = {\n    'feat': 'Features',\n    'fix': 'Bug Fixes',\n    'docs': 'Documentation',\n    'style': 'Styles',\n    'refactor': 'Code Refactoring',\n    'perf': 'Performance Improvements',\n    'test': 'Tests',\n    'build': 'Build System',\n    'ci': 'CI/CD',\n    'chore': 'Chores',\n    'revert': 'Reverts',\n}\n\n# Regex for parsing conventional commits\nCONVENTIONAL_COMMIT_PATTERN = re.compile(\n    r'^(?P<type>feat|fix|docs|style|refactor|perf|test|build|ci|chore|revert)'\n    r'(?:\\((?P<scope>[^)]+)\\))?'\n    r'(?P<breaking>!)?'\n    r':\\s*'\n    r'(?P<description>.+)$',\n    re.IGNORECASE\n)\n\n# Pattern for issue references\nISSUE_PATTERN = re.compile(r'#(\\d+)')\n\n\ndef parse_commit_message(message: str) -> Optional[ChangelogEntry]:\n    \"\"\"\n    Parse a conventional commit message.\n\n    Args:\n        message: Commit message\n\n    Returns:\n        ChangelogEntry or None if not conventional format\n    \"\"\"\n    match = CONVENTIONAL_COMMIT_PATTERN.mat", "chunk_type": "file", "line_start": 1, "line_end": 368, "language": "python", "name": "changelog.py"}, "a2d9ea88d3a1_func_parse_commit_message": {"id": "a2d9ea88d3a1_func_parse_commit_message", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\changelog.py", "content": "def parse_commit_message(message: str) -> Optional[ChangelogEntry]:\n    \"\"\"\n    Parse a conventional commit message.\n\n    Args:\n        message: Commit message\n\n    Returns:\n        ChangelogEntry or None if not conventional format\n    \"\"\"\n    match = CONVENTIONAL_COMMIT_PATTERN.match(message.strip())\n    if not match:\n        return None\n\n    groups = match.groupdict()\n\n    # Extract issue references\n    issues = ISSUE_PATTERN.findall(message)\n\n    return ChangelogEntry(\n        commit_type=groups['type'].lower(),\n        scope=groups['scope'],\n        description=groups['description'].strip(),\n        commit_hash=\"\",  # Will be set later\n        breaking=bool(groups['breaking']),\n        issues=issues\n    )", "chunk_type": "function", "line_start": 76, "line_end": 102, "language": "python", "name": "parse_commit_message"}, "a2d9ea88d3a1_func_get_git_tags": {"id": "a2d9ea88d3a1_func_get_git_tags", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\changelog.py", "content": "def get_git_tags() -> List[Tuple[str, str]]:\n    \"\"\"Get all git tags with their dates.\"\"\"\n    output = run_git_command(['tag', '-l', '--format=%(refname:short)|%(creatordate:short)'])\n    if not output:\n        return []\n\n    tags = []\n    for line in output.split('\\n'):\n        if '|' in line:\n            tag, date = line.split('|', 1)\n            tags.append((tag.strip(), date.strip()))\n\n    return tags", "chunk_type": "function", "line_start": 105, "line_end": 117, "language": "python", "name": "get_git_tags"}, "a2d9ea88d3a1_func_get_commits_since_tag": {"id": "a2d9ea88d3a1_func_get_commits_since_tag", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\changelog.py", "content": "def get_commits_since_tag(tag: str = None, cwd: Path = None) -> List[GitCommit]:\n    \"\"\"Get commits since a specific tag.\"\"\"\n    if tag:\n        args = ['log', f'{tag}..HEAD', '--format=%H|%h|%an|%ai|%s|%b', '--no-merges']\n    else:\n        args = ['log', '--format=%H|%h|%an|%ai|%s|%b', '--no-merges', '-100']\n\n    output = run_git_command(args, cwd=cwd)\n    if not output:\n        return []\n\n    commits = []\n    for entry in output.split('\\n'):\n        if not entry.strip():\n            continue\n\n        parts = entry.split('|')\n        if len(parts) >= 5:\n            commits.append(GitCommit(\n                hash=parts[0],\n                short_hash=parts[1],\n                author=parts[2],\n                date=parts[3],\n                message=parts[4],\n                body=parts[5] if len(parts) > 5 else \"\"\n            ))\n\n    return commits", "chunk_type": "function", "line_start": 120, "line_end": 147, "language": "python", "name": "get_commits_since_tag"}, "a2d9ea88d3a1_func_generate_changelog": {"id": "a2d9ea88d3a1_func_generate_changelog", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\changelog.py", "content": "def generate_changelog(\n    cwd: Path = None,\n    since_tag: str = None,\n    version: str = \"Unreleased\"\n) -> ChangelogVersion:\n    \"\"\"\n    Generate changelog from git commits.\n\n    Args:\n        cwd: Working directory\n        since_tag: Tag to start from\n        version: Version number for this release\n\n    Returns:\n        ChangelogVersion object\n    \"\"\"\n    commits = get_commits_since_tag(since_tag, cwd)\n\n    import datetime\n    changelog = ChangelogVersion(\n        version=version,\n        date=datetime.datetime.now().strftime('%Y-%m-%d')\n    )\n\n    for commit in commits:\n        entry = parse_commit_message(commit.message)\n        if entry:\n            entry.commit_hash = commit.short_hash\n\n            # Add to appropriate category\n            changelog.entries[entry.commit_type].append(entry)\n\n            # Track breaking changes\n            if entry.breaking or 'BREAKING CHANGE' in commit.body:\n                changelog.breaking_changes.append(\n                    f\"{entry.descr", "chunk_type": "function", "line_start": 150, "line_end": 197, "language": "python", "name": "generate_changelog"}, "a2d9ea88d3a1_func_format_changelog_markdown": {"id": "a2d9ea88d3a1_func_format_changelog_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\changelog.py", "content": "def format_changelog_markdown(\n    changelog: ChangelogVersion,\n    include_hash: bool = True,\n    repo_url: str = None\n) -> str:\n    \"\"\"\n    Format changelog as Markdown.\n\n    Args:\n        changelog: ChangelogVersion object\n        include_hash: Whether to include commit hashes\n        repo_url: Repository URL for linking\n\n    Returns:\n        Markdown formatted changelog\n    \"\"\"\n    lines = [\n        f\"## [{changelog.version}] - {changelog.date}\",\n        \"\",\n    ]\n\n    # Breaking changes first\n    if changelog.breaking_changes:\n        lines.extend([\n            \"### BREAKING CHANGES\",\n            \"\",\n        ])\n        for change in changelog.breaking_changes:\n            lines.append(f\"- {change}\")\n        lines.append(\"\")\n\n    # Categorized changes\n    category_order = ['feat', 'fix', 'perf', 'refactor', 'docs', 'test', 'build', 'ci', 'chore', 'other']\n\n    for category in category_order:\n        entries = changelog.entries.get(category, [])\n        if not entries:\n            c", "chunk_type": "function", "line_start": 200, "line_end": 273, "language": "python", "name": "format_changelog_markdown"}, "a2d9ea88d3a1_func_update_changelog_file": {"id": "a2d9ea88d3a1_func_update_changelog_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\changelog.py", "content": "def update_changelog_file(\n    changelog_path: Path,\n    new_content: str,\n    prepend: bool = True\n) -> None:\n    \"\"\"\n    Update a changelog file with new content.\n\n    Args:\n        changelog_path: Path to CHANGELOG.md\n        new_content: New content to add\n        prepend: Whether to prepend (True) or append\n    \"\"\"\n    header = \"# Changelog\\n\\nAll notable changes to this project will be documented in this file.\\n\\n\"\n\n    if changelog_path.exists():\n        with open(changelog_path, 'r', encoding='utf-8') as f:\n            existing = f.read()\n\n        # Remove header if present\n        if existing.startswith(\"# Changelog\"):\n            lines = existing.split('\\n')\n            # Find first version heading\n            for i, line in enumerate(lines):\n                if line.startswith('## '):\n                    existing = '\\n'.join(lines[i:])\n                    break\n\n        if prepend:\n            content = header + new_content + \"\\n\" + existing\n        else:\n            content ", "chunk_type": "function", "line_start": 276, "line_end": 312, "language": "python", "name": "update_changelog_file"}, "a2d9ea88d3a1_func_main": {"id": "a2d9ea88d3a1_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\changelog.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Changelog Generator\")\n\n    # Parse args\n    since_tag = None\n    output_file = None\n    version = \"Unreleased\"\n\n    args = sys.argv[1:]\n    i = 0\n    while i < len(args):\n        if args[i] == '--since' and i + 1 < len(args):\n            since_tag = args[i + 1]\n            i += 2\n        elif args[i] == '--output' and i + 1 < len(args):\n            output_file = Path(args[i + 1])\n            i += 2\n        elif args[i] == '--version' and i + 1 < len(args):\n            version = args[i + 1]\n            i += 2\n        else:\n            i += 1\n\n    # Find project root\n    cwd = find_project_root() or Path.cwd()\n\n    Console.info(f\"Analyzing: {cwd}\")\n    if since_tag:\n        Console.info(f\"Since tag: {since_tag}\")\n\n    # Generate changelog\n    changelog = generate_changelog(cwd, since_tag, version)\n\n    # Count entries\n    total_entries = sum(len(entries) for entries in changelog.entries.values())\n    Console.info(f\"Found {total_e", "chunk_type": "function", "line_start": 315, "line_end": 363, "language": "python", "name": "main"}, "a2d9ea88d3a1_class_ChangelogEntry": {"id": "a2d9ea88d3a1_class_ChangelogEntry", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\changelog.py", "content": "class ChangelogEntry:\n    \"\"\"A single changelog entry.\"\"\"\n    commit_type: str\n    scope: Optional[str]\n    description: str\n    commit_hash: str\n    breaking: bool = False\n    issues: List[str] = field(default_factory=list)", "chunk_type": "class", "line_start": 28, "line_end": 35, "language": "python", "name": "ChangelogEntry"}, "a2d9ea88d3a1_class_ChangelogVersion": {"id": "a2d9ea88d3a1_class_ChangelogVersion", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\changelog.py", "content": "class ChangelogVersion:\n    \"\"\"A version section in the changelog.\"\"\"\n    version: str\n    date: str\n    entries: Dict[str, List[ChangelogEntry]] = field(default_factory=lambda: defaultdict(list))\n    breaking_changes: List[str] = field(default_factory=list)", "chunk_type": "class", "line_start": 39, "line_end": 44, "language": "python", "name": "ChangelogVersion"}, "c3d3bc62560c_file": {"id": "c3d3bc62560c_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\cicd.py", "content": "\"\"\"\nCI/CD Pipeline Generator\n========================\nGenerate CI/CD pipelines for various providers.\n\nUsage:\n    python mcp.py github-action\n    python mcp.py pipeline --gitlab\n\"\"\"\n\nfrom dataclasses import dataclass\nfrom pathlib import Path\nfrom typing import Dict, List, Optional\nimport json\nimport sys\n\nfrom .utils import Console, find_project_root\n\n\n@dataclass\nclass ProjectType:\n    \"\"\"Detected project type.\"\"\"\n    language: str\n    framework: Optional[str]\n    package_manager: str\n    test_command: str\n    lint_command: str\n    has_docker: bool\n\n\n# GitHub Actions Templates\nGITHUB_PYTHON = '''name: Python CI\n\non:\n  push:\n    branches: [ main, master ]\n  pull_request:\n    branches: [ main, master ]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        python-version: ['3.11']\n\n    steps:\n    - uses: actions/checkout@v4\n\n    - name: Set up Python ${{ matrix.python-version }}\n      uses: actions/setup-python@v5\n      with:\n        python-version: ${{ matrix.python-version }}\n\n    - name: Install dependencies\n      run: |\n        python -m pip install --upgrade pip\n        pip install -r requirements.txt\n        pip install pytest pytest-cov flake8 mypy\n\n    - name: Lint with flake8\n      run: flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics\n\n    - name: Type check with mypy\n      run: mypy . --ignore-missing-imports || true\n\n    - name: Test with pytest\n      run: pytest --cov=. --cov-report=xml\n\n    - name: Upload coverage\n      uses: codecov/codecov-action@v3\n      with:\n        files: ./coverage.xml\n'''\n\nGITHUB_NODE = '''name: Node.js CI\n\non:\n  push:\n    branches: [ main, master ]\n  pull_request:\n    branches: [ main, master ]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        node-version: ['18.x', '20.x']\n\n    steps:\n    - uses: actions/checkout@v4\n\n    - name: Use Node.js ${{ matrix.node-version }}\n      uses: actions/setup-node@v4\n      with:\n        node-version: ${{ matrix.node-version }}\n ", "chunk_type": "file", "line_start": 1, "line_end": 369, "language": "python", "name": "cicd.py"}, "c3d3bc62560c_func_detect_project_type": {"id": "c3d3bc62560c_func_detect_project_type", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\cicd.py", "content": "def detect_project_type(root: Path) -> ProjectType:\n    \"\"\"Detect project type from files.\"\"\"\n    # Check for Python\n    has_requirements = (root / 'requirements.txt').exists()\n    has_setup_py = (root / 'setup.py').exists()\n    has_pyproject = (root / 'pyproject.toml').exists()\n\n    # Check for Node\n    has_package_json = (root / 'package.json').exists()\n\n    # Check for Docker\n    has_docker = (root / 'Dockerfile').exists()\n\n    if has_requirements or has_setup_py or has_pyproject:\n        framework = None\n        if has_pyproject:\n            content = (root / 'pyproject.toml').read_text()\n            if 'fastapi' in content.lower():\n                framework = 'fastapi'\n            elif 'django' in content.lower():\n                framework = 'django'\n            elif 'flask' in content.lower():\n                framework = 'flask'\n\n        return ProjectType(\n            language='python',\n            framework=framework,\n            package_manager='pip',\n            test_command=", "chunk_type": "function", "line_start": 220, "line_end": 284, "language": "python", "name": "detect_project_type"}, "c3d3bc62560c_func_generate_github_action": {"id": "c3d3bc62560c_func_generate_github_action", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\cicd.py", "content": "def generate_github_action(project_type: ProjectType) -> str:\n    \"\"\"Generate GitHub Actions workflow.\"\"\"\n    if project_type.has_docker:\n        return GITHUB_DOCKER\n\n    if project_type.language == 'python':\n        return GITHUB_PYTHON\n\n    if project_type.language == 'node':\n        return GITHUB_NODE\n\n    return GITHUB_PYTHON  # Default", "chunk_type": "function", "line_start": 287, "line_end": 298, "language": "python", "name": "generate_github_action"}, "c3d3bc62560c_func_generate_gitlab_ci": {"id": "c3d3bc62560c_func_generate_gitlab_ci", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\cicd.py", "content": "def generate_gitlab_ci(project_type: ProjectType) -> str:\n    \"\"\"Generate GitLab CI config.\"\"\"\n    if project_type.language == 'python':\n        return GITLAB_PYTHON\n\n    if project_type.language == 'node':\n        return GITLAB_NODE\n\n    return GITLAB_PYTHON  # Default", "chunk_type": "function", "line_start": 301, "line_end": 309, "language": "python", "name": "generate_gitlab_ci"}, "c3d3bc62560c_func_write_github_action": {"id": "c3d3bc62560c_func_write_github_action", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\cicd.py", "content": "def write_github_action(root: Path) -> Path:\n    \"\"\"Write GitHub Actions workflow to file.\"\"\"\n    project_type = detect_project_type(root)\n    content = generate_github_action(project_type)\n\n    workflow_dir = root / '.github' / 'workflows'\n    workflow_dir.mkdir(parents=True, exist_ok=True)\n\n    workflow_file = workflow_dir / 'ci.yml'\n    workflow_file.write_text(content)\n\n    return workflow_file", "chunk_type": "function", "line_start": 312, "line_end": 323, "language": "python", "name": "write_github_action"}, "c3d3bc62560c_func_write_gitlab_ci": {"id": "c3d3bc62560c_func_write_gitlab_ci", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\cicd.py", "content": "def write_gitlab_ci(root: Path) -> Path:\n    \"\"\"Write GitLab CI config to file.\"\"\"\n    project_type = detect_project_type(root)\n    content = generate_gitlab_ci(project_type)\n\n    ci_file = root / '.gitlab-ci.yml'\n    ci_file.write_text(content)\n\n    return ci_file", "chunk_type": "function", "line_start": 326, "line_end": 334, "language": "python", "name": "write_gitlab_ci"}, "c3d3bc62560c_func_main": {"id": "c3d3bc62560c_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\cicd.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"CI/CD Generator\")\n\n    root = find_project_root() or Path.cwd()\n    project_type = detect_project_type(root)\n\n    Console.info(f\"Detected: {project_type.language}\")\n    if project_type.framework:\n        Console.info(f\"Framework: {project_type.framework}\")\n    if project_type.has_docker:\n        Console.info(\"Docker: Yes\")\n\n    if '--gitlab' in sys.argv:\n        path = write_gitlab_ci(root)\n        Console.ok(f\"Generated: {path}\")\n        return 0\n\n    if '--print' in sys.argv:\n        content = generate_github_action(project_type)\n        print(content)\n        return 0\n\n    # Default: GitHub Actions\n    path = write_github_action(root)\n    Console.ok(f\"Generated: {path}\")\n\n    return 0", "chunk_type": "function", "line_start": 337, "line_end": 364, "language": "python", "name": "main"}, "c3d3bc62560c_class_ProjectType": {"id": "c3d3bc62560c_class_ProjectType", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\cicd.py", "content": "class ProjectType:\n    \"\"\"Detected project type.\"\"\"\n    language: str\n    framework: Optional[str]\n    package_manager: str\n    test_command: str\n    lint_command: str\n    has_docker: bool", "chunk_type": "class", "line_start": 21, "line_end": 28, "language": "python", "name": "ProjectType"}, "5a1ba5168191_file": {"id": "5a1ba5168191_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\config_index.py", "content": "\"\"\"\nConfig Index\n=============\nIndex configuration files, env vars, and settings.\n\nUsage:\n    python mcp.py config-index\n    python mcp.py config-index --env\n\"\"\"\n\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Set\nimport json\nimport os\nimport re\nimport sys\n\nfrom .utils import Console, find_project_root\n\n\n@dataclass\nclass ConfigItem:\n    \"\"\"A configuration item.\"\"\"\n    name: str\n    value: Optional[str]\n    source: str  # file path\n    type: str  # 'env', 'json', 'yaml', 'ini', 'toml'\n    line: int = 0\n\n\n# Patterns for finding env var usage in code\nENV_PATTERNS = [\n    r'os\\.environ\\[[\\'\"]([\\w_]+)[\\'\"]\\]',\n    r'os\\.environ\\.get\\([\\'\"]([\\w_]+)[\\'\"]',\n    r'os\\.getenv\\([\\'\"]([\\w_]+)[\\'\"]',\n    r'config\\[[\\'\"]([\\w_]+)[\\'\"]\\]',\n    r'settings\\.([\\w_]+)',\n    r'process\\.env\\.([\\w_]+)',\n    r'\\$\\{([\\w_]+)\\}',\n]\n\n\ndef find_config_files(root: Path) -> List[Path]:\n    \"\"\"Find configuration files.\"\"\"\n    patterns = [\n        '.env', '.env.*', 'config.json', 'config.yaml', 'config.yml',\n        'settings.json', 'settings.yaml', 'settings.yml', 'settings.py',\n        'pyproject.toml', 'setup.cfg', 'requirements.txt',\n        'package.json', 'tsconfig.json',\n        '*.ini', '*.toml', '*.conf'\n    ]\n\n    files = []\n\n    for pattern in patterns:\n        for path in root.glob(pattern):\n            if path.is_file() and '.git' not in str(path):\n                files.append(path)\n        for path in root.glob(f'**/{pattern}'):\n            if path.is_file() and '.git' not in str(path) and 'node_modules' not in str(path):\n                files.append(path)\n\n    return list(set(files))\n\n\ndef parse_env_file(file_path: Path) -> List[ConfigItem]:\n    \"\"\"Parse .env file.\"\"\"\n    items = []\n\n    try:\n        with open(file_path, 'r', encoding='utf-8') as f:\n            for i, line in enumerate(f, 1):\n                line = line.strip()\n                if line and not line.startswith('#'):\n                    if '=' in line:\n        ", "chunk_type": "file", "line_start": 1, "line_end": 247, "language": "python", "name": "config_index.py"}, "5a1ba5168191_func_find_config_files": {"id": "5a1ba5168191_func_find_config_files", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\config_index.py", "content": "def find_config_files(root: Path) -> List[Path]:\n    \"\"\"Find configuration files.\"\"\"\n    patterns = [\n        '.env', '.env.*', 'config.json', 'config.yaml', 'config.yml',\n        'settings.json', 'settings.yaml', 'settings.yml', 'settings.py',\n        'pyproject.toml', 'setup.cfg', 'requirements.txt',\n        'package.json', 'tsconfig.json',\n        '*.ini', '*.toml', '*.conf'\n    ]\n\n    files = []\n\n    for pattern in patterns:\n        for path in root.glob(pattern):\n            if path.is_file() and '.git' not in str(path):\n                files.append(path)\n        for path in root.glob(f'**/{pattern}'):\n            if path.is_file() and '.git' not in str(path) and 'node_modules' not in str(path):\n                files.append(path)\n\n    return list(set(files))", "chunk_type": "function", "line_start": 44, "line_end": 64, "language": "python", "name": "find_config_files"}, "5a1ba5168191_func_parse_env_file": {"id": "5a1ba5168191_func_parse_env_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\config_index.py", "content": "def parse_env_file(file_path: Path) -> List[ConfigItem]:\n    \"\"\"Parse .env file.\"\"\"\n    items = []\n\n    try:\n        with open(file_path, 'r', encoding='utf-8') as f:\n            for i, line in enumerate(f, 1):\n                line = line.strip()\n                if line and not line.startswith('#'):\n                    if '=' in line:\n                        name, _, value = line.partition('=')\n                        items.append(ConfigItem(\n                            name=name.strip(),\n                            value=value.strip().strip('\"\\''),\n                            source=str(file_path),\n                            type='env',\n                            line=i\n                        ))\n    except Exception:\n        pass\n\n    return items", "chunk_type": "function", "line_start": 67, "line_end": 88, "language": "python", "name": "parse_env_file"}, "5a1ba5168191_func_parse_json_file": {"id": "5a1ba5168191_func_parse_json_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\config_index.py", "content": "def parse_json_file(file_path: Path) -> List[ConfigItem]:\n    \"\"\"Parse JSON config file.\"\"\"\n    items = []\n\n    try:\n        with open(file_path, 'r', encoding='utf-8') as f:\n            data = json.load(f)\n\n        def extract(obj, prefix=''):\n            for key, value in obj.items() if isinstance(obj, dict) else []:\n                full_key = f\"{prefix}.{key}\" if prefix else key\n                if isinstance(value, dict):\n                    extract(value, full_key)\n                else:\n                    items.append(ConfigItem(\n                        name=full_key,\n                        value=str(value)[:50] if value is not None else None,\n                        source=str(file_path),\n                        type='json'\n                    ))\n\n        extract(data)\n    except Exception:\n        pass\n\n    return items", "chunk_type": "function", "line_start": 91, "line_end": 116, "language": "python", "name": "parse_json_file"}, "5a1ba5168191_func_find_env_usage_in_file": {"id": "5a1ba5168191_func_find_env_usage_in_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\config_index.py", "content": "def find_env_usage_in_file(file_path: Path) -> Set[str]:\n    \"\"\"Find env var usage in a code file.\"\"\"\n    env_vars = set()\n\n    try:\n        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n            content = f.read()\n\n        for pattern in ENV_PATTERNS:\n            matches = re.findall(pattern, content)\n            env_vars.update(matches)\n    except Exception:\n        pass\n\n    return env_vars", "chunk_type": "function", "line_start": 119, "line_end": 133, "language": "python", "name": "find_env_usage_in_file"}, "5a1ba5168191_func_index_configs": {"id": "5a1ba5168191_func_index_configs", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\config_index.py", "content": "def index_configs(root: Path = None) -> Dict:\n    \"\"\"Build configuration index.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    Console.info(\"Indexing configuration...\")\n\n    index = {\n        \"config_files\": [],\n        \"env_vars\": {},\n        \"env_usage\": {},\n        \"missing_vars\": []\n    }\n\n    # Find and parse config files\n    config_files = find_config_files(root)\n\n    for config_path in config_files:\n        index[\"config_files\"].append(str(config_path.relative_to(root)))\n\n        if config_path.name.startswith('.env'):\n            items = parse_env_file(config_path)\n            for item in items:\n                index[\"env_vars\"][item.name] = {\n                    \"source\": item.source,\n                    \"has_value\": item.value is not None and item.value != ''\n                }\n        elif config_path.suffix == '.json':\n            items = parse_json_file(config_path)\n\n    # Find env var usage in code\n    all_used = set()\n    extensions = ['.py', '.js', '.ts']\n\n", "chunk_type": "function", "line_start": 136, "line_end": 196, "language": "python", "name": "index_configs"}, "5a1ba5168191_func_get_env_vars_for_file": {"id": "5a1ba5168191_func_get_env_vars_for_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\config_index.py", "content": "def get_env_vars_for_file(file_path: Path, root: Path = None) -> List[str]:\n    \"\"\"Get env vars used by a specific file.\"\"\"\n    return list(find_env_usage_in_file(file_path))", "chunk_type": "function", "line_start": 199, "line_end": 201, "language": "python", "name": "get_env_vars_for_file"}, "5a1ba5168191_func_main": {"id": "5a1ba5168191_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\config_index.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Config Index\")\n\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n    root = find_project_root() or Path.cwd()\n\n    if '--index' in sys.argv:\n        index_configs(root)\n        return 0\n\n    if '--env' in sys.argv:\n        index = index_configs(root)\n        print(\"\\n## Defined Environment Variables\")\n        for name, info in index[\"env_vars\"].items():\n            status = \"\u2713\" if info[\"has_value\"] else \"\u2717\"\n            print(f\"  {status} {name}\")\n        return 0\n\n    if '--missing' in sys.argv:\n        index = index_configs(root)\n        if index[\"missing_vars\"]:\n            Console.warn(\"Used but not defined:\")\n            for var in index[\"missing_vars\"]:\n                print(f\"  - {var}\")\n        else:\n            Console.ok(\"All used env vars are defined!\")\n        return 0\n\n    if args:\n        file_path = Path(args[0])\n        vars_used = get_env_vars_for_file(file_path)\n        Console.info(f\"Env vars used", "chunk_type": "function", "line_start": 204, "line_end": 242, "language": "python", "name": "main"}, "5a1ba5168191_func_extract": {"id": "5a1ba5168191_func_extract", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\config_index.py", "content": "        def extract(obj, prefix=''):\n            for key, value in obj.items() if isinstance(obj, dict) else []:\n                full_key = f\"{prefix}.{key}\" if prefix else key\n                if isinstance(value, dict):\n                    extract(value, full_key)\n                else:\n                    items.append(ConfigItem(\n                        name=full_key,\n                        value=str(value)[:50] if value is not None else None,\n                        source=str(file_path),\n                        type='json'\n                    ))", "chunk_type": "function", "line_start": 99, "line_end": 110, "language": "python", "name": "extract"}, "5a1ba5168191_class_ConfigItem": {"id": "5a1ba5168191_class_ConfigItem", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\config_index.py", "content": "class ConfigItem:\n    \"\"\"A configuration item.\"\"\"\n    name: str\n    value: Optional[str]\n    source: str  # file path\n    type: str  # 'env', 'json', 'yaml', 'ini', 'toml'\n    line: int = 0", "chunk_type": "class", "line_start": 23, "line_end": 29, "language": "python", "name": "ConfigItem"}, "774633605339_file": {"id": "774633605339_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\context.py", "content": "\"\"\"\nSmart Context Loader\n====================\nExtract relevant context from codebases for AI agents with token budgets.\n\nUsage:\n    python context.py \"query\" [path] [--tokens 4000]\n    python -m scripts.context \"authentication\" src/\n\"\"\"\n\nfrom collections import Counter\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Tuple\nimport ast\nimport math\nimport re\nimport sys\n\nfrom .utils import (\n    find_python_files,\n    find_project_root,\n    parse_file,\n    analyze_module,\n    get_changed_files,\n    run_git_command,\n    Console\n)\n\n\n@dataclass\nclass ContextItem:\n    \"\"\"A piece of context from the codebase.\"\"\"\n    path: Path\n    content: str\n    relevance_score: float\n    item_type: str  # 'function', 'class', 'file', 'docstring'\n    line_start: int\n    line_end: int\n    tokens: int  # Estimated token count\n\n\n@dataclass\nclass ContextResult:\n    \"\"\"Result of context extraction.\"\"\"\n    query: str\n    items: List[ContextItem] = field(default_factory=list)\n    total_tokens: int = 0\n    files_scanned: int = 0\n\n    def to_markdown(self) -> str:\n        \"\"\"Format context as markdown.\"\"\"\n        lines = [\n            f\"# Context for: {self.query}\",\n            \"\",\n            f\"**Files scanned:** {self.files_scanned}\",\n            f\"**Total tokens:** {self.total_tokens}\",\n            f\"**Items found:** {len(self.items)}\",\n            \"\",\n        ]\n\n        for item in self.items:\n            lines.extend([\n                f\"## {item.item_type.title()}: {item.path}:{item.line_start}\",\n                f\"**Relevance:** {item.relevance_score:.2f}\",\n                \"\",\n                \"```python\",\n                item.content,\n                \"```\",\n                \"\",\n            ])\n\n        return \"\\n\".join(lines)\n\n\ndef estimate_tokens(text: str) -> int:\n    \"\"\"Estimate token count (rough: 4 chars per token).\"\"\"\n    return len(text) // 4\n\n\ndef tokenize_query(query: str) -> List[str]:\n    \"\"\"Tokenize query into searchable terms", "chunk_type": "file", "line_start": 1, "line_end": 382, "language": "python", "name": "context.py"}, "774633605339_func_estimate_tokens": {"id": "774633605339_func_estimate_tokens", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\context.py", "content": "def estimate_tokens(text: str) -> int:\n    \"\"\"Estimate token count (rough: 4 chars per token).\"\"\"\n    return len(text) // 4", "chunk_type": "function", "line_start": 76, "line_end": 78, "language": "python", "name": "estimate_tokens"}, "774633605339_func_tokenize_query": {"id": "774633605339_func_tokenize_query", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\context.py", "content": "def tokenize_query(query: str) -> List[str]:\n    \"\"\"Tokenize query into searchable terms.\"\"\"\n    # Convert to lowercase and split on non-alphanumeric\n    terms = re.findall(r'[a-z0-9]+', query.lower())\n\n    # Expand common abbreviations\n    expansions = {\n        'auth': ['authentication', 'authorize', 'authorization'],\n        'db': ['database', 'connection'],\n        'api': ['endpoint', 'route', 'handler'],\n        'cfg': ['config', 'configuration', 'settings'],\n        'msg': ['message', 'notification'],\n        'err': ['error', 'exception'],\n        'req': ['request', 'require'],\n        'res': ['response', 'result'],\n    }\n\n    expanded = list(terms)\n    for term in terms:\n        if term in expansions:\n            expanded.extend(expansions[term])\n\n    return expanded", "chunk_type": "function", "line_start": 81, "line_end": 103, "language": "python", "name": "tokenize_query"}, "774633605339_func_calculate_tf_idf": {"id": "774633605339_func_calculate_tf_idf", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\context.py", "content": "def calculate_tf_idf(\n    terms: List[str],\n    document: str,\n    all_documents: List[str]\n) -> float:\n    \"\"\"Calculate TF-IDF relevance score.\"\"\"\n    doc_lower = document.lower()\n\n    # Term frequency in this document\n    tf_scores = []\n    for term in terms:\n        tf = doc_lower.count(term)\n        if tf > 0:\n            tf_scores.append(1 + math.log(tf))\n        else:\n            tf_scores.append(0)\n\n    if not tf_scores or sum(tf_scores) == 0:\n        return 0.0\n\n    # Inverse document frequency\n    idf_scores = []\n    for term in terms:\n        docs_with_term = sum(1 for doc in all_documents if term in doc.lower())\n        if docs_with_term > 0:\n            idf = math.log(len(all_documents) / docs_with_term)\n            idf_scores.append(idf)\n        else:\n            idf_scores.append(0)\n\n    # Combined TF-IDF\n    score = sum(tf * idf for tf, idf in zip(tf_scores, idf_scores))\n    return score", "chunk_type": "function", "line_start": 106, "line_end": 138, "language": "python", "name": "calculate_tf_idf"}, "774633605339_func_get_recent_files": {"id": "774633605339_func_get_recent_files", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\context.py", "content": "def get_recent_files(root: Path, limit: int = 10) -> List[Path]:\n    \"\"\"Get recently modified files from git.\"\"\"\n    output = run_git_command(\n        ['log', '--name-only', '--format=', '-n', '50'],\n        cwd=root\n    )\n\n    if not output:\n        return []\n\n    recent = []\n    seen = set()\n    for line in output.split('\\n'):\n        line = line.strip()\n        if line and line.endswith('.py') and line not in seen:\n            path = root / line\n            if path.exists():\n                recent.append(path)\n                seen.add(line)\n            if len(recent) >= limit:\n                break\n\n    return recent", "chunk_type": "function", "line_start": 141, "line_end": 163, "language": "python", "name": "get_recent_files"}, "774633605339_func_extract_function_context": {"id": "774633605339_func_extract_function_context", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\context.py", "content": "def extract_function_context(\n    path: Path,\n    tree: ast.Module,\n    source_lines: List[str]\n) -> List[Tuple[str, int, int, str]]:\n    \"\"\"Extract function definitions with context.\"\"\"\n    results = []\n\n    for node in ast.walk(tree):\n        if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n            # Get function signature and docstring\n            start = node.lineno - 1\n            end = node.end_lineno if node.end_lineno else start + 1\n\n            # Include signature + docstring + first few lines\n            content_lines = source_lines[start:min(end, start + 20)]\n            content = '\\n'.join(content_lines)\n\n            results.append((node.name, start + 1, end, content))\n\n    return results", "chunk_type": "function", "line_start": 166, "line_end": 186, "language": "python", "name": "extract_function_context"}, "774633605339_func_extract_class_context": {"id": "774633605339_func_extract_class_context", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\context.py", "content": "def extract_class_context(\n    path: Path,\n    tree: ast.Module,\n    source_lines: List[str]\n) -> List[Tuple[str, int, int, str]]:\n    \"\"\"Extract class definitions with context.\"\"\"\n    results = []\n\n    for node in ast.walk(tree):\n        if isinstance(node, ast.ClassDef):\n            start = node.lineno - 1\n            end = node.end_lineno if node.end_lineno else start + 1\n\n            # Include class definition + docstring + method signatures\n            content_lines = source_lines[start:min(end, start + 30)]\n            content = '\\n'.join(content_lines)\n\n            results.append((node.name, start + 1, end, content))\n\n    return results", "chunk_type": "function", "line_start": 189, "line_end": 208, "language": "python", "name": "extract_class_context"}, "774633605339_func_load_context": {"id": "774633605339_func_load_context", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\context.py", "content": "def load_context(\n    query: str,\n    root: Path,\n    token_budget: int = 4000,\n    exclude_patterns: List[str] = None\n) -> ContextResult:\n    \"\"\"\n    Load relevant context for a query.\n\n    Args:\n        query: Search query\n        root: Root directory\n        token_budget: Maximum tokens to return\n        exclude_patterns: Patterns to exclude\n\n    Returns:\n        ContextResult with relevant items\n    \"\"\"\n    result = ContextResult(query=query)\n\n    Console.info(f\"Searching for context: '{query}'\")\n\n    # Tokenize query\n    terms = tokenize_query(query)\n    Console.info(f\"Search terms: {', '.join(terms)}\")\n\n    # Get all Python files\n    files = list(find_python_files(root, exclude_patterns))\n    result.files_scanned = len(files)\n\n    Console.info(f\"Scanning {len(files)} files...\")\n\n    # Get recent files for priority boost\n    recent_files = set(get_recent_files(root))\n\n    # Load all file contents for IDF calculation\n    all_contents = []\n    file_data = []\n\n    for path in files:\n", "chunk_type": "function", "line_start": 211, "line_end": 333, "language": "python", "name": "load_context"}, "774633605339_func_main": {"id": "774633605339_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\context.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Smart Context Loader\")\n\n    # Parse args\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n\n    token_budget = 4000\n    for i, arg in enumerate(sys.argv):\n        if arg == '--tokens' and i + 1 < len(sys.argv):\n            try:\n                token_budget = int(sys.argv[i + 1])\n            except ValueError:\n                pass\n\n    if not args:\n        Console.fail(\"Usage: mcp context <query> [path] [--tokens N]\")\n        print(\"\\nExamples:\")\n        print('  mcp context \"authentication\"')\n        print('  mcp context \"database connection\" src/')\n        print('  mcp context \"api handler\" --tokens 8000')\n        return 1\n\n    query = args[0]\n\n    if len(args) > 1:\n        path = Path(args[1])\n    else:\n        path = find_project_root() or Path.cwd()\n\n    if not path.exists():\n        Console.fail(f\"Path not found: {path}\")\n        return 1\n\n    Console.info(f\"Root: {path}\")\n    Console.info(f\"Token budget: {toke", "chunk_type": "function", "line_start": 336, "line_end": 377, "language": "python", "name": "main"}, "774633605339_func_to_markdown": {"id": "774633605339_func_to_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\context.py", "content": "    def to_markdown(self) -> str:\n        \"\"\"Format context as markdown.\"\"\"\n        lines = [\n            f\"# Context for: {self.query}\",\n            \"\",\n            f\"**Files scanned:** {self.files_scanned}\",\n            f\"**Total tokens:** {self.total_tokens}\",\n            f\"**Items found:** {len(self.items)}\",\n            \"\",\n        ]\n\n        for item in self.items:\n            lines.extend([\n                f\"## {item.item_type.title()}: {item.path}:{item.line_start}\",\n                f\"**Relevance:** {item.relevance_score:.2f}\",\n                \"\",\n                \"```python\",\n                item.content,\n                \"```\",\n                \"\",\n            ])\n\n        return \"\\n\".join(lines)", "chunk_type": "function", "line_start": 51, "line_end": 73, "language": "python", "name": "to_markdown"}, "774633605339_class_ContextItem": {"id": "774633605339_class_ContextItem", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\context.py", "content": "class ContextItem:\n    \"\"\"A piece of context from the codebase.\"\"\"\n    path: Path\n    content: str\n    relevance_score: float\n    item_type: str  # 'function', 'class', 'file', 'docstring'\n    line_start: int\n    line_end: int\n    tokens: int  # Estimated token count", "chunk_type": "class", "line_start": 32, "line_end": 40, "language": "python", "name": "ContextItem"}, "774633605339_class_ContextResult": {"id": "774633605339_class_ContextResult", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\context.py", "content": "class ContextResult:\n    \"\"\"Result of context extraction.\"\"\"\n    query: str\n    items: List[ContextItem] = field(default_factory=list)\n    total_tokens: int = 0\n    files_scanned: int = 0\n\n    def to_markdown(self) -> str:\n        \"\"\"Format context as markdown.\"\"\"\n        lines = [\n            f\"# Context for: {self.query}\",\n            \"\",\n            f\"**Files scanned:** {self.files_scanned}\",\n            f\"**Total tokens:** {self.total_tokens}\",\n            f\"**Items found:** {len(self.items)}\",\n            \"\",\n        ]\n\n        for item in self.items:\n            lines.extend([\n                f\"## {item.item_type.title()}: {item.path}:{item.line_start}\",\n                f\"**Relevance:** {item.relevance_score:.2f}\",\n                \"\",\n                \"```python\",\n                item.content,\n                \"```\",\n                \"\",\n            ])\n\n        return \"\\n\".join(lines)", "chunk_type": "class", "line_start": 44, "line_end": 73, "language": "python", "name": "ContextResult"}, "ca0ad6ce63fc_file": {"id": "ca0ad6ce63fc_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\coverage_index.py", "content": "\"\"\"\nCoverage Index\n==============\nTrack and index test coverage data.\n\nUsage:\n    python mcp.py coverage [file]\n    python mcp.py coverage --uncovered\n\"\"\"\n\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Set\nimport json\nimport sys\n\nfrom .utils import Console, find_project_root\n\n\n@dataclass\nclass CoverageData:\n    \"\"\"Coverage data for a file.\"\"\"\n    file: str\n    covered_lines: List[int] = field(default_factory=list)\n    uncovered_lines: List[int] = field(default_factory=list)\n    total_lines: int = 0\n    coverage_pct: float = 0.0\n\n\ndef load_coverage_file(coverage_path: Path) -> Optional[Dict]:\n    \"\"\"Load coverage data from .coverage or coverage.json.\"\"\"\n    # Try JSON format\n    json_path = coverage_path.parent / 'coverage.json'\n    if json_path.exists():\n        try:\n            with open(json_path, 'r') as f:\n                return json.load(f)\n        except Exception:\n            pass\n\n    # Try coverage.py format\n    if coverage_path.exists():\n        try:\n            import sqlite3\n            conn = sqlite3.connect(str(coverage_path))\n            cursor = conn.cursor()\n\n            # Query coverage data\n            cursor.execute(\"SELECT file_id, path FROM file\")\n            files = {row[0]: row[1] for row in cursor.fetchall()}\n\n            cursor.execute(\"SELECT file_id, lineno FROM line_bits\")\n            lines = {}\n            for file_id, lineno in cursor.fetchall():\n                if file_id not in lines:\n                    lines[file_id] = []\n                lines[file_id].append(lineno)\n\n            conn.close()\n\n            return {\n                \"files\": {files[fid]: {\"covered\": lns} for fid, lns in lines.items() if fid in files}\n            }\n        except Exception:\n            pass\n\n    return None\n\n\ndef get_file_coverage(file_path: Path, root: Path = None) -> Optional[CoverageData]:\n    \"\"\"Get coverage data for a specific file.\"\"\"\n    root = root or find_project_root() or Path.cwd()", "chunk_type": "file", "line_start": 1, "line_end": 275, "language": "python", "name": "coverage_index.py"}, "ca0ad6ce63fc_func_load_coverage_file": {"id": "ca0ad6ce63fc_func_load_coverage_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\coverage_index.py", "content": "def load_coverage_file(coverage_path: Path) -> Optional[Dict]:\n    \"\"\"Load coverage data from .coverage or coverage.json.\"\"\"\n    # Try JSON format\n    json_path = coverage_path.parent / 'coverage.json'\n    if json_path.exists():\n        try:\n            with open(json_path, 'r') as f:\n                return json.load(f)\n        except Exception:\n            pass\n\n    # Try coverage.py format\n    if coverage_path.exists():\n        try:\n            import sqlite3\n            conn = sqlite3.connect(str(coverage_path))\n            cursor = conn.cursor()\n\n            # Query coverage data\n            cursor.execute(\"SELECT file_id, path FROM file\")\n            files = {row[0]: row[1] for row in cursor.fetchall()}\n\n            cursor.execute(\"SELECT file_id, lineno FROM line_bits\")\n            lines = {}\n            for file_id, lineno in cursor.fetchall():\n                if file_id not in lines:\n                    lines[file_id] = []\n                lines[file_id].append(lineno)\n\n        ", "chunk_type": "function", "line_start": 30, "line_end": 67, "language": "python", "name": "load_coverage_file"}, "ca0ad6ce63fc_func_get_file_coverage": {"id": "ca0ad6ce63fc_func_get_file_coverage", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\coverage_index.py", "content": "def get_file_coverage(file_path: Path, root: Path = None) -> Optional[CoverageData]:\n    \"\"\"Get coverage data for a specific file.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n    coverage_path = root / '.coverage'\n\n    data = load_coverage_file(coverage_path)\n    if not data:\n        return None\n\n    file_key = str(file_path.relative_to(root)) if file_path.is_absolute() else str(file_path)\n\n    for key, file_data in data.get('files', {}).items():\n        if file_key in key or key.endswith(file_key):\n            covered = file_data.get('covered', file_data.get('executed_lines', []))\n            total = file_data.get('total', len(covered) + len(file_data.get('missing', [])))\n            missing = file_data.get('missing', file_data.get('uncovered', []))\n\n            pct = (len(covered) / total * 100) if total > 0 else 0\n\n            return CoverageData(\n                file=file_key,\n                covered_lines=covered,\n                uncovered_lines=missing,\n              ", "chunk_type": "function", "line_start": 70, "line_end": 97, "language": "python", "name": "get_file_coverage"}, "ca0ad6ce63fc_func_get_tests_for_file": {"id": "ca0ad6ce63fc_func_get_tests_for_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\coverage_index.py", "content": "def get_tests_for_file(file_path: Path, root: Path = None) -> List[str]:\n    \"\"\"Find tests that likely cover a file.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    tests = []\n    file_name = file_path.stem\n\n    # Look for test files\n    for test_file in root.rglob('test_*.py'):\n        if file_name in test_file.stem or file_name in test_file.read_text(errors='ignore'):\n            tests.append(str(test_file.relative_to(root)))\n\n    for test_file in root.rglob('*_test.py'):\n        if file_name in test_file.stem:\n            tests.append(str(test_file.relative_to(root)))\n\n    # Check tests/ directory\n    tests_dir = root / 'tests'\n    if tests_dir.exists():\n        for test_file in tests_dir.rglob('*.py'):\n            if file_name in test_file.stem:\n                tests.append(str(test_file.relative_to(root)))\n\n    return list(set(tests))", "chunk_type": "function", "line_start": 100, "line_end": 123, "language": "python", "name": "get_tests_for_file"}, "ca0ad6ce63fc_func_suggest_tests_needed": {"id": "ca0ad6ce63fc_func_suggest_tests_needed", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\coverage_index.py", "content": "def suggest_tests_needed(file_path: Path, root: Path = None) -> List[str]:\n    \"\"\"Suggest what tests are needed for a file.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    suggestions = []\n    file_name = file_path.stem\n\n    existing_tests = get_tests_for_file(file_path, root)\n\n    if not existing_tests:\n        suggestions.append(f\"Create test file: tests/test_{file_name}.py\")\n\n    # Check coverage\n    coverage = get_file_coverage(file_path, root)\n    if coverage and coverage.uncovered_lines:\n        suggestions.append(f\"Add tests for uncovered lines: {coverage.uncovered_lines[:10]}\")\n\n    # Check for public functions without tests\n    try:\n        import ast\n        with open(file_path, 'r', encoding='utf-8') as f:\n            tree = ast.parse(f.read())\n\n        for node in ast.walk(tree):\n            if isinstance(node, ast.FunctionDef) and not node.name.startswith('_'):\n                test_name = f\"test_{node.name}\"\n                # Check if test exists\n             ", "chunk_type": "function", "line_start": 126, "line_end": 167, "language": "python", "name": "suggest_tests_needed"}, "ca0ad6ce63fc_func_index_coverage": {"id": "ca0ad6ce63fc_func_index_coverage", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\coverage_index.py", "content": "def index_coverage(root: Path = None) -> Dict:\n    \"\"\"Build coverage index.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n    coverage_path = root / '.coverage'\n\n    Console.info(\"Indexing coverage data...\")\n\n    data = load_coverage_file(coverage_path)\n    if not data:\n        Console.warn(\"No coverage data found. Run pytest --cov first.\")\n        return {}\n\n    index = {\n        \"total_files\": 0,\n        \"covered_files\": 0,\n        \"average_coverage\": 0.0,\n        \"files\": {}\n    }\n\n    total_pct = 0.0\n\n    for file_key, file_data in data.get('files', {}).items():\n        covered = len(file_data.get('covered', file_data.get('executed_lines', [])))\n        missing = len(file_data.get('missing', file_data.get('uncovered', [])))\n        total = covered + missing\n\n        pct = (covered / total * 100) if total > 0 else 0\n\n        index[\"files\"][file_key] = {\n            \"covered\": covered,\n            \"missing\": missing,\n            \"total\": total,\n            \"percentage\": rou", "chunk_type": "function", "line_start": 170, "line_end": 222, "language": "python", "name": "index_coverage"}, "ca0ad6ce63fc_func_main": {"id": "ca0ad6ce63fc_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\coverage_index.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Coverage Index\")\n\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n    root = find_project_root() or Path.cwd()\n\n    if '--index' in sys.argv:\n        index_coverage(root)\n        return 0\n\n    if '--suggest' in sys.argv and args:\n        file_path = Path(args[0])\n        suggestions = suggest_tests_needed(file_path, root)\n        Console.info(f\"Test suggestions for {file_path.name}:\")\n        for s in suggestions:\n            print(f\"  - {s}\")\n        return 0\n\n    if args:\n        file_path = Path(args[0])\n        coverage = get_file_coverage(file_path, root)\n\n        if coverage:\n            print(f\"Coverage: {coverage.coverage_pct:.1f}%\")\n            print(f\"Covered lines: {len(coverage.covered_lines)}\")\n            if coverage.uncovered_lines:\n                print(f\"Uncovered: {coverage.uncovered_lines[:20]}\")\n        else:\n            Console.warn(\"No coverage data for this file\")\n\n        tests = get_tests_", "chunk_type": "function", "line_start": 225, "line_end": 270, "language": "python", "name": "main"}, "ca0ad6ce63fc_class_CoverageData": {"id": "ca0ad6ce63fc_class_CoverageData", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\coverage_index.py", "content": "class CoverageData:\n    \"\"\"Coverage data for a file.\"\"\"\n    file: str\n    covered_lines: List[int] = field(default_factory=list)\n    uncovered_lines: List[int] = field(default_factory=list)\n    total_lines: int = 0\n    coverage_pct: float = 0.0", "chunk_type": "class", "line_start": 21, "line_end": 27, "language": "python", "name": "CoverageData"}, "4cbcd7bc8263_file": {"id": "4cbcd7bc8263_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\cybersec.py", "content": "#!/usr/bin/env python3\n\"\"\"\nMCP Cybersecurity Tool Wrapper\nIntegrates 70+ security tools from wizardpanda into the MCP CLI.\n\"\"\"\n\nfrom pathlib import Path\nfrom typing import List, Dict, Optional\nimport os\nimport subprocess\nimport sys\n\n# Tool Categories\nCATEGORIES = {\n    \"Network\": [\"nmap\", \"masscan\", \"arp-scan\", \"netdiscover\", \"fping\", \"hping3\"],\n    \"Web\": [\"gobuster\", \"dirb\", \"dirbuster\", \"nikto\", \"sqlmap\", \"wfuzz\", \"commix\"],\n    \"Exploitation\": [\"msfconsole\", \"msfvenom\", \"searchsploit\", \"beef-xss\", \"social-engineer-toolkit\"],\n    \"Password\": [\"hydra\", \"john\", \"hashcat\", \"medusa\", \"ncrack\"],\n    \"Wireless\": [\"aircrack-ng\", \"airmon-ng\", \"airodump-ng\", \"aireplay-ng\", \"reaver\", \"bully\", \"wifite\"],\n    \"Forensics\": [\"autopsy\", \"binwalk\", \"foremost\", \"scalpel\", \"chkrootkit\", \"rkhunter\"],\n    \"OSINT\": [\"theHarvester\", \"recon-ng\", \"whois\", \"dig\", \"nslookup\"],\n    \"Reverse\": [\"gdb\", \"radare2\", \"ghidra\", \"cutter\", \"objdump\"],\n    \"Post-Exploitation\": [\"impacket\", \"powersploit\", \"bloodhound\", \"mimikatz\"]\n}\n\n# Special Environment Paths\nCYBERSEC_ENV = Path.home() / \"cybersec-env\"\nCYBERSEC_BIN = CYBERSEC_ENV / \"bin\"\n\ndef get_impacket_tools() -> List[str]:\n    \"\"\"List tools available in the Impacket virtualenv.\"\"\"\n    if not CYBERSEC_BIN.exists():\n        return []\n    return [f.name for f in CYBERSEC_BIN.iterdir() if f.is_file() and f.name.endswith(\".py\")]\n\ndef show_help():\n    \"\"\"Show help for the cybersec command.\"\"\"\n    print(\"MCP Cybersecurity Tool Wrapper\")\n    print(\"Usage: mcp cybersec <category|tool|list> [args]\")\n    print(\"\\nCommands:\")\n    print(\"  list              List all tool categories and available tools\")\n    print(\"  help <tool>       Show help for a specific tool\")\n    print(\"  <tool> [args]     Execute a specific tool (e.g., mcp cybersec nmap -sV target)\")\n    print(\"\\nCategories:\")\n    for cat in CATEGORIES:\n        print(f\"  {cat}\")\n\ndef list_tools():\n    \"\"\"List all tools organized by category.\"\"\"\n    print(\"Available Cybersecurity Tools:\")\n    for cat,", "chunk_type": "file", "line_start": 1, "line_end": 120, "language": "python", "name": "cybersec.py"}, "4cbcd7bc8263_func_get_impacket_tools": {"id": "4cbcd7bc8263_func_get_impacket_tools", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\cybersec.py", "content": "def get_impacket_tools() -> List[str]:\n    \"\"\"List tools available in the Impacket virtualenv.\"\"\"\n    if not CYBERSEC_BIN.exists():\n        return []\n    return [f.name for f in CYBERSEC_BIN.iterdir() if f.is_file() and f.name.endswith(\".py\")]", "chunk_type": "function", "line_start": 30, "line_end": 34, "language": "python", "name": "get_impacket_tools"}, "4cbcd7bc8263_func_show_help": {"id": "4cbcd7bc8263_func_show_help", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\cybersec.py", "content": "def show_help():\n    \"\"\"Show help for the cybersec command.\"\"\"\n    print(\"MCP Cybersecurity Tool Wrapper\")\n    print(\"Usage: mcp cybersec <category|tool|list> [args]\")\n    print(\"\\nCommands:\")\n    print(\"  list              List all tool categories and available tools\")\n    print(\"  help <tool>       Show help for a specific tool\")\n    print(\"  <tool> [args]     Execute a specific tool (e.g., mcp cybersec nmap -sV target)\")\n    print(\"\\nCategories:\")\n    for cat in CATEGORIES:\n        print(f\"  {cat}\")", "chunk_type": "function", "line_start": 36, "line_end": 46, "language": "python", "name": "show_help"}, "4cbcd7bc8263_func_list_tools": {"id": "4cbcd7bc8263_func_list_tools", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\cybersec.py", "content": "def list_tools():\n    \"\"\"List all tools organized by category.\"\"\"\n    print(\"Available Cybersecurity Tools:\")\n    for cat, tools in CATEGORIES.items():\n        print(f\"\\n[{cat}]\")\n        print(\", \".join(tools))\n\n    impacket_tools = get_impacket_tools()\n    if impacket_tools:\n        print(\"\\n[Impacket (Auto-activates VENV)]\")\n        # Split into manageable chunks for display\n        for i in range(0, len(impacket_tools), 5):\n            print(\", \".join(impacket_tools[i:i+5]))", "chunk_type": "function", "line_start": 48, "line_end": 60, "language": "python", "name": "list_tools"}, "4cbcd7bc8263_func_run_tool": {"id": "4cbcd7bc8263_func_run_tool", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\cybersec.py", "content": "def run_tool(tool_name: str, args: List[str]):\n    \"\"\"Run a specific tool, handling env activation if needed.\"\"\"\n\n    # Check if it's an impacket tool\n    impacket_tools = get_impacket_tools()\n    if tool_name in impacket_tools or tool_name.replace(\".py\", \"\") in [t.replace(\".py\", \"\") for t in impacket_tools]:\n        if not tool_name.endswith(\".py\"):\n            tool_name += \".py\"\n\n        python_bin = CYBERSEC_BIN / \"python3\"\n        tool_path = CYBERSEC_BIN / tool_name\n\n        if not python_bin.exists() or not tool_path.exists():\n            print(f\"[FAIL] Impacket tool {tool_name} not found or venv invalid.\")\n            return 1\n\n        cmd = [str(python_bin), str(tool_path)] + args\n        print(f\"[EXEC] Running Impacket tool: {' '.join(cmd)}\")\n    else:\n        # Check if tool is in PATH\n        from shutil import which\n        if not which(tool_name):\n            print(f\"[FAIL] Tool '{tool_name}' not found in system PATH.\")\n            print(\"Tip: Use 'mcp cybersec list' to se", "chunk_type": "function", "line_start": 62, "line_end": 98, "language": "python", "name": "run_tool"}, "4cbcd7bc8263_func_main": {"id": "4cbcd7bc8263_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\cybersec.py", "content": "def main():\n    if len(sys.argv) < 2:\n        show_help()\n        return 0\n\n    cmd = sys.argv[1]\n    args = sys.argv[2:]\n\n    if cmd == \"list\":\n        list_tools()\n    elif cmd == \"help\" and args:\n        run_tool(args[0], [\"--help\"])\n    elif cmd in CATEGORIES:\n        print(f\"Tools in category '{cmd}':\")\n        print(\", \".join(CATEGORIES[cmd]))\n    else:\n        return run_tool(cmd, args)", "chunk_type": "function", "line_start": 100, "line_end": 116, "language": "python", "name": "main"}, "634d3275b897_file": {"id": "634d3275b897_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\dead_code.py", "content": "\"\"\"\nDead Code Detector\n==================\nFind unused functions, classes, imports, and variables in Python code.\n\nUsage:\n    python dead_code.py [path]\n    python -m scripts.dead_code [path]\n\"\"\"\n\nfrom collections import defaultdict\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, List, Set, Tuple\nimport ast\nimport sys\n\nfrom .utils import (\n    find_python_files,\n    find_project_root,\n    parse_file,\n    Console,\n    format_as_markdown_table\n)\n\n\n@dataclass\nclass DeadCodeReport:\n    \"\"\"Report of detected dead code.\"\"\"\n    unused_imports: List[Tuple[Path, int, str]] = field(default_factory=list)\n    unused_functions: List[Tuple[Path, int, str]] = field(default_factory=list)\n    unused_classes: List[Tuple[Path, int, str]] = field(default_factory=list)\n    unused_variables: List[Tuple[Path, int, str]] = field(default_factory=list)\n\n    @property\n    def total_issues(self) -> int:\n        return (len(self.unused_imports) + len(self.unused_functions) +\n                len(self.unused_classes) + len(self.unused_variables))\n\n    def to_markdown(self) -> str:\n        \"\"\"Convert report to markdown format.\"\"\"\n        lines = [\"# Dead Code Report\\n\"]\n\n        if self.total_issues == 0:\n            lines.append(\"No dead code detected.\\n\")\n            return \"\\n\".join(lines)\n\n        lines.append(f\"**Total issues found: {self.total_issues}**\\n\")\n\n        if self.unused_imports:\n            lines.append(\"## Unused Imports\\n\")\n            rows = [[str(p), str(line), name] for p, line, name in self.unused_imports]\n            lines.append(format_as_markdown_table([\"File\", \"Line\", \"Import\"], rows))\n            lines.append(\"\")\n\n        if self.unused_functions:\n            lines.append(\"## Unused Functions\\n\")\n            rows = [[str(p), str(line), name] for p, line, name in self.unused_functions]\n            lines.append(format_as_markdown_table([\"File\", \"Line\", \"Function\"], rows))\n            lines.append(\"\")\n\n        if self.unused_classe", "chunk_type": "file", "line_start": 1, "line_end": 287, "language": "python", "name": "dead_code.py"}, "634d3275b897_func_analyze_file": {"id": "634d3275b897_func_analyze_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\dead_code.py", "content": "def analyze_file(path: Path) -> Tuple[Dict[str, Dict[str, int]], Set[str]]:\n    \"\"\"\n    Analyze a single file for definitions and usages.\n\n    Returns:\n        Tuple of (definitions dict, used names set)\n    \"\"\"\n    tree = parse_file(path)\n    if tree is None:\n        return {}, set()\n\n    # Collect definitions\n    def_collector = DefinitionCollector(path)\n    def_collector.visit(tree)\n\n    # Collect usages\n    usage_collector = UsageCollector()\n    usage_collector.visit(tree)\n\n    definitions = {\n        'imports': def_collector.imports,\n        'functions': def_collector.functions,\n        'classes': def_collector.classes,\n        'variables': def_collector.variables\n    }\n\n    return definitions, usage_collector.used_names", "chunk_type": "function", "line_start": 156, "line_end": 182, "language": "python", "name": "analyze_file"}, "634d3275b897_func_detect_dead_code": {"id": "634d3275b897_func_detect_dead_code", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\dead_code.py", "content": "def detect_dead_code(\n    root: Path,\n    exclude_patterns: List[str] = None\n) -> DeadCodeReport:\n    \"\"\"\n    Detect dead code in a Python project.\n\n    Args:\n        root: Root directory to analyze\n        exclude_patterns: Patterns to exclude\n\n    Returns:\n        DeadCodeReport with findings\n    \"\"\"\n    report = DeadCodeReport()\n\n    # Collect all definitions and usages across the project\n    all_definitions: Dict[Path, Dict[str, Dict[str, int]]] = {}\n    all_usages: Set[str] = set()\n\n    # Known always-used names (builtins, common patterns)\n    always_used = {\n        'self', 'cls', 'args', 'kwargs',\n        'main', 'setup', 'teardown',\n        '__all__', '__version__', '__name__', '__main__'\n    }\n    all_usages.update(always_used)\n\n    Console.info(f\"Scanning for Python files in {root}...\")\n\n    files = list(find_python_files(root, exclude_patterns))\n    Console.info(f\"Found {len(files)} Python files\")\n\n    for path in files:\n        definitions, usages = analyze_file(path)\n     ", "chunk_type": "function", "line_start": 185, "line_end": 254, "language": "python", "name": "detect_dead_code"}, "634d3275b897_func_main": {"id": "634d3275b897_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\dead_code.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Dead Code Detector\")\n\n    # Get path from args or use project root\n    if len(sys.argv) > 1:\n        path = Path(sys.argv[1])\n    else:\n        path = find_project_root() or Path.cwd()\n\n    if not path.exists():\n        Console.fail(f\"Path not found: {path}\")\n        sys.exit(1)\n\n    Console.info(f\"Analyzing: {path}\")\n\n    report = detect_dead_code(path)\n\n    print(report.to_markdown())\n\n    if report.total_issues > 0:\n        Console.warn(f\"Found {report.total_issues} potential dead code issues\")\n    else:\n        Console.ok(\"No dead code detected\")\n\n    return report.total_issues", "chunk_type": "function", "line_start": 257, "line_end": 282, "language": "python", "name": "main"}, "634d3275b897_func_total_issues": {"id": "634d3275b897_func_total_issues", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\dead_code.py", "content": "    def total_issues(self) -> int:\n        return (len(self.unused_imports) + len(self.unused_functions) +\n                len(self.unused_classes) + len(self.unused_variables))", "chunk_type": "function", "line_start": 36, "line_end": 38, "language": "python", "name": "total_issues"}, "634d3275b897_func_to_markdown": {"id": "634d3275b897_func_to_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\dead_code.py", "content": "    def to_markdown(self) -> str:\n        \"\"\"Convert report to markdown format.\"\"\"\n        lines = [\"# Dead Code Report\\n\"]\n\n        if self.total_issues == 0:\n            lines.append(\"No dead code detected.\\n\")\n            return \"\\n\".join(lines)\n\n        lines.append(f\"**Total issues found: {self.total_issues}**\\n\")\n\n        if self.unused_imports:\n            lines.append(\"## Unused Imports\\n\")\n            rows = [[str(p), str(line), name] for p, line, name in self.unused_imports]\n            lines.append(format_as_markdown_table([\"File\", \"Line\", \"Import\"], rows))\n            lines.append(\"\")\n\n        if self.unused_functions:\n            lines.append(\"## Unused Functions\\n\")\n            rows = [[str(p), str(line), name] for p, line, name in self.unused_functions]\n            lines.append(format_as_markdown_table([\"File\", \"Line\", \"Function\"], rows))\n            lines.append(\"\")\n\n        if self.unused_classes:\n            lines.append(\"## Unused Classes\\n\")\n            rows = [[str", "chunk_type": "function", "line_start": 40, "line_end": 74, "language": "python", "name": "to_markdown"}, "634d3275b897_func___init__": {"id": "634d3275b897_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\dead_code.py", "content": "    def __init__(self):\n        self.used_names: Set[str] = set()", "chunk_type": "function", "line_start": 134, "line_end": 135, "language": "python", "name": "__init__"}, "634d3275b897_func_visit_Import": {"id": "634d3275b897_func_visit_Import", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\dead_code.py", "content": "    def visit_Import(self, node: ast.Import):\n        for alias in node.names:\n            name = alias.asname or alias.name.split('.')[0]\n            self.imports[name] = node.lineno\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 88, "line_end": 92, "language": "python", "name": "visit_Import"}, "634d3275b897_func_visit_ImportFrom": {"id": "634d3275b897_func_visit_ImportFrom", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\dead_code.py", "content": "    def visit_ImportFrom(self, node: ast.ImportFrom):\n        for alias in node.names:\n            if alias.name != '*':\n                name = alias.asname or alias.name\n                self.imports[name] = node.lineno\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 94, "line_end": 99, "language": "python", "name": "visit_ImportFrom"}, "634d3275b897_func_visit_FunctionDef": {"id": "634d3275b897_func_visit_FunctionDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\dead_code.py", "content": "    def visit_FunctionDef(self, node: ast.FunctionDef):\n        if not self._in_class and not node.name.startswith('_'):\n            self.functions[node.name] = node.lineno\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 101, "line_end": 104, "language": "python", "name": "visit_FunctionDef"}, "634d3275b897_func_visit_AsyncFunctionDef": {"id": "634d3275b897_func_visit_AsyncFunctionDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\dead_code.py", "content": "    def visit_AsyncFunctionDef(self, node: ast.AsyncFunctionDef):\n        if not self._in_class and not node.name.startswith('_'):\n            self.functions[node.name] = node.lineno\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 106, "line_end": 109, "language": "python", "name": "visit_AsyncFunctionDef"}, "634d3275b897_func_visit_ClassDef": {"id": "634d3275b897_func_visit_ClassDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\dead_code.py", "content": "    def visit_ClassDef(self, node: ast.ClassDef):\n        if not node.name.startswith('_'):\n            self.classes[node.name] = node.lineno\n\n        old_in_class = self._in_class\n        self._in_class = True\n        self.generic_visit(node)\n        self._in_class = old_in_class", "chunk_type": "function", "line_start": 111, "line_end": 118, "language": "python", "name": "visit_ClassDef"}, "634d3275b897_func_visit_Assign": {"id": "634d3275b897_func_visit_Assign", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\dead_code.py", "content": "    def visit_Assign(self, node: ast.Assign):\n        if not self._in_class:\n            for target in node.targets:\n                if isinstance(target, ast.Name) and not target.id.startswith('_'):\n                    # Skip common constants/configs\n                    if target.id.isupper():\n                        continue\n                    self.variables[target.id] = node.lineno\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 120, "line_end": 128, "language": "python", "name": "visit_Assign"}, "634d3275b897_func_visit_Name": {"id": "634d3275b897_func_visit_Name", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\dead_code.py", "content": "    def visit_Name(self, node: ast.Name):\n        self.used_names.add(node.id)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 137, "line_end": 139, "language": "python", "name": "visit_Name"}, "634d3275b897_func_visit_Attribute": {"id": "634d3275b897_func_visit_Attribute", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\dead_code.py", "content": "    def visit_Attribute(self, node: ast.Attribute):\n        # Track the base name\n        if isinstance(node.value, ast.Name):\n            self.used_names.add(node.value.id)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 141, "line_end": 145, "language": "python", "name": "visit_Attribute"}, "634d3275b897_func_visit_Call": {"id": "634d3275b897_func_visit_Call", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\dead_code.py", "content": "    def visit_Call(self, node: ast.Call):\n        if isinstance(node.func, ast.Name):\n            self.used_names.add(node.func.id)\n        elif isinstance(node.func, ast.Attribute):\n            if isinstance(node.func.value, ast.Name):\n                self.used_names.add(node.func.value.id)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 147, "line_end": 153, "language": "python", "name": "visit_Call"}, "634d3275b897_class_DeadCodeReport": {"id": "634d3275b897_class_DeadCodeReport", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\dead_code.py", "content": "class DeadCodeReport:\n    \"\"\"Report of detected dead code.\"\"\"\n    unused_imports: List[Tuple[Path, int, str]] = field(default_factory=list)\n    unused_functions: List[Tuple[Path, int, str]] = field(default_factory=list)\n    unused_classes: List[Tuple[Path, int, str]] = field(default_factory=list)\n    unused_variables: List[Tuple[Path, int, str]] = field(default_factory=list)\n\n    @property\n    def total_issues(self) -> int:\n        return (len(self.unused_imports) + len(self.unused_functions) +\n                len(self.unused_classes) + len(self.unused_variables))\n\n    def to_markdown(self) -> str:\n        \"\"\"Convert report to markdown format.\"\"\"\n        lines = [\"# Dead Code Report\\n\"]\n\n        if self.total_issues == 0:\n            lines.append(\"No dead code detected.\\n\")\n            return \"\\n\".join(lines)\n\n        lines.append(f\"**Total issues found: {self.total_issues}**\\n\")\n\n        if self.unused_imports:\n            lines.append(\"## Unused Imports\\n\")\n            rows = [[str(p", "chunk_type": "class", "line_start": 28, "line_end": 74, "language": "python", "name": "DeadCodeReport"}, "634d3275b897_class_DefinitionCollector": {"id": "634d3275b897_class_DefinitionCollector", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\dead_code.py", "content": "class DefinitionCollector(ast.NodeVisitor):\n    \"\"\"Collect all definitions in a module.\"\"\"\n\n    def __init__(self, path: Path):\n        self.path = path\n        self.imports: Dict[str, int] = {}  # name -> lineno\n        self.functions: Dict[str, int] = {}\n        self.classes: Dict[str, int] = {}\n        self.variables: Dict[str, int] = {}\n        self._in_class = False\n\n    def visit_Import(self, node: ast.Import):\n        for alias in node.names:\n            name = alias.asname or alias.name.split('.')[0]\n            self.imports[name] = node.lineno\n        self.generic_visit(node)\n\n    def visit_ImportFrom(self, node: ast.ImportFrom):\n        for alias in node.names:\n            if alias.name != '*':\n                name = alias.asname or alias.name\n                self.imports[name] = node.lineno\n        self.generic_visit(node)\n\n    def visit_FunctionDef(self, node: ast.FunctionDef):\n        if not self._in_class and not node.name.startswith('_'):\n            self.functions[node.", "chunk_type": "class", "line_start": 77, "line_end": 128, "language": "python", "name": "DefinitionCollector"}, "634d3275b897_class_UsageCollector": {"id": "634d3275b897_class_UsageCollector", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\dead_code.py", "content": "class UsageCollector(ast.NodeVisitor):\n    \"\"\"Collect all name usages in a module.\"\"\"\n\n    def __init__(self):\n        self.used_names: Set[str] = set()\n\n    def visit_Name(self, node: ast.Name):\n        self.used_names.add(node.id)\n        self.generic_visit(node)\n\n    def visit_Attribute(self, node: ast.Attribute):\n        # Track the base name\n        if isinstance(node.value, ast.Name):\n            self.used_names.add(node.value.id)\n        self.generic_visit(node)\n\n    def visit_Call(self, node: ast.Call):\n        if isinstance(node.func, ast.Name):\n            self.used_names.add(node.func.id)\n        elif isinstance(node.func, ast.Attribute):\n            if isinstance(node.func.value, ast.Name):\n                self.used_names.add(node.func.value.id)\n        self.generic_visit(node)", "chunk_type": "class", "line_start": 131, "line_end": 153, "language": "python", "name": "UsageCollector"}, "ebcc55050033_file": {"id": "ebcc55050033_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\deps.py", "content": "\"\"\"\nDependency Analyzer\n===================\nAnalyze and visualize project dependencies, detect circular imports.\n\nUsage:\n    python deps.py [path] [--output deps.md]\n    python -m scripts.deps [path]\n\"\"\"\n\nfrom collections import defaultdict\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, List, Set, Optional, Tuple\nimport ast\nimport sys\n\nfrom .utils import (\n    find_python_files,\n    find_project_root,\n    parse_file,\n    Console,\n    format_as_markdown_table\n)\n\n\n@dataclass\nclass DependencyInfo:\n    \"\"\"Dependency information for a module.\"\"\"\n    path: Path\n    module_name: str\n    imports: Set[str] = field(default_factory=set)\n    from_imports: Dict[str, Set[str]] = field(default_factory=lambda: defaultdict(set))\n\n    @property\n    def all_dependencies(self) -> Set[str]:\n        \"\"\"Get all dependencies.\"\"\"\n        deps = set(self.imports)\n        deps.update(self.from_imports.keys())\n        return deps\n\n\n@dataclass\nclass DependencyReport:\n    \"\"\"Report of dependency analysis.\"\"\"\n    modules: Dict[str, DependencyInfo] = field(default_factory=dict)\n    external_deps: Set[str] = field(default_factory=set)\n    internal_deps: Dict[str, Set[str]] = field(default_factory=lambda: defaultdict(set))\n    circular_deps: List[Tuple[str, str]] = field(default_factory=list)\n    missing_deps: List[Tuple[str, str]] = field(default_factory=list)\n\n\n# Standard library modules\nSTDLIB_MODULES = {\n    'abc', 'aifc', 'argparse', 'array', 'ast', 'asyncio', 'atexit',\n    'base64', 'bdb', 'binascii', 'bisect', 'builtins', 'bz2',\n    'calendar', 'cgi', 'cgitb', 'chunk', 'cmath', 'cmd', 'code',\n    'codecs', 'codeop', 'collections', 'colorsys', 'compileall',\n    'concurrent', 'configparser', 'contextlib', 'copy', 'copyreg',\n    'cProfile', 'crypt', 'csv', 'ctypes', 'curses',\n    'dataclasses', 'datetime', 'dbm', 'decimal', 'difflib', 'dis',\n    'distutils', 'doctest',\n    'email', 'encodings', 'enum', 'errno',\n    'faulthandler', 'fcntl', 'filecmp', '", "chunk_type": "file", "line_start": 1, "line_end": 367, "language": "python", "name": "deps.py"}, "ebcc55050033_func_analyze_imports": {"id": "ebcc55050033_func_analyze_imports", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\deps.py", "content": "def analyze_imports(path: Path) -> Optional[DependencyInfo]:\n    \"\"\"\n    Analyze imports in a Python file.\n\n    Args:\n        path: Path to Python file\n\n    Returns:\n        DependencyInfo or None if parsing fails\n    \"\"\"\n    tree = parse_file(path)\n    if tree is None:\n        return None\n\n    info = DependencyInfo(\n        path=path,\n        module_name=path.stem\n    )\n\n    for node in ast.walk(tree):\n        if isinstance(node, ast.Import):\n            for alias in node.names:\n                info.imports.add(alias.name.split('.')[0])\n        elif isinstance(node, ast.ImportFrom):\n            if node.module:\n                base_module = node.module.split('.')[0]\n                info.imports.add(base_module)\n                for alias in node.names:\n                    info.from_imports[node.module].add(alias.name)\n\n    return info", "chunk_type": "function", "line_start": 99, "line_end": 129, "language": "python", "name": "analyze_imports"}, "ebcc55050033_func_path_to_module_name": {"id": "ebcc55050033_func_path_to_module_name", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\deps.py", "content": "def path_to_module_name(path: Path, root: Path) -> str:\n    \"\"\"Convert a file path to a module name.\"\"\"\n    try:\n        relative = path.relative_to(root)\n        parts = list(relative.with_suffix('').parts)\n        return '.'.join(parts)\n    except ValueError:\n        return path.stem", "chunk_type": "function", "line_start": 132, "line_end": 139, "language": "python", "name": "path_to_module_name"}, "ebcc55050033_func_analyze_dependencies": {"id": "ebcc55050033_func_analyze_dependencies", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\deps.py", "content": "def analyze_dependencies(\n    root: Path,\n    exclude_patterns: List[str] = None\n) -> DependencyReport:\n    \"\"\"\n    Analyze dependencies in a Python project.\n\n    Args:\n        root: Root directory\n        exclude_patterns: Patterns to exclude\n\n    Returns:\n        DependencyReport\n    \"\"\"\n    report = DependencyReport()\n\n    Console.info(f\"Scanning {root} for Python files...\")\n\n    files = list(find_python_files(root, exclude_patterns))\n    Console.info(f\"Found {len(files)} Python files\")\n\n    # Build module name mapping\n    module_names = set()\n    for path in files:\n        module_name = path_to_module_name(path, root)\n        module_names.add(module_name.split('.')[0])\n\n    # Analyze each file\n    for path in files:\n        info = analyze_imports(path)\n        if info:\n            module_name = path_to_module_name(path, root)\n            report.modules[module_name] = info\n\n            # Categorize dependencies\n            for dep in info.all_dependencies:\n                base_dep =", "chunk_type": "function", "line_start": 142, "line_end": 204, "language": "python", "name": "analyze_dependencies"}, "ebcc55050033_func_generate_mermaid_diagram": {"id": "ebcc55050033_func_generate_mermaid_diagram", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\deps.py", "content": "def generate_mermaid_diagram(report: DependencyReport, max_nodes: int = 20) -> str:\n    \"\"\"\n    Generate a Mermaid diagram of dependencies.\n\n    Args:\n        report: DependencyReport\n        max_nodes: Maximum number of nodes to show\n\n    Returns:\n        Mermaid diagram code\n    \"\"\"\n    lines = [\"```mermaid\", \"graph LR\"]\n\n    # Track nodes we've added\n    nodes_added = set()\n    edges_added = set()\n\n    # Add internal dependencies\n    for module, deps in list(report.internal_deps.items())[:max_nodes]:\n        base_module = module.split('.')[0]\n\n        if base_module not in nodes_added:\n            lines.append(f'    {base_module}[\"{base_module}\"]')\n            nodes_added.add(base_module)\n\n        for dep in list(deps)[:5]:  # Limit edges per node\n            base_dep = dep.split('.')[0]\n\n            if base_dep not in nodes_added and len(nodes_added) < max_nodes:\n                lines.append(f'    {base_dep}[\"{base_dep}\"]')\n                nodes_added.add(base_dep)\n\n            edg", "chunk_type": "function", "line_start": 207, "line_end": 250, "language": "python", "name": "generate_mermaid_diagram"}, "ebcc55050033_func_format_report_markdown": {"id": "ebcc55050033_func_format_report_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\deps.py", "content": "def format_report_markdown(report: DependencyReport) -> str:\n    \"\"\"Format dependency report as Markdown.\"\"\"\n    lines = [\n        \"# Dependency Analysis\",\n        \"\",\n        \"## Summary\",\n        \"\",\n        f\"- **Internal Modules:** {len(report.modules)}\",\n        f\"- **External Dependencies:** {len(report.external_deps)}\",\n        f\"- **Circular Dependencies:** {len(report.circular_deps)}\",\n        \"\",\n    ]\n\n    # External dependencies\n    if report.external_deps:\n        lines.extend([\n            \"## External Dependencies\",\n            \"\",\n            \"These packages need to be installed:\",\n            \"\",\n        ])\n        for dep in sorted(report.external_deps):\n            lines.append(f\"- `{dep}`\")\n        lines.append(\"\")\n\n    # Circular dependencies (warning)\n    if report.circular_deps:\n        lines.extend([\n            \"## Circular Dependencies [WARNING]\",\n            \"\",\n            \"The following modules have circular imports:\",\n            \"\",\n        ])\n        for", "chunk_type": "function", "line_start": 253, "line_end": 316, "language": "python", "name": "format_report_markdown"}, "ebcc55050033_func_main": {"id": "ebcc55050033_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\deps.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Dependency Analyzer\")\n\n    # Parse args\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n    output_file = None\n\n    for i, arg in enumerate(sys.argv):\n        if arg == '--output' and i + 1 < len(sys.argv):\n            output_file = Path(sys.argv[i + 1])\n\n    # Get path\n    if args:\n        path = Path(args[0])\n    else:\n        path = find_project_root() or Path.cwd()\n\n    if not path.exists():\n        Console.fail(f\"Path not found: {path}\")\n        sys.exit(1)\n\n    Console.info(f\"Analyzing: {path}\")\n\n    report = analyze_dependencies(path)\n    markdown = format_report_markdown(report)\n\n    # Output\n    if output_file:\n        with open(output_file, 'w', encoding='utf-8') as f:\n            f.write(markdown)\n        Console.ok(f\"Report written to: {output_file}\")\n    else:\n        print(markdown)\n\n    # Summary\n    if report.circular_deps:\n        Console.warn(f\"Found {len(report.circular_deps)} circular dependenc", "chunk_type": "function", "line_start": 319, "line_end": 362, "language": "python", "name": "main"}, "ebcc55050033_func_all_dependencies": {"id": "ebcc55050033_func_all_dependencies", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\deps.py", "content": "    def all_dependencies(self) -> Set[str]:\n        \"\"\"Get all dependencies.\"\"\"\n        deps = set(self.imports)\n        deps.update(self.from_imports.keys())\n        return deps", "chunk_type": "function", "line_start": 36, "line_end": 40, "language": "python", "name": "all_dependencies"}, "ebcc55050033_class_DependencyInfo": {"id": "ebcc55050033_class_DependencyInfo", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\deps.py", "content": "class DependencyInfo:\n    \"\"\"Dependency information for a module.\"\"\"\n    path: Path\n    module_name: str\n    imports: Set[str] = field(default_factory=set)\n    from_imports: Dict[str, Set[str]] = field(default_factory=lambda: defaultdict(set))\n\n    @property\n    def all_dependencies(self) -> Set[str]:\n        \"\"\"Get all dependencies.\"\"\"\n        deps = set(self.imports)\n        deps.update(self.from_imports.keys())\n        return deps", "chunk_type": "class", "line_start": 28, "line_end": 40, "language": "python", "name": "DependencyInfo"}, "ebcc55050033_class_DependencyReport": {"id": "ebcc55050033_class_DependencyReport", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\deps.py", "content": "class DependencyReport:\n    \"\"\"Report of dependency analysis.\"\"\"\n    modules: Dict[str, DependencyInfo] = field(default_factory=dict)\n    external_deps: Set[str] = field(default_factory=set)\n    internal_deps: Dict[str, Set[str]] = field(default_factory=lambda: defaultdict(set))\n    circular_deps: List[Tuple[str, str]] = field(default_factory=list)\n    missing_deps: List[Tuple[str, str]] = field(default_factory=list)", "chunk_type": "class", "line_start": 44, "line_end": 50, "language": "python", "name": "DependencyReport"}, "251e792a8aeb_file": {"id": "251e792a8aeb_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "\"\"\"\nDocumentation Coverage Checker\n==============================\nMeasure documentation coverage and identify undocumented code.\n\nUsage:\n    python doc_coverage.py [path] [--format google]\n    python -m scripts.doc_coverage src/\n\"\"\"\n\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, List, Optional\nimport ast\nimport re\nimport sys\n\nfrom .utils import (\n    find_python_files,\n    find_project_root,\n    parse_file,\n    Console,\n    format_as_markdown_table\n)\n\n\n@dataclass\nclass CoverageItem:\n    \"\"\"A single item that should have documentation.\"\"\"\n    path: Path\n    name: str\n    line: int\n    item_type: str  # 'function', 'class', 'method', 'module'\n    has_docstring: bool\n    docstring_valid: bool = True\n    issues: List[str] = field(default_factory=list)\n\n\n@dataclass\nclass CoverageReport:\n    \"\"\"Documentation coverage report.\"\"\"\n    items: List[CoverageItem] = field(default_factory=list)\n\n    @property\n    def total(self) -> int:\n        return len(self.items)\n\n    @property\n    def documented(self) -> int:\n        return sum(1 for i in self.items if i.has_docstring)\n\n    @property\n    def valid(self) -> int:\n        return sum(1 for i in self.items if i.has_docstring and i.docstring_valid)\n\n    @property\n    def coverage_percent(self) -> float:\n        return (self.documented / self.total * 100) if self.total > 0 else 0\n\n    @property\n    def undocumented(self) -> List[CoverageItem]:\n        return [i for i in self.items if not i.has_docstring]\n\n    @property\n    def invalid(self) -> List[CoverageItem]:\n        return [i for i in self.items if i.has_docstring and not i.docstring_valid]\n\n    def to_markdown(self) -> str:\n        lines = [\n            \"# Documentation Coverage Report\",\n            \"\",\n            \"## Summary\",\n            \"\",\n            f\"| Metric | Value |\",\n            f\"|--------|-------|\",\n            f\"| Total Items | {self.total} |\",\n            f\"| Documented | {self.documented} |\",\n            f\"| Covera", "chunk_type": "file", "line_start": 1, "line_end": 319, "language": "python", "name": "doc_coverage.py"}, "251e792a8aeb_func_analyze_file": {"id": "251e792a8aeb_func_analyze_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "def analyze_file(path: Path, validator: DocstringValidator) -> List[CoverageItem]:\n    \"\"\"Analyze documentation coverage in a file.\"\"\"\n    tree = parse_file(path)\n    if tree is None:\n        return []\n\n    analyzer = CoverageAnalyzer(path, validator)\n    analyzer.visit(tree)\n\n    return analyzer.items", "chunk_type": "function", "line_start": 241, "line_end": 250, "language": "python", "name": "analyze_file"}, "251e792a8aeb_func_check_coverage": {"id": "251e792a8aeb_func_check_coverage", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "def check_coverage(\n    root: Path,\n    doc_format: str = 'google',\n    exclude_patterns: List[str] = None\n) -> CoverageReport:\n    \"\"\"Check documentation coverage in a project.\"\"\"\n    report = CoverageReport()\n    validator = DocstringValidator(doc_format)\n\n    Console.info(f\"Checking documentation coverage in {root}...\")\n\n    files = list(find_python_files(root, exclude_patterns))\n    Console.info(f\"Found {len(files)} Python files\")\n\n    for path in files:\n        items = analyze_file(path, validator)\n        report.items.extend(items)\n\n    return report", "chunk_type": "function", "line_start": 253, "line_end": 271, "language": "python", "name": "check_coverage"}, "251e792a8aeb_func_main": {"id": "251e792a8aeb_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Documentation Coverage Checker\")\n\n    # Parse args\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n    doc_format = 'google'\n\n    for i, arg in enumerate(sys.argv):\n        if arg == '--format' and i + 1 < len(sys.argv):\n            doc_format = sys.argv[i + 1]\n\n    if args:\n        path = Path(args[0])\n    else:\n        path = find_project_root() or Path.cwd()\n\n    if not path.exists():\n        Console.fail(f\"Path not found: {path}\")\n        return 1\n\n    Console.info(f\"Analyzing: {path}\")\n    Console.info(f\"Format: {doc_format}\")\n\n    report = check_coverage(path, doc_format)\n\n    print(report.to_markdown())\n\n    # Summary\n    if report.coverage_percent >= 80:\n        Console.ok(f\"Coverage: {report.coverage_percent:.1f}%\")\n    elif report.coverage_percent >= 50:\n        Console.warn(f\"Coverage: {report.coverage_percent:.1f}% (target: 80%)\")\n    else:\n        Console.fail(f\"Coverage: {report.coverage_percent:.1f}", "chunk_type": "function", "line_start": 274, "line_end": 310, "language": "python", "name": "main"}, "251e792a8aeb_func_total": {"id": "251e792a8aeb_func_total", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "    def total(self) -> int:\n        return len(self.items)", "chunk_type": "function", "line_start": 45, "line_end": 46, "language": "python", "name": "total"}, "251e792a8aeb_func_documented": {"id": "251e792a8aeb_func_documented", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "    def documented(self) -> int:\n        return sum(1 for i in self.items if i.has_docstring)", "chunk_type": "function", "line_start": 49, "line_end": 50, "language": "python", "name": "documented"}, "251e792a8aeb_func_valid": {"id": "251e792a8aeb_func_valid", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "    def valid(self) -> int:\n        return sum(1 for i in self.items if i.has_docstring and i.docstring_valid)", "chunk_type": "function", "line_start": 53, "line_end": 54, "language": "python", "name": "valid"}, "251e792a8aeb_func_coverage_percent": {"id": "251e792a8aeb_func_coverage_percent", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "    def coverage_percent(self) -> float:\n        return (self.documented / self.total * 100) if self.total > 0 else 0", "chunk_type": "function", "line_start": 57, "line_end": 58, "language": "python", "name": "coverage_percent"}, "251e792a8aeb_func_undocumented": {"id": "251e792a8aeb_func_undocumented", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "    def undocumented(self) -> List[CoverageItem]:\n        return [i for i in self.items if not i.has_docstring]", "chunk_type": "function", "line_start": 61, "line_end": 62, "language": "python", "name": "undocumented"}, "251e792a8aeb_func_invalid": {"id": "251e792a8aeb_func_invalid", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "    def invalid(self) -> List[CoverageItem]:\n        return [i for i in self.items if i.has_docstring and not i.docstring_valid]", "chunk_type": "function", "line_start": 65, "line_end": 66, "language": "python", "name": "invalid"}, "251e792a8aeb_func_to_markdown": {"id": "251e792a8aeb_func_to_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "    def to_markdown(self) -> str:\n        lines = [\n            \"# Documentation Coverage Report\",\n            \"\",\n            \"## Summary\",\n            \"\",\n            f\"| Metric | Value |\",\n            f\"|--------|-------|\",\n            f\"| Total Items | {self.total} |\",\n            f\"| Documented | {self.documented} |\",\n            f\"| Coverage | {self.coverage_percent:.1f}% |\",\n            f\"| Valid Format | {self.valid} |\",\n            \"\",\n        ]\n\n        # Coverage bar\n        filled = int(self.coverage_percent / 5)\n        bar = \"[\" + \"#\" * filled + \"-\" * (20 - filled) + \"]\"\n        lines.append(f\"**Coverage:** {bar} {self.coverage_percent:.1f}%\")\n        lines.append(\"\")\n\n        # Undocumented items\n        if self.undocumented:\n            lines.append(\"## Undocumented Items\")\n            lines.append(\"\")\n\n            # Group by type\n            by_type: Dict[str, List[CoverageItem]] = {}\n            for item in self.undocumented:\n                if item.item_type not in b", "chunk_type": "function", "line_start": 68, "line_end": 120, "language": "python", "name": "to_markdown"}, "251e792a8aeb_func___init__": {"id": "251e792a8aeb_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "    def __init__(self, path: Path, validator: DocstringValidator):\n        self.path = path\n        self.validator = validator\n        self.items: List[CoverageItem] = []\n        self._in_class = False", "chunk_type": "function", "line_start": 163, "line_end": 167, "language": "python", "name": "__init__"}, "251e792a8aeb_func_validate": {"id": "251e792a8aeb_func_validate", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "    def validate(self, docstring: str, node) -> Tuple[bool, List[str]]:\n        \"\"\"Validate docstring format.\"\"\"\n        issues = []\n\n        if not docstring or not docstring.strip():\n            return False, [\"Empty docstring\"]\n\n        lines = docstring.strip().split('\\n')\n\n        # Check first line\n        first_line = lines[0].strip()\n        if not first_line:\n            issues.append(\"First line is empty\")\n        elif not first_line.endswith('.') and not first_line.endswith('!'):\n            issues.append(\"First line should end with period\")\n\n        # Check for function-specific requirements\n        if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n            # Check Args section if function has parameters\n            params = [a.arg for a in node.args.args if a.arg not in ('self', 'cls')]\n            if params and 'Args:' not in docstring and 'Parameters:' not in docstring:\n                issues.append(f\"Missing Args section for: {', '.join(params)}\")\n\n      ", "chunk_type": "function", "line_start": 129, "line_end": 157, "language": "python", "name": "validate"}, "251e792a8aeb_func_visit_Module": {"id": "251e792a8aeb_func_visit_Module", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "    def visit_Module(self, node: ast.Module):\n        # Check module docstring\n        docstring = ast.get_docstring(node)\n        self.items.append(CoverageItem(\n            path=self.path,\n            name=self.path.stem,\n            line=1,\n            item_type='module',\n            has_docstring=docstring is not None\n        ))\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 169, "line_end": 179, "language": "python", "name": "visit_Module"}, "251e792a8aeb_func_visit_FunctionDef": {"id": "251e792a8aeb_func_visit_FunctionDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "    def visit_FunctionDef(self, node: ast.FunctionDef):\n        self._check_function(node)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 181, "line_end": 183, "language": "python", "name": "visit_FunctionDef"}, "251e792a8aeb_func_visit_AsyncFunctionDef": {"id": "251e792a8aeb_func_visit_AsyncFunctionDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "    def visit_AsyncFunctionDef(self, node: ast.AsyncFunctionDef):\n        self._check_function(node)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 185, "line_end": 187, "language": "python", "name": "visit_AsyncFunctionDef"}, "251e792a8aeb_func__check_function": {"id": "251e792a8aeb_func__check_function", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "    def _check_function(self, node):\n        # Skip private/magic methods\n        if node.name.startswith('_') and not node.name.startswith('__init__'):\n            return\n\n        docstring = ast.get_docstring(node)\n        item_type = 'method' if self._in_class else 'function'\n\n        item = CoverageItem(\n            path=self.path,\n            name=node.name,\n            line=node.lineno,\n            item_type=item_type,\n            has_docstring=docstring is not None\n        )\n\n        if docstring:\n            valid, issues = self.validator.validate(docstring, node)\n            item.docstring_valid = valid\n            item.issues = issues\n\n        self.items.append(item)", "chunk_type": "function", "line_start": 189, "line_end": 210, "language": "python", "name": "_check_function"}, "251e792a8aeb_func_visit_ClassDef": {"id": "251e792a8aeb_func_visit_ClassDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "    def visit_ClassDef(self, node: ast.ClassDef):\n        # Skip private classes\n        if node.name.startswith('_'):\n            self.generic_visit(node)\n            return\n\n        docstring = ast.get_docstring(node)\n        item = CoverageItem(\n            path=self.path,\n            name=node.name,\n            line=node.lineno,\n            item_type='class',\n            has_docstring=docstring is not None\n        )\n\n        if docstring:\n            valid, issues = self.validator.validate(docstring, node)\n            item.docstring_valid = valid\n            item.issues = issues\n\n        self.items.append(item)\n\n        # Visit methods\n        old_in_class = self._in_class\n        self._in_class = True\n        self.generic_visit(node)\n        self._in_class = old_in_class", "chunk_type": "function", "line_start": 212, "line_end": 238, "language": "python", "name": "visit_ClassDef"}, "251e792a8aeb_class_CoverageItem": {"id": "251e792a8aeb_class_CoverageItem", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "class CoverageItem:\n    \"\"\"A single item that should have documentation.\"\"\"\n    path: Path\n    name: str\n    line: int\n    item_type: str  # 'function', 'class', 'method', 'module'\n    has_docstring: bool\n    docstring_valid: bool = True\n    issues: List[str] = field(default_factory=list)", "chunk_type": "class", "line_start": 28, "line_end": 36, "language": "python", "name": "CoverageItem"}, "251e792a8aeb_class_CoverageReport": {"id": "251e792a8aeb_class_CoverageReport", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "class CoverageReport:\n    \"\"\"Documentation coverage report.\"\"\"\n    items: List[CoverageItem] = field(default_factory=list)\n\n    @property\n    def total(self) -> int:\n        return len(self.items)\n\n    @property\n    def documented(self) -> int:\n        return sum(1 for i in self.items if i.has_docstring)\n\n    @property\n    def valid(self) -> int:\n        return sum(1 for i in self.items if i.has_docstring and i.docstring_valid)\n\n    @property\n    def coverage_percent(self) -> float:\n        return (self.documented / self.total * 100) if self.total > 0 else 0\n\n    @property\n    def undocumented(self) -> List[CoverageItem]:\n        return [i for i in self.items if not i.has_docstring]\n\n    @property\n    def invalid(self) -> List[CoverageItem]:\n        return [i for i in self.items if i.has_docstring and not i.docstring_valid]\n\n    def to_markdown(self) -> str:\n        lines = [\n            \"# Documentation Coverage Report\",\n            \"\",\n            \"## Summary\",\n            \"\",\n      ", "chunk_type": "class", "line_start": 40, "line_end": 120, "language": "python", "name": "CoverageReport"}, "251e792a8aeb_class_DocstringValidator": {"id": "251e792a8aeb_class_DocstringValidator", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "class DocstringValidator:\n    \"\"\"Validate docstring format.\"\"\"\n\n    def __init__(self, format: str = 'google'):\n        self.format = format\n\n    def validate(self, docstring: str, node) -> Tuple[bool, List[str]]:\n        \"\"\"Validate docstring format.\"\"\"\n        issues = []\n\n        if not docstring or not docstring.strip():\n            return False, [\"Empty docstring\"]\n\n        lines = docstring.strip().split('\\n')\n\n        # Check first line\n        first_line = lines[0].strip()\n        if not first_line:\n            issues.append(\"First line is empty\")\n        elif not first_line.endswith('.') and not first_line.endswith('!'):\n            issues.append(\"First line should end with period\")\n\n        # Check for function-specific requirements\n        if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n            # Check Args section if function has parameters\n            params = [a.arg for a in node.args.args if a.arg not in ('self', 'cls')]\n            if params and 'Args:", "chunk_type": "class", "line_start": 123, "line_end": 157, "language": "python", "name": "DocstringValidator"}, "251e792a8aeb_class_CoverageAnalyzer": {"id": "251e792a8aeb_class_CoverageAnalyzer", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "class CoverageAnalyzer(ast.NodeVisitor):\n    \"\"\"Analyze documentation coverage.\"\"\"\n\n    def __init__(self, path: Path, validator: DocstringValidator):\n        self.path = path\n        self.validator = validator\n        self.items: List[CoverageItem] = []\n        self._in_class = False\n\n    def visit_Module(self, node: ast.Module):\n        # Check module docstring\n        docstring = ast.get_docstring(node)\n        self.items.append(CoverageItem(\n            path=self.path,\n            name=self.path.stem,\n            line=1,\n            item_type='module',\n            has_docstring=docstring is not None\n        ))\n        self.generic_visit(node)\n\n    def visit_FunctionDef(self, node: ast.FunctionDef):\n        self._check_function(node)\n        self.generic_visit(node)\n\n    def visit_AsyncFunctionDef(self, node: ast.AsyncFunctionDef):\n        self._check_function(node)\n        self.generic_visit(node)\n\n    def _check_function(self, node):\n        # Skip private/magic methods\n        if", "chunk_type": "class", "line_start": 160, "line_end": 238, "language": "python", "name": "CoverageAnalyzer"}, "67dcc4c44379_file": {"id": "67dcc4c44379_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\doc_index.py", "content": "\"\"\"\nDocumentation Index\n====================\nIndex READMEs, docstrings, and module summaries.\n\nUsage:\n    python mcp.py doc-index\n    python mcp.py doc-index --search \"api\"\n\"\"\"\n\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, List, Optional\nimport ast\nimport json\nimport re\nimport sys\n\nfrom .utils import Console, find_python_files, find_project_root\n\n\n@dataclass\nclass DocItem:\n    \"\"\"A documentation item.\"\"\"\n    type: str  # 'readme', 'module', 'class', 'function'\n    name: str\n    path: str\n    summary: str\n    full_text: str = \"\"\n\n\ndef extract_module_docstring(file_path: Path) -> Optional[str]:\n    \"\"\"Extract module docstring from a Python file.\"\"\"\n    try:\n        with open(file_path, 'r', encoding='utf-8') as f:\n            source = f.read()\n        tree = ast.parse(source)\n        return ast.get_docstring(tree)\n    except Exception:\n        return None\n\n\ndef extract_docstrings(file_path: Path) -> List[DocItem]:\n    \"\"\"Extract all docstrings from a file.\"\"\"\n    docs = []\n\n    try:\n        with open(file_path, 'r', encoding='utf-8') as f:\n            source = f.read()\n        tree = ast.parse(source)\n    except Exception:\n        return docs\n\n    # Module docstring\n    module_doc = ast.get_docstring(tree)\n    if module_doc:\n        docs.append(DocItem(\n            type='module',\n            name=file_path.stem,\n            path=str(file_path),\n            summary=module_doc.split('\\n')[0][:100],\n            full_text=module_doc[:500]\n        ))\n\n    # Function and class docstrings\n    for node in ast.walk(tree):\n        if isinstance(node, ast.FunctionDef):\n            doc = ast.get_docstring(node)\n            if doc:\n                docs.append(DocItem(\n                    type='function',\n                    name=node.name,\n                    path=str(file_path),\n                    summary=doc.split('\\n')[0][:100],\n                    full_text=doc[:500]\n                ))\n        elif isinstance(node, ast.ClassDef):\n", "chunk_type": "file", "line_start": 1, "line_end": 272, "language": "python", "name": "doc_index.py"}, "67dcc4c44379_func_extract_module_docstring": {"id": "67dcc4c44379_func_extract_module_docstring", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\doc_index.py", "content": "def extract_module_docstring(file_path: Path) -> Optional[str]:\n    \"\"\"Extract module docstring from a Python file.\"\"\"\n    try:\n        with open(file_path, 'r', encoding='utf-8') as f:\n            source = f.read()\n        tree = ast.parse(source)\n        return ast.get_docstring(tree)\n    except Exception:\n        return None", "chunk_type": "function", "line_start": 32, "line_end": 40, "language": "python", "name": "extract_module_docstring"}, "67dcc4c44379_func_extract_docstrings": {"id": "67dcc4c44379_func_extract_docstrings", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\doc_index.py", "content": "def extract_docstrings(file_path: Path) -> List[DocItem]:\n    \"\"\"Extract all docstrings from a file.\"\"\"\n    docs = []\n\n    try:\n        with open(file_path, 'r', encoding='utf-8') as f:\n            source = f.read()\n        tree = ast.parse(source)\n    except Exception:\n        return docs\n\n    # Module docstring\n    module_doc = ast.get_docstring(tree)\n    if module_doc:\n        docs.append(DocItem(\n            type='module',\n            name=file_path.stem,\n            path=str(file_path),\n            summary=module_doc.split('\\n')[0][:100],\n            full_text=module_doc[:500]\n        ))\n\n    # Function and class docstrings\n    for node in ast.walk(tree):\n        if isinstance(node, ast.FunctionDef):\n            doc = ast.get_docstring(node)\n            if doc:\n                docs.append(DocItem(\n                    type='function',\n                    name=node.name,\n                    path=str(file_path),\n                    summary=doc.split('\\n')[0][:100],\n                  ", "chunk_type": "function", "line_start": 43, "line_end": 88, "language": "python", "name": "extract_docstrings"}, "67dcc4c44379_func_find_readme_files": {"id": "67dcc4c44379_func_find_readme_files", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\doc_index.py", "content": "def find_readme_files(root: Path) -> List[Path]:\n    \"\"\"Find README files in project.\"\"\"\n    readmes = []\n    patterns = ['README', 'README.md', 'README.rst', 'README.txt', 'DOCUMENTATION.md']\n\n    for pattern in patterns:\n        for readme in root.rglob(pattern):\n            if '.git' not in str(readme) and 'node_modules' not in str(readme):\n                readmes.append(readme)\n\n    return readmes", "chunk_type": "function", "line_start": 91, "line_end": 101, "language": "python", "name": "find_readme_files"}, "67dcc4c44379_func_index_readme": {"id": "67dcc4c44379_func_index_readme", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\doc_index.py", "content": "def index_readme(readme_path: Path) -> DocItem:\n    \"\"\"Index a README file.\"\"\"\n    try:\n        content = readme_path.read_text(encoding='utf-8', errors='ignore')\n\n        # Get first paragraph as summary\n        lines = content.split('\\n')\n        summary_lines = []\n        for line in lines:\n            if line.strip() and not line.startswith('#'):\n                summary_lines.append(line)\n                if len(summary_lines) >= 3:\n                    break\n\n        summary = ' '.join(summary_lines)[:200]\n\n        return DocItem(\n            type='readme',\n            name=readme_path.name,\n            path=str(readme_path),\n            summary=summary,\n            full_text=content[:2000]\n        )\n    except Exception:\n        return None", "chunk_type": "function", "line_start": 104, "line_end": 128, "language": "python", "name": "index_readme"}, "67dcc4c44379_func_index_documentation": {"id": "67dcc4c44379_func_index_documentation", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\doc_index.py", "content": "def index_documentation(root: Path = None) -> Dict:\n    \"\"\"Build documentation index.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    Console.info(\"Indexing documentation...\")\n\n    index = {\n        \"total_items\": 0,\n        \"by_type\": {\"readme\": 0, \"module\": 0, \"class\": 0, \"function\": 0},\n        \"items\": []\n    }\n\n    # Index READMEs\n    for readme in find_readme_files(root):\n        item = index_readme(readme)\n        if item:\n            index[\"items\"].append({\n                \"type\": item.type,\n                \"name\": item.name,\n                \"path\": str(item.path),\n                \"summary\": item.summary\n            })\n            index[\"by_type\"][\"readme\"] += 1\n            index[\"total_items\"] += 1\n\n    # Index Python docstrings\n    exclude = ['node_modules', 'venv', '.venv', '__pycache__', '.git', 'vendor']\n    for file_path in find_python_files(root, exclude):\n        docs = extract_docstrings(file_path)\n        for item in docs:\n            index[\"items\"].appen", "chunk_type": "function", "line_start": 131, "line_end": 179, "language": "python", "name": "index_documentation"}, "67dcc4c44379_func_search_docs": {"id": "67dcc4c44379_func_search_docs", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\doc_index.py", "content": "def search_docs(query: str, root: Path = None) -> List[DocItem]:\n    \"\"\"Search documentation index.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n    index_path = root / '.mcp' / 'doc_index.json'\n\n    if not index_path.exists():\n        index_documentation(root)\n\n    with open(index_path, 'r') as f:\n        index = json.load(f)\n\n    results = []\n    query_lower = query.lower()\n\n    for item in index.get('items', []):\n        if query_lower in item['name'].lower() or query_lower in item['summary'].lower():\n            results.append(DocItem(\n                type=item['type'],\n                name=item['name'],\n                path=item['path'],\n                summary=item['summary']\n            ))\n\n    return results", "chunk_type": "function", "line_start": 182, "line_end": 205, "language": "python", "name": "search_docs"}, "67dcc4c44379_func_get_module_summary": {"id": "67dcc4c44379_func_get_module_summary", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\doc_index.py", "content": "def get_module_summary(module_path: Path) -> str:\n    \"\"\"Get summary of a module.\"\"\"\n    docs = extract_docstrings(module_path)\n\n    lines = [f\"# Module: {module_path.stem}\", \"\"]\n\n    # Module docstring\n    module_docs = [d for d in docs if d.type == 'module']\n    if module_docs:\n        lines.append(module_docs[0].full_text)\n        lines.append(\"\")\n\n    # Classes\n    class_docs = [d for d in docs if d.type == 'class']\n    if class_docs:\n        lines.append(\"## Classes\")\n        for d in class_docs:\n            lines.append(f\"- **{d.name}**: {d.summary}\")\n        lines.append(\"\")\n\n    # Functions\n    func_docs = [d for d in docs if d.type == 'function']\n    if func_docs:\n        lines.append(\"## Functions\")\n        for d in func_docs[:10]:\n            lines.append(f\"- **{d.name}**: {d.summary}\")\n\n    return '\\n'.join(lines)", "chunk_type": "function", "line_start": 208, "line_end": 235, "language": "python", "name": "get_module_summary"}, "67dcc4c44379_func_main": {"id": "67dcc4c44379_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\doc_index.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Documentation Index\")\n\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n    root = find_project_root() or Path.cwd()\n\n    if '--index' in sys.argv:\n        index_documentation(root)\n        return 0\n\n    if '--search' in sys.argv and args:\n        query = args[0]\n        results = search_docs(query, root)\n        Console.info(f\"Found {len(results)} results for '{query}':\")\n        for r in results[:15]:\n            print(f\"  [{r.type}] {r.name}: {r.summary[:50]}...\")\n        return 0\n\n    if args:\n        # Show module summary\n        file_path = Path(args[0])\n        if file_path.exists():\n            summary = get_module_summary(file_path)\n            print(summary)\n    else:\n        # Just index\n        index_documentation(root)\n\n    return 0", "chunk_type": "function", "line_start": 238, "line_end": 267, "language": "python", "name": "main"}, "67dcc4c44379_class_DocItem": {"id": "67dcc4c44379_class_DocItem", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\doc_index.py", "content": "class DocItem:\n    \"\"\"A documentation item.\"\"\"\n    type: str  # 'readme', 'module', 'class', 'function'\n    name: str\n    path: str\n    summary: str\n    full_text: str = \"\"", "chunk_type": "class", "line_start": 23, "line_end": 29, "language": "python", "name": "DocItem"}, "57f4585b29fe_file": {"id": "57f4585b29fe_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\embeddings.py", "content": "\"\"\"\nEmbeddings Generation\n=====================\nGenerate vector embeddings for code semantic search.\nUses sentence-transformers or falls back to TF-IDF.\n\nUsage:\n    from scripts.embeddings import embed_text, embed_code\n\"\"\"\n\nimport sys\nimport re\nimport math\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Tuple\nfrom dataclasses import dataclass\n\nfrom .utils import Console\n\n\n# Try to import sentence-transformers\ntry:\n    from sentence_transformers import SentenceTransformer\n    TRANSFORMERS_AVAILABLE = True\nexcept ImportError:\n    TRANSFORMERS_AVAILABLE = False\n\n# Try to import numpy\ntry:\n    import numpy as np\n    NUMPY_AVAILABLE = True\nexcept ImportError:\n    NUMPY_AVAILABLE = False\n\n\n# Model cache\n_model = None\n_model_name = \"all-MiniLM-L6-v2\"  # 22MB, good quality/speed balance\n\n\ndef get_model():\n    \"\"\"Get or load embedding model.\"\"\"\n    global _model\n\n    if _model is not None:\n        return _model\n\n    if not TRANSFORMERS_AVAILABLE:\n        return None\n\n    try:\n        # Try to load from local cache first\n        _model = SentenceTransformer(_model_name)\n        return _model\n    except Exception as e:\n        Console.warn(f\"Could not load embedding model: {e}\")\n        return None\n\n\ndef embed_text(text: str) -> Optional[List[float]]:\n    \"\"\"Generate embedding for text.\"\"\"\n    model = get_model()\n\n    if model is not None:\n        embedding = model.encode(text, convert_to_numpy=True)\n        return embedding.tolist()\n\n    # Fallback to simple TF-IDF-like embedding\n    return _fallback_embed(text)\n\n\ndef embed_texts(texts: List[str]) -> List[List[float]]:\n    \"\"\"Generate embeddings for multiple texts.\"\"\"\n    model = get_model()\n\n    if model is not None:\n        embeddings = model.encode(texts, convert_to_numpy=True)\n        return embeddings.tolist()\n\n    # Fallback\n    return [_fallback_embed(t) for t in texts]\n\n\ndef embed_code(code: str, language: str = \"python\") -> Optional[List[float]]:\n    \"\"\"Generate embedding for code with language-awar", "chunk_type": "file", "line_start": 1, "line_end": 217, "language": "python", "name": "embeddings.py"}, "57f4585b29fe_func_get_model": {"id": "57f4585b29fe_func_get_model", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\embeddings.py", "content": "def get_model():\n    \"\"\"Get or load embedding model.\"\"\"\n    global _model\n\n    if _model is not None:\n        return _model\n\n    if not TRANSFORMERS_AVAILABLE:\n        return None\n\n    try:\n        # Try to load from local cache first\n        _model = SentenceTransformer(_model_name)\n        return _model\n    except Exception as e:\n        Console.warn(f\"Could not load embedding model: {e}\")\n        return None", "chunk_type": "function", "line_start": 41, "line_end": 57, "language": "python", "name": "get_model"}, "57f4585b29fe_func_embed_text": {"id": "57f4585b29fe_func_embed_text", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\embeddings.py", "content": "def embed_text(text: str) -> Optional[List[float]]:\n    \"\"\"Generate embedding for text.\"\"\"\n    model = get_model()\n\n    if model is not None:\n        embedding = model.encode(text, convert_to_numpy=True)\n        return embedding.tolist()\n\n    # Fallback to simple TF-IDF-like embedding\n    return _fallback_embed(text)", "chunk_type": "function", "line_start": 60, "line_end": 69, "language": "python", "name": "embed_text"}, "57f4585b29fe_func_embed_texts": {"id": "57f4585b29fe_func_embed_texts", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\embeddings.py", "content": "def embed_texts(texts: List[str]) -> List[List[float]]:\n    \"\"\"Generate embeddings for multiple texts.\"\"\"\n    model = get_model()\n\n    if model is not None:\n        embeddings = model.encode(texts, convert_to_numpy=True)\n        return embeddings.tolist()\n\n    # Fallback\n    return [_fallback_embed(t) for t in texts]", "chunk_type": "function", "line_start": 72, "line_end": 81, "language": "python", "name": "embed_texts"}, "57f4585b29fe_func_embed_code": {"id": "57f4585b29fe_func_embed_code", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\embeddings.py", "content": "def embed_code(code: str, language: str = \"python\") -> Optional[List[float]]:\n    \"\"\"Generate embedding for code with language-aware preprocessing.\"\"\"\n    # Preprocess code for better embeddings\n    processed = _preprocess_code(code, language)\n    return embed_text(processed)", "chunk_type": "function", "line_start": 84, "line_end": 88, "language": "python", "name": "embed_code"}, "57f4585b29fe_func__preprocess_code": {"id": "57f4585b29fe_func__preprocess_code", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\embeddings.py", "content": "def _preprocess_code(code: str, language: str) -> str:\n    \"\"\"Preprocess code for embedding.\"\"\"\n    # Remove comments based on language\n    if language in ('python', 'ruby'):\n        code = re.sub(r'#.*$', '', code, flags=re.MULTILINE)\n    elif language in ('javascript', 'typescript', 'java', 'c', 'cpp', 'go', 'rust'):\n        code = re.sub(r'//.*$', '', code, flags=re.MULTILINE)\n        code = re.sub(r'/\\*.*?\\*/', '', code, flags=re.DOTALL)\n\n    # Normalize whitespace\n    code = ' '.join(code.split())\n\n    # Split camelCase and snake_case for better semantic matching\n    code = re.sub(r'([a-z])([A-Z])', r'\\1 \\2', code)\n    code = code.replace('_', ' ')\n\n    return code.lower()", "chunk_type": "function", "line_start": 91, "line_end": 107, "language": "python", "name": "_preprocess_code"}, "57f4585b29fe_func__fallback_embed": {"id": "57f4585b29fe_func__fallback_embed", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\embeddings.py", "content": "def _fallback_embed(text: str, dim: int = 384) -> List[float]:\n    \"\"\"Simple fallback embedding using hashing + TF-IDF-like approach.\"\"\"\n    # Tokenize\n    tokens = re.findall(r'[a-z0-9]+', text.lower())\n\n    if not tokens:\n        return [0.0] * dim\n\n    # Create embedding via feature hashing\n    embedding = [0.0] * dim\n\n    for token in tokens:\n        # Hash token to get index\n        h = hash(token)\n        idx = abs(h) % dim\n\n        # Add weighted value\n        tf = tokens.count(token) / len(tokens)\n        embedding[idx] += tf\n\n    # Normalize\n    norm = math.sqrt(sum(x * x for x in embedding))\n    if norm > 0:\n        embedding = [x / norm for x in embedding]\n\n    return embedding", "chunk_type": "function", "line_start": 110, "line_end": 135, "language": "python", "name": "_fallback_embed"}, "57f4585b29fe_func_cosine_similarity": {"id": "57f4585b29fe_func_cosine_similarity", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\embeddings.py", "content": "def cosine_similarity(a: List[float], b: List[float]) -> float:\n    \"\"\"Compute cosine similarity between two vectors.\"\"\"\n    if len(a) != len(b):\n        return 0.0\n\n    dot = sum(x * y for x, y in zip(a, b))\n    norm_a = math.sqrt(sum(x * x for x in a))\n    norm_b = math.sqrt(sum(x * x for x in b))\n\n    if norm_a == 0 or norm_b == 0:\n        return 0.0\n\n    return dot / (norm_a * norm_b)", "chunk_type": "function", "line_start": 138, "line_end": 150, "language": "python", "name": "cosine_similarity"}, "57f4585b29fe_func_embedding_dimension": {"id": "57f4585b29fe_func_embedding_dimension", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\embeddings.py", "content": "def embedding_dimension() -> int:\n    \"\"\"Get embedding dimension.\"\"\"\n    model = get_model()\n    if model is not None:\n        return model.get_sentence_embedding_dimension()\n    return 384  # Fallback dimension", "chunk_type": "function", "line_start": 153, "line_end": 158, "language": "python", "name": "embedding_dimension"}, "57f4585b29fe_func_is_transformers_available": {"id": "57f4585b29fe_func_is_transformers_available", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\embeddings.py", "content": "def is_transformers_available() -> bool:\n    \"\"\"Check if sentence-transformers is available.\"\"\"\n    return TRANSFORMERS_AVAILABLE", "chunk_type": "function", "line_start": 161, "line_end": 163, "language": "python", "name": "is_transformers_available"}, "57f4585b29fe_func_embed_with_info": {"id": "57f4585b29fe_func_embed_with_info", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\embeddings.py", "content": "def embed_with_info(text: str) -> EmbeddingResult:\n    \"\"\"Generate embedding with metadata.\"\"\"\n    model = get_model()\n\n    if model is not None:\n        embedding = model.encode(text, convert_to_numpy=True).tolist()\n        return EmbeddingResult(text=text, embedding=embedding, method='transformer')\n\n    embedding = _fallback_embed(text)\n    return EmbeddingResult(text=text, embedding=embedding, method='fallback')", "chunk_type": "function", "line_start": 174, "line_end": 183, "language": "python", "name": "embed_with_info"}, "57f4585b29fe_func_main": {"id": "57f4585b29fe_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\embeddings.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Embedding Generation\")\n\n    if TRANSFORMERS_AVAILABLE:\n        Console.ok(\"sentence-transformers available\")\n        model = get_model()\n        if model:\n            Console.ok(f\"Model: {_model_name}\")\n            Console.ok(f\"Dimension: {embedding_dimension()}\")\n    else:\n        Console.warn(\"sentence-transformers not available, using fallback\")\n        Console.info(f\"Fallback dimension: 384\")\n\n    # Test embedding\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n\n    if args:\n        text = ' '.join(args)\n        Console.info(f\"Embedding: {text[:50]}...\")\n\n        result = embed_with_info(text)\n        Console.ok(f\"Method: {result.method}\")\n        Console.ok(f\"Dimension: {len(result.embedding)}\")\n        Console.ok(f\"Sample values: {result.embedding[:5]}\")\n\n    return 0", "chunk_type": "function", "line_start": 186, "line_end": 212, "language": "python", "name": "main"}, "57f4585b29fe_class_EmbeddingResult": {"id": "57f4585b29fe_class_EmbeddingResult", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\embeddings.py", "content": "class EmbeddingResult:\n    \"\"\"Result of embedding generation.\"\"\"\n    text: str\n    embedding: List[float]\n    method: str  # 'transformer' or 'fallback'", "chunk_type": "class", "line_start": 167, "line_end": 171, "language": "python", "name": "EmbeddingResult"}, "a2788e27d1e8_file": {"id": "a2788e27d1e8_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\errors.py", "content": "\"\"\"\nError Pattern Analyzer\n======================\nAnalyze exception handling and error patterns in code.\n\nUsage:\n    python errors.py [path]\n    python -m scripts.errors src/\n\"\"\"\n\nfrom collections import Counter\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Set\nimport ast\nimport sys\n\nfrom .utils import (\n    find_python_files,\n    find_project_root,\n    parse_file,\n    Console,\n    format_as_markdown_table\n)\n\n\n@dataclass\nclass ErrorPattern:\n    \"\"\"An error handling pattern.\"\"\"\n    path: Path\n    line: int\n    pattern_type: str  # 'bare_except', 'swallowed', 'broad', 'reraise', 'logged'\n    exception_type: Optional[str] = None\n    severity: str = 'medium'\n    description: str = \"\"\n\n\n@dataclass\nclass ErrorReport:\n    \"\"\"Complete error analysis report.\"\"\"\n    patterns: List[ErrorPattern] = field(default_factory=list)\n    exception_usage: Counter = field(default_factory=Counter)\n    total_try_blocks: int = 0\n\n    @property\n    def issues(self) -> List[ErrorPattern]:\n        return [p for p in self.patterns if p.severity in ('high', 'medium')]\n\n    def to_markdown(self) -> str:\n        lines = [\n            \"# Error Handling Analysis\",\n            \"\",\n            \"## Summary\",\n            \"\",\n            f\"- **Try blocks:** {self.total_try_blocks}\",\n            f\"- **Issues found:** {len(self.issues)}\",\n            \"\",\n        ]\n\n        # Exception types used\n        if self.exception_usage:\n            lines.extend([\n                \"## Exception Types Used\",\n                \"\",\n                \"| Exception | Count |\",\n                \"|-----------|-------|\",\n            ])\n            for exc, count in self.exception_usage.most_common(10):\n                lines.append(f\"| `{exc}` | {count} |\")\n            lines.append(\"\")\n\n        # Issues by severity\n        for severity in ['high', 'medium', 'low']:\n            items = [p for p in self.patterns if p.severity == severity]\n            if not items:\n         ", "chunk_type": "file", "line_start": 1, "line_end": 341, "language": "python", "name": "errors.py"}, "a2788e27d1e8_func_analyze_file": {"id": "a2788e27d1e8_func_analyze_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\errors.py", "content": "def analyze_file(path: Path) -> Tuple[List[ErrorPattern], Counter, int]:\n    \"\"\"Analyze a file for error patterns.\"\"\"\n    patterns = []\n    exception_usage: Counter = Counter()\n    try_count = 0\n\n    tree = parse_file(path)\n    if tree is None:\n        return patterns, exception_usage, try_count\n\n    # Exception handling analysis\n    exc_analyzer = ExceptionAnalyzer(path)\n    exc_analyzer.visit(tree)\n    patterns.extend(exc_analyzer.patterns)\n    exception_usage.update(exc_analyzer.exception_usage)\n    try_count = exc_analyzer.try_count\n\n    # Raise analysis\n    raise_analyzer = RaiseAnalyzer(path)\n    raise_analyzer.visit(tree)\n    patterns.extend(raise_analyzer.patterns)\n    exception_usage.update(raise_analyzer.exception_usage)\n\n    return patterns, exception_usage, try_count", "chunk_type": "function", "line_start": 254, "line_end": 277, "language": "python", "name": "analyze_file"}, "a2788e27d1e8_func_analyze_project": {"id": "a2788e27d1e8_func_analyze_project", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\errors.py", "content": "def analyze_project(\n    root: Path,\n    exclude_patterns: List[str] = None\n) -> ErrorReport:\n    \"\"\"Analyze project for error patterns.\"\"\"\n    report = ErrorReport()\n\n    Console.info(f\"Analyzing {root}...\")\n\n    files = list(find_python_files(root, exclude_patterns))\n    Console.info(f\"Found {len(files)} Python files\")\n\n    for path in files:\n        patterns, exc_usage, try_count = analyze_file(path)\n        report.patterns.extend(patterns)\n        report.exception_usage.update(exc_usage)\n        report.total_try_blocks += try_count\n\n    return report", "chunk_type": "function", "line_start": 280, "line_end": 298, "language": "python", "name": "analyze_project"}, "a2788e27d1e8_func_main": {"id": "a2788e27d1e8_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\errors.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Error Pattern Analyzer\")\n\n    # Parse args\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n\n    if args:\n        path = Path(args[0])\n    else:\n        path = find_project_root() or Path.cwd()\n\n    if not path.exists():\n        Console.fail(f\"Path not found: {path}\")\n        return 1\n\n    Console.info(f\"Analyzing: {path}\")\n\n    report = analyze_project(path)\n\n    print(report.to_markdown())\n\n    # Summary\n    issues = report.issues\n    if issues:\n        Console.warn(f\"Found {len(issues)} error handling issues\")\n    else:\n        Console.ok(\"No error handling issues found\")\n\n    Console.info(f\"Analyzed {report.total_try_blocks} try blocks\")\n\n    return 0", "chunk_type": "function", "line_start": 305, "line_end": 336, "language": "python", "name": "main"}, "a2788e27d1e8_func_issues": {"id": "a2788e27d1e8_func_issues", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\errors.py", "content": "    def issues(self) -> List[ErrorPattern]:\n        return [p for p in self.patterns if p.severity in ('high', 'medium')]", "chunk_type": "function", "line_start": 46, "line_end": 47, "language": "python", "name": "issues"}, "a2788e27d1e8_func_to_markdown": {"id": "a2788e27d1e8_func_to_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\errors.py", "content": "    def to_markdown(self) -> str:\n        lines = [\n            \"# Error Handling Analysis\",\n            \"\",\n            \"## Summary\",\n            \"\",\n            f\"- **Try blocks:** {self.total_try_blocks}\",\n            f\"- **Issues found:** {len(self.issues)}\",\n            \"\",\n        ]\n\n        # Exception types used\n        if self.exception_usage:\n            lines.extend([\n                \"## Exception Types Used\",\n                \"\",\n                \"| Exception | Count |\",\n                \"|-----------|-------|\",\n            ])\n            for exc, count in self.exception_usage.most_common(10):\n                lines.append(f\"| `{exc}` | {count} |\")\n            lines.append(\"\")\n\n        # Issues by severity\n        for severity in ['high', 'medium', 'low']:\n            items = [p for p in self.patterns if p.severity == severity]\n            if not items:\n                continue\n\n            lines.append(f\"## {severity.upper()} Severity\")\n            lines.append(\"\")\n\n          ", "chunk_type": "function", "line_start": 49, "line_end": 86, "language": "python", "name": "to_markdown"}, "a2788e27d1e8_func___init__": {"id": "a2788e27d1e8_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\errors.py", "content": "    def __init__(self, path: Path):\n        self.path = path\n        self.patterns: List[ErrorPattern] = []\n        self.exception_usage: Counter = Counter()", "chunk_type": "function", "line_start": 229, "line_end": 232, "language": "python", "name": "__init__"}, "a2788e27d1e8_func_visit_Try": {"id": "a2788e27d1e8_func_visit_Try", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\errors.py", "content": "    def visit_Try(self, node: ast.Try):\n        self.try_count += 1\n\n        for handler in node.handlers:\n            self._analyze_handler(handler)\n\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 113, "line_end": 119, "language": "python", "name": "visit_Try"}, "a2788e27d1e8_func__analyze_handler": {"id": "a2788e27d1e8_func__analyze_handler", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\errors.py", "content": "    def _analyze_handler(self, handler: ast.ExceptHandler):\n        # Get exception type\n        if handler.type is None:\n            # Bare except\n            self.patterns.append(ErrorPattern(\n                path=self.path,\n                line=handler.lineno,\n                pattern_type='bare_except',\n                severity='high',\n                description=\"Bare 'except:' catches all exceptions including KeyboardInterrupt\"\n            ))\n            self.exception_usage['Exception'] += 1\n        elif isinstance(handler.type, ast.Name):\n            exc_name = handler.type.id\n            self.exception_usage[exc_name] += 1\n\n            # Check for broad exception\n            if exc_name == 'Exception':\n                self.patterns.append(ErrorPattern(\n                    path=self.path,\n                    line=handler.lineno,\n                    pattern_type='broad_exception',\n                    exception_type=exc_name,\n                    severity='medium',\n                ", "chunk_type": "function", "line_start": 121, "line_end": 179, "language": "python", "name": "_analyze_handler"}, "a2788e27d1e8_func__is_swallowed": {"id": "a2788e27d1e8_func__is_swallowed", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\errors.py", "content": "    def _is_swallowed(self, handler: ast.ExceptHandler) -> bool:\n        \"\"\"Check if exception is swallowed (ignored).\"\"\"\n        if not handler.body:\n            return True\n\n        if len(handler.body) == 1:\n            stmt = handler.body[0]\n            # Just 'pass'\n            if isinstance(stmt, ast.Pass):\n                return True\n            # Just '...'\n            if isinstance(stmt, ast.Expr) and isinstance(stmt.value, ast.Constant):\n                if stmt.value.value is ...:\n                    return True\n\n        # Check if there's any logging or re-raise\n        for node in ast.walk(handler):\n            if isinstance(node, ast.Raise):\n                return False\n            if isinstance(node, ast.Call):\n                func = self._get_func_name(node.func)\n                if any(x in func for x in ['log', 'error', 'warn', 'print', 'logger']):\n                    return False\n\n        return False", "chunk_type": "function", "line_start": 181, "line_end": 205, "language": "python", "name": "_is_swallowed"}, "a2788e27d1e8_func__has_logging": {"id": "a2788e27d1e8_func__has_logging", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\errors.py", "content": "    def _has_logging(self, handler: ast.ExceptHandler) -> bool:\n        \"\"\"Check if handler has logging.\"\"\"\n        for node in ast.walk(handler):\n            if isinstance(node, ast.Call):\n                func = self._get_func_name(node.func)\n                if any(x in func for x in ['logging', 'logger', 'log']):\n                    return True\n        return False", "chunk_type": "function", "line_start": 207, "line_end": 214, "language": "python", "name": "_has_logging"}, "a2788e27d1e8_func__get_func_name": {"id": "a2788e27d1e8_func__get_func_name", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\errors.py", "content": "    def _get_func_name(self, node) -> str:\n        if isinstance(node, ast.Name):\n            return node.id.lower()\n        elif isinstance(node, ast.Attribute):\n            if isinstance(node.value, ast.Name):\n                return f\"{node.value.id}.{node.attr}\".lower()\n            return node.attr.lower()\n        return \"\"", "chunk_type": "function", "line_start": 216, "line_end": 223, "language": "python", "name": "_get_func_name"}, "a2788e27d1e8_func_visit_Raise": {"id": "a2788e27d1e8_func_visit_Raise", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\errors.py", "content": "    def visit_Raise(self, node: ast.Raise):\n        if node.exc:\n            if isinstance(node.exc, ast.Call):\n                if isinstance(node.exc.func, ast.Name):\n                    self.exception_usage[node.exc.func.id] += 1\n\n                    # Check for generic Exception raise\n                    if node.exc.func.id == 'Exception':\n                        self.patterns.append(ErrorPattern(\n                            path=self.path,\n                            line=node.lineno,\n                            pattern_type='generic_raise',\n                            exception_type='Exception',\n                            severity='low',\n                            description=\"Raising generic 'Exception', consider using specific exception types\"\n                        ))\n\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 234, "line_end": 251, "language": "python", "name": "visit_Raise"}, "a2788e27d1e8_class_ErrorPattern": {"id": "a2788e27d1e8_class_ErrorPattern", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\errors.py", "content": "class ErrorPattern:\n    \"\"\"An error handling pattern.\"\"\"\n    path: Path\n    line: int\n    pattern_type: str  # 'bare_except', 'swallowed', 'broad', 'reraise', 'logged'\n    exception_type: Optional[str] = None\n    severity: str = 'medium'\n    description: str = \"\"", "chunk_type": "class", "line_start": 28, "line_end": 35, "language": "python", "name": "ErrorPattern"}, "a2788e27d1e8_class_ErrorReport": {"id": "a2788e27d1e8_class_ErrorReport", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\errors.py", "content": "class ErrorReport:\n    \"\"\"Complete error analysis report.\"\"\"\n    patterns: List[ErrorPattern] = field(default_factory=list)\n    exception_usage: Counter = field(default_factory=Counter)\n    total_try_blocks: int = 0\n\n    @property\n    def issues(self) -> List[ErrorPattern]:\n        return [p for p in self.patterns if p.severity in ('high', 'medium')]\n\n    def to_markdown(self) -> str:\n        lines = [\n            \"# Error Handling Analysis\",\n            \"\",\n            \"## Summary\",\n            \"\",\n            f\"- **Try blocks:** {self.total_try_blocks}\",\n            f\"- **Issues found:** {len(self.issues)}\",\n            \"\",\n        ]\n\n        # Exception types used\n        if self.exception_usage:\n            lines.extend([\n                \"## Exception Types Used\",\n                \"\",\n                \"| Exception | Count |\",\n                \"|-----------|-------|\",\n            ])\n            for exc, count in self.exception_usage.most_common(10):\n                lines.append(f\"| `{e", "chunk_type": "class", "line_start": 39, "line_end": 86, "language": "python", "name": "ErrorReport"}, "a2788e27d1e8_class_ExceptionAnalyzer": {"id": "a2788e27d1e8_class_ExceptionAnalyzer", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\errors.py", "content": "class ExceptionAnalyzer(ast.NodeVisitor):\n    \"\"\"Analyze exception handling patterns.\"\"\"\n\n    def __init__(self, path: Path):\n        self.path = path\n        self.patterns: List[ErrorPattern] = []\n        self.exception_usage: Counter = Counter()\n        self.try_count = 0\n\n    def visit_Try(self, node: ast.Try):\n        self.try_count += 1\n\n        for handler in node.handlers:\n            self._analyze_handler(handler)\n\n        self.generic_visit(node)\n\n    def _analyze_handler(self, handler: ast.ExceptHandler):\n        # Get exception type\n        if handler.type is None:\n            # Bare except\n            self.patterns.append(ErrorPattern(\n                path=self.path,\n                line=handler.lineno,\n                pattern_type='bare_except',\n                severity='high',\n                description=\"Bare 'except:' catches all exceptions including KeyboardInterrupt\"\n            ))\n            self.exception_usage['Exception'] += 1\n        elif isinstance(handler.type", "chunk_type": "class", "line_start": 104, "line_end": 223, "language": "python", "name": "ExceptionAnalyzer"}, "a2788e27d1e8_class_RaiseAnalyzer": {"id": "a2788e27d1e8_class_RaiseAnalyzer", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\errors.py", "content": "class RaiseAnalyzer(ast.NodeVisitor):\n    \"\"\"Analyze raise statements.\"\"\"\n\n    def __init__(self, path: Path):\n        self.path = path\n        self.patterns: List[ErrorPattern] = []\n        self.exception_usage: Counter = Counter()\n\n    def visit_Raise(self, node: ast.Raise):\n        if node.exc:\n            if isinstance(node.exc, ast.Call):\n                if isinstance(node.exc.func, ast.Name):\n                    self.exception_usage[node.exc.func.id] += 1\n\n                    # Check for generic Exception raise\n                    if node.exc.func.id == 'Exception':\n                        self.patterns.append(ErrorPattern(\n                            path=self.path,\n                            line=node.lineno,\n                            pattern_type='generic_raise',\n                            exception_type='Exception',\n                            severity='low',\n                            description=\"Raising generic 'Exception', consider using specific exception types\"\n   ", "chunk_type": "class", "line_start": 226, "line_end": 251, "language": "python", "name": "RaiseAnalyzer"}, "a30e3d14c268_file": {"id": "a30e3d14c268_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\finder.py", "content": "\"\"\"\nSmart File Finder\n=================\nFind files by natural language queries and patterns.\n\nUsage:\n    python finder.py \"authentication\" [path]\n    python -m scripts.finder \"database handler\"\n\"\"\"\n\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Tuple\nimport re\nimport sys\n\nfrom .utils import (\n    find_python_files,\n    find_project_root,\n    parse_file,\n    analyze_module,\n    run_git_command,\n    Console\n)\n\n\n@dataclass\nclass SearchResult:\n    \"\"\"A search result.\"\"\"\n    path: Path\n    score: float\n    match_type: str  # 'filename', 'content', 'import', 'function', 'class'\n    context: str\n    line: Optional[int] = None\n\n\n@dataclass\nclass SearchResults:\n    \"\"\"Collection of search results.\"\"\"\n    query: str\n    results: List[SearchResult] = field(default_factory=list)\n\n    def to_markdown(self) -> str:\n        lines = [\n            f\"# Search: {self.query}\",\n            \"\",\n            f\"**Found:** {len(self.results)} results\",\n            \"\",\n        ]\n\n        if not self.results:\n            lines.append(\"No results found.\")\n            return \"\\n\".join(lines)\n\n        # Group by match type\n        by_type: Dict[str, List[SearchResult]] = {}\n        for r in self.results:\n            if r.match_type not in by_type:\n                by_type[r.match_type] = []\n            by_type[r.match_type].append(r)\n\n        type_order = ['filename', 'function', 'class', 'import', 'content']\n        for match_type in type_order:\n            items = by_type.get(match_type, [])\n            if not items:\n                continue\n\n            lines.append(f\"## {match_type.title()} Matches\")\n            lines.append(\"\")\n\n            for r in sorted(items, key=lambda x: x.score, reverse=True)[:10]:\n                if r.line:\n                    lines.append(f\"- `{r.path}:{r.line}` (score: {r.score:.2f})\")\n                else:\n                    lines.append(f\"- `{r.path}` (score: {r.score:.2f})\")\n                lines.appen", "chunk_type": "file", "line_start": 1, "line_end": 300, "language": "python", "name": "finder.py"}, "a30e3d14c268_func_expand_query": {"id": "a30e3d14c268_func_expand_query", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\finder.py", "content": "def expand_query(query: str) -> List[str]:\n    \"\"\"Expand query into search terms.\"\"\"\n    terms = re.findall(r'[a-z0-9]+', query.lower())\n    expanded = list(terms)\n\n    for term in terms:\n        if term in QUERY_EXPANSIONS:\n            expanded.extend(QUERY_EXPANSIONS[term])\n\n    return list(set(expanded))", "chunk_type": "function", "line_start": 97, "line_end": 106, "language": "python", "name": "expand_query"}, "a30e3d14c268_func_score_filename_match": {"id": "a30e3d14c268_func_score_filename_match", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\finder.py", "content": "def score_filename_match(filename: str, terms: List[str]) -> float:\n    \"\"\"Score a filename against search terms.\"\"\"\n    name_lower = filename.lower()\n    score = 0.0\n\n    for term in terms:\n        if term in name_lower:\n            # Exact match gets higher score\n            score += 2.0\n            # Even higher if at word boundary\n            if f\"_{term}\" in name_lower or name_lower.startswith(term):\n                score += 1.0\n\n    return score", "chunk_type": "function", "line_start": 109, "line_end": 122, "language": "python", "name": "score_filename_match"}, "a30e3d14c268_func_search_file_content": {"id": "a30e3d14c268_func_search_file_content", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\finder.py", "content": "def search_file_content(\n    path: Path,\n    terms: List[str]\n) -> List[Tuple[int, str, float]]:\n    \"\"\"Search file content for terms.\"\"\"\n    matches = []\n\n    try:\n        with open(path, 'r', encoding='utf-8', errors='ignore') as f:\n            lines = f.readlines()\n    except Exception:\n        return matches\n\n    for i, line in enumerate(lines, 1):\n        line_lower = line.lower()\n        score = sum(1.0 for term in terms if term in line_lower)\n        if score > 0:\n            matches.append((i, line.strip()[:100], score))\n\n    return matches", "chunk_type": "function", "line_start": 125, "line_end": 144, "language": "python", "name": "search_file_content"}, "a30e3d14c268_func_search_module_structure": {"id": "a30e3d14c268_func_search_module_structure", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\finder.py", "content": "def search_module_structure(\n    path: Path,\n    terms: List[str]\n) -> List[SearchResult]:\n    \"\"\"Search module functions and classes.\"\"\"\n    results = []\n\n    module = analyze_module(path)\n    if module is None:\n        return results\n\n    # Search functions\n    for func in module.functions:\n        name_lower = func.name.lower()\n        score = sum(2.0 for term in terms if term in name_lower)\n\n        # Check docstring\n        if func.docstring:\n            doc_lower = func.docstring.lower()\n            score += sum(0.5 for term in terms if term in doc_lower)\n\n        if score > 0:\n            results.append(SearchResult(\n                path=path,\n                score=score,\n                match_type='function',\n                context=f\"def {func.name}(): {func.docstring or ''}\",\n                line=func.lineno\n            ))\n\n    # Search classes\n    for cls in module.classes:\n        name_lower = cls.name.lower()\n        score = sum(2.0 for term in terms if term in name_lower)", "chunk_type": "function", "line_start": 147, "line_end": 206, "language": "python", "name": "search_module_structure"}, "a30e3d14c268_func_find_files": {"id": "a30e3d14c268_func_find_files", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\finder.py", "content": "def find_files(\n    query: str,\n    root: Path,\n    limit: int = 20,\n    exclude_patterns: List[str] = None\n) -> SearchResults:\n    \"\"\"Find files matching a query.\"\"\"\n    results = SearchResults(query=query)\n    terms = expand_query(query)\n\n    Console.info(f\"Searching for: '{query}'\")\n    Console.info(f\"Terms: {', '.join(terms)}\")\n\n    files = list(find_python_files(root, exclude_patterns))\n    Console.info(f\"Scanning {len(files)} files...\")\n\n    all_results = []\n\n    for path in files:\n        # Filename match\n        filename_score = score_filename_match(path.name, terms)\n        if filename_score > 0:\n            all_results.append(SearchResult(\n                path=path,\n                score=filename_score,\n                match_type='filename',\n                context=path.name\n            ))\n\n        # Module structure search\n        structure_results = search_module_structure(path, terms)\n        all_results.extend(structure_results)\n\n        # Content search (only if not foun", "chunk_type": "function", "line_start": 209, "line_end": 258, "language": "python", "name": "find_files"}, "a30e3d14c268_func_main": {"id": "a30e3d14c268_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\finder.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Smart File Finder\")\n\n    # Parse args\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n\n    if not args:\n        Console.fail(\"Usage: mcp find <query> [path]\")\n        print(\"\\nExamples:\")\n        print('  mcp find \"authentication\"')\n        print('  mcp find \"database handler\"')\n        print('  mcp find \"api endpoint\" src/')\n        return 1\n\n    query = args[0]\n\n    if len(args) > 1:\n        path = Path(args[1])\n    else:\n        path = find_project_root() or Path.cwd()\n\n    if not path.exists():\n        Console.fail(f\"Path not found: {path}\")\n        return 1\n\n    Console.info(f\"Searching in: {path}\")\n\n    results = find_files(query, path)\n\n    print(results.to_markdown())\n\n    Console.ok(f\"Found {len(results.results)} results\")\n\n    return 0", "chunk_type": "function", "line_start": 261, "line_end": 295, "language": "python", "name": "main"}, "a30e3d14c268_func_to_markdown": {"id": "a30e3d14c268_func_to_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\finder.py", "content": "    def to_markdown(self) -> str:\n        lines = [\n            f\"# Search: {self.query}\",\n            \"\",\n            f\"**Found:** {len(self.results)} results\",\n            \"\",\n        ]\n\n        if not self.results:\n            lines.append(\"No results found.\")\n            return \"\\n\".join(lines)\n\n        # Group by match type\n        by_type: Dict[str, List[SearchResult]] = {}\n        for r in self.results:\n            if r.match_type not in by_type:\n                by_type[r.match_type] = []\n            by_type[r.match_type].append(r)\n\n        type_order = ['filename', 'function', 'class', 'import', 'content']\n        for match_type in type_order:\n            items = by_type.get(match_type, [])\n            if not items:\n                continue\n\n            lines.append(f\"## {match_type.title()} Matches\")\n            lines.append(\"\")\n\n            for r in sorted(items, key=lambda x: x.score, reverse=True)[:10]:\n                if r.line:\n                    lines.append(f\"- `{r.pat", "chunk_type": "function", "line_start": 43, "line_end": 79, "language": "python", "name": "to_markdown"}, "a30e3d14c268_class_SearchResult": {"id": "a30e3d14c268_class_SearchResult", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\finder.py", "content": "class SearchResult:\n    \"\"\"A search result.\"\"\"\n    path: Path\n    score: float\n    match_type: str  # 'filename', 'content', 'import', 'function', 'class'\n    context: str\n    line: Optional[int] = None", "chunk_type": "class", "line_start": 28, "line_end": 34, "language": "python", "name": "SearchResult"}, "a30e3d14c268_class_SearchResults": {"id": "a30e3d14c268_class_SearchResults", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\finder.py", "content": "class SearchResults:\n    \"\"\"Collection of search results.\"\"\"\n    query: str\n    results: List[SearchResult] = field(default_factory=list)\n\n    def to_markdown(self) -> str:\n        lines = [\n            f\"# Search: {self.query}\",\n            \"\",\n            f\"**Found:** {len(self.results)} results\",\n            \"\",\n        ]\n\n        if not self.results:\n            lines.append(\"No results found.\")\n            return \"\\n\".join(lines)\n\n        # Group by match type\n        by_type: Dict[str, List[SearchResult]] = {}\n        for r in self.results:\n            if r.match_type not in by_type:\n                by_type[r.match_type] = []\n            by_type[r.match_type].append(r)\n\n        type_order = ['filename', 'function', 'class', 'import', 'content']\n        for match_type in type_order:\n            items = by_type.get(match_type, [])\n            if not items:\n                continue\n\n            lines.append(f\"## {match_type.title()} Matches\")\n            lines.append(\"\")\n\n          ", "chunk_type": "class", "line_start": 38, "line_end": 79, "language": "python", "name": "SearchResults"}, "42f0b178e264_file": {"id": "42f0b178e264_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\fix.py", "content": "\"\"\"\nAuto-Fix Tool\n=============\nAutomatically fix common code issues.\n\nUsage:\n    python fix.py [path] [--lint] [--format] [--imports]\n    python -m scripts.fix src/\n\"\"\"\n\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Tuple, Set\nimport ast\nimport re\nimport sys\n\nfrom .utils import (\n    find_python_files,\n    find_project_root,\n    parse_file,\n    Console\n)\n\n\n@dataclass\nclass FixResult:\n    \"\"\"Result of a fix operation.\"\"\"\n    path: Path\n    fix_type: str\n    original: str\n    fixed: str\n    line: int\n    description: str\n\n\n@dataclass\nclass FixReport:\n    \"\"\"Complete fix report.\"\"\"\n    fixes_applied: List[FixResult] = field(default_factory=list)\n    files_modified: int = 0\n\n    def to_markdown(self) -> str:\n        lines = [\n            \"# Auto-Fix Report\",\n            \"\",\n            f\"**Files modified:** {self.files_modified}\",\n            f\"**Fixes applied:** {len(self.fixes_applied)}\",\n            \"\",\n        ]\n\n        if not self.fixes_applied:\n            lines.append(\"No fixes needed.\")\n            return \"\\n\".join(lines)\n\n        # Group by file\n        by_file: Dict[Path, List[FixResult]] = {}\n        for fix in self.fixes_applied:\n            if fix.path not in by_file:\n                by_file[fix.path] = []\n            by_file[fix.path].append(fix)\n\n        for path, fixes in by_file.items():\n            lines.append(f\"## {path}\")\n            lines.append(\"\")\n            for fix in fixes:\n                lines.append(f\"- **Line {fix.line}:** {fix.description}\")\n            lines.append(\"\")\n\n        return \"\\n\".join(lines)\n\n\ndef sort_imports(content: str) -> Tuple[str, List[FixResult]]:\n    \"\"\"Sort and organize imports.\"\"\"\n    fixes = []\n    lines = content.split('\\n')\n\n    # Find import block\n    import_lines = []\n    import_start = None\n    import_end = None\n\n    for i, line in enumerate(lines):\n        stripped = line.strip()\n        if stripped.startswith('import ') or stripped.startswith('fro", "chunk_type": "file", "line_start": 1, "line_end": 476, "language": "python", "name": "fix.py"}, "42f0b178e264_func_sort_imports": {"id": "42f0b178e264_func_sort_imports", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\fix.py", "content": "def sort_imports(content: str) -> Tuple[str, List[FixResult]]:\n    \"\"\"Sort and organize imports.\"\"\"\n    fixes = []\n    lines = content.split('\\n')\n\n    # Find import block\n    import_lines = []\n    import_start = None\n    import_end = None\n\n    for i, line in enumerate(lines):\n        stripped = line.strip()\n        if stripped.startswith('import ') or stripped.startswith('from '):\n            if import_start is None:\n                import_start = i\n            import_end = i\n            import_lines.append((i, line))\n        elif import_start is not None and stripped and not stripped.startswith('#'):\n            break\n\n    if not import_lines:\n        return content, fixes\n\n    # Group imports\n    stdlib = []\n    third_party = []\n    local = []\n\n    STDLIB = {\n        'os', 'sys', 're', 'json', 'pathlib', 'typing', 'collections',\n        'itertools', 'functools', 'datetime', 'time', 'logging', 'ast',\n        'subprocess', 'threading', 'multiprocessing', 'queue', 'socket',\n        'ht", "chunk_type": "function", "line_start": 73, "line_end": 165, "language": "python", "name": "sort_imports"}, "42f0b178e264_func_fix_trailing_whitespace": {"id": "42f0b178e264_func_fix_trailing_whitespace", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\fix.py", "content": "def fix_trailing_whitespace(content: str) -> Tuple[str, List[FixResult]]:\n    \"\"\"Remove trailing whitespace.\"\"\"\n    fixes = []\n    lines = content.split('\\n')\n    fixed_lines = []\n\n    for i, line in enumerate(lines):\n        if line != line.rstrip():\n            fixes.append(FixResult(\n                path=Path(''),\n                fix_type='whitespace',\n                original=line,\n                fixed=line.rstrip(),\n                line=i + 1,\n                description='Removed trailing whitespace'\n            ))\n            fixed_lines.append(line.rstrip())\n        else:\n            fixed_lines.append(line)\n\n    return '\\n'.join(fixed_lines), fixes", "chunk_type": "function", "line_start": 168, "line_end": 188, "language": "python", "name": "fix_trailing_whitespace"}, "42f0b178e264_func_fix_blank_lines": {"id": "42f0b178e264_func_fix_blank_lines", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\fix.py", "content": "def fix_blank_lines(content: str) -> Tuple[str, List[FixResult]]:\n    \"\"\"Fix excessive blank lines.\"\"\"\n    fixes = []\n\n    # Replace 3+ blank lines with 2\n    pattern = r'\\n{4,}'\n    if re.search(pattern, content):\n        content = re.sub(pattern, '\\n\\n\\n', content)\n        fixes.append(FixResult(\n            path=Path(''),\n            fix_type='formatting',\n            original='',\n            fixed='',\n            line=0,\n            description='Reduced excessive blank lines'\n        ))\n\n    # Ensure file ends with single newline\n    if content and not content.endswith('\\n'):\n        content += '\\n'\n        fixes.append(FixResult(\n            path=Path(''),\n            fix_type='formatting',\n            original='',\n            fixed='',\n            line=0,\n            description='Added final newline'\n        ))\n\n    return content, fixes", "chunk_type": "function", "line_start": 191, "line_end": 220, "language": "python", "name": "fix_blank_lines"}, "42f0b178e264_func_remove_unused_imports": {"id": "42f0b178e264_func_remove_unused_imports", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\fix.py", "content": "def remove_unused_imports(path: Path, content: str) -> Tuple[str, List[FixResult]]:\n    \"\"\"Remove unused imports.\"\"\"\n    fixes = []\n\n    tree = parse_file(path)\n    if tree is None:\n        return content, fixes\n\n    # Find all imports\n    imported_names = {}  # name -> line\n    for node in ast.walk(tree):\n        if isinstance(node, ast.Import):\n            for alias in node.names:\n                name = alias.asname or alias.name.split('.')[0]\n                imported_names[name] = node.lineno\n        elif isinstance(node, ast.ImportFrom):\n            for alias in node.names:\n                if alias.name != '*':\n                    name = alias.asname or alias.name\n                    imported_names[name] = node.lineno\n\n    # Find all name usages\n    used_names: Set[str] = set()\n    for node in ast.walk(tree):\n        if isinstance(node, ast.Name):\n            used_names.add(node.id)\n        elif isinstance(node, ast.Attribute):\n            if isinstance(node.value, ast.Name):\n     ", "chunk_type": "function", "line_start": 223, "line_end": 286, "language": "python", "name": "remove_unused_imports"}, "42f0b178e264_func_fix_file": {"id": "42f0b178e264_func_fix_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\fix.py", "content": "def fix_file(\n    path: Path,\n    fix_imports: bool = True,\n    fix_whitespace: bool = True,\n    fix_formatting: bool = True,\n    fix_unused: bool = True,\n    dry_run: bool = False\n) -> List[FixResult]:\n    \"\"\"Fix issues in a single file.\"\"\"\n    all_fixes = []\n\n    try:\n        with open(path, 'r', encoding='utf-8') as f:\n            content = f.read()\n    except Exception:\n        return all_fixes\n\n    original = content\n\n    # Apply fixes\n    if fix_imports:\n        content, fixes = sort_imports(content)\n        for fix in fixes:\n            fix.path = path\n        all_fixes.extend(fixes)\n\n    if fix_whitespace:\n        content, fixes = fix_trailing_whitespace(content)\n        for fix in fixes:\n            fix.path = path\n        all_fixes.extend(fixes)\n\n    if fix_formatting:\n        content, fixes = fix_blank_lines(content)\n        for fix in fixes:\n            fix.path = path\n        all_fixes.extend(fixes)\n\n    if fix_unused:\n        content, fixes = remove_unused_imports(path, c", "chunk_type": "function", "line_start": 289, "line_end": 338, "language": "python", "name": "fix_file"}, "42f0b178e264_func_fix_project": {"id": "42f0b178e264_func_fix_project", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\fix.py", "content": "def fix_project(\n    root: Path,\n    fix_imports: bool = True,\n    fix_whitespace: bool = True,\n    fix_formatting: bool = True,\n    fix_unused: bool = True,\n    dry_run: bool = False,\n    exclude_patterns: List[str] = None\n) -> FixReport:\n    \"\"\"Fix issues in a project.\"\"\"\n    report = FixReport()\n\n    Console.info(f\"Fixing issues in {root}...\")\n    if dry_run:\n        Console.warn(\"DRY RUN - no files will be modified\")\n\n    files = list(find_python_files(root, exclude_patterns))\n    Console.info(f\"Found {len(files)} Python files\")\n\n    for path in files:\n        fixes = fix_file(\n            path,\n            fix_imports=fix_imports,\n            fix_whitespace=fix_whitespace,\n            fix_formatting=fix_formatting,\n            fix_unused=fix_unused,\n            dry_run=dry_run\n        )\n\n        if fixes:\n            report.files_modified += 1\n            report.fixes_applied.extend(fixes)\n\n    return report", "chunk_type": "function", "line_start": 341, "line_end": 374, "language": "python", "name": "fix_project"}, "42f0b178e264_func_fix_staged_files": {"id": "42f0b178e264_func_fix_staged_files", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\fix.py", "content": "def fix_staged_files(dry_run: bool = False) -> FixReport:\n    \"\"\"Fix only git staged files.\"\"\"\n    import subprocess\n\n    report = FixReport()\n\n    try:\n        result = subprocess.run(\n            ['git', 'diff', '--cached', '--name-only', '--diff-filter=ACM'],\n            capture_output=True, text=True\n        )\n        staged = [f.strip() for f in result.stdout.strip().split('\\n') if f.strip().endswith('.py')]\n    except Exception:\n        return report\n\n    if not staged:\n        return report\n\n    Console.info(f\"Fixing {len(staged)} staged files...\")\n\n    for file_path in staged:\n        path = Path(file_path)\n        if path.exists():\n            fixes = fix_file(path, dry_run=dry_run)\n            if fixes:\n                report.files_modified += 1\n                report.fixes_applied.extend(fixes)\n\n    return report", "chunk_type": "function", "line_start": 377, "line_end": 405, "language": "python", "name": "fix_staged_files"}, "42f0b178e264_func_main": {"id": "42f0b178e264_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\fix.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Auto-Fix Tool\")\n\n    # Parse args\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n\n    dry_run = '--dry-run' in sys.argv\n    safe_only = '--safe' in sys.argv\n    apply_mode = '--apply' in sys.argv\n    staged_only = '--staged' in sys.argv\n\n    # Safe mode: only whitespace, imports, formatting (no complex changes)\n    if safe_only:\n        fix_imports = True\n        fix_format = True\n        fix_lint = False  # Don't remove unused imports in safe mode\n    else:\n        fix_imports = '--imports' in sys.argv or not any(\n            a in sys.argv for a in ['--imports', '--lint', '--format']\n        )\n        fix_format = '--format' in sys.argv or not any(\n            a in sys.argv for a in ['--imports', '--lint', '--format']\n        )\n        fix_lint = '--lint' in sys.argv or not any(\n            a in sys.argv for a in ['--imports', '--lint', '--format']\n        )\n\n    # Apply mode: actually apply fixes (not dry run)\n", "chunk_type": "function", "line_start": 408, "line_end": 470, "language": "python", "name": "main"}, "42f0b178e264_func_to_markdown": {"id": "42f0b178e264_func_to_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\fix.py", "content": "    def to_markdown(self) -> str:\n        lines = [\n            \"# Auto-Fix Report\",\n            \"\",\n            f\"**Files modified:** {self.files_modified}\",\n            f\"**Fixes applied:** {len(self.fixes_applied)}\",\n            \"\",\n        ]\n\n        if not self.fixes_applied:\n            lines.append(\"No fixes needed.\")\n            return \"\\n\".join(lines)\n\n        # Group by file\n        by_file: Dict[Path, List[FixResult]] = {}\n        for fix in self.fixes_applied:\n            if fix.path not in by_file:\n                by_file[fix.path] = []\n            by_file[fix.path].append(fix)\n\n        for path, fixes in by_file.items():\n            lines.append(f\"## {path}\")\n            lines.append(\"\")\n            for fix in fixes:\n                lines.append(f\"- **Line {fix.line}:** {fix.description}\")\n            lines.append(\"\")\n\n        return \"\\n\".join(lines)", "chunk_type": "function", "line_start": 43, "line_end": 70, "language": "python", "name": "to_markdown"}, "42f0b178e264_class_FixResult": {"id": "42f0b178e264_class_FixResult", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\fix.py", "content": "class FixResult:\n    \"\"\"Result of a fix operation.\"\"\"\n    path: Path\n    fix_type: str\n    original: str\n    fixed: str\n    line: int\n    description: str", "chunk_type": "class", "line_start": 27, "line_end": 34, "language": "python", "name": "FixResult"}, "42f0b178e264_class_FixReport": {"id": "42f0b178e264_class_FixReport", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\fix.py", "content": "class FixReport:\n    \"\"\"Complete fix report.\"\"\"\n    fixes_applied: List[FixResult] = field(default_factory=list)\n    files_modified: int = 0\n\n    def to_markdown(self) -> str:\n        lines = [\n            \"# Auto-Fix Report\",\n            \"\",\n            f\"**Files modified:** {self.files_modified}\",\n            f\"**Fixes applied:** {len(self.fixes_applied)}\",\n            \"\",\n        ]\n\n        if not self.fixes_applied:\n            lines.append(\"No fixes needed.\")\n            return \"\\n\".join(lines)\n\n        # Group by file\n        by_file: Dict[Path, List[FixResult]] = {}\n        for fix in self.fixes_applied:\n            if fix.path not in by_file:\n                by_file[fix.path] = []\n            by_file[fix.path].append(fix)\n\n        for path, fixes in by_file.items():\n            lines.append(f\"## {path}\")\n            lines.append(\"\")\n            for fix in fixes:\n                lines.append(f\"- **Line {fix.line}:** {fix.description}\")\n            lines.append(\"\")\n\n        retur", "chunk_type": "class", "line_start": 38, "line_end": 70, "language": "python", "name": "FixReport"}, "0b2f6f4464c6_file": {"id": "0b2f6f4464c6_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\git_index.py", "content": "\"\"\"\nGit History Index\n=================\nIndex git commits, blame, and file evolution for AI agents.\n\nUsage:\n    python mcp.py git-history [file]\n    python mcp.py blame [file]\n\"\"\"\n\nfrom dataclasses import dataclass, field, asdict\nfrom datetime import datetime\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Tuple\nimport json\nimport re\nimport subprocess\nimport sys\n\nfrom .utils import Console, find_project_root\n\n\n@dataclass\nclass Commit:\n    \"\"\"A git commit.\"\"\"\n    hash: str\n    short_hash: str\n    author: str\n    email: str\n    date: str\n    message: str\n    files_changed: List[str] = field(default_factory=list)\n\n\n@dataclass\nclass BlameInfo:\n    \"\"\"Blame info for a line.\"\"\"\n    line_num: int\n    commit_hash: str\n    author: str\n    date: str\n    content: str\n\n\n@dataclass\nclass FileHistory:\n    \"\"\"History of a file.\"\"\"\n    path: str\n    commits: List[Commit] = field(default_factory=list)\n    authors: List[str] = field(default_factory=list)\n    first_commit: Optional[str] = None\n    last_commit: Optional[str] = None\n\n\ndef run_git(args: List[str], cwd: Path = None) -> Optional[str]:\n    \"\"\"Run git command and return output.\"\"\"\n    try:\n        result = subprocess.run(\n            ['git'] + args,\n            capture_output=True,\n            text=True,\n            cwd=cwd or Path.cwd()\n        )\n        if result.returncode == 0:\n            return result.stdout.strip()\n        return None\n    except Exception:\n        return None\n\n\ndef get_commits(\n    path: Path = None,\n    since: str = None,\n    limit: int = 100,\n    file_path: Path = None\n) -> List[Commit]:\n    \"\"\"Get list of commits.\"\"\"\n    args = [\n        'log',\n        f'-{limit}',\n        '--format=%H|%h|%an|%ae|%aI|%s',\n        '--name-only'\n    ]\n\n    if since:\n        args.append(f'--since={since}')\n\n    if file_path:\n        args.extend(['--', str(file_path)])\n\n    output = run_git(args, path)\n    if not output:\n        return []\n\n    commits = []\n    current_commit = None\n\n    for line in ou", "chunk_type": "file", "line_start": 1, "line_end": 328, "language": "python", "name": "git_index.py"}, "0b2f6f4464c6_func_run_git": {"id": "0b2f6f4464c6_func_run_git", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\git_index.py", "content": "def run_git(args: List[str], cwd: Path = None) -> Optional[str]:\n    \"\"\"Run git command and return output.\"\"\"\n    try:\n        result = subprocess.run(\n            ['git'] + args,\n            capture_output=True,\n            text=True,\n            cwd=cwd or Path.cwd()\n        )\n        if result.returncode == 0:\n            return result.stdout.strip()\n        return None\n    except Exception:\n        return None", "chunk_type": "function", "line_start": 55, "line_end": 68, "language": "python", "name": "run_git"}, "0b2f6f4464c6_func_get_commits": {"id": "0b2f6f4464c6_func_get_commits", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\git_index.py", "content": "def get_commits(\n    path: Path = None,\n    since: str = None,\n    limit: int = 100,\n    file_path: Path = None\n) -> List[Commit]:\n    \"\"\"Get list of commits.\"\"\"\n    args = [\n        'log',\n        f'-{limit}',\n        '--format=%H|%h|%an|%ae|%aI|%s',\n        '--name-only'\n    ]\n\n    if since:\n        args.append(f'--since={since}')\n\n    if file_path:\n        args.extend(['--', str(file_path)])\n\n    output = run_git(args, path)\n    if not output:\n        return []\n\n    commits = []\n    current_commit = None\n\n    for line in output.split('\\n'):\n        if '|' in line and line.count('|') >= 5:\n            # Commit line\n            parts = line.split('|', 5)\n            if current_commit:\n                commits.append(current_commit)\n\n            current_commit = Commit(\n                hash=parts[0],\n                short_hash=parts[1],\n                author=parts[2],\n                email=parts[3],\n                date=parts[4],\n                message=parts[5] if len(parts) > 5 else ", "chunk_type": "function", "line_start": 71, "line_end": 120, "language": "python", "name": "get_commits"}, "0b2f6f4464c6_func_get_blame": {"id": "0b2f6f4464c6_func_get_blame", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\git_index.py", "content": "def get_blame(file_path: Path, root: Path = None) -> List[BlameInfo]:\n    \"\"\"Get blame info for file.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    args = ['blame', '--line-porcelain', str(file_path)]\n    output = run_git(args, root)\n\n    if not output:\n        return []\n\n    blame_info = []\n    current = {}\n    line_num = 0\n\n    for line in output.split('\\n'):\n        if line.startswith('author '):\n            current['author'] = line[7:]\n        elif line.startswith('author-time '):\n            ts = int(line[12:])\n            current['date'] = datetime.fromtimestamp(ts).isoformat()\n        elif line.startswith('\\t'):\n            line_num += 1\n            if 'commit_hash' in current:\n                blame_info.append(BlameInfo(\n                    line_num=line_num,\n                    commit_hash=current.get('commit_hash', ''),\n                    author=current.get('author', 'Unknown'),\n                    date=current.get('date', ''),\n                    content=line", "chunk_type": "function", "line_start": 123, "line_end": 157, "language": "python", "name": "get_blame"}, "0b2f6f4464c6_func_get_file_history": {"id": "0b2f6f4464c6_func_get_file_history", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\git_index.py", "content": "def get_file_history(file_path: Path, root: Path = None) -> FileHistory:\n    \"\"\"Get complete history of a file.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    commits = get_commits(root, file_path=file_path)\n\n    authors = list(set(c.author for c in commits))\n\n    return FileHistory(\n        path=str(file_path),\n        commits=commits,\n        authors=authors,\n        first_commit=commits[-1].short_hash if commits else None,\n        last_commit=commits[0].short_hash if commits else None\n    )", "chunk_type": "function", "line_start": 160, "line_end": 174, "language": "python", "name": "get_file_history"}, "0b2f6f4464c6_func_get_change_intent": {"id": "0b2f6f4464c6_func_get_change_intent", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\git_index.py", "content": "def get_change_intent(file_path: Path, root: Path = None) -> str:\n    \"\"\"Get the intent behind recent changes to a file.\"\"\"\n    history = get_file_history(file_path, root)\n\n    if not history.commits:\n        return \"No git history available\"\n\n    # Summarize recent commits\n    recent = history.commits[:5]\n\n    lines = [f\"Recent changes to {file_path.name}:\", \"\"]\n    for commit in recent:\n        lines.append(f\"- {commit.message} ({commit.author}, {commit.date[:10]})\")\n\n    lines.append(\"\")\n    lines.append(f\"Authors: {', '.join(history.authors[:5])}\")\n    lines.append(f\"Total commits: {len(history.commits)}\")\n\n    return '\\n'.join(lines)", "chunk_type": "function", "line_start": 177, "line_end": 195, "language": "python", "name": "get_change_intent"}, "0b2f6f4464c6_func_search_commits": {"id": "0b2f6f4464c6_func_search_commits", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\git_index.py", "content": "def search_commits(query: str, root: Path = None, limit: int = 20) -> List[Commit]:\n    \"\"\"Search commit messages.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    args = [\n        'log',\n        f'-{limit}',\n        '--format=%H|%h|%an|%ae|%aI|%s',\n        f'--grep={query}',\n        '-i'  # Case insensitive\n    ]\n\n    output = run_git(args, root)\n    if not output:\n        return []\n\n    commits = []\n    for line in output.split('\\n'):\n        if '|' in line:\n            parts = line.split('|', 5)\n            commits.append(Commit(\n                hash=parts[0],\n                short_hash=parts[1],\n                author=parts[2],\n                email=parts[3],\n                date=parts[4],\n                message=parts[5] if len(parts) > 5 else \"\"\n            ))\n\n    return commits", "chunk_type": "function", "line_start": 198, "line_end": 227, "language": "python", "name": "search_commits"}, "0b2f6f4464c6_func_index_git_history": {"id": "0b2f6f4464c6_func_index_git_history", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\git_index.py", "content": "def index_git_history(root: Path = None, since: str = \"3 months\") -> Dict:\n    \"\"\"Build git history index.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    Console.info(f\"Indexing git history (since {since})...\")\n\n    commits = get_commits(root, since=since, limit=500)\n\n    # Build index\n    index = {\n        \"commit_count\": len(commits),\n        \"authors\": {},\n        \"files\": {},\n        \"commits\": []\n    }\n\n    for commit in commits:\n        # Track authors\n        if commit.author not in index[\"authors\"]:\n            index[\"authors\"][commit.author] = 0\n        index[\"authors\"][commit.author] += 1\n\n        # Track files\n        for file in commit.files_changed:\n            if file not in index[\"files\"]:\n                index[\"files\"][file] = []\n            index[\"files\"][file].append(commit.short_hash)\n\n        # Store commit (without files to save space)\n        index[\"commits\"].append({\n            \"hash\": commit.short_hash,\n            \"author\": commit.author,\n       ", "chunk_type": "function", "line_start": 230, "line_end": 275, "language": "python", "name": "index_git_history"}, "0b2f6f4464c6_func_main": {"id": "0b2f6f4464c6_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\git_index.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Git History Index\")\n\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n    root = find_project_root() or Path.cwd()\n\n    if '--index' in sys.argv:\n        since = \"3 months\"\n        for i, arg in enumerate(sys.argv):\n            if arg == '--since' and i + 1 < len(sys.argv):\n                since = sys.argv[i + 1]\n        index_git_history(root, since)\n        return 0\n\n    if '--search' in sys.argv and args:\n        query = args[0]\n        Console.info(f\"Searching commits: {query}\")\n        commits = search_commits(query, root)\n\n        for commit in commits:\n            print(f\"{commit.short_hash} {commit.message[:60]} ({commit.author})\")\n        return 0\n\n    if '--blame' in sys.argv and args:\n        file_path = Path(args[0])\n        Console.info(f\"Blame: {file_path}\")\n\n        blame = get_blame(file_path, root)\n        for info in blame[:30]:\n            print(f\"{info.line_num:4d} {info.commit_hash[:7]} {info.a", "chunk_type": "function", "line_start": 278, "line_end": 323, "language": "python", "name": "main"}, "0b2f6f4464c6_class_Commit": {"id": "0b2f6f4464c6_class_Commit", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\git_index.py", "content": "class Commit:\n    \"\"\"A git commit.\"\"\"\n    hash: str\n    short_hash: str\n    author: str\n    email: str\n    date: str\n    message: str\n    files_changed: List[str] = field(default_factory=list)", "chunk_type": "class", "line_start": 24, "line_end": 32, "language": "python", "name": "Commit"}, "0b2f6f4464c6_class_BlameInfo": {"id": "0b2f6f4464c6_class_BlameInfo", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\git_index.py", "content": "class BlameInfo:\n    \"\"\"Blame info for a line.\"\"\"\n    line_num: int\n    commit_hash: str\n    author: str\n    date: str\n    content: str", "chunk_type": "class", "line_start": 36, "line_end": 42, "language": "python", "name": "BlameInfo"}, "0b2f6f4464c6_class_FileHistory": {"id": "0b2f6f4464c6_class_FileHistory", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\git_index.py", "content": "class FileHistory:\n    \"\"\"History of a file.\"\"\"\n    path: str\n    commits: List[Commit] = field(default_factory=list)\n    authors: List[str] = field(default_factory=list)\n    first_commit: Optional[str] = None\n    last_commit: Optional[str] = None", "chunk_type": "class", "line_start": 46, "line_end": 52, "language": "python", "name": "FileHistory"}, "96303a223518_file": {"id": "96303a223518_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\impact.py", "content": "\"\"\"\nImpact Analysis\n================\nAnalyze what breaks when code changes.\n\nUsage:\n    python mcp.py impact [file]\n    python mcp.py impact --test [file]  # Show affected tests\n\"\"\"\n\nfrom collections import defaultdict\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Set, Tuple\nimport ast\nimport json\nimport sys\n\nfrom .utils import Console, find_python_files, find_project_root\n\n\n@dataclass\nclass ImpactReport:\n    \"\"\"Report of change impact.\"\"\"\n    file: str\n    direct_dependents: List[str] = field(default_factory=list)  # Files that import this\n    indirect_dependents: List[str] = field(default_factory=list)  # Transitive deps\n    affected_tests: List[str] = field(default_factory=list)\n    total_impact: int = 0\n\n    def to_markdown(self) -> str:\n        lines = [\n            f\"# Impact Report: {Path(self.file).name}\",\n            \"\",\n            f\"**Total Impact:** {self.total_impact} files\",\n            \"\",\n        ]\n\n        if self.direct_dependents:\n            lines.append(\"## Direct Dependents\")\n            for dep in self.direct_dependents[:10]:\n                lines.append(f\"- {dep}\")\n            lines.append(\"\")\n\n        if self.indirect_dependents:\n            lines.append(\"## Indirect Dependents\")\n            for dep in self.indirect_dependents[:10]:\n                lines.append(f\"- {dep}\")\n            lines.append(\"\")\n\n        if self.affected_tests:\n            lines.append(\"## Affected Tests\")\n            for test in self.affected_tests[:10]:\n                lines.append(f\"- {test}\")\n\n        return '\\n'.join(lines)\n\n\nclass DependencyGraph:\n    \"\"\"Graph of file dependencies.\"\"\"\n\n    def __init__(self):\n        self.imports: Dict[str, Set[str]] = defaultdict(set)  # file -> what it imports\n        self.imported_by: Dict[str, Set[str]] = defaultdict(set)  # file -> who imports it\n        self.module_to_file: Dict[str, str] = {}  # module name -> file path\n\n    def add_file(self, file_path: Path, ro", "chunk_type": "file", "line_start": 1, "line_end": 235, "language": "python", "name": "impact.py"}, "96303a223518_func_build_dependency_graph": {"id": "96303a223518_func_build_dependency_graph", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\impact.py", "content": "def build_dependency_graph(root: Path = None) -> DependencyGraph:\n    \"\"\"Build and return dependency graph.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    Console.info(\"Building dependency graph...\")\n\n    graph = DependencyGraph()\n    exclude = ['node_modules', 'venv', '.venv', '__pycache__', '.git', 'vendor']\n    graph.build(root, exclude)\n\n    Console.ok(f\"Indexed {len(graph.imports)} files\")\n\n    return graph", "chunk_type": "function", "line_start": 131, "line_end": 143, "language": "python", "name": "build_dependency_graph"}, "96303a223518_func_analyze_impact": {"id": "96303a223518_func_analyze_impact", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\impact.py", "content": "def analyze_impact(file_path: Path, root: Path = None) -> ImpactReport:\n    \"\"\"Analyze impact of changing a file.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    graph = build_dependency_graph(root)\n\n    try:\n        file_key = str(file_path.relative_to(root))\n    except ValueError:\n        file_key = str(file_path)\n\n    direct = list(graph.get_dependents(file_key))\n\n    all_deps = graph.get_transitive_dependents(file_key)\n    indirect = [d for d in all_deps if d not in direct]\n\n    # Find affected tests\n    tests = [d for d in all_deps if 'test' in d.lower() or d.startswith('tests/')]\n\n    return ImpactReport(\n        file=file_key,\n        direct_dependents=direct,\n        indirect_dependents=indirect,\n        affected_tests=tests,\n        total_impact=len(all_deps)\n    )", "chunk_type": "function", "line_start": 146, "line_end": 171, "language": "python", "name": "analyze_impact"}, "96303a223518_func_save_impact_graph": {"id": "96303a223518_func_save_impact_graph", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\impact.py", "content": "def save_impact_graph(root: Path = None):\n    \"\"\"Save dependency graph to disk.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    graph = build_dependency_graph(root)\n\n    # Convert to serializable format\n    data = {\n        \"imports\": {k: list(v) for k, v in graph.imports.items()},\n        \"imported_by\": {k: list(v) for k, v in graph.imported_by.items()},\n        \"file_count\": len(graph.imports)\n    }\n\n    index_path = root / '.mcp' / 'impact_graph.json'\n    index_path.parent.mkdir(parents=True, exist_ok=True)\n\n    with open(index_path, 'w', encoding='utf-8') as f:\n        json.dump(data, f, indent=2)\n\n    Console.ok(f\"Saved impact graph to {index_path}\")", "chunk_type": "function", "line_start": 174, "line_end": 193, "language": "python", "name": "save_impact_graph"}, "96303a223518_func_main": {"id": "96303a223518_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\impact.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Impact Analysis\")\n\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n    root = find_project_root() or Path.cwd()\n\n    if '--index' in sys.argv:\n        save_impact_graph(root)\n        return 0\n\n    if not args:\n        Console.info(\"Usage: python impact.py <file>\")\n        Console.info(\"Options:\")\n        Console.info(\"  --index    Save dependency graph\")\n        Console.info(\"  --test     Show only affected tests\")\n        return 1\n\n    file_path = Path(args[0])\n\n    if not file_path.exists():\n        Console.fail(f\"File not found: {file_path}\")\n        return 1\n\n    report = analyze_impact(file_path, root)\n\n    if '--test' in sys.argv:\n        Console.info(f\"Affected tests for {file_path.name}:\")\n        for test in report.affected_tests:\n            print(f\"  - {test}\")\n        print(f\"\\nTotal: {len(report.affected_tests)} tests\")\n    else:\n        print(report.to_markdown())\n\n    return 0", "chunk_type": "function", "line_start": 196, "line_end": 230, "language": "python", "name": "main"}, "96303a223518_func_to_markdown": {"id": "96303a223518_func_to_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\impact.py", "content": "    def to_markdown(self) -> str:\n        lines = [\n            f\"# Impact Report: {Path(self.file).name}\",\n            \"\",\n            f\"**Total Impact:** {self.total_impact} files\",\n            \"\",\n        ]\n\n        if self.direct_dependents:\n            lines.append(\"## Direct Dependents\")\n            for dep in self.direct_dependents[:10]:\n                lines.append(f\"- {dep}\")\n            lines.append(\"\")\n\n        if self.indirect_dependents:\n            lines.append(\"## Indirect Dependents\")\n            for dep in self.indirect_dependents[:10]:\n                lines.append(f\"- {dep}\")\n            lines.append(\"\")\n\n        if self.affected_tests:\n            lines.append(\"## Affected Tests\")\n            for test in self.affected_tests[:10]:\n                lines.append(f\"- {test}\")\n\n        return '\\n'.join(lines)", "chunk_type": "function", "line_start": 31, "line_end": 56, "language": "python", "name": "to_markdown"}, "96303a223518_func___init__": {"id": "96303a223518_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\impact.py", "content": "    def __init__(self):\n        self.imports: Dict[str, Set[str]] = defaultdict(set)  # file -> what it imports\n        self.imported_by: Dict[str, Set[str]] = defaultdict(set)  # file -> who imports it\n        self.module_to_file: Dict[str, str] = {}  # module name -> file path", "chunk_type": "function", "line_start": 62, "line_end": 65, "language": "python", "name": "__init__"}, "96303a223518_func_add_file": {"id": "96303a223518_func_add_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\impact.py", "content": "    def add_file(self, file_path: Path, root: Path):\n        \"\"\"Add a file's imports to the graph.\"\"\"\n        try:\n            with open(file_path, 'r', encoding='utf-8') as f:\n                source = f.read()\n            tree = ast.parse(source)\n        except Exception:\n            return\n\n        file_key = str(file_path.relative_to(root))\n\n        # Register this module\n        module_name = str(file_path.relative_to(root).with_suffix('')).replace('\\\\', '.').replace('/', '.')\n        self.module_to_file[module_name] = file_key\n\n        # Extract imports\n        for node in ast.walk(tree):\n            if isinstance(node, ast.Import):\n                for alias in node.names:\n                    self.imports[file_key].add(alias.name)\n            elif isinstance(node, ast.ImportFrom):\n                if node.module:\n                    self.imports[file_key].add(node.module)", "chunk_type": "function", "line_start": 67, "line_end": 89, "language": "python", "name": "add_file"}, "96303a223518_func_build": {"id": "96303a223518_func_build", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\impact.py", "content": "    def build(self, root: Path, exclude_patterns: List[str] = None):\n        \"\"\"Build full dependency graph.\"\"\"\n        for file_path in find_python_files(root, exclude_patterns):\n            self.add_file(file_path, root)\n\n        # Build reverse mapping\n        for file_key, imports in self.imports.items():\n            for imp in imports:\n                # Try to resolve import to file\n                if imp in self.module_to_file:\n                    self.imported_by[self.module_to_file[imp]].add(file_key)", "chunk_type": "function", "line_start": 91, "line_end": 101, "language": "python", "name": "build"}, "96303a223518_func_get_dependents": {"id": "96303a223518_func_get_dependents", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\impact.py", "content": "    def get_dependents(self, file_path: str) -> Set[str]:\n        \"\"\"Get files that depend on this file.\"\"\"\n        return self.imported_by.get(file_path, set())", "chunk_type": "function", "line_start": 103, "line_end": 105, "language": "python", "name": "get_dependents"}, "96303a223518_func_get_dependencies": {"id": "96303a223518_func_get_dependencies", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\impact.py", "content": "    def get_dependencies(self, file_path: str) -> Set[str]:\n        \"\"\"Get files this file depends on.\"\"\"\n        return self.imports.get(file_path, set())", "chunk_type": "function", "line_start": 107, "line_end": 109, "language": "python", "name": "get_dependencies"}, "96303a223518_func_get_transitive_dependents": {"id": "96303a223518_func_get_transitive_dependents", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\impact.py", "content": "    def get_transitive_dependents(self, file_path: str, visited: Set[str] = None) -> Set[str]:\n        \"\"\"Get all transitive dependents.\"\"\"\n        if visited is None:\n            visited = set()\n\n        if file_path in visited:\n            return set()\n\n        visited.add(file_path)\n\n        all_deps = set()\n        direct = self.get_dependents(file_path)\n        all_deps.update(direct)\n\n        for dep in direct:\n            all_deps.update(self.get_transitive_dependents(dep, visited))\n\n        return all_deps", "chunk_type": "function", "line_start": 111, "line_end": 128, "language": "python", "name": "get_transitive_dependents"}, "96303a223518_class_ImpactReport": {"id": "96303a223518_class_ImpactReport", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\impact.py", "content": "class ImpactReport:\n    \"\"\"Report of change impact.\"\"\"\n    file: str\n    direct_dependents: List[str] = field(default_factory=list)  # Files that import this\n    indirect_dependents: List[str] = field(default_factory=list)  # Transitive deps\n    affected_tests: List[str] = field(default_factory=list)\n    total_impact: int = 0\n\n    def to_markdown(self) -> str:\n        lines = [\n            f\"# Impact Report: {Path(self.file).name}\",\n            \"\",\n            f\"**Total Impact:** {self.total_impact} files\",\n            \"\",\n        ]\n\n        if self.direct_dependents:\n            lines.append(\"## Direct Dependents\")\n            for dep in self.direct_dependents[:10]:\n                lines.append(f\"- {dep}\")\n            lines.append(\"\")\n\n        if self.indirect_dependents:\n            lines.append(\"## Indirect Dependents\")\n            for dep in self.indirect_dependents[:10]:\n                lines.append(f\"- {dep}\")\n            lines.append(\"\")\n\n        if self.affected_tests:\n        ", "chunk_type": "class", "line_start": 23, "line_end": 56, "language": "python", "name": "ImpactReport"}, "96303a223518_class_DependencyGraph": {"id": "96303a223518_class_DependencyGraph", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\impact.py", "content": "class DependencyGraph:\n    \"\"\"Graph of file dependencies.\"\"\"\n\n    def __init__(self):\n        self.imports: Dict[str, Set[str]] = defaultdict(set)  # file -> what it imports\n        self.imported_by: Dict[str, Set[str]] = defaultdict(set)  # file -> who imports it\n        self.module_to_file: Dict[str, str] = {}  # module name -> file path\n\n    def add_file(self, file_path: Path, root: Path):\n        \"\"\"Add a file's imports to the graph.\"\"\"\n        try:\n            with open(file_path, 'r', encoding='utf-8') as f:\n                source = f.read()\n            tree = ast.parse(source)\n        except Exception:\n            return\n\n        file_key = str(file_path.relative_to(root))\n\n        # Register this module\n        module_name = str(file_path.relative_to(root).with_suffix('')).replace('\\\\', '.').replace('/', '.')\n        self.module_to_file[module_name] = file_key\n\n        # Extract imports\n        for node in ast.walk(tree):\n            if isinstance(node, ast.Import):\n           ", "chunk_type": "class", "line_start": 59, "line_end": 128, "language": "python", "name": "DependencyGraph"}, "ba620ada3d94_file": {"id": "ba620ada3d94_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\index_all.py", "content": "\"\"\"\nUnified Index Manager\n=====================\nRun all indexes at once for complete codebase intelligence.\n\nUsage:\n    python mcp.py index-all      # Full reindex\n    python mcp.py index-all --what  # Show what's indexed\n\"\"\"\n\nfrom datetime import datetime\nfrom pathlib import Path\nimport json\nimport sys\nimport time\n\nfrom .utils import Console, find_project_root\n\n\ndef run_all_indexes(root: Path = None, verbose: bool = True) -> dict:\n    \"\"\"Run all indexes and return summary.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    if verbose:\n        Console.header(\"Full Index Build\")\n        Console.info(f\"Indexing {root}...\")\n\n    start_time = time.time()\n    results = {}\n\n    # 1. Semantic code index\n    if verbose:\n        Console.info(\"1/7 Semantic code index...\")\n    try:\n        from .vector_store import VectorStore\n        store = VectorStore(root / '.mcp' / 'vector_index')\n        count = store.index_codebase(root)\n        results['semantic'] = {'status': 'ok', 'items': count}\n    except Exception as e:\n        results['semantic'] = {'status': 'error', 'error': str(e)}\n\n    # 2. Git history index\n    if verbose:\n        Console.info(\"2/7 Git history index...\")\n    try:\n        from .git_index import index_git_history\n        index = index_git_history(root, since=\"3 months\")\n        results['git'] = {'status': 'ok', 'commits': index.get('commit_count', 0)}\n    except Exception as e:\n        results['git'] = {'status': 'error', 'error': str(e)}\n\n    # 3. TODO/FIXME index\n    if verbose:\n        Console.info(\"3/7 TODO/FIXME index...\")\n    try:\n        from .todo_index import index_todos\n        index = index_todos(root)\n        results['todos'] = {'status': 'ok', 'items': index.get('total', 0)}\n    except Exception as e:\n        results['todos'] = {'status': 'error', 'error': str(e)}\n\n    # 4. Impact graph\n    if verbose:\n        Console.info(\"4/7 Dependency impact graph...\")\n    try:\n        from .impact import save_impact_graph\n        save_impact_graph(r", "chunk_type": "file", "line_start": 1, "line_end": 195, "language": "python", "name": "index_all.py"}, "ba620ada3d94_func_run_all_indexes": {"id": "ba620ada3d94_func_run_all_indexes", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\index_all.py", "content": "def run_all_indexes(root: Path = None, verbose: bool = True) -> dict:\n    \"\"\"Run all indexes and return summary.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    if verbose:\n        Console.header(\"Full Index Build\")\n        Console.info(f\"Indexing {root}...\")\n\n    start_time = time.time()\n    results = {}\n\n    # 1. Semantic code index\n    if verbose:\n        Console.info(\"1/7 Semantic code index...\")\n    try:\n        from .vector_store import VectorStore\n        store = VectorStore(root / '.mcp' / 'vector_index')\n        count = store.index_codebase(root)\n        results['semantic'] = {'status': 'ok', 'items': count}\n    except Exception as e:\n        results['semantic'] = {'status': 'error', 'error': str(e)}\n\n    # 2. Git history index\n    if verbose:\n        Console.info(\"2/7 Git history index...\")\n    try:\n        from .git_index import index_git_history\n        index = index_git_history(root, since=\"3 months\")\n        results['git'] = {'status': 'ok', 'commits': index.", "chunk_type": "function", "line_start": 20, "line_end": 123, "language": "python", "name": "run_all_indexes"}, "ba620ada3d94_func_show_index_status": {"id": "ba620ada3d94_func_show_index_status", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\index_all.py", "content": "def show_index_status(root: Path = None):\n    \"\"\"Show what's currently indexed.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n    mcp_dir = root / '.mcp'\n\n    print(\"\\n## Index Status\")\n    print(\"\")\n\n    indexes = [\n        ('vector_index', 'Semantic Code', 'chunks.json'),\n        ('git_index.json', 'Git History', None),\n        ('todo_index.json', 'TODOs/FIXMEs', None),\n        ('impact_graph.json', 'Impact Graph', None),\n        ('doc_index.json', 'Documentation', None),\n        ('config_index.json', 'Config', None),\n        ('coverage_index.json', 'Coverage', None),\n    ]\n\n    for idx_name, display_name, sub_file in indexes:\n        idx_path = mcp_dir / idx_name\n\n        if sub_file:\n            idx_path = idx_path / sub_file\n\n        if idx_path.exists():\n            size = idx_path.stat().st_size\n            size_str = f\"{size / 1024:.1f}KB\" if size > 1024 else f\"{size}B\"\n            print(f\"  \u2713 {display_name:20} ({size_str})\")\n        else:\n            print(f\"  \u2717 {dis", "chunk_type": "function", "line_start": 126, "line_end": 155, "language": "python", "name": "show_index_status"}, "ba620ada3d94_func_main": {"id": "ba620ada3d94_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\index_all.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    root = find_project_root() or Path.cwd()\n\n    if '--what' in sys.argv or '--status' in sys.argv:\n        Console.header(\"Index Status\")\n        show_index_status(root)\n        return 0\n\n    if '--quick' in sys.argv:\n        # Quick mode: only semantic + todos\n        Console.header(\"Quick Index\")\n\n        try:\n            from .vector_store import VectorStore\n            store = VectorStore(root / '.mcp' / 'vector_index')\n            store.index_codebase(root)\n        except Exception:\n            pass\n\n        try:\n            from .todo_index import index_todos\n            index_todos(root)\n        except Exception:\n            pass\n\n        Console.ok(\"Quick index complete\")\n        return 0\n\n    # Full index\n    run_all_indexes(root, verbose=True)\n\n    return 0", "chunk_type": "function", "line_start": 158, "line_end": 190, "language": "python", "name": "main"}, "51913194cded_file": {"id": "51913194cded_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\learning.py", "content": "\"\"\"\nLearning System\n================\nLearn from feedback, preferences, and past mistakes.\n\nUsage:\n    python mcp.py learn --show-patterns\n    python mcp.py learn --from-feedback\n\"\"\"\n\nfrom collections import Counter\nfrom dataclasses import dataclass, field, asdict\nfrom datetime import datetime\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Any\nimport json\nimport sys\n\nfrom .utils import Console, find_project_root\n\n\n@dataclass\nclass Feedback:\n    \"\"\"A feedback entry.\"\"\"\n    action: str\n    outcome: str  # 'success', 'failure', 'partial'\n    context: str\n    timestamp: str\n    details: Dict[str, Any] = field(default_factory=dict)\n\n\n@dataclass\nclass ErrorPattern:\n    \"\"\"A learned error pattern.\"\"\"\n    error_type: str\n    pattern: str\n    fix: str\n    occurrences: int = 1\n    last_seen: str = \"\"\n    contexts: List[str] = field(default_factory=list)\n\n\n@dataclass\nclass Preference:\n    \"\"\"A user preference.\"\"\"\n    key: str\n    value: Any\n    learned_from: str = \"default\"\n    confidence: float = 0.5\n\n\nclass LearningStore:\n    \"\"\"Store for learning data.\"\"\"\n\n    def __init__(self, storage_path: Path = None):\n        if storage_path:\n            self.storage_path = storage_path\n        else:\n            home = Path.home()\n            self.storage_path = home / '.mcp' / 'learning'\n\n        self.storage_path.mkdir(parents=True, exist_ok=True)\n\n        self.feedback: List[Feedback] = []\n        self.errors: Dict[str, ErrorPattern] = {}\n        self.preferences: Dict[str, Preference] = {}\n\n        self.load()\n\n    def load(self):\n        \"\"\"Load learning data.\"\"\"\n        # Load feedback\n        fb_path = self.storage_path / 'feedback.json'\n        if fb_path.exists():\n            try:\n                with open(fb_path, 'r') as f:\n                    data = json.load(f)\n                    self.feedback = [Feedback(**d) for d in data]\n            except Exception:\n                pass\n\n        # Load error patterns\n        err_path = self.storage_path / 'errors.js", "chunk_type": "file", "line_start": 1, "line_end": 311, "language": "python", "name": "learning.py"}, "51913194cded_func_get_store": {"id": "51913194cded_func_get_store", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\learning.py", "content": "def get_store() -> LearningStore:\n    global _store\n    if _store is None:\n        _store = LearningStore()\n    return _store", "chunk_type": "function", "line_start": 248, "line_end": 252, "language": "python", "name": "get_store"}, "51913194cded_func_record_feedback": {"id": "51913194cded_func_record_feedback", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\learning.py", "content": "    def record_feedback(\n        self,\n        action: str,\n        outcome: str,\n        context: str = \"\",\n        details: Dict = None\n    ):\n        \"\"\"Record feedback on an action.\"\"\"\n        fb = Feedback(\n            action=action,\n            outcome=outcome,\n            context=context,\n            timestamp=datetime.utcnow().isoformat() + 'Z',\n            details=details or {}\n        )\n        self.feedback.append(fb)\n        self.save()", "chunk_type": "function", "line_start": 119, "line_end": 135, "language": "python", "name": "record_feedback"}, "51913194cded_func_record_error": {"id": "51913194cded_func_record_error", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\learning.py", "content": "    def record_error(self, error_type: str, pattern: str, fix: str, context: str = \"\"):\n        \"\"\"Record an error and its fix.\"\"\"\n        key = f\"{error_type}:{pattern[:50]}\"\n\n        if key in self.errors:\n            err = self.errors[key]\n            err.occurrences += 1\n            err.last_seen = datetime.utcnow().isoformat() + 'Z'\n            if context and context not in err.contexts:\n                err.contexts.append(context)\n                err.contexts = err.contexts[-5:]  # Keep last 5\n        else:\n            self.errors[key] = ErrorPattern(\n                error_type=error_type,\n                pattern=pattern,\n                fix=fix,\n                last_seen=datetime.utcnow().isoformat() + 'Z',\n                contexts=[context] if context else []\n            )\n\n        self.save()", "chunk_type": "function", "line_start": 137, "line_end": 157, "language": "python", "name": "record_error"}, "51913194cded_func_suggest_fix": {"id": "51913194cded_func_suggest_fix", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\learning.py", "content": "    def suggest_fix(self, error_type: str, pattern: str) -> Optional[str]:\n        \"\"\"Suggest a fix for an error based on patterns.\"\"\"\n        key = f\"{error_type}:{pattern[:50]}\"\n\n        if key in self.errors:\n            return self.errors[key].fix\n\n        # Fuzzy match\n        for k, err in self.errors.items():\n            if error_type in k and pattern[:20] in err.pattern:\n                return err.fix\n\n        return None", "chunk_type": "function", "line_start": 174, "line_end": 186, "language": "python", "name": "suggest_fix"}, "51913194cded_func_main": {"id": "51913194cded_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\learning.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Learning System\")\n\n    store = get_store()\n\n    Console.info(f\"Storage: {store.storage_path}\")\n    Console.info(f\"Feedback entries: {len(store.feedback)}\")\n    Console.info(f\"Error patterns: {len(store.errors)}\")\n    Console.info(f\"Preferences: {len(store.preferences)}\")\n\n    if '--show-patterns' in sys.argv or '--patterns' in sys.argv:\n        analysis = store.analyze_patterns()\n\n        print(\"\\n## Action Outcomes\")\n        for action, data in analysis[\"action_outcomes\"].items():\n            print(f\"  {action}: {data['success_rate']*100:.0f}% success ({data['count']} times)\")\n\n        print(\"\\n## Common Errors\")\n        for err in analysis[\"common_errors\"]:\n            print(f\"  [{err['type']}] {err['pattern']}\")\n            print(f\"    Fix: {err['fix']}\")\n            print(f\"    Occurred: {err['occurrences']} times\")\n\n        return 0\n\n    if '--preferences' in sys.argv:\n        print(\"\\n## Preferences\")\n        for key, pre", "chunk_type": "function", "line_start": 270, "line_end": 306, "language": "python", "name": "main"}, "51913194cded_func___init__": {"id": "51913194cded_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\learning.py", "content": "    def __init__(self, storage_path: Path = None):\n        if storage_path:\n            self.storage_path = storage_path\n        else:\n            home = Path.home()\n            self.storage_path = home / '.mcp' / 'learning'\n\n        self.storage_path.mkdir(parents=True, exist_ok=True)\n\n        self.feedback: List[Feedback] = []\n        self.errors: Dict[str, ErrorPattern] = {}\n        self.preferences: Dict[str, Preference] = {}\n\n        self.load()", "chunk_type": "function", "line_start": 55, "line_end": 68, "language": "python", "name": "__init__"}, "51913194cded_func_load": {"id": "51913194cded_func_load", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\learning.py", "content": "    def load(self):\n        \"\"\"Load learning data.\"\"\"\n        # Load feedback\n        fb_path = self.storage_path / 'feedback.json'\n        if fb_path.exists():\n            try:\n                with open(fb_path, 'r') as f:\n                    data = json.load(f)\n                    self.feedback = [Feedback(**d) for d in data]\n            except Exception:\n                pass\n\n        # Load error patterns\n        err_path = self.storage_path / 'errors.json'\n        if err_path.exists():\n            try:\n                with open(err_path, 'r') as f:\n                    data = json.load(f)\n                    self.errors = {k: ErrorPattern(**v) for k, v in data.items()}\n            except Exception:\n                pass\n\n        # Load preferences\n        pref_path = self.storage_path / 'preferences.json'\n        if pref_path.exists():\n            try:\n                with open(pref_path, 'r') as f:\n                    data = json.load(f)\n                    self.preferences = {k: Pr", "chunk_type": "function", "line_start": 70, "line_end": 100, "language": "python", "name": "load"}, "51913194cded_func_save": {"id": "51913194cded_func_save", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\learning.py", "content": "    def save(self):\n        \"\"\"Save all learning data.\"\"\"\n        # Save feedback\n        fb_path = self.storage_path / 'feedback.json'\n        with open(fb_path, 'w') as f:\n            json.dump([asdict(fb) for fb in self.feedback[-1000:]], f, indent=2)\n\n        # Save errors\n        err_path = self.storage_path / 'errors.json'\n        with open(err_path, 'w') as f:\n            json.dump({k: asdict(v) for k, v in self.errors.items()}, f, indent=2)\n\n        # Save preferences\n        pref_path = self.storage_path / 'preferences.json'\n        with open(pref_path, 'w') as f:\n            json.dump({k: asdict(v) for k, v in self.preferences.items()}, f, indent=2)", "chunk_type": "function", "line_start": 102, "line_end": 117, "language": "python", "name": "save"}, "51913194cded_func_get_preference": {"id": "51913194cded_func_get_preference", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\learning.py", "content": "    def get_preference(self, key: str, default: Any = None) -> Any:\n        \"\"\"Get a preference value.\"\"\"\n        pref = self.preferences.get(key)\n        return pref.value if pref else default", "chunk_type": "function", "line_start": 159, "line_end": 162, "language": "python", "name": "get_preference"}, "51913194cded_func_set_preference": {"id": "51913194cded_func_set_preference", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\learning.py", "content": "    def set_preference(self, key: str, value: Any, source: str = \"user\"):\n        \"\"\"Set a preference.\"\"\"\n        self.preferences[key] = Preference(\n            key=key,\n            value=value,\n            learned_from=source,\n            confidence=1.0 if source == \"user\" else 0.7\n        )\n        self.save()", "chunk_type": "function", "line_start": 164, "line_end": 172, "language": "python", "name": "set_preference"}, "51913194cded_func_get_action_success_rate": {"id": "51913194cded_func_get_action_success_rate", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\learning.py", "content": "    def get_action_success_rate(self, action: str) -> float:\n        \"\"\"Get success rate for an action type.\"\"\"\n        relevant = [fb for fb in self.feedback if fb.action == action]\n        if not relevant:\n            return 0.5  # Unknown\n\n        successes = sum(1 for fb in relevant if fb.outcome == 'success')\n        return successes / len(relevant)", "chunk_type": "function", "line_start": 188, "line_end": 195, "language": "python", "name": "get_action_success_rate"}, "51913194cded_func_get_common_errors": {"id": "51913194cded_func_get_common_errors", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\learning.py", "content": "    def get_common_errors(self, limit: int = 10) -> List[ErrorPattern]:\n        \"\"\"Get most common errors.\"\"\"\n        sorted_errors = sorted(\n            self.errors.values(),\n            key=lambda e: e.occurrences,\n            reverse=True\n        )\n        return sorted_errors[:limit]", "chunk_type": "function", "line_start": 197, "line_end": 204, "language": "python", "name": "get_common_errors"}, "51913194cded_func_analyze_patterns": {"id": "51913194cded_func_analyze_patterns", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\learning.py", "content": "    def analyze_patterns(self) -> Dict:\n        \"\"\"Analyze learning patterns.\"\"\"\n        analysis = {\n            \"total_feedback\": len(self.feedback),\n            \"total_errors\": len(self.errors),\n            \"total_preferences\": len(self.preferences),\n            \"action_outcomes\": {},\n            \"common_errors\": []\n        }\n\n        # Analyze action outcomes\n        action_counts = Counter()\n        action_success = Counter()\n\n        for fb in self.feedback:\n            action_counts[fb.action] += 1\n            if fb.outcome == 'success':\n                action_success[fb.action] += 1\n\n        for action, count in action_counts.most_common(10):\n            rate = action_success[action] / count if count > 0 else 0\n            analysis[\"action_outcomes\"][action] = {\n                \"count\": count,\n                \"success_rate\": round(rate, 2)\n            }\n\n        # Common errors\n        for err in self.get_common_errors(5):\n            analysis[\"common_errors\"].append({\n        ", "chunk_type": "function", "line_start": 206, "line_end": 241, "language": "python", "name": "analyze_patterns"}, "51913194cded_class_Feedback": {"id": "51913194cded_class_Feedback", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\learning.py", "content": "class Feedback:\n    \"\"\"A feedback entry.\"\"\"\n    action: str\n    outcome: str  # 'success', 'failure', 'partial'\n    context: str\n    timestamp: str\n    details: Dict[str, Any] = field(default_factory=dict)", "chunk_type": "class", "line_start": 23, "line_end": 29, "language": "python", "name": "Feedback"}, "51913194cded_class_ErrorPattern": {"id": "51913194cded_class_ErrorPattern", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\learning.py", "content": "class ErrorPattern:\n    \"\"\"A learned error pattern.\"\"\"\n    error_type: str\n    pattern: str\n    fix: str\n    occurrences: int = 1\n    last_seen: str = \"\"\n    contexts: List[str] = field(default_factory=list)", "chunk_type": "class", "line_start": 33, "line_end": 40, "language": "python", "name": "ErrorPattern"}, "51913194cded_class_Preference": {"id": "51913194cded_class_Preference", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\learning.py", "content": "class Preference:\n    \"\"\"A user preference.\"\"\"\n    key: str\n    value: Any\n    learned_from: str = \"default\"\n    confidence: float = 0.5", "chunk_type": "class", "line_start": 44, "line_end": 49, "language": "python", "name": "Preference"}, "51913194cded_class_LearningStore": {"id": "51913194cded_class_LearningStore", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\learning.py", "content": "class LearningStore:\n    \"\"\"Store for learning data.\"\"\"\n\n    def __init__(self, storage_path: Path = None):\n        if storage_path:\n            self.storage_path = storage_path\n        else:\n            home = Path.home()\n            self.storage_path = home / '.mcp' / 'learning'\n\n        self.storage_path.mkdir(parents=True, exist_ok=True)\n\n        self.feedback: List[Feedback] = []\n        self.errors: Dict[str, ErrorPattern] = {}\n        self.preferences: Dict[str, Preference] = {}\n\n        self.load()\n\n    def load(self):\n        \"\"\"Load learning data.\"\"\"\n        # Load feedback\n        fb_path = self.storage_path / 'feedback.json'\n        if fb_path.exists():\n            try:\n                with open(fb_path, 'r') as f:\n                    data = json.load(f)\n                    self.feedback = [Feedback(**d) for d in data]\n            except Exception:\n                pass\n\n        # Load error patterns\n        err_path = self.storage_path / 'errors.json'\n        if err_path.ex", "chunk_type": "class", "line_start": 52, "line_end": 241, "language": "python", "name": "LearningStore"}, "e92ab53d7b72_file": {"id": "e92ab53d7b72_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\memory.py", "content": "\"\"\"\nPersistent Memory System\n========================\nCross-session knowledge base for AI agents.\n\nUsage:\n    python mcp.py remember \"key\" \"value\"\n    python mcp.py recall \"query\"\n    python mcp.py forget \"key\"\n\"\"\"\n\nfrom dataclasses import dataclass, field, asdict\nfrom datetime import datetime\nfrom pathlib import Path\nfrom typing import Dict, List, Optional\nimport hashlib\nimport json\nimport sys\n\nfrom .embeddings import embed_text, cosine_similarity\nfrom .utils import Console, find_project_root\n\n\n@dataclass\nclass Memory:\n    \"\"\"A memory item.\"\"\"\n    key: str\n    value: str\n    tags: List[str] = field(default_factory=list)\n    created: str = \"\"\n    updated: str = \"\"\n    access_count: int = 0\n    embedding: List[float] = field(default_factory=list)\n\n    def to_dict(self) -> dict:\n        return asdict(self)\n\n    @classmethod\n    def from_dict(cls, data: dict) -> 'Memory':\n        return cls(**data)\n\n\nclass MemoryStore:\n    \"\"\"Persistent memory storage.\"\"\"\n\n    def __init__(self, storage_path: Path = None):\n        if storage_path:\n            self.storage_path = storage_path\n        else:\n            # Use user-level storage for cross-project memory\n            home = Path.home()\n            self.storage_path = home / '.mcp' / 'memory'\n\n        self.storage_path.mkdir(parents=True, exist_ok=True)\n        self.memories: Dict[str, Memory] = {}\n        self.load()\n\n    def _get_file_path(self) -> Path:\n        return self.storage_path / 'knowledge.json'\n\n    def load(self):\n        \"\"\"Load memories from disk.\"\"\"\n        file_path = self._get_file_path()\n        if file_path.exists():\n            try:\n                with open(file_path, 'r', encoding='utf-8') as f:\n                    data = json.load(f)\n                    self.memories = {k: Memory.from_dict(v) for k, v in data.items()}\n            except Exception:\n                self.memories = {}\n\n    def save(self):\n        \"\"\"Save memories to disk.\"\"\"\n        file_path = self._get_file_path()\n        with open(fil", "chunk_type": "file", "line_start": 1, "line_end": 277, "language": "python", "name": "memory.py"}, "e92ab53d7b72_func_get_store": {"id": "e92ab53d7b72_func_get_store", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\memory.py", "content": "def get_store() -> MemoryStore:\n    \"\"\"Get or create memory store.\"\"\"\n    global _store\n    if _store is None:\n        _store = MemoryStore()\n    return _store", "chunk_type": "function", "line_start": 193, "line_end": 198, "language": "python", "name": "get_store"}, "e92ab53d7b72_func_remember": {"id": "e92ab53d7b72_func_remember", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\memory.py", "content": "    def remember(self, key: str, value: str, tags: List[str] = None) -> Memory:\n        \"\"\"Store a memory.\"\"\"\n        now = datetime.utcnow().isoformat() + 'Z'\n\n        # Generate embedding for semantic search\n        combined = f\"{key} {value}\"\n        embedding = embed_text(combined) or []\n\n        if key in self.memories:\n            # Update existing\n            memory = self.memories[key]\n            memory.value = value\n            memory.updated = now\n            memory.tags = tags or memory.tags\n            memory.embedding = embedding\n        else:\n            # Create new\n            memory = Memory(\n                key=key,\n                value=value,\n                tags=tags or [],\n                created=now,\n                updated=now,\n                embedding=embedding\n            )\n\n        self.memories[key] = memory\n        self.save()\n        return memory", "chunk_type": "function", "line_start": 79, "line_end": 107, "language": "python", "name": "remember"}, "e92ab53d7b72_func_recall": {"id": "e92ab53d7b72_func_recall", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\memory.py", "content": "    def recall(self, query: str, limit: int = 10) -> List[Memory]:\n        \"\"\"Search memories semantically.\"\"\"\n        if not self.memories:\n            return []\n\n        # Generate query embedding\n        query_emb = embed_text(query)\n\n        results = []\n        for key, memory in self.memories.items():\n            # Update access count\n            memory.access_count += 1\n\n            # Calculate relevance score\n            score = 0.0\n\n            # Exact key match\n            if query.lower() in key.lower():\n                score += 1.0\n\n            # Value match\n            if query.lower() in memory.value.lower():\n                score += 0.5\n\n            # Tag match\n            for tag in memory.tags:\n                if query.lower() in tag.lower():\n                    score += 0.3\n\n            # Semantic similarity\n            if query_emb and memory.embedding:\n                semantic_score = cosine_similarity(query_emb, memory.embedding)\n                score += semantic_s", "chunk_type": "function", "line_start": 109, "line_end": 150, "language": "python", "name": "recall"}, "e92ab53d7b72_func_forget": {"id": "e92ab53d7b72_func_forget", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\memory.py", "content": "    def forget(self, key: str) -> bool:\n        \"\"\"Remove a memory.\"\"\"\n        if key in self.memories:\n            del self.memories[key]\n            self.save()\n            return True\n        return False", "chunk_type": "function", "line_start": 152, "line_end": 158, "language": "python", "name": "forget"}, "e92ab53d7b72_func_main": {"id": "e92ab53d7b72_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\memory.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Persistent Memory\")\n\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n    store = get_store()\n\n    Console.info(f\"Memory storage: {store.storage_path}\")\n    Console.info(f\"Total memories: {len(store.memories)}\")\n\n    if len(args) >= 2:\n        key = args[0]\n        value = args[1]\n        tags = args[2:] if len(args) > 2 else []\n\n        memory = store.remember(key, value, tags)\n        Console.ok(f\"Remembered: {key}\")\n        print(f\"  Value: {value}\")\n        if tags:\n            print(f\"  Tags: {', '.join(tags)}\")\n        return 0\n\n    if len(args) == 1:\n        query = args[0]\n\n        if '--forget' in sys.argv or '--delete' in sys.argv:\n            if store.forget(query):\n                Console.ok(f\"Forgot: {query}\")\n            else:\n                Console.warn(f\"Not found: {query}\")\n            return 0\n\n        # Search\n        Console.info(f\"Recalling: {query}\")\n        results = store.recall(query)\n\n   ", "chunk_type": "function", "line_start": 216, "line_end": 272, "language": "python", "name": "main"}, "e92ab53d7b72_func_to_dict": {"id": "e92ab53d7b72_func_to_dict", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\memory.py", "content": "    def to_dict(self) -> dict:\n        return asdict(self)", "chunk_type": "function", "line_start": 35, "line_end": 36, "language": "python", "name": "to_dict"}, "e92ab53d7b72_func_from_dict": {"id": "e92ab53d7b72_func_from_dict", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\memory.py", "content": "    def from_dict(cls, data: dict) -> 'Memory':\n        return cls(**data)", "chunk_type": "function", "line_start": 39, "line_end": 40, "language": "python", "name": "from_dict"}, "e92ab53d7b72_func___init__": {"id": "e92ab53d7b72_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\memory.py", "content": "    def __init__(self, storage_path: Path = None):\n        if storage_path:\n            self.storage_path = storage_path\n        else:\n            # Use user-level storage for cross-project memory\n            home = Path.home()\n            self.storage_path = home / '.mcp' / 'memory'\n\n        self.storage_path.mkdir(parents=True, exist_ok=True)\n        self.memories: Dict[str, Memory] = {}\n        self.load()", "chunk_type": "function", "line_start": 46, "line_end": 56, "language": "python", "name": "__init__"}, "e92ab53d7b72_func__get_file_path": {"id": "e92ab53d7b72_func__get_file_path", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\memory.py", "content": "    def _get_file_path(self) -> Path:\n        return self.storage_path / 'knowledge.json'", "chunk_type": "function", "line_start": 58, "line_end": 59, "language": "python", "name": "_get_file_path"}, "e92ab53d7b72_func_load": {"id": "e92ab53d7b72_func_load", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\memory.py", "content": "    def load(self):\n        \"\"\"Load memories from disk.\"\"\"\n        file_path = self._get_file_path()\n        if file_path.exists():\n            try:\n                with open(file_path, 'r', encoding='utf-8') as f:\n                    data = json.load(f)\n                    self.memories = {k: Memory.from_dict(v) for k, v in data.items()}\n            except Exception:\n                self.memories = {}", "chunk_type": "function", "line_start": 61, "line_end": 70, "language": "python", "name": "load"}, "e92ab53d7b72_func_save": {"id": "e92ab53d7b72_func_save", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\memory.py", "content": "    def save(self):\n        \"\"\"Save memories to disk.\"\"\"\n        file_path = self._get_file_path()\n        with open(file_path, 'w', encoding='utf-8') as f:\n            data = {k: v.to_dict() for k, v in self.memories.items()}\n            json.dump(data, f, indent=2)", "chunk_type": "function", "line_start": 72, "line_end": 77, "language": "python", "name": "save"}, "e92ab53d7b72_func_list_all": {"id": "e92ab53d7b72_func_list_all", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\memory.py", "content": "    def list_all(self, tag: str = None) -> List[Memory]:\n        \"\"\"List all memories, optionally filtered by tag.\"\"\"\n        if tag:\n            return [m for m in self.memories.values() if tag in m.tags]\n        return list(self.memories.values())", "chunk_type": "function", "line_start": 160, "line_end": 164, "language": "python", "name": "list_all"}, "e92ab53d7b72_func_get_by_key": {"id": "e92ab53d7b72_func_get_by_key", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\memory.py", "content": "    def get_by_key(self, key: str) -> Optional[Memory]:\n        \"\"\"Get memory by exact key.\"\"\"\n        return self.memories.get(key)", "chunk_type": "function", "line_start": 166, "line_end": 168, "language": "python", "name": "get_by_key"}, "e92ab53d7b72_func_export_all": {"id": "e92ab53d7b72_func_export_all", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\memory.py", "content": "    def export_all(self) -> str:\n        \"\"\"Export all memories as JSON.\"\"\"\n        return json.dumps({k: v.to_dict() for k, v in self.memories.items()}, indent=2)", "chunk_type": "function", "line_start": 170, "line_end": 172, "language": "python", "name": "export_all"}, "e92ab53d7b72_func_import_memories": {"id": "e92ab53d7b72_func_import_memories", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\memory.py", "content": "    def import_memories(self, json_str: str) -> int:\n        \"\"\"Import memories from JSON.\"\"\"\n        try:\n            data = json.loads(json_str)\n            count = 0\n            for key, mem_data in data.items():\n                if key not in self.memories:\n                    self.memories[key] = Memory.from_dict(mem_data)\n                    count += 1\n            self.save()\n            return count\n        except Exception:\n            return 0", "chunk_type": "function", "line_start": 174, "line_end": 186, "language": "python", "name": "import_memories"}, "e92ab53d7b72_class_Memory": {"id": "e92ab53d7b72_class_Memory", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\memory.py", "content": "class Memory:\n    \"\"\"A memory item.\"\"\"\n    key: str\n    value: str\n    tags: List[str] = field(default_factory=list)\n    created: str = \"\"\n    updated: str = \"\"\n    access_count: int = 0\n    embedding: List[float] = field(default_factory=list)\n\n    def to_dict(self) -> dict:\n        return asdict(self)\n\n    @classmethod\n    def from_dict(cls, data: dict) -> 'Memory':\n        return cls(**data)", "chunk_type": "class", "line_start": 25, "line_end": 40, "language": "python", "name": "Memory"}, "e92ab53d7b72_class_MemoryStore": {"id": "e92ab53d7b72_class_MemoryStore", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\memory.py", "content": "class MemoryStore:\n    \"\"\"Persistent memory storage.\"\"\"\n\n    def __init__(self, storage_path: Path = None):\n        if storage_path:\n            self.storage_path = storage_path\n        else:\n            # Use user-level storage for cross-project memory\n            home = Path.home()\n            self.storage_path = home / '.mcp' / 'memory'\n\n        self.storage_path.mkdir(parents=True, exist_ok=True)\n        self.memories: Dict[str, Memory] = {}\n        self.load()\n\n    def _get_file_path(self) -> Path:\n        return self.storage_path / 'knowledge.json'\n\n    def load(self):\n        \"\"\"Load memories from disk.\"\"\"\n        file_path = self._get_file_path()\n        if file_path.exists():\n            try:\n                with open(file_path, 'r', encoding='utf-8') as f:\n                    data = json.load(f)\n                    self.memories = {k: Memory.from_dict(v) for k, v in data.items()}\n            except Exception:\n                self.memories = {}\n\n    def save(self):\n        \"\"\"", "chunk_type": "class", "line_start": 43, "line_end": 186, "language": "python", "name": "MemoryStore"}, "8d004967c18f_file": {"id": "8d004967c18f_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\migrate.py", "content": "\"\"\"\nMigration Helper\n================\nAssist with Python version and framework migrations.\n\nUsage:\n    python migrate.py [path] [--target 3.11]\n    python -m scripts.migrate src/\n\"\"\"\n\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Set\nimport ast\nimport re\nimport sys\n\nfrom .utils import (\n    find_python_files,\n    find_project_root,\n    parse_file,\n    Console,\n    format_as_markdown_table\n)\n\n\n@dataclass\nclass MigrationIssue:\n    \"\"\"A migration issue or suggestion.\"\"\"\n    path: Path\n    line: int\n    severity: str  # 'required', 'recommended', 'optional'\n    category: str\n    title: str\n    description: str\n    old_syntax: Optional[str] = None\n    new_syntax: Optional[str] = None\n\n\n@dataclass\nclass MigrationReport:\n    \"\"\"Complete migration report.\"\"\"\n    target_version: str\n    issues: List[MigrationIssue] = field(default_factory=list)\n\n    @property\n    def required(self) -> List[MigrationIssue]:\n        return [i for i in self.issues if i.severity == 'required']\n\n    @property\n    def recommended(self) -> List[MigrationIssue]:\n        return [i for i in self.issues if i.severity == 'recommended']\n\n    def to_markdown(self) -> str:\n        lines = [\n            \"# Migration Report\",\n            \"\",\n            f\"**Target Version:** Python {self.target_version}\",\n            \"\",\n            \"## Summary\",\n            \"\",\n            f\"- **Required changes:** {len(self.required)}\",\n            f\"- **Recommended changes:** {len(self.recommended)}\",\n            f\"- **Total issues:** {len(self.issues)}\",\n            \"\",\n        ]\n\n        if not self.issues:\n            lines.append(\"No migration issues found. Code is compatible.\")\n            return \"\\n\".join(lines)\n\n        for severity in ['required', 'recommended', 'optional']:\n            items = [i for i in self.issues if i.severity == severity]\n            if not items:\n                continue\n\n            lines.extend([f\"## {severity.title()}\", \"\"])\n\n ", "chunk_type": "file", "line_start": 1, "line_end": 360, "language": "python", "name": "migrate.py"}, "8d004967c18f_func_analyze_file": {"id": "8d004967c18f_func_analyze_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\migrate.py", "content": "def analyze_file(\n    path: Path,\n    target: str\n) -> List[MigrationIssue]:\n    \"\"\"Analyze a file for migration issues.\"\"\"\n    issues = []\n\n    tree = parse_file(path)\n    if tree is None:\n        return issues\n\n    try:\n        with open(path, 'r', encoding='utf-8') as f:\n            source_lines = f.readlines()\n    except Exception:\n        return issues\n\n    # Run analyzers\n    deprecation = DeprecationAnalyzer(path, target)\n    deprecation.visit(tree)\n    issues.extend(deprecation.issues)\n\n    modernizer = SyntaxModernizer(path, source_lines, target)\n    modernizer.visit(tree)\n    issues.extend(modernizer.issues)\n\n    string_format = StringFormatAnalyzer(path, source_lines)\n    string_format.visit(tree)\n    issues.extend(string_format.issues)\n\n    return issues", "chunk_type": "function", "line_start": 266, "line_end": 296, "language": "python", "name": "analyze_file"}, "8d004967c18f_func_check_migration": {"id": "8d004967c18f_func_check_migration", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\migrate.py", "content": "def check_migration(\n    root: Path,\n    target: str = \"3.11\",\n    exclude_patterns: List[str] = None\n) -> MigrationReport:\n    \"\"\"Check project for migration issues.\"\"\"\n    report = MigrationReport(target_version=target)\n\n    Console.info(f\"Checking migration to Python {target}...\")\n\n    files = list(find_python_files(root, exclude_patterns))\n    Console.info(f\"Found {len(files)} Python files\")\n\n    for path in files:\n        issues = analyze_file(path, target)\n        report.issues.extend(issues)\n\n    return report", "chunk_type": "function", "line_start": 299, "line_end": 316, "language": "python", "name": "check_migration"}, "8d004967c18f_func_main": {"id": "8d004967c18f_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\migrate.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Migration Helper\")\n\n    # Parse args\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n    target = \"3.11\"\n\n    for i, arg in enumerate(sys.argv):\n        if arg == '--target' and i + 1 < len(sys.argv):\n            target = sys.argv[i + 1]\n\n    if args:\n        path = Path(args[0])\n    else:\n        path = find_project_root() or Path.cwd()\n\n    if not path.exists():\n        Console.fail(f\"Path not found: {path}\")\n        return 1\n\n    Console.info(f\"Analyzing: {path}\")\n    Console.info(f\"Target version: Python {target}\")\n\n    report = check_migration(path, target)\n\n    print(report.to_markdown())\n\n    # Summary\n    if report.required:\n        Console.warn(f\"Found {len(report.required)} required changes\")\n    elif report.recommended:\n        Console.info(f\"Found {len(report.recommended)} recommended changes\")\n    else:\n        Console.ok(\"Code is ready for migration\")\n\n    return 0", "chunk_type": "function", "line_start": 319, "line_end": 355, "language": "python", "name": "main"}, "8d004967c18f_func_required": {"id": "8d004967c18f_func_required", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\migrate.py", "content": "    def required(self) -> List[MigrationIssue]:\n        return [i for i in self.issues if i.severity == 'required']", "chunk_type": "function", "line_start": 47, "line_end": 48, "language": "python", "name": "required"}, "8d004967c18f_func_recommended": {"id": "8d004967c18f_func_recommended", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\migrate.py", "content": "    def recommended(self) -> List[MigrationIssue]:\n        return [i for i in self.issues if i.severity == 'recommended']", "chunk_type": "function", "line_start": 51, "line_end": 52, "language": "python", "name": "recommended"}, "8d004967c18f_func_to_markdown": {"id": "8d004967c18f_func_to_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\migrate.py", "content": "    def to_markdown(self) -> str:\n        lines = [\n            \"# Migration Report\",\n            \"\",\n            f\"**Target Version:** Python {self.target_version}\",\n            \"\",\n            \"## Summary\",\n            \"\",\n            f\"- **Required changes:** {len(self.required)}\",\n            f\"- **Recommended changes:** {len(self.recommended)}\",\n            f\"- **Total issues:** {len(self.issues)}\",\n            \"\",\n        ]\n\n        if not self.issues:\n            lines.append(\"No migration issues found. Code is compatible.\")\n            return \"\\n\".join(lines)\n\n        for severity in ['required', 'recommended', 'optional']:\n            items = [i for i in self.issues if i.severity == severity]\n            if not items:\n                continue\n\n            lines.extend([f\"## {severity.title()}\", \"\"])\n\n            for issue in items:\n                lines.append(f\"### {issue.title}\")\n                lines.append(f\"**File:** `{issue.path}:{issue.line}`\")\n                lines.app", "chunk_type": "function", "line_start": 54, "line_end": 96, "language": "python", "name": "to_markdown"}, "8d004967c18f_func___init__": {"id": "8d004967c18f_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\migrate.py", "content": "    def __init__(self, path: Path, source_lines: List[str]):\n        self.path = path\n        self.source_lines = source_lines\n        self.issues: List[MigrationIssue] = []", "chunk_type": "function", "line_start": 243, "line_end": 246, "language": "python", "name": "__init__"}, "8d004967c18f_func_visit_ImportFrom": {"id": "8d004967c18f_func_visit_ImportFrom", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\migrate.py", "content": "    def visit_ImportFrom(self, node: ast.ImportFrom):\n        if node.module == 'typing':\n            for alias in node.names:\n                self._typing_imports.add(alias.name)\n\n                # Check deprecated typing imports\n                if alias.name in DEPRECATED_PATTERNS:\n                    new, version, desc = DEPRECATED_PATTERNS[f'typing.{alias.name}']\n                    if self._version_ge(version):\n                        self.issues.append(MigrationIssue(\n                            path=self.path,\n                            line=node.lineno,\n                            severity='recommended',\n                            category='typing',\n                            title=f\"Deprecated: typing.{alias.name}\",\n                            description=desc,\n                            old_syntax=f\"from typing import {alias.name}\",\n                            new_syntax=f\"# Use {new} directly\"\n                        ))\n\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 135, "line_end": 155, "language": "python", "name": "visit_ImportFrom"}, "8d004967c18f_func_visit_Subscript": {"id": "8d004967c18f_func_visit_Subscript", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\migrate.py", "content": "    def visit_Subscript(self, node: ast.Subscript):\n        # Check for Optional[X] -> X | None\n        if isinstance(node.value, ast.Attribute):\n            if isinstance(node.value.value, ast.Name):\n                if node.value.value.id == 'typing':\n                    attr = node.value.attr\n                    if attr in ('Optional', 'Union') and self._version_ge('3.10+'):\n                        self.issues.append(MigrationIssue(\n                            path=self.path,\n                            line=node.lineno,\n                            severity='recommended',\n                            category='typing',\n                            title=f\"Modernize: typing.{attr}\",\n                            description=f\"Python 3.10+ supports | syntax for unions\",\n                            old_syntax=f\"typing.{attr}[...]\",\n                            new_syntax=\"X | Y | None\"\n                        ))\n\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 157, "line_end": 175, "language": "python", "name": "visit_Subscript"}, "8d004967c18f_func_visit_Call": {"id": "8d004967c18f_func_visit_Call", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\migrate.py", "content": "    def visit_Call(self, node: ast.Call):\n        # Check for deprecated function calls\n        func_name = self._get_func_name(node.func)\n\n        # Check for old string formatting\n        if func_name == 'format' or '%' in str(node):\n            pass  # Would need more context\n\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 177, "line_end": 185, "language": "python", "name": "visit_Call"}, "8d004967c18f_func__get_func_name": {"id": "8d004967c18f_func__get_func_name", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\migrate.py", "content": "    def _get_func_name(self, node) -> str:\n        if isinstance(node, ast.Name):\n            return node.id\n        elif isinstance(node, ast.Attribute):\n            return node.attr\n        return \"\"", "chunk_type": "function", "line_start": 187, "line_end": 192, "language": "python", "name": "_get_func_name"}, "8d004967c18f_func__version_ge": {"id": "8d004967c18f_func__version_ge", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\migrate.py", "content": "    def _version_ge(self, version: str) -> bool:\n        \"\"\"Check if target version is >= specified version.\"\"\"\n        target_parts = self.target.split('.')\n        version_parts = version.replace('+', '').split('.')\n\n        try:\n            for t, v in zip(target_parts, version_parts):\n                if int(t) > int(v):\n                    return True\n                elif int(t) < int(v):\n                    return False\n            return True\n        except ValueError:\n            return False", "chunk_type": "function", "line_start": 194, "line_end": 207, "language": "python", "name": "_version_ge"}, "8d004967c18f_func_visit_FunctionDef": {"id": "8d004967c18f_func_visit_FunctionDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\migrate.py", "content": "    def visit_FunctionDef(self, node: ast.FunctionDef):\n        # Check for missing type hints\n        if not node.returns and not node.name.startswith('_'):\n            self.issues.append(MigrationIssue(\n                path=self.path,\n                line=node.lineno,\n                severity='optional',\n                category='type_hints',\n                title=f\"Add return type to {node.name}\",\n                description=\"Adding type hints improves code quality and IDE support\"\n            ))\n\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 219, "line_end": 231, "language": "python", "name": "visit_FunctionDef"}, "8d004967c18f_func_visit_Assign": {"id": "8d004967c18f_func_visit_Assign", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\migrate.py", "content": "    def visit_Assign(self, node: ast.Assign):\n        # Check for walrus operator opportunities in Python 3.8+\n        pass\n\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 233, "line_end": 237, "language": "python", "name": "visit_Assign"}, "8d004967c18f_func_visit_BinOp": {"id": "8d004967c18f_func_visit_BinOp", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\migrate.py", "content": "    def visit_BinOp(self, node: ast.BinOp):\n        # Check for % string formatting\n        if isinstance(node.op, ast.Mod):\n            if isinstance(node.left, ast.Constant) and isinstance(node.left.value, str):\n                self.issues.append(MigrationIssue(\n                    path=self.path,\n                    line=node.lineno,\n                    severity='optional',\n                    category='string_format',\n                    title=\"Modernize string formatting\",\n                    description=\"Consider using f-strings for better readability\",\n                    old_syntax='\"%s\" % value',\n                    new_syntax='f\"{value}\"'\n                ))\n\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 248, "line_end": 263, "language": "python", "name": "visit_BinOp"}, "8d004967c18f_class_MigrationIssue": {"id": "8d004967c18f_class_MigrationIssue", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\migrate.py", "content": "class MigrationIssue:\n    \"\"\"A migration issue or suggestion.\"\"\"\n    path: Path\n    line: int\n    severity: str  # 'required', 'recommended', 'optional'\n    category: str\n    title: str\n    description: str\n    old_syntax: Optional[str] = None\n    new_syntax: Optional[str] = None", "chunk_type": "class", "line_start": 28, "line_end": 37, "language": "python", "name": "MigrationIssue"}, "8d004967c18f_class_MigrationReport": {"id": "8d004967c18f_class_MigrationReport", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\migrate.py", "content": "class MigrationReport:\n    \"\"\"Complete migration report.\"\"\"\n    target_version: str\n    issues: List[MigrationIssue] = field(default_factory=list)\n\n    @property\n    def required(self) -> List[MigrationIssue]:\n        return [i for i in self.issues if i.severity == 'required']\n\n    @property\n    def recommended(self) -> List[MigrationIssue]:\n        return [i for i in self.issues if i.severity == 'recommended']\n\n    def to_markdown(self) -> str:\n        lines = [\n            \"# Migration Report\",\n            \"\",\n            f\"**Target Version:** Python {self.target_version}\",\n            \"\",\n            \"## Summary\",\n            \"\",\n            f\"- **Required changes:** {len(self.required)}\",\n            f\"- **Recommended changes:** {len(self.recommended)}\",\n            f\"- **Total issues:** {len(self.issues)}\",\n            \"\",\n        ]\n\n        if not self.issues:\n            lines.append(\"No migration issues found. Code is compatible.\")\n            return \"\\n\".join(lines)\n\n        f", "chunk_type": "class", "line_start": 41, "line_end": 96, "language": "python", "name": "MigrationReport"}, "8d004967c18f_class_DeprecationAnalyzer": {"id": "8d004967c18f_class_DeprecationAnalyzer", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\migrate.py", "content": "class DeprecationAnalyzer(ast.NodeVisitor):\n    \"\"\"Analyze code for deprecated patterns.\"\"\"\n\n    def __init__(self, path: Path, target: str):\n        self.path = path\n        self.target = target\n        self.issues: List[MigrationIssue] = []\n        self._typing_imports: Set[str] = set()\n\n    def visit_ImportFrom(self, node: ast.ImportFrom):\n        if node.module == 'typing':\n            for alias in node.names:\n                self._typing_imports.add(alias.name)\n\n                # Check deprecated typing imports\n                if alias.name in DEPRECATED_PATTERNS:\n                    new, version, desc = DEPRECATED_PATTERNS[f'typing.{alias.name}']\n                    if self._version_ge(version):\n                        self.issues.append(MigrationIssue(\n                            path=self.path,\n                            line=node.lineno,\n                            severity='recommended',\n                            category='typing',\n                            title=f\"Depre", "chunk_type": "class", "line_start": 126, "line_end": 207, "language": "python", "name": "DeprecationAnalyzer"}, "8d004967c18f_class_SyntaxModernizer": {"id": "8d004967c18f_class_SyntaxModernizer", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\migrate.py", "content": "class SyntaxModernizer(ast.NodeVisitor):\n    \"\"\"Suggest syntax modernization.\"\"\"\n\n    def __init__(self, path: Path, source_lines: List[str], target: str):\n        self.path = path\n        self.source_lines = source_lines\n        self.target = target\n        self.issues: List[MigrationIssue] = []\n\n    def visit_FunctionDef(self, node: ast.FunctionDef):\n        # Check for missing type hints\n        if not node.returns and not node.name.startswith('_'):\n            self.issues.append(MigrationIssue(\n                path=self.path,\n                line=node.lineno,\n                severity='optional',\n                category='type_hints',\n                title=f\"Add return type to {node.name}\",\n                description=\"Adding type hints improves code quality and IDE support\"\n            ))\n\n        self.generic_visit(node)\n\n    def visit_Assign(self, node: ast.Assign):\n        # Check for walrus operator opportunities in Python 3.8+\n        pass\n\n        self.generic_visit(node)", "chunk_type": "class", "line_start": 210, "line_end": 237, "language": "python", "name": "SyntaxModernizer"}, "8d004967c18f_class_StringFormatAnalyzer": {"id": "8d004967c18f_class_StringFormatAnalyzer", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\migrate.py", "content": "class StringFormatAnalyzer(ast.NodeVisitor):\n    \"\"\"Check string formatting patterns.\"\"\"\n\n    def __init__(self, path: Path, source_lines: List[str]):\n        self.path = path\n        self.source_lines = source_lines\n        self.issues: List[MigrationIssue] = []\n\n    def visit_BinOp(self, node: ast.BinOp):\n        # Check for % string formatting\n        if isinstance(node.op, ast.Mod):\n            if isinstance(node.left, ast.Constant) and isinstance(node.left.value, str):\n                self.issues.append(MigrationIssue(\n                    path=self.path,\n                    line=node.lineno,\n                    severity='optional',\n                    category='string_format',\n                    title=\"Modernize string formatting\",\n                    description=\"Consider using f-strings for better readability\",\n                    old_syntax='\"%s\" % value',\n                    new_syntax='f\"{value}\"'\n                ))\n\n        self.generic_visit(node)", "chunk_type": "class", "line_start": 240, "line_end": 263, "language": "python", "name": "StringFormatAnalyzer"}, "f97886e0fdd4_file": {"id": "f97886e0fdd4_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\model_manager.py", "content": "#!/usr/bin/env python3\n\"\"\"\nAntigravity Model Priority Manager\nManages model selection based on user preference and availability.\nPriority 1: Gemini 3 Flash\nPriority 2: Claude Opus (Latest/4.5 Thinking)\n\"\"\"\n\nfrom pathlib import Path\nimport json\nimport os\nimport sys\n\n# Configuration Path\nCONFIG_PATH = Path(\"C:/Users/dbiss/Desktop/Projects/_BLANK_/mcp-global-rules/model_preferences.json\") if os.name == 'nt' else Path(\"/home/p4nd4pr0t0c01/Projects/mcp-global-rules/model_preferences.json\")\n\nDEFAULT_PRIORITY = [\n    \"Gemini 3 Flash\",\n    \"Claude Opus (4.5 Thinking)\",\n    \"GPT-4o\"\n]\n\ndef get_preferences():\n    if CONFIG_PATH.exists():\n        with open(CONFIG_PATH, \"r\") as f:\n            return json.load(f)\n    return {\"priority\": DEFAULT_PRIORITY, \"current\": DEFAULT_PRIORITY[0]}\n\ndef save_preferences(prefs):\n    with open(CONFIG_PATH, \"w\") as f:\n        json.dump(prefs, f, indent=2)\n\ndef get_current_model():\n    prefs = get_preferences()\n    return prefs.get(\"current\", DEFAULT_PRIORITY[0])\n\ndef switch_model(reason=\"manual\"):\n    prefs = get_preferences()\n    priority = prefs.get(\"priority\", DEFAULT_PRIORITY)\n    current = prefs.get(\"current\", priority[0])\n\n    try:\n        idx = priority.index(current)\n        next_idx = (idx + 1) % len(priority)\n        prefs[\"current\"] = priority[next_idx]\n        save_preferences(prefs)\n        print(f\"[MODEL] Switched to {prefs['current']} (Reason: {reason})\")\n        return prefs[\"current\"]\n    except ValueError:\n        prefs[\"current\"] = priority[0]\n        save_preferences(prefs)\n        return priority[0]\n\ndef main():\n    if len(sys.argv) < 2:\n        print(get_current_model())\n        return 0\n\n    cmd = sys.argv[1]\n    if cmd == \"status\":\n        print(f\"Current Priority Model: {get_current_model()}\")\n    elif cmd == \"switch\":\n        reason = sys.argv[2] if len(sys.argv) > 2 else \"limit reached\"\n        switch_model(reason)\n    elif cmd == \"reset\":\n        prefs = {\"priority\": DEFAULT_PRIORITY, \"current\": DEFAULT_PRIORITY[0]}\n", "chunk_type": "file", "line_start": 1, "line_end": 73, "language": "python", "name": "model_manager.py"}, "f97886e0fdd4_func_get_preferences": {"id": "f97886e0fdd4_func_get_preferences", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\model_manager.py", "content": "def get_preferences():\n    if CONFIG_PATH.exists():\n        with open(CONFIG_PATH, \"r\") as f:\n            return json.load(f)\n    return {\"priority\": DEFAULT_PRIORITY, \"current\": DEFAULT_PRIORITY[0]}", "chunk_type": "function", "line_start": 23, "line_end": 27, "language": "python", "name": "get_preferences"}, "f97886e0fdd4_func_save_preferences": {"id": "f97886e0fdd4_func_save_preferences", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\model_manager.py", "content": "def save_preferences(prefs):\n    with open(CONFIG_PATH, \"w\") as f:\n        json.dump(prefs, f, indent=2)", "chunk_type": "function", "line_start": 29, "line_end": 31, "language": "python", "name": "save_preferences"}, "f97886e0fdd4_func_get_current_model": {"id": "f97886e0fdd4_func_get_current_model", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\model_manager.py", "content": "def get_current_model():\n    prefs = get_preferences()\n    return prefs.get(\"current\", DEFAULT_PRIORITY[0])", "chunk_type": "function", "line_start": 33, "line_end": 35, "language": "python", "name": "get_current_model"}, "f97886e0fdd4_func_switch_model": {"id": "f97886e0fdd4_func_switch_model", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\model_manager.py", "content": "def switch_model(reason=\"manual\"):\n    prefs = get_preferences()\n    priority = prefs.get(\"priority\", DEFAULT_PRIORITY)\n    current = prefs.get(\"current\", priority[0])\n\n    try:\n        idx = priority.index(current)\n        next_idx = (idx + 1) % len(priority)\n        prefs[\"current\"] = priority[next_idx]\n        save_preferences(prefs)\n        print(f\"[MODEL] Switched to {prefs['current']} (Reason: {reason})\")\n        return prefs[\"current\"]\n    except ValueError:\n        prefs[\"current\"] = priority[0]\n        save_preferences(prefs)\n        return priority[0]", "chunk_type": "function", "line_start": 37, "line_end": 52, "language": "python", "name": "switch_model"}, "f97886e0fdd4_func_main": {"id": "f97886e0fdd4_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\model_manager.py", "content": "def main():\n    if len(sys.argv) < 2:\n        print(get_current_model())\n        return 0\n\n    cmd = sys.argv[1]\n    if cmd == \"status\":\n        print(f\"Current Priority Model: {get_current_model()}\")\n    elif cmd == \"switch\":\n        reason = sys.argv[2] if len(sys.argv) > 2 else \"limit reached\"\n        switch_model(reason)\n    elif cmd == \"reset\":\n        prefs = {\"priority\": DEFAULT_PRIORITY, \"current\": DEFAULT_PRIORITY[0]}\n        save_preferences(prefs)\n        print(\"[MODEL] Preferences reset to defaults.\")\n    return 0", "chunk_type": "function", "line_start": 54, "line_end": 69, "language": "python", "name": "main"}, "c602e67b800f_file": {"id": "c602e67b800f_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\multi_repo.py", "content": "\"\"\"\nMulti-Repo Search\n=================\nSearch across all registered projects.\n\nUsage:\n    python mcp.py search-all \"query\"\n    python mcp.py repos --add /path/to/repo\n\"\"\"\n\nfrom dataclasses import dataclass, field, asdict\nfrom datetime import datetime\nfrom pathlib import Path\nfrom typing import Dict, List, Optional\nimport json\nimport sys\n\nfrom .utils import Console, find_project_root\n\n\n@dataclass\nclass RepoInfo:\n    \"\"\"Information about a registered repository.\"\"\"\n    path: str\n    name: str\n    added: str\n    last_indexed: Optional[str] = None\n    file_count: int = 0\n\n\n@dataclass\nclass SearchResult:\n    \"\"\"A search result from multi-repo search.\"\"\"\n    repo: str\n    file: str\n    line: int\n    content: str\n    score: float\n\n\nclass MultiRepoStore:\n    \"\"\"Manage multiple repository indexes.\"\"\"\n\n    def __init__(self):\n        home = Path.home()\n        self.storage_path = home / '.mcp' / 'repos'\n        self.storage_path.mkdir(parents=True, exist_ok=True)\n\n        self.repos: Dict[str, RepoInfo] = {}\n        self.load()\n\n    def _config_path(self) -> Path:\n        return self.storage_path / 'repos.json'\n\n    def load(self):\n        \"\"\"Load repo list.\"\"\"\n        config = self._config_path()\n        if config.exists():\n            try:\n                with open(config, 'r') as f:\n                    data = json.load(f)\n                    self.repos = {k: RepoInfo(**v) for k, v in data.items()}\n            except Exception:\n                pass\n\n    def save(self):\n        \"\"\"Save repo list.\"\"\"\n        config = self._config_path()\n        with open(config, 'w') as f:\n            json.dump({k: asdict(v) for k, v in self.repos.items()}, f, indent=2)\n\n    def add_repo(self, path: Path) -> bool:\n        \"\"\"Add a repository to track.\"\"\"\n        path = path.resolve()\n        if not path.exists():\n            return False\n\n        key = str(path)\n\n        # Count files\n        file_count = sum(1 for _ in path.rglob('*.py'))\n\n        self.repos[key] = RepoInfo(\n            pat", "chunk_type": "file", "line_start": 1, "line_end": 250, "language": "python", "name": "multi_repo.py"}, "c602e67b800f_func_get_store": {"id": "c602e67b800f_func_get_store", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\multi_repo.py", "content": "def get_store() -> MultiRepoStore:\n    global _store\n    if _store is None:\n        _store = MultiRepoStore()\n    return _store", "chunk_type": "function", "line_start": 188, "line_end": 192, "language": "python", "name": "get_store"}, "c602e67b800f_func_main": {"id": "c602e67b800f_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\multi_repo.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Multi-Repo Search\")\n\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n    store = get_store()\n\n    Console.info(f\"Registered repos: {len(store.repos)}\")\n\n    if '--add' in sys.argv and args:\n        path = Path(args[0]).resolve()\n        if store.add_repo(path):\n            Console.ok(f\"Added: {path}\")\n        else:\n            Console.fail(f\"Not found: {path}\")\n        return 0\n\n    if '--remove' in sys.argv and args:\n        if store.remove_repo(args[0]):\n            Console.ok(f\"Removed: {args[0]}\")\n        else:\n            Console.fail(f\"Not found: {args[0]}\")\n        return 0\n\n    if '--list' in sys.argv or not args:\n        repos = store.list_repos()\n        if repos:\n            print(\"\\n## Registered Repositories\")\n            for repo in repos:\n                print(f\"  [{repo.name}] {repo.path}\")\n                print(f\"    Files: {repo.file_count}, Added: {repo.added[:10]}\")\n        else:\n            Co", "chunk_type": "function", "line_start": 195, "line_end": 245, "language": "python", "name": "main"}, "c602e67b800f_func___init__": {"id": "c602e67b800f_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\multi_repo.py", "content": "    def __init__(self):\n        home = Path.home()\n        self.storage_path = home / '.mcp' / 'repos'\n        self.storage_path.mkdir(parents=True, exist_ok=True)\n\n        self.repos: Dict[str, RepoInfo] = {}\n        self.load()", "chunk_type": "function", "line_start": 44, "line_end": 50, "language": "python", "name": "__init__"}, "c602e67b800f_func__config_path": {"id": "c602e67b800f_func__config_path", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\multi_repo.py", "content": "    def _config_path(self) -> Path:\n        return self.storage_path / 'repos.json'", "chunk_type": "function", "line_start": 52, "line_end": 53, "language": "python", "name": "_config_path"}, "c602e67b800f_func_load": {"id": "c602e67b800f_func_load", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\multi_repo.py", "content": "    def load(self):\n        \"\"\"Load repo list.\"\"\"\n        config = self._config_path()\n        if config.exists():\n            try:\n                with open(config, 'r') as f:\n                    data = json.load(f)\n                    self.repos = {k: RepoInfo(**v) for k, v in data.items()}\n            except Exception:\n                pass", "chunk_type": "function", "line_start": 55, "line_end": 64, "language": "python", "name": "load"}, "c602e67b800f_func_save": {"id": "c602e67b800f_func_save", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\multi_repo.py", "content": "    def save(self):\n        \"\"\"Save repo list.\"\"\"\n        config = self._config_path()\n        with open(config, 'w') as f:\n            json.dump({k: asdict(v) for k, v in self.repos.items()}, f, indent=2)", "chunk_type": "function", "line_start": 66, "line_end": 70, "language": "python", "name": "save"}, "c602e67b800f_func_add_repo": {"id": "c602e67b800f_func_add_repo", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\multi_repo.py", "content": "    def add_repo(self, path: Path) -> bool:\n        \"\"\"Add a repository to track.\"\"\"\n        path = path.resolve()\n        if not path.exists():\n            return False\n\n        key = str(path)\n\n        # Count files\n        file_count = sum(1 for _ in path.rglob('*.py'))\n\n        self.repos[key] = RepoInfo(\n            path=key,\n            name=path.name,\n            added=datetime.utcnow().isoformat() + 'Z',\n            file_count=file_count\n        )\n\n        self.save()\n        return True", "chunk_type": "function", "line_start": 72, "line_end": 91, "language": "python", "name": "add_repo"}, "c602e67b800f_func_remove_repo": {"id": "c602e67b800f_func_remove_repo", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\multi_repo.py", "content": "    def remove_repo(self, path: str) -> bool:\n        \"\"\"Remove a repository.\"\"\"\n        if path in self.repos:\n            del self.repos[path]\n            self.save()\n            return True\n        return False", "chunk_type": "function", "line_start": 93, "line_end": 99, "language": "python", "name": "remove_repo"}, "c602e67b800f_func_list_repos": {"id": "c602e67b800f_func_list_repos", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\multi_repo.py", "content": "    def list_repos(self) -> List[RepoInfo]:\n        \"\"\"List all registered repos.\"\"\"\n        return list(self.repos.values())", "chunk_type": "function", "line_start": 101, "line_end": 103, "language": "python", "name": "list_repos"}, "c602e67b800f_func_search_all": {"id": "c602e67b800f_func_search_all", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\multi_repo.py", "content": "    def search_all(self, query: str, limit: int = 20) -> List[SearchResult]:\n        \"\"\"Search across all repos.\"\"\"\n        results = []\n        query_lower = query.lower()\n\n        for repo_path, repo_info in self.repos.items():\n            path = Path(repo_path)\n            if not path.exists():\n                continue\n\n            # Search files\n            for file_path in path.rglob('*.py'):\n                if '.git' in str(file_path) or 'node_modules' in str(file_path):\n                    continue\n\n                try:\n                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n                        for i, line in enumerate(f, 1):\n                            if query_lower in line.lower():\n                                results.append(SearchResult(\n                                    repo=repo_info.name,\n                                    file=str(file_path.relative_to(path)),\n                                    line=i,\n                           ", "chunk_type": "function", "line_start": 105, "line_end": 139, "language": "python", "name": "search_all"}, "c602e67b800f_func_find_similar_code": {"id": "c602e67b800f_func_find_similar_code", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\multi_repo.py", "content": "    def find_similar_code(self, code_snippet: str, limit: int = 10) -> List[SearchResult]:\n        \"\"\"Find similar code across repos.\"\"\"\n        results = []\n\n        # Tokenize snippet\n        tokens = set(code_snippet.lower().split())\n        tokens = {t for t in tokens if len(t) > 2}\n\n        if not tokens:\n            return results\n\n        for repo_path, repo_info in self.repos.items():\n            path = Path(repo_path)\n            if not path.exists():\n                continue\n\n            for file_path in path.rglob('*.py'):\n                if '.git' in str(file_path):\n                    continue\n\n                try:\n                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n                        content = f.read()\n\n                    # Calculate similarity\n                    file_tokens = set(content.lower().split())\n                    overlap = len(tokens & file_tokens) / len(tokens) if tokens else 0\n\n                    if overlap > 0.3:  ", "chunk_type": "function", "line_start": 141, "line_end": 181, "language": "python", "name": "find_similar_code"}, "c602e67b800f_class_RepoInfo": {"id": "c602e67b800f_class_RepoInfo", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\multi_repo.py", "content": "class RepoInfo:\n    \"\"\"Information about a registered repository.\"\"\"\n    path: str\n    name: str\n    added: str\n    last_indexed: Optional[str] = None\n    file_count: int = 0", "chunk_type": "class", "line_start": 22, "line_end": 28, "language": "python", "name": "RepoInfo"}, "c602e67b800f_class_SearchResult": {"id": "c602e67b800f_class_SearchResult", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\multi_repo.py", "content": "class SearchResult:\n    \"\"\"A search result from multi-repo search.\"\"\"\n    repo: str\n    file: str\n    line: int\n    content: str\n    score: float", "chunk_type": "class", "line_start": 32, "line_end": 38, "language": "python", "name": "SearchResult"}, "c602e67b800f_class_MultiRepoStore": {"id": "c602e67b800f_class_MultiRepoStore", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\multi_repo.py", "content": "class MultiRepoStore:\n    \"\"\"Manage multiple repository indexes.\"\"\"\n\n    def __init__(self):\n        home = Path.home()\n        self.storage_path = home / '.mcp' / 'repos'\n        self.storage_path.mkdir(parents=True, exist_ok=True)\n\n        self.repos: Dict[str, RepoInfo] = {}\n        self.load()\n\n    def _config_path(self) -> Path:\n        return self.storage_path / 'repos.json'\n\n    def load(self):\n        \"\"\"Load repo list.\"\"\"\n        config = self._config_path()\n        if config.exists():\n            try:\n                with open(config, 'r') as f:\n                    data = json.load(f)\n                    self.repos = {k: RepoInfo(**v) for k, v in data.items()}\n            except Exception:\n                pass\n\n    def save(self):\n        \"\"\"Save repo list.\"\"\"\n        config = self._config_path()\n        with open(config, 'w') as f:\n            json.dump({k: asdict(v) for k, v in self.repos.items()}, f, indent=2)\n\n    def add_repo(self, path: Path) -> bool:\n        \"\"\"Add a r", "chunk_type": "class", "line_start": 41, "line_end": 181, "language": "python", "name": "MultiRepoStore"}, "205f1e5e3d4f_file": {"id": "205f1e5e3d4f_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\nsync.py", "content": "#!/usr/bin/env python3\n\"\"\"\nMCP NSync Module\nProvides real-time cross-device synchronization and remote execution.\n\"\"\"\n\nfrom pathlib import Path\nfrom typing import List, Optional\nimport os\nimport subprocess\nimport sys\nimport time\n\ntry:\n    from watchdog.observers import Observer\n    from watchdog.events import FileSystemEventHandler\nexcept ImportError:\n    Observer = None\n    FileSystemEventHandler = object\n\n# NSync Configuration\nfrom .utils import find_project_root\n\n# NSync Configuration\n# Enforce containment within the current project\n_project_root = find_project_root() or Path.cwd()\nWINDOWS_NSYNC = _project_root / \".nsync\"\nLINUX_NSYNC = _project_root / \".nsync\"\n\ndef get_remote_peer():\n    import socket\n    host = socket.gethostname()\n    if host.lower() == \"wizardpanda\":\n        return \"quasar\"\n    return \"wizardpanda\"\n\nREMOTE_USER = \"p4nd4pr0t0c01\"\n\nclass NSyncHandler(FileSystemEventHandler):\n    \"\"\"Handles file system events and triggers git sync.\"\"\"\n    def __init__(self, repo_path: Path):\n        self.repo_path = repo_path\n        self.last_sync = 0\n        self.debounce = 2 # Seconds\n\n    def on_any_event(self, event):\n        if event.is_directory or \".git\" in event.src_path:\n            return\n\n        now = time.time()\n        if now - self.last_sync > self.debounce:\n            self.sync()\n            self.last_sync = now\n\n    def sync(self):\n        \"\"\"Perform a git sync cycle.\"\"\"\n        print(f\"[NSYNC] Change detected. Syncing...\")\n\n        # [NEW] Ensure rules links exist in all projects before sync\n        self.ensure_rules_links()\n\n        try:\n            os.chdir(self.repo_path)\n            # Add and commit\n            subprocess.run([\"git\", \"add\", \"-A\"], capture_output=True)\n            subprocess.run([\"git\", \"commit\", \"-m\", \"nsync: auto-sync\"], capture_output=True)\n\n            # Pull with rebase to handle conflicts cleanly\n            subprocess.run([\"git\", \"pull\", \"--rebase\", get_remote_peer(), \"master\"], capture_output=True)\n\n            # Pu", "chunk_type": "file", "line_start": 1, "line_end": 372, "language": "python", "name": "nsync.py"}, "205f1e5e3d4f_func_get_remote_peer": {"id": "205f1e5e3d4f_func_get_remote_peer", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\nsync.py", "content": "def get_remote_peer():\n    import socket\n    host = socket.gethostname()\n    if host.lower() == \"wizardpanda\":\n        return \"quasar\"\n    return \"wizardpanda\"", "chunk_type": "function", "line_start": 30, "line_end": 35, "language": "python", "name": "get_remote_peer"}, "205f1e5e3d4f_func_get_nsync_path": {"id": "205f1e5e3d4f_func_get_nsync_path", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\nsync.py", "content": "def get_nsync_path() -> Path:\n    \"\"\"Determine the local NSync path based on OS.\"\"\"\n    if os.name == 'nt':\n        return WINDOWS_NSYNC\n    return LINUX_NSYNC", "chunk_type": "function", "line_start": 106, "line_end": 110, "language": "python", "name": "get_nsync_path"}, "205f1e5e3d4f_func_show_help": {"id": "205f1e5e3d4f_func_show_help", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\nsync.py", "content": "def show_help():\n    print(\"MCP NSync: Real-time synchronization and remote execution\")\n    print(\"Usage: mcp nsync <command> [args]\")\n    print(\"\\nCommands:\")\n    print(\"  watch               Start the real-time sync service\")\n    print(\"  status              Check sync status and peer connectivity\")\n    print(\"  run <file>          Sync and execute a file on wizardpanda\")\n    print(\"  sync                Perform a manual sync cycle\")\n    print(\"  setup               Install Git hooks for sync automation\")\n    print(\"  init-project <name> Initialize a new project folder with MCP links\")", "chunk_type": "function", "line_start": 112, "line_end": 121, "language": "python", "name": "show_help"}, "205f1e5e3d4f_func_init_project": {"id": "205f1e5e3d4f_func_init_project", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\nsync.py", "content": "def init_project(name: str):\n    \"\"\"Initialize a sub-project within NSync with MCP links.\"\"\"\n    nsync_path = get_nsync_path()\n    project_path = nsync_path / name\n\n    if project_path.exists():\n        print(f\"[FAIL] Project {name} already exists at {project_path}\")\n        return 1\n\n    project_path.mkdir(parents=True)\n    print(f\"[OK] Created project directory: {project_path}\")\n\n    # Create link to mcp-global-rules\n    mcp_source = Path(\"C:/Users/dbiss/Desktop/Projects/_BLANK_/mcp-global-rules\") if os.name == 'nt' else Path(\"/home/p4nd4pr0t0c01/Projects/mcp-global-rules\")\n    mcp_target = project_path / \"mcp-global-rules\"\n\n    try:\n        if os.name == 'nt':\n            # Use Junction for Windows directory link\n            subprocess.run([\"cmd\", \"/c\", \"mklink\", \"/J\", str(mcp_target), str(mcp_source)], check=True)\n        else:\n            os.symlink(mcp_source, mcp_target)\n        print(f\"[OK] Linked mcp-global-rules to {mcp_target}\")\n    except Exception as e:\n        print(f\"[WA", "chunk_type": "function", "line_start": 123, "line_end": 189, "language": "python", "name": "init_project"}, "205f1e5e3d4f_func_start_watch": {"id": "205f1e5e3d4f_func_start_watch", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\nsync.py", "content": "def start_watch():\n    if not Observer:\n        print(\"[FAIL] 'watchdog' package not found. Install with: pip install watchdog\")\n        return 1\n\n    path = get_nsync_path()\n    if not path.exists():\n        print(f\"[FAIL] NSync directory not found at {path}\")\n        return 1\n\n    # [NEW] PID-based singleton protection\n    import tempfile\n    pid_file = Path(tempfile.gettempdir()) / \"nsync_watch.pid\"\n    if pid_file.exists():\n        try:\n            with open(pid_file, \"r\") as f:\n                old_pid = int(f.read().strip())\n                if os.name == 'nt':\n                    # Windows PID check\n                    subprocess.run([\"tasklist\", \"/FI\", f\"PID eq {old_pid}\"], check=True, capture_output=True)\n                else:\n                    # Linux PID check\n                    os.kill(old_pid, 0)\n                print(f\"[NSYNC] Watch service already running (PID {old_pid}). Exiting.\")\n                return 0\n        except:\n            pid_file.unlink()\n\n    with open(pi", "chunk_type": "function", "line_start": 191, "line_end": 262, "language": "python", "name": "start_watch"}, "205f1e5e3d4f_func_remote_run": {"id": "205f1e5e3d4f_func_remote_run", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\nsync.py", "content": "def remote_run(filename: str):\n    \"\"\"Sync and run a script on wizardpanda.\"\"\"\n    local_path = get_nsync_path() / filename\n    if not local_path.exists():\n        print(f\"[FAIL] File {filename} not found in NSync directory.\")\n        return 1\n\n    print(f\"[NSYNC] Syncing {filename} to {get_remote_peer()}...\")\n    # Manual sync before execution\n    handler = NSyncHandler(get_nsync_path())\n    handler.sync()\n\n    remote_cmd = f\"cd ~/Projects/NSync && python3 {filename}\"\n    ssh_cmd = [\"ssh\", f\"{REMOTE_USER}@{get_remote_peer()}\", remote_cmd]\n\n    print(f\"[EXEC] Executing on {get_remote_peer()}...\\n\" + \"-\"*40)\n    subprocess.run(ssh_cmd)\n    print(\"-\"*40 + \"\\n[NSYNC] Remote execution complete.\")\n    return 0", "chunk_type": "function", "line_start": 264, "line_end": 282, "language": "python", "name": "remote_run"}, "205f1e5e3d4f_func_check_status": {"id": "205f1e5e3d4f_func_check_status", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\nsync.py", "content": "def check_status():\n    \"\"\"Verify connectivity and repo states.\"\"\"\n    path = get_nsync_path()\n    print(f\"Local Path: {path}\")\n    if path.exists():\n        print(\"[OK] Local directory exists.\")\n        os.chdir(path)\n        res = subprocess.run([\"git\", \"status\"], capture_output=True, text=True)\n        if res.returncode == 0:\n            print(\"[OK] Git repository initialized.\")\n        else:\n            print(\"[WARN] Git not initialized in NSync directory.\")\n    else:\n        print(\"[FAIL] Local directory missing.\")\n\n    print(f\"Peer: {get_remote_peer()}\")\n    res = subprocess.run([\"ssh\", f\"{REMOTE_USER}@{get_remote_peer()}\", \"date\"], capture_output=True)\n    if res.returncode == 0:\n        print(\"[OK] Peer reachable via SSH.\")\n    else:\n        print(\"[FAIL] Peer unreachable or SSH failed.\")", "chunk_type": "function", "line_start": 284, "line_end": 304, "language": "python", "name": "check_status"}, "205f1e5e3d4f_func_setup_hooks": {"id": "205f1e5e3d4f_func_setup_hooks", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\nsync.py", "content": "def setup_hooks():\n    \"\"\"Install Git hooks for sync automation.\"\"\"\n    path = get_nsync_path()\n    hooks_dir = path / \".git\" / \"hooks\"\n    if not hooks_dir.exists():\n        print(f\"[FAIL] Git hooks directory missing at {hooks_dir}\")\n        return 1\n\n    # Post-commit hook: Trigger sync immediately\n    post_commit_path = hooks_dir / (\"post-commit\" if os.name != 'nt' else \"post-commit\")\n    # Note: On Windows Git Bash uses the same name\n\n    sync_cmd = \"mcp nsync sync\"\n    if os.name == 'nt':\n        # Create a shell script for Git to run\n        with open(post_commit_path, \"w\") as f:\n            f.write(f\"#!/bin/sh\\n{sync_cmd}\\n\")\n    else:\n        with open(post_commit_path, \"w\") as f:\n            f.write(f\"#!/bin/bash\\npython3 /home/p4nd4pr0t0c01/Projects/mcp-global-rules/mcp.py nsync sync\\n\")\n\n    os.chmod(post_commit_path, 0o755)\n    print(f\"[OK] Installed post-commit hook at {post_commit_path}\")\n\n    # Post-merge hook: Re-index context\n    post_merge_path = hooks_dir / \"post-mer", "chunk_type": "function", "line_start": 306, "line_end": 342, "language": "python", "name": "setup_hooks"}, "205f1e5e3d4f_func_main": {"id": "205f1e5e3d4f_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\nsync.py", "content": "def main():\n    if len(sys.argv) < 2:\n        show_help()\n        return 0\n\n    cmd = sys.argv[1]\n    args = sys.argv[2:]\n\n    if cmd == \"watch\":\n        return start_watch()\n    elif cmd == \"run\" and args:\n        return remote_run(args[0])\n    elif cmd == \"status\":\n        return check_status()\n    elif cmd == \"sync\":\n        handler = NSyncHandler(get_nsync_path())\n        handler.sync()\n        return 0\n    elif cmd == \"setup\":\n        return setup_hooks()\n    elif cmd == \"init-project\" and args:\n        return init_project(args[0])\n    else:\n        show_help()\n    return 0", "chunk_type": "function", "line_start": 344, "line_end": 368, "language": "python", "name": "main"}, "205f1e5e3d4f_func___init__": {"id": "205f1e5e3d4f_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\nsync.py", "content": "    def __init__(self, repo_path: Path):\n        self.repo_path = repo_path\n        self.last_sync = 0\n        self.debounce = 2 # Seconds", "chunk_type": "function", "line_start": 41, "line_end": 44, "language": "python", "name": "__init__"}, "205f1e5e3d4f_func_on_any_event": {"id": "205f1e5e3d4f_func_on_any_event", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\nsync.py", "content": "    def on_any_event(self, event):\n        if event.is_directory or \".git\" in event.src_path:\n            return\n\n        now = time.time()\n        if now - self.last_sync > self.debounce:\n            self.sync()\n            self.last_sync = now", "chunk_type": "function", "line_start": 46, "line_end": 53, "language": "python", "name": "on_any_event"}, "205f1e5e3d4f_func_sync": {"id": "205f1e5e3d4f_func_sync", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\nsync.py", "content": "    def sync(self):\n        \"\"\"Perform a git sync cycle.\"\"\"\n        print(f\"[NSYNC] Change detected. Syncing...\")\n\n        # [NEW] Ensure rules links exist in all projects before sync\n        self.ensure_rules_links()\n\n        try:\n            os.chdir(self.repo_path)\n            # Add and commit\n            subprocess.run([\"git\", \"add\", \"-A\"], capture_output=True)\n            subprocess.run([\"git\", \"commit\", \"-m\", \"nsync: auto-sync\"], capture_output=True)\n\n            # Pull with rebase to handle conflicts cleanly\n            subprocess.run([\"git\", \"pull\", \"--rebase\", get_remote_peer(), \"master\"], capture_output=True)\n\n            # Push to peer\n            subprocess.run([\"git\", \"push\", get_remote_peer(), \"master\"], capture_output=True)\n            print(f\"[NSYNC] Sync complete.\")\n        except Exception as e:\n            print(f\"[FAIL] Sync failed: {e}\")", "chunk_type": "function", "line_start": 55, "line_end": 75, "language": "python", "name": "sync"}, "205f1e5e3d4f_func_ensure_rules_links": {"id": "205f1e5e3d4f_func_ensure_rules_links", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\nsync.py", "content": "    def ensure_rules_links(self):\n        \"\"\"Iterate through all projects and ensure mcp-global-rules is linked.\"\"\"\n        mcp_source = Path(\"C:/Users/dbiss/Desktop/Projects/_BLANK_/mcp-global-rules\") if os.name == 'nt' else Path(\"/home/p4nd4pr0t0c01/Projects/mcp-global-rules\")\n\n        for item in self.repo_path.iterdir():\n            if item.is_dir() and not item.name.startswith(\".\"):\n                target = item / \"mcp-global-rules\"\n\n                # If it's a real directory (not a link), remove it to make way for the link\n                if target.exists() and not target.is_symlink():\n                    if os.name != 'nt': # Extra check for Linux directory sync issue\n                         # Only remove if it's not a junction/symlink\n                         import shutil\n                         try:\n                             if target.is_dir() and not target.is_symlink():\n                                 shutil.rmtree(target)\n                         except:\n            ", "chunk_type": "function", "line_start": 77, "line_end": 104, "language": "python", "name": "ensure_rules_links"}, "205f1e5e3d4f_func_poll_remote": {"id": "205f1e5e3d4f_func_poll_remote", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\nsync.py", "content": "    def poll_remote():\n        while True:\n            time.sleep(30) # Poll every 30 seconds\n            print(\"[NSYNC] Periodic check for remote changes...\")\n            handler.sync()", "chunk_type": "function", "line_start": 230, "line_end": 234, "language": "python", "name": "poll_remote"}, "205f1e5e3d4f_class_NSyncHandler": {"id": "205f1e5e3d4f_class_NSyncHandler", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\nsync.py", "content": "class NSyncHandler(FileSystemEventHandler):\n    \"\"\"Handles file system events and triggers git sync.\"\"\"\n    def __init__(self, repo_path: Path):\n        self.repo_path = repo_path\n        self.last_sync = 0\n        self.debounce = 2 # Seconds\n\n    def on_any_event(self, event):\n        if event.is_directory or \".git\" in event.src_path:\n            return\n\n        now = time.time()\n        if now - self.last_sync > self.debounce:\n            self.sync()\n            self.last_sync = now\n\n    def sync(self):\n        \"\"\"Perform a git sync cycle.\"\"\"\n        print(f\"[NSYNC] Change detected. Syncing...\")\n\n        # [NEW] Ensure rules links exist in all projects before sync\n        self.ensure_rules_links()\n\n        try:\n            os.chdir(self.repo_path)\n            # Add and commit\n            subprocess.run([\"git\", \"add\", \"-A\"], capture_output=True)\n            subprocess.run([\"git\", \"commit\", \"-m\", \"nsync: auto-sync\"], capture_output=True)\n\n            # Pull with rebase to handle confli", "chunk_type": "class", "line_start": 39, "line_end": 104, "language": "python", "name": "NSyncHandler"}, "ba125f115b98_file": {"id": "ba125f115b98_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\predict.py", "content": "\"\"\"\nBug Prediction\n==============\nPredict bugs before they happen based on code patterns.\n\nUsage:\n    python mcp.py predict-bugs [file]\n    python mcp.py risk-score\n\"\"\"\n\nfrom collections import Counter\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Tuple\nimport ast\nimport json\nimport sys\n\nfrom .utils import Console, find_python_files, find_project_root\n\n\n@dataclass\nclass BugPrediction:\n    \"\"\"A predicted bug.\"\"\"\n    file: str\n    line: int\n    risk_level: str  # 'high', 'medium', 'low'\n    category: str\n    description: str\n    confidence: float\n    suggestion: str = \"\"\n\n\n@dataclass\nclass RiskReport:\n    \"\"\"Risk assessment report.\"\"\"\n    total_risk_score: float\n    risk_level: str\n    predictions: List[BugPrediction] = field(default_factory=list)\n    hotspots: List[str] = field(default_factory=list)\n\n    def to_markdown(self) -> str:\n        level_label = {'high': '[HIGH]', 'medium': '[MEDIUM]', 'low': '[LOW]'}\n\n        lines = [\n            f\"# Risk Report\",\n            \"\",\n            f\"**Overall Risk:** {level_label.get(self.risk_level, '')} {self.risk_level.upper()} ({self.total_risk_score:.1f}/100)\",\n            \"\",\n        ]\n\n        if self.predictions:\n            lines.append(\"## Predictions\")\n            for pred in self.predictions[:10]:\n                lines.append(f\"- **{pred.category}** ({pred.risk_level}): {pred.description}\")\n                lines.append(f\"  - {pred.file}:{pred.line}\")\n                if pred.suggestion:\n                    lines.append(f\"  - Fix: {pred.suggestion}\")\n            lines.append(\"\")\n\n        if self.hotspots:\n            lines.append(\"## Hotspots\")\n            for hs in self.hotspots[:5]:\n                lines.append(f\"- {hs}\")\n\n        return '\\n'.join(lines)\n\n\n# Risk patterns\nRISK_PATTERNS = {\n    'complexity': {\n        'threshold': 10,\n        'weight': 2.0,\n        'description': 'High cyclomatic complexity'\n    },\n    'nesting': {\n        'threshold': 4,\n ", "chunk_type": "file", "line_start": 1, "line_end": 367, "language": "python", "name": "predict.py"}, "ba125f115b98_func_predict_bugs": {"id": "ba125f115b98_func_predict_bugs", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\predict.py", "content": "def predict_bugs(file_path: Path) -> List[BugPrediction]:\n    \"\"\"Predict bugs in a file.\"\"\"\n    try:\n        with open(file_path, 'r', encoding='utf-8') as f:\n            source = f.read()\n            lines = source.split('\\n')\n\n        tree = ast.parse(source)\n    except Exception:\n        return []\n\n    predictor = BugPredictor(lines)\n    predictor.current_file = str(file_path)\n    predictor.visit(tree)\n\n    return predictor.predictions", "chunk_type": "function", "line_start": 253, "line_end": 268, "language": "python", "name": "predict_bugs"}, "ba125f115b98_func_predict_bugs_project": {"id": "ba125f115b98_func_predict_bugs_project", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\predict.py", "content": "def predict_bugs_project(root: Path) -> List[BugPrediction]:\n    \"\"\"Predict bugs across project.\"\"\"\n    all_predictions = []\n\n    exclude = ['node_modules', 'venv', '.venv', '__pycache__', '.git', 'vendor']\n\n    for file_path in find_python_files(root, exclude):\n        predictions = predict_bugs(file_path)\n        all_predictions.extend(predictions)\n\n    # Sort by risk level\n    level_order = {'high': 0, 'medium': 1, 'low': 2}\n    all_predictions.sort(key=lambda p: level_order.get(p.risk_level, 3))\n\n    return all_predictions", "chunk_type": "function", "line_start": 271, "line_end": 285, "language": "python", "name": "predict_bugs_project"}, "ba125f115b98_func_calculate_risk_score": {"id": "ba125f115b98_func_calculate_risk_score", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\predict.py", "content": "def calculate_risk_score(predictions: List[BugPrediction]) -> float:\n    \"\"\"Calculate overall risk score (0-100).\"\"\"\n    if not predictions:\n        return 0.0\n\n    score = 0.0\n    for pred in predictions:\n        weight = RISK_PATTERNS.get(pred.category, {}).get('weight', 1.0)\n        level_mult = {'high': 3, 'medium': 2, 'low': 1}.get(pred.risk_level, 1)\n        score += weight * level_mult * pred.confidence\n\n    # Normalize to 0-100\n    return min(100, score)", "chunk_type": "function", "line_start": 288, "line_end": 300, "language": "python", "name": "calculate_risk_score"}, "ba125f115b98_func_get_risk_report": {"id": "ba125f115b98_func_get_risk_report", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\predict.py", "content": "def get_risk_report(root: Path = None) -> RiskReport:\n    \"\"\"Generate risk report for project.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    predictions = predict_bugs_project(root)\n    score = calculate_risk_score(predictions)\n\n    # Determine level\n    if score >= 50:\n        level = 'high'\n    elif score >= 20:\n        level = 'medium'\n    else:\n        level = 'low'\n\n    # Find hotspots (files with most issues)\n    file_counts = Counter(p.file for p in predictions)\n    hotspots = [f\"{path} ({count} issues)\" for path, count in file_counts.most_common(5)]\n\n    return RiskReport(\n        total_risk_score=score,\n        risk_level=level,\n        predictions=predictions,\n        hotspots=hotspots\n    )", "chunk_type": "function", "line_start": 303, "line_end": 327, "language": "python", "name": "get_risk_report"}, "ba125f115b98_func_main": {"id": "ba125f115b98_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\predict.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Bug Prediction\")\n\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n    root = find_project_root() or Path.cwd()\n\n    if args:\n        file_path = Path(args[0])\n        if file_path.exists() and file_path.is_file():\n            Console.info(f\"Analyzing {file_path}...\")\n            predictions = predict_bugs(file_path)\n\n            if predictions:\n                Console.warn(f\"Found {len(predictions)} potential issues\")\n                for pred in predictions:\n                    level_color = {'high': '\\033[91m', 'medium': '\\033[93m', 'low': '\\033[92m'}\n                    nc = '\\033[0m'\n                    print(f\"\\n  {level_color.get(pred.risk_level, '')}{pred.risk_level.upper()}{nc}: {pred.category}\")\n                    print(f\"  Line {pred.line}: {pred.description}\")\n                    if pred.suggestion:\n                        print(f\"  Suggestion: {pred.suggestion}\")\n            else:\n                Conso", "chunk_type": "function", "line_start": 330, "line_end": 362, "language": "python", "name": "main"}, "ba125f115b98_func_to_markdown": {"id": "ba125f115b98_func_to_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\predict.py", "content": "    def to_markdown(self) -> str:\n        level_label = {'high': '[HIGH]', 'medium': '[MEDIUM]', 'low': '[LOW]'}\n\n        lines = [\n            f\"# Risk Report\",\n            \"\",\n            f\"**Overall Risk:** {level_label.get(self.risk_level, '')} {self.risk_level.upper()} ({self.total_risk_score:.1f}/100)\",\n            \"\",\n        ]\n\n        if self.predictions:\n            lines.append(\"## Predictions\")\n            for pred in self.predictions[:10]:\n                lines.append(f\"- **{pred.category}** ({pred.risk_level}): {pred.description}\")\n                lines.append(f\"  - {pred.file}:{pred.line}\")\n                if pred.suggestion:\n                    lines.append(f\"  - Fix: {pred.suggestion}\")\n            lines.append(\"\")\n\n        if self.hotspots:\n            lines.append(\"## Hotspots\")\n            for hs in self.hotspots[:5]:\n                lines.append(f\"- {hs}\")\n\n        return '\\n'.join(lines)", "chunk_type": "function", "line_start": 42, "line_end": 66, "language": "python", "name": "to_markdown"}, "ba125f115b98_func___init__": {"id": "ba125f115b98_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\predict.py", "content": "    def __init__(self, source_lines: List[str]):\n        self.predictions: List[BugPrediction] = []\n        self.source_lines = source_lines\n        self.current_file = \"\"", "chunk_type": "function", "line_start": 157, "line_end": 160, "language": "python", "name": "__init__"}, "ba125f115b98_func_visit_If": {"id": "ba125f115b98_func_visit_If", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\predict.py", "content": "    def visit_If(self, node):\n        self.complexity += 1\n        self._enter_nesting()\n        self.generic_visit(node)\n        self._exit_nesting()", "chunk_type": "function", "line_start": 120, "line_end": 124, "language": "python", "name": "visit_If"}, "ba125f115b98_func_visit_For": {"id": "ba125f115b98_func_visit_For", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\predict.py", "content": "    def visit_For(self, node):\n        self.complexity += 1\n        self._enter_nesting()\n        self.generic_visit(node)\n        self._exit_nesting()", "chunk_type": "function", "line_start": 126, "line_end": 130, "language": "python", "name": "visit_For"}, "ba125f115b98_func_visit_While": {"id": "ba125f115b98_func_visit_While", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\predict.py", "content": "    def visit_While(self, node):\n        self.complexity += 1\n        self._enter_nesting()\n        self.generic_visit(node)\n        self._exit_nesting()", "chunk_type": "function", "line_start": 132, "line_end": 136, "language": "python", "name": "visit_While"}, "ba125f115b98_func_visit_ExceptHandler": {"id": "ba125f115b98_func_visit_ExceptHandler", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\predict.py", "content": "    def visit_ExceptHandler(self, node):\n        if node.type is None:\n            self.predictions.append(BugPrediction(\n                file=self.current_file,\n                line=node.lineno,\n                risk_level='high',\n                category='bare_except',\n                description=\"Bare except catches all exceptions\",\n                confidence=0.95,\n                suggestion=\"Specify exception type: except Exception:\"\n            ))\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 227, "line_end": 238, "language": "python", "name": "visit_ExceptHandler"}, "ba125f115b98_func_visit_BoolOp": {"id": "ba125f115b98_func_visit_BoolOp", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\predict.py", "content": "    def visit_BoolOp(self, node):\n        self.complexity += len(node.values) - 1\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 142, "line_end": 144, "language": "python", "name": "visit_BoolOp"}, "ba125f115b98_func__enter_nesting": {"id": "ba125f115b98_func__enter_nesting", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\predict.py", "content": "    def _enter_nesting(self):\n        self.current_nesting += 1\n        self.max_nesting = max(self.max_nesting, self.current_nesting)", "chunk_type": "function", "line_start": 146, "line_end": 148, "language": "python", "name": "_enter_nesting"}, "ba125f115b98_func__exit_nesting": {"id": "ba125f115b98_func__exit_nesting", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\predict.py", "content": "    def _exit_nesting(self):\n        self.current_nesting -= 1", "chunk_type": "function", "line_start": 150, "line_end": 151, "language": "python", "name": "_exit_nesting"}, "ba125f115b98_func_analyze_function": {"id": "ba125f115b98_func_analyze_function", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\predict.py", "content": "    def analyze_function(self, node: ast.FunctionDef):\n        \"\"\"Analyze a function for bug risks.\"\"\"\n        # Complexity analysis\n        analyzer = ComplexityAnalyzer()\n        analyzer.visit(node)\n\n        line_count = (node.end_lineno or node.lineno) - node.lineno\n        param_count = len(node.args.args)\n\n        # Check complexity\n        if analyzer.complexity > RISK_PATTERNS['complexity']['threshold']:\n            self.predictions.append(BugPrediction(\n                file=self.current_file,\n                line=node.lineno,\n                risk_level='high' if analyzer.complexity > 20 else 'medium',\n                category='complexity',\n                description=f\"Cyclomatic complexity {analyzer.complexity} in {node.name}()\",\n                confidence=0.8,\n                suggestion=\"Break into smaller functions\"\n            ))\n\n        # Check nesting\n        if analyzer.max_nesting > RISK_PATTERNS['nesting']['threshold']:\n            self.predictions.append(BugPredicti", "chunk_type": "function", "line_start": 162, "line_end": 217, "language": "python", "name": "analyze_function"}, "ba125f115b98_func_visit_FunctionDef": {"id": "ba125f115b98_func_visit_FunctionDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\predict.py", "content": "    def visit_FunctionDef(self, node):\n        self.analyze_function(node)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 219, "line_end": 221, "language": "python", "name": "visit_FunctionDef"}, "ba125f115b98_func_visit_AsyncFunctionDef": {"id": "ba125f115b98_func_visit_AsyncFunctionDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\predict.py", "content": "    def visit_AsyncFunctionDef(self, node):\n        self.analyze_function(node)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 223, "line_end": 225, "language": "python", "name": "visit_AsyncFunctionDef"}, "ba125f115b98_func_visit_Global": {"id": "ba125f115b98_func_visit_Global", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\predict.py", "content": "    def visit_Global(self, node):\n        self.predictions.append(BugPrediction(\n            file=self.current_file,\n            line=node.lineno,\n            risk_level='medium',\n            category='global_var',\n            description=f\"Global variable: {', '.join(node.names)}\",\n            confidence=0.6,\n            suggestion=\"Consider using a class or passing as parameter\"\n        ))\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 240, "line_end": 250, "language": "python", "name": "visit_Global"}, "ba125f115b98_class_BugPrediction": {"id": "ba125f115b98_class_BugPrediction", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\predict.py", "content": "class BugPrediction:\n    \"\"\"A predicted bug.\"\"\"\n    file: str\n    line: int\n    risk_level: str  # 'high', 'medium', 'low'\n    category: str\n    description: str\n    confidence: float\n    suggestion: str = \"\"", "chunk_type": "class", "line_start": 23, "line_end": 31, "language": "python", "name": "BugPrediction"}, "ba125f115b98_class_RiskReport": {"id": "ba125f115b98_class_RiskReport", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\predict.py", "content": "class RiskReport:\n    \"\"\"Risk assessment report.\"\"\"\n    total_risk_score: float\n    risk_level: str\n    predictions: List[BugPrediction] = field(default_factory=list)\n    hotspots: List[str] = field(default_factory=list)\n\n    def to_markdown(self) -> str:\n        level_label = {'high': '[HIGH]', 'medium': '[MEDIUM]', 'low': '[LOW]'}\n\n        lines = [\n            f\"# Risk Report\",\n            \"\",\n            f\"**Overall Risk:** {level_label.get(self.risk_level, '')} {self.risk_level.upper()} ({self.total_risk_score:.1f}/100)\",\n            \"\",\n        ]\n\n        if self.predictions:\n            lines.append(\"## Predictions\")\n            for pred in self.predictions[:10]:\n                lines.append(f\"- **{pred.category}** ({pred.risk_level}): {pred.description}\")\n                lines.append(f\"  - {pred.file}:{pred.line}\")\n                if pred.suggestion:\n                    lines.append(f\"  - Fix: {pred.suggestion}\")\n            lines.append(\"\")\n\n        if self.hotspots:\n         ", "chunk_type": "class", "line_start": 35, "line_end": 66, "language": "python", "name": "RiskReport"}, "ba125f115b98_class_ComplexityAnalyzer": {"id": "ba125f115b98_class_ComplexityAnalyzer", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\predict.py", "content": "class ComplexityAnalyzer(ast.NodeVisitor):\n    \"\"\"Analyze code complexity.\"\"\"\n\n    def __init__(self):\n        self.complexity = 1\n        self.max_nesting = 0\n        self.current_nesting = 0\n        self.function_lines = 0\n        self.param_count = 0\n\n    def visit_If(self, node):\n        self.complexity += 1\n        self._enter_nesting()\n        self.generic_visit(node)\n        self._exit_nesting()\n\n    def visit_For(self, node):\n        self.complexity += 1\n        self._enter_nesting()\n        self.generic_visit(node)\n        self._exit_nesting()\n\n    def visit_While(self, node):\n        self.complexity += 1\n        self._enter_nesting()\n        self.generic_visit(node)\n        self._exit_nesting()\n\n    def visit_ExceptHandler(self, node):\n        self.complexity += 1\n        self.generic_visit(node)\n\n    def visit_BoolOp(self, node):\n        self.complexity += len(node.values) - 1\n        self.generic_visit(node)\n\n    def _enter_nesting(self):\n        self.current_nesting += 1\n ", "chunk_type": "class", "line_start": 110, "line_end": 151, "language": "python", "name": "ComplexityAnalyzer"}, "ba125f115b98_class_BugPredictor": {"id": "ba125f115b98_class_BugPredictor", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\predict.py", "content": "class BugPredictor(ast.NodeVisitor):\n    \"\"\"Predict bugs in code.\"\"\"\n\n    def __init__(self, source_lines: List[str]):\n        self.predictions: List[BugPrediction] = []\n        self.source_lines = source_lines\n        self.current_file = \"\"\n\n    def analyze_function(self, node: ast.FunctionDef):\n        \"\"\"Analyze a function for bug risks.\"\"\"\n        # Complexity analysis\n        analyzer = ComplexityAnalyzer()\n        analyzer.visit(node)\n\n        line_count = (node.end_lineno or node.lineno) - node.lineno\n        param_count = len(node.args.args)\n\n        # Check complexity\n        if analyzer.complexity > RISK_PATTERNS['complexity']['threshold']:\n            self.predictions.append(BugPrediction(\n                file=self.current_file,\n                line=node.lineno,\n                risk_level='high' if analyzer.complexity > 20 else 'medium',\n                category='complexity',\n                description=f\"Cyclomatic complexity {analyzer.complexity} in {node.name}()\",\n       ", "chunk_type": "class", "line_start": 154, "line_end": 250, "language": "python", "name": "BugPredictor"}, "924cb2144676_file": {"id": "924cb2144676_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\profile.py", "content": "\"\"\"\nPerformance Profiler\n====================\nStatic analysis for performance bottlenecks and code complexity.\n\nUsage:\n    python profile.py [path]\n    python -m scripts.profile src/\n\"\"\"\n\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Set\nimport ast\nimport sys\n\nfrom .utils import (\n    find_python_files,\n    find_project_root,\n    parse_file,\n    Console,\n    format_as_markdown_table\n)\n\n\n@dataclass\nclass PerformanceIssue:\n    \"\"\"A performance finding.\"\"\"\n    path: Path\n    line: int\n    severity: str  # 'critical', 'high', 'medium', 'low'\n    category: str\n    title: str\n    description: str\n    complexity: Optional[str] = None  # Big-O notation\n    suggestion: Optional[str] = None\n\n\n@dataclass\nclass PerformanceReport:\n    \"\"\"Complete performance analysis report.\"\"\"\n    issues: List[PerformanceIssue] = field(default_factory=list)\n    complexity_scores: Dict[str, int] = field(default_factory=dict)\n\n    def to_markdown(self) -> str:\n        lines = [\n            \"# Performance Analysis Report\",\n            \"\",\n            \"## Summary\",\n            \"\",\n            f\"**Total Issues:** {len(self.issues)}\",\n            \"\",\n        ]\n\n        if self.complexity_scores:\n            lines.extend([\n                \"## Complexity Scores (Cyclomatic)\",\n                \"\",\n                \"| Function | Score |\",\n                \"|----------|-------|\",\n            ])\n            sorted_scores = sorted(\n                self.complexity_scores.items(),\n                key=lambda x: x[1],\n                reverse=True\n            )[:10]\n            for name, score in sorted_scores:\n                status = \"HIGH\" if score > 10 else \"OK\" if score <= 5 else \"MEDIUM\"\n                lines.append(f\"| `{name}` | {score} ({status}) |\")\n            lines.append(\"\")\n\n        if self.issues:\n            lines.extend([\"## Issues\", \"\"])\n\n            for issue in sorted(self.issues, key=lambda x: (\n                {'critical': 0, 'high':", "chunk_type": "file", "line_start": 1, "line_end": 441, "language": "python", "name": "profile.py"}, "924cb2144676_func_analyze_file": {"id": "924cb2144676_func_analyze_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\profile.py", "content": "def analyze_file(path: Path) -> Tuple[List[PerformanceIssue], Dict[str, int]]:\n    \"\"\"Analyze a single file for performance issues.\"\"\"\n    issues = []\n    complexity = {}\n\n    tree = parse_file(path)\n    if tree is None:\n        return issues, complexity\n\n    # Run analyzers\n    perf = PerformanceAnalyzer(path)\n    perf.visit(tree)\n    issues.extend(perf.issues)\n    complexity.update(perf.complexity_scores)\n\n    mem = MemoryAnalyzer(path)\n    mem.visit(tree)\n    issues.extend(mem.issues)\n\n    async_analyzer = AsyncAnalyzer(path)\n    async_analyzer.visit(tree)\n    issues.extend(async_analyzer.issues)\n\n    return issues, complexity", "chunk_type": "function", "line_start": 356, "line_end": 379, "language": "python", "name": "analyze_file"}, "924cb2144676_func_analyze_project": {"id": "924cb2144676_func_analyze_project", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\profile.py", "content": "def analyze_project(\n    root: Path,\n    exclude_patterns: List[str] = None\n) -> PerformanceReport:\n    \"\"\"Analyze project for performance issues.\"\"\"\n    report = PerformanceReport()\n\n    Console.info(f\"Analyzing {root}...\")\n\n    files = list(find_python_files(root, exclude_patterns))\n    Console.info(f\"Found {len(files)} Python files\")\n\n    for path in files:\n        issues, complexity = analyze_file(path)\n        report.issues.extend(issues)\n        report.complexity_scores.update(complexity)\n\n    return report", "chunk_type": "function", "line_start": 382, "line_end": 399, "language": "python", "name": "analyze_project"}, "924cb2144676_func_main": {"id": "924cb2144676_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\profile.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Performance Profiler\")\n\n    # Parse args\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n\n    if args:\n        path = Path(args[0])\n    else:\n        path = find_project_root() or Path.cwd()\n\n    if not path.exists():\n        Console.fail(f\"Path not found: {path}\")\n        return 1\n\n    Console.info(f\"Analyzing: {path}\")\n\n    report = analyze_project(path)\n\n    print(report.to_markdown())\n\n    # Summary\n    high_complexity = sum(1 for s in report.complexity_scores.values() if s > 10)\n\n    if high_complexity > 0:\n        Console.warn(f\"Found {high_complexity} functions with high complexity\")\n\n    Console.info(f\"Found {len(report.issues)} performance issues\")\n\n    return 0", "chunk_type": "function", "line_start": 406, "line_end": 436, "language": "python", "name": "main"}, "924cb2144676_func_to_markdown": {"id": "924cb2144676_func_to_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\profile.py", "content": "    def to_markdown(self) -> str:\n        lines = [\n            \"# Performance Analysis Report\",\n            \"\",\n            \"## Summary\",\n            \"\",\n            f\"**Total Issues:** {len(self.issues)}\",\n            \"\",\n        ]\n\n        if self.complexity_scores:\n            lines.extend([\n                \"## Complexity Scores (Cyclomatic)\",\n                \"\",\n                \"| Function | Score |\",\n                \"|----------|-------|\",\n            ])\n            sorted_scores = sorted(\n                self.complexity_scores.items(),\n                key=lambda x: x[1],\n                reverse=True\n            )[:10]\n            for name, score in sorted_scores:\n                status = \"HIGH\" if score > 10 else \"OK\" if score <= 5 else \"MEDIUM\"\n                lines.append(f\"| `{name}` | {score} ({status}) |\")\n            lines.append(\"\")\n\n        if self.issues:\n            lines.extend([\"## Issues\", \"\"])\n\n            for issue in sorted(self.issues, key=lambda x: (\n          ", "chunk_type": "function", "line_start": 45, "line_end": 90, "language": "python", "name": "to_markdown"}, "924cb2144676_func___init__": {"id": "924cb2144676_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\profile.py", "content": "    def __init__(self, path: Path):\n        self.path = path\n        self.issues: List[PerformanceIssue] = []\n        self._in_async = False", "chunk_type": "function", "line_start": 310, "line_end": 313, "language": "python", "name": "__init__"}, "924cb2144676_func_visit_If": {"id": "924cb2144676_func_visit_If", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\profile.py", "content": "    def visit_If(self, node: ast.If):\n        self.complexity += 1\n        # Count elif branches\n        for _ in node.orelse:\n            if isinstance(_, ast.If):\n                self.complexity += 1\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 99, "line_end": 105, "language": "python", "name": "visit_If"}, "924cb2144676_func_visit_While": {"id": "924cb2144676_func_visit_While", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\profile.py", "content": "    def visit_While(self, node: ast.While):\n        self.complexity += 1\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 107, "line_end": 109, "language": "python", "name": "visit_While"}, "924cb2144676_func_visit_For": {"id": "924cb2144676_func_visit_For", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\profile.py", "content": "    def visit_For(self, node: ast.For):\n        self.complexity += 1\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 111, "line_end": 113, "language": "python", "name": "visit_For"}, "924cb2144676_func_visit_ExceptHandler": {"id": "924cb2144676_func_visit_ExceptHandler", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\profile.py", "content": "    def visit_ExceptHandler(self, node: ast.ExceptHandler):\n        self.complexity += 1\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 115, "line_end": 117, "language": "python", "name": "visit_ExceptHandler"}, "924cb2144676_func_visit_BoolOp": {"id": "924cb2144676_func_visit_BoolOp", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\profile.py", "content": "    def visit_BoolOp(self, node: ast.BoolOp):\n        # Each and/or adds a decision point\n        self.complexity += len(node.values) - 1\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 119, "line_end": 122, "language": "python", "name": "visit_BoolOp"}, "924cb2144676_func_visit_comprehension": {"id": "924cb2144676_func_visit_comprehension", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\profile.py", "content": "    def visit_comprehension(self, node: ast.comprehension):\n        self.complexity += 1\n        self.complexity += len(node.ifs)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 124, "line_end": 127, "language": "python", "name": "visit_comprehension"}, "924cb2144676_func_visit_FunctionDef": {"id": "924cb2144676_func_visit_FunctionDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\profile.py", "content": "    def visit_FunctionDef(self, node: ast.FunctionDef):\n        self._analyze_function(node)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 140, "line_end": 142, "language": "python", "name": "visit_FunctionDef"}, "924cb2144676_func_visit_AsyncFunctionDef": {"id": "924cb2144676_func_visit_AsyncFunctionDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\profile.py", "content": "    def visit_AsyncFunctionDef(self, node: ast.AsyncFunctionDef):\n        old_in_async = self._in_async\n        self._in_async = True\n        self.generic_visit(node)\n        self._in_async = old_in_async", "chunk_type": "function", "line_start": 315, "line_end": 319, "language": "python", "name": "visit_AsyncFunctionDef"}, "924cb2144676_func__analyze_function": {"id": "924cb2144676_func__analyze_function", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\profile.py", "content": "    def _analyze_function(self, node):\n        # Calculate complexity\n        analyzer = ComplexityAnalyzer()\n        analyzer.visit(node)\n\n        func_name = f\"{self.path.stem}.{node.name}\"\n        self.complexity_scores[func_name] = analyzer.complexity\n\n        # Check for high complexity\n        if analyzer.complexity > 15:\n            self.issues.append(PerformanceIssue(\n                path=self.path,\n                line=node.lineno,\n                severity='high',\n                category='complexity',\n                title=f\"High cyclomatic complexity: {node.name}\",\n                description=f\"Function has complexity of {analyzer.complexity} (threshold: 15)\",\n                suggestion=\"Break down into smaller functions\"\n            ))\n        elif analyzer.complexity > 10:\n            self.issues.append(PerformanceIssue(\n                path=self.path,\n                line=node.lineno,\n                severity='medium',\n                category='complexity',\n              ", "chunk_type": "function", "line_start": 148, "line_end": 190, "language": "python", "name": "_analyze_function"}, "924cb2144676_func__check_nested_loops": {"id": "924cb2144676_func__check_nested_loops", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\profile.py", "content": "    def _check_nested_loops(self, node: ast.For, parent_func):\n        \"\"\"Detect nested loops (O(n^2) or worse).\"\"\"\n        nested = 0\n        for child in ast.walk(node):\n            if isinstance(child, ast.For) and child != node:\n                nested += 1\n\n        if nested >= 2:\n            self.issues.append(PerformanceIssue(\n                path=self.path,\n                line=node.lineno,\n                severity='high',\n                category='algorithm',\n                title=\"Deeply nested loops\",\n                description=f\"Found {nested + 1} levels of nested loops\",\n                complexity=f\"O(n^{nested + 1})\",\n                suggestion=\"Consider using sets, dicts, or algorithmic optimizations\"\n            ))\n        elif nested == 1:\n            self.issues.append(PerformanceIssue(\n                path=self.path,\n                line=node.lineno,\n                severity='medium',\n                category='algorithm',\n                title=\"Nested loop\",\n        ", "chunk_type": "function", "line_start": 192, "line_end": 220, "language": "python", "name": "_check_nested_loops"}, "924cb2144676_func__check_list_comprehension": {"id": "924cb2144676_func__check_list_comprehension", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\profile.py", "content": "    def _check_list_comprehension(self, node: ast.ListComp):\n        \"\"\"Check for expensive list comprehensions.\"\"\"\n        # Check for nested comprehensions\n        for gen in node.generators:\n            if isinstance(gen.iter, ast.ListComp):\n                self.issues.append(PerformanceIssue(\n                    path=self.path,\n                    line=node.lineno,\n                    severity='medium',\n                    category='memory',\n                    title=\"Nested list comprehension\",\n                    description=\"Nested comprehensions create intermediate lists\",\n                    suggestion=\"Consider using generator expressions\"\n                ))", "chunk_type": "function", "line_start": 222, "line_end": 235, "language": "python", "name": "_check_list_comprehension"}, "924cb2144676_func__check_expensive_calls": {"id": "924cb2144676_func__check_expensive_calls", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\profile.py", "content": "    def _check_expensive_calls(self, node: ast.Call):\n        \"\"\"Check for expensive function calls.\"\"\"\n        func_name = self._get_func_name(node.func)\n\n        # String concatenation in loop\n        if func_name == 'join':\n            pass  # join is good\n\n        # len() in loop condition\n        # (would need more context to detect)\n\n        # Regular expression compilation in loop\n        if func_name in ('re.match', 're.search', 're.findall'):\n            # Check if inside a loop\n            pass  # Would need parent context", "chunk_type": "function", "line_start": 237, "line_end": 251, "language": "python", "name": "_check_expensive_calls"}, "924cb2144676_func__get_func_name": {"id": "924cb2144676_func__get_func_name", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\profile.py", "content": "    def _get_func_name(self, node) -> str:\n        if isinstance(node, ast.Name):\n            return node.id\n        elif isinstance(node, ast.Attribute):\n            if isinstance(node.value, ast.Name):\n                return f\"{node.value.id}.{node.attr}\"\n            return node.attr\n        return \"\"", "chunk_type": "function", "line_start": 346, "line_end": 353, "language": "python", "name": "_get_func_name"}, "924cb2144676_func_visit_Call": {"id": "924cb2144676_func_visit_Call", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\profile.py", "content": "    def visit_Call(self, node: ast.Call):\n        if self._in_async:\n            func_name = self._get_func_name(node.func)\n\n            # Blocking calls in async code\n            blocking = {\n                'time.sleep': 'asyncio.sleep',\n                'requests.get': 'aiohttp.get',\n                'requests.post': 'aiohttp.post',\n                'open': 'aiofiles.open',\n            }\n\n            if func_name in blocking:\n                self.issues.append(PerformanceIssue(\n                    path=self.path,\n                    line=node.lineno,\n                    severity='high',\n                    category='async',\n                    title=f\"Blocking call in async: {func_name}\",\n                    description=f\"{func_name}() blocks the event loop\",\n                    suggestion=f\"Use {blocking[func_name]}() instead\"\n                ))\n\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 321, "line_end": 344, "language": "python", "name": "visit_Call"}, "924cb2144676_class_PerformanceIssue": {"id": "924cb2144676_class_PerformanceIssue", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\profile.py", "content": "class PerformanceIssue:\n    \"\"\"A performance finding.\"\"\"\n    path: Path\n    line: int\n    severity: str  # 'critical', 'high', 'medium', 'low'\n    category: str\n    title: str\n    description: str\n    complexity: Optional[str] = None  # Big-O notation\n    suggestion: Optional[str] = None", "chunk_type": "class", "line_start": 27, "line_end": 36, "language": "python", "name": "PerformanceIssue"}, "924cb2144676_class_PerformanceReport": {"id": "924cb2144676_class_PerformanceReport", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\profile.py", "content": "class PerformanceReport:\n    \"\"\"Complete performance analysis report.\"\"\"\n    issues: List[PerformanceIssue] = field(default_factory=list)\n    complexity_scores: Dict[str, int] = field(default_factory=dict)\n\n    def to_markdown(self) -> str:\n        lines = [\n            \"# Performance Analysis Report\",\n            \"\",\n            \"## Summary\",\n            \"\",\n            f\"**Total Issues:** {len(self.issues)}\",\n            \"\",\n        ]\n\n        if self.complexity_scores:\n            lines.extend([\n                \"## Complexity Scores (Cyclomatic)\",\n                \"\",\n                \"| Function | Score |\",\n                \"|----------|-------|\",\n            ])\n            sorted_scores = sorted(\n                self.complexity_scores.items(),\n                key=lambda x: x[1],\n                reverse=True\n            )[:10]\n            for name, score in sorted_scores:\n                status = \"HIGH\" if score > 10 else \"OK\" if score <= 5 else \"MEDIUM\"\n                lines.append(f", "chunk_type": "class", "line_start": 40, "line_end": 90, "language": "python", "name": "PerformanceReport"}, "924cb2144676_class_ComplexityAnalyzer": {"id": "924cb2144676_class_ComplexityAnalyzer", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\profile.py", "content": "class ComplexityAnalyzer(ast.NodeVisitor):\n    \"\"\"Calculate cyclomatic complexity.\"\"\"\n\n    def __init__(self):\n        self.complexity = 1  # Base complexity\n\n    def visit_If(self, node: ast.If):\n        self.complexity += 1\n        # Count elif branches\n        for _ in node.orelse:\n            if isinstance(_, ast.If):\n                self.complexity += 1\n        self.generic_visit(node)\n\n    def visit_While(self, node: ast.While):\n        self.complexity += 1\n        self.generic_visit(node)\n\n    def visit_For(self, node: ast.For):\n        self.complexity += 1\n        self.generic_visit(node)\n\n    def visit_ExceptHandler(self, node: ast.ExceptHandler):\n        self.complexity += 1\n        self.generic_visit(node)\n\n    def visit_BoolOp(self, node: ast.BoolOp):\n        # Each and/or adds a decision point\n        self.complexity += len(node.values) - 1\n        self.generic_visit(node)\n\n    def visit_comprehension(self, node: ast.comprehension):\n        self.complexity += 1\n        sel", "chunk_type": "class", "line_start": 93, "line_end": 127, "language": "python", "name": "ComplexityAnalyzer"}, "924cb2144676_class_PerformanceAnalyzer": {"id": "924cb2144676_class_PerformanceAnalyzer", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\profile.py", "content": "class PerformanceAnalyzer(ast.NodeVisitor):\n    \"\"\"Analyze code for performance issues.\"\"\"\n\n    def __init__(self, path: Path):\n        self.path = path\n        self.issues: List[PerformanceIssue] = []\n        self.complexity_scores: Dict[str, int] = {}\n        self._current_function: Optional[str] = None\n        self._loop_depth = 0\n\n    def visit_FunctionDef(self, node: ast.FunctionDef):\n        self._analyze_function(node)\n        self.generic_visit(node)\n\n    def visit_AsyncFunctionDef(self, node: ast.AsyncFunctionDef):\n        self._analyze_function(node)\n        self.generic_visit(node)\n\n    def _analyze_function(self, node):\n        # Calculate complexity\n        analyzer = ComplexityAnalyzer()\n        analyzer.visit(node)\n\n        func_name = f\"{self.path.stem}.{node.name}\"\n        self.complexity_scores[func_name] = analyzer.complexity\n\n        # Check for high complexity\n        if analyzer.complexity > 15:\n            self.issues.append(PerformanceIssue(\n                path", "chunk_type": "class", "line_start": 130, "line_end": 260, "language": "python", "name": "PerformanceAnalyzer"}, "924cb2144676_class_MemoryAnalyzer": {"id": "924cb2144676_class_MemoryAnalyzer", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\profile.py", "content": "class MemoryAnalyzer(ast.NodeVisitor):\n    \"\"\"Analyze code for memory issues.\"\"\"\n\n    def __init__(self, path: Path):\n        self.path = path\n        self.issues: List[PerformanceIssue] = []\n\n    def visit_Call(self, node: ast.Call):\n        func_name = self._get_func_name(node.func)\n\n        # Check for reading entire files\n        if func_name in ('read', 'readlines'):\n            self.issues.append(PerformanceIssue(\n                path=self.path,\n                line=node.lineno,\n                severity='low',\n                category='memory',\n                title=\"Reading entire file into memory\",\n                description=\"Using read()/readlines() loads entire file\",\n                suggestion=\"Consider iterating line by line for large files\"\n            ))\n\n        # Large list operations\n        if func_name == 'sorted' or func_name == 'list':\n            self.issues.append(PerformanceIssue(\n                path=self.path,\n                line=node.lineno,\n               ", "chunk_type": "class", "line_start": 263, "line_end": 304, "language": "python", "name": "MemoryAnalyzer"}, "924cb2144676_class_AsyncAnalyzer": {"id": "924cb2144676_class_AsyncAnalyzer", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\profile.py", "content": "class AsyncAnalyzer(ast.NodeVisitor):\n    \"\"\"Analyze async code for issues.\"\"\"\n\n    def __init__(self, path: Path):\n        self.path = path\n        self.issues: List[PerformanceIssue] = []\n        self._in_async = False\n\n    def visit_AsyncFunctionDef(self, node: ast.AsyncFunctionDef):\n        old_in_async = self._in_async\n        self._in_async = True\n        self.generic_visit(node)\n        self._in_async = old_in_async\n\n    def visit_Call(self, node: ast.Call):\n        if self._in_async:\n            func_name = self._get_func_name(node.func)\n\n            # Blocking calls in async code\n            blocking = {\n                'time.sleep': 'asyncio.sleep',\n                'requests.get': 'aiohttp.get',\n                'requests.post': 'aiohttp.post',\n                'open': 'aiofiles.open',\n            }\n\n            if func_name in blocking:\n                self.issues.append(PerformanceIssue(\n                    path=self.path,\n                    line=node.lineno,\n               ", "chunk_type": "class", "line_start": 307, "line_end": 353, "language": "python", "name": "AsyncAnalyzer"}, "f22796ef6e01_file": {"id": "f22796ef6e01_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\record.py", "content": "\"\"\"\nContext Recorder\n================\nRecord development actions and context snapshots to memory.\n\nUsage:\n    python mcp.py record \"Action description\"\n    python mcp.py record --snapshot\n\"\"\"\n\nfrom datetime import datetime\nfrom pathlib import Path\nfrom typing import List, Optional\nimport subprocess\nimport sys\n\nfrom .memory import get_store\nfrom .utils import Console, find_project_root, run_git_command\n\ndef get_git_status(root: Path) -> str:\n    \"\"\"Get concise git status.\"\"\"\n    status = run_git_command(['status', '--short'], cwd=root)\n    if not status:\n        return \"No changes\"\n    return status\n\ndef get_git_diff_stat(root: Path) -> str:\n    \"\"\"Get git diff stats.\"\"\"\n    # Staged changes\n    staged = run_git_command(['diff', '--cached', '--stat'], cwd=root)\n    return staged or \"No staged changes\"\n\ndef analyze_diff(root: Path) -> str:\n    \"\"\"Analyze the staged diff for semantic meaning.\"\"\"\n    diff = run_git_command(['diff', '--cached', '-U0'], cwd=root)\n    if not diff:\n        return \"No staged changes detected.\"\n\n    changes = []\n    current_file = \"\"\n\n    for line in diff.split('\\n'):\n        if line.startswith('diff --git'):\n            # diff --git a/file.py b/file.py\n            parts = line.split()\n            if len(parts) >= 4:\n                current_file = parts[-1].lstrip('b/')\n        elif line.startswith('@@'):\n            # @@ -10,0 +11,5 @@ def new_function():\n            # Try to extract context hint\n            context = line.split('@@')[-1].strip()\n            if context and current_file:\n                changes.append(f\"- {current_file}: {context}\")\n            elif current_file:\n                 changes.append(f\"- {current_file}: (modification)\")\n\n    # Deduplicate and summarize\n    unique_changes = sorted(list(set(changes)))\n    if len(unique_changes) > 10:\n        return \"\\n\".join(unique_changes[:10]) + f\"\\n... ({len(unique_changes) - 10} more changes)\"\n    return \"\\n\".join(unique_changes)\n\ndef record_snapshot(root: Path) -> bool:\n    \"\"\"R", "chunk_type": "file", "line_start": 1, "line_end": 109, "language": "python", "name": "record.py"}, "f22796ef6e01_func_get_git_status": {"id": "f22796ef6e01_func_get_git_status", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\record.py", "content": "def get_git_status(root: Path) -> str:\n    \"\"\"Get concise git status.\"\"\"\n    status = run_git_command(['status', '--short'], cwd=root)\n    if not status:\n        return \"No changes\"\n    return status", "chunk_type": "function", "line_start": 20, "line_end": 25, "language": "python", "name": "get_git_status"}, "f22796ef6e01_func_get_git_diff_stat": {"id": "f22796ef6e01_func_get_git_diff_stat", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\record.py", "content": "def get_git_diff_stat(root: Path) -> str:\n    \"\"\"Get git diff stats.\"\"\"\n    # Staged changes\n    staged = run_git_command(['diff', '--cached', '--stat'], cwd=root)\n    return staged or \"No staged changes\"", "chunk_type": "function", "line_start": 27, "line_end": 31, "language": "python", "name": "get_git_diff_stat"}, "f22796ef6e01_func_analyze_diff": {"id": "f22796ef6e01_func_analyze_diff", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\record.py", "content": "def analyze_diff(root: Path) -> str:\n    \"\"\"Analyze the staged diff for semantic meaning.\"\"\"\n    diff = run_git_command(['diff', '--cached', '-U0'], cwd=root)\n    if not diff:\n        return \"No staged changes detected.\"\n\n    changes = []\n    current_file = \"\"\n\n    for line in diff.split('\\n'):\n        if line.startswith('diff --git'):\n            # diff --git a/file.py b/file.py\n            parts = line.split()\n            if len(parts) >= 4:\n                current_file = parts[-1].lstrip('b/')\n        elif line.startswith('@@'):\n            # @@ -10,0 +11,5 @@ def new_function():\n            # Try to extract context hint\n            context = line.split('@@')[-1].strip()\n            if context and current_file:\n                changes.append(f\"- {current_file}: {context}\")\n            elif current_file:\n                 changes.append(f\"- {current_file}: (modification)\")\n\n    # Deduplicate and summarize\n    unique_changes = sorted(list(set(changes)))\n    if len(unique_changes) > 10:", "chunk_type": "function", "line_start": 33, "line_end": 61, "language": "python", "name": "analyze_diff"}, "f22796ef6e01_func_record_snapshot": {"id": "f22796ef6e01_func_record_snapshot", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\record.py", "content": "def record_snapshot(root: Path) -> bool:\n    \"\"\"Record a context snapshot of current state.\"\"\"\n    Console.info(\"Recording context snapshot...\")\n\n    status = get_git_status(root)\n    semantic_summary = analyze_diff(root)\n\n    content = f\"# Context Snapshot\\n\\n## Git Status\\n{status}\\n\\n## Semantic Changes\\n{semantic_summary}\"\n\n    store = get_store()\n    timestamp = datetime.now().isoformat()\n\n    store.remember(\n        key=f\"Snapshot {timestamp}\",\n        value=content,\n        tags=['snapshot', 'auto-context', 'pre-commit']\n    )\n\n    Console.ok(\"Context snapshot recorded\")\n    return True", "chunk_type": "function", "line_start": 63, "line_end": 82, "language": "python", "name": "record_snapshot"}, "f22796ef6e01_func_main": {"id": "f22796ef6e01_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\record.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n    root = find_project_root() or Path.cwd()\n\n    if '--snapshot' in sys.argv:\n        record_snapshot(root)\n        return 0\n\n    if not args:\n        Console.fail(\"Usage: mcp record 'message' OR mcp record --snapshot\")\n        return 1\n\n    message = \" \".join(args)\n    store = get_store()\n    store.remember(\n        key=f\"Action {datetime.now().isoformat()}\",\n        value=message,\n        tags=['user-action']\n    )\n    Console.ok(\"Action recorded\")\n    return 0", "chunk_type": "function", "line_start": 84, "line_end": 105, "language": "python", "name": "main"}, "be2178a1cbbc_file": {"id": "be2178a1cbbc_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\refactor.py", "content": "\"\"\"\nAuto-Refactorer\n===============\nDetect and suggest code refactorings for improved quality.\n\nUsage:\n    python refactor.py [path] [--apply]\n    python -m scripts.refactor src/\n\"\"\"\n\nfrom collections import defaultdict\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Tuple, Set\nimport ast\nimport hashlib\nimport sys\n\nfrom .utils import (\n    find_python_files,\n    find_project_root,\n    parse_file,\n    Console,\n    format_as_markdown_table\n)\n\n\n@dataclass\nclass RefactoringSuggestion:\n    \"\"\"A suggested refactoring.\"\"\"\n    path: Path\n    line_start: int\n    line_end: int\n    severity: str  # 'high', 'medium', 'low'\n    category: str  # 'long_function', 'duplicate', 'complex', 'naming'\n    message: str\n    suggestion: str\n\n\n@dataclass\nclass RefactoringReport:\n    \"\"\"Complete refactoring report.\"\"\"\n    suggestions: List[RefactoringSuggestion] = field(default_factory=list)\n\n    @property\n    def high_priority(self) -> List[RefactoringSuggestion]:\n        return [s for s in self.suggestions if s.severity == 'high']\n\n    def to_markdown(self) -> str:\n        lines = [\n            \"# Refactoring Suggestions\",\n            \"\",\n            f\"**Total suggestions:** {len(self.suggestions)}\",\n            f\"**High priority:** {len(self.high_priority)}\",\n            \"\",\n        ]\n\n        # Group by severity\n        for severity in ['high', 'medium', 'low']:\n            items = [s for s in self.suggestions if s.severity == severity]\n            if not items:\n                continue\n\n            lines.append(f\"## {severity.upper()} Priority\")\n            lines.append(\"\")\n\n            for s in items:\n                lines.append(f\"### {s.category}: {s.path}:{s.line_start}\")\n                lines.append(f\"**Issue:** {s.message}\")\n                lines.append(f\"**Suggestion:** {s.suggestion}\")\n                lines.append(\"\")\n\n        return \"\\n\".join(lines)\n\n\nclass LongFunctionDetector(ast.NodeVisitor):\n    \"\"\"Detect functions ", "chunk_type": "file", "line_start": 1, "line_end": 403, "language": "python", "name": "refactor.py"}, "be2178a1cbbc_func_analyze_file": {"id": "be2178a1cbbc_func_analyze_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\refactor.py", "content": "    def analyze_file(self, path: Path, tree: ast.Module, source_lines: List[str]):\n        \"\"\"Analyze file for duplicate blocks.\"\"\"\n        for node in ast.walk(tree):\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n                if node.end_lineno:\n                    start = node.lineno - 1\n                    end = node.end_lineno\n                    if end - start >= self.MIN_LINES:\n                        content = '\\n'.join(source_lines[start:end])\n                        # Normalize whitespace\n                        normalized = ' '.join(content.split())\n                        code_hash = hashlib.md5(normalized.encode()).hexdigest()\n                        self.code_hashes[code_hash].append((path, start + 1, end))", "chunk_type": "function", "line_start": 173, "line_end": 185, "language": "python", "name": "analyze_file"}, "be2178a1cbbc_func_analyze_project": {"id": "be2178a1cbbc_func_analyze_project", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\refactor.py", "content": "def analyze_project(\n    root: Path,\n    exclude_patterns: List[str] = None\n) -> RefactoringReport:\n    \"\"\"Analyze project for refactoring opportunities.\"\"\"\n    report = RefactoringReport()\n    duplicate_detector = DuplicateCodeDetector()\n\n    Console.info(f\"Analyzing {root}...\")\n\n    files = list(find_python_files(root, exclude_patterns))\n    Console.info(f\"Found {len(files)} Python files\")\n\n    for path in files:\n        # Single file analysis\n        issues = analyze_file(path)\n        report.suggestions.extend(issues)\n\n        # Collect for duplicate detection\n        tree = parse_file(path)\n        if tree:\n            try:\n                with open(path, 'r', encoding='utf-8') as f:\n                    source_lines = f.readlines()\n                duplicate_detector.analyze_file(path, tree, source_lines)\n            except Exception:\n                pass\n\n    # Finalize duplicate detection\n    duplicate_detector.finalize()\n    report.suggestions.extend(duplicate_detector.issues)\n\n", "chunk_type": "function", "line_start": 338, "line_end": 370, "language": "python", "name": "analyze_project"}, "be2178a1cbbc_func_main": {"id": "be2178a1cbbc_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\refactor.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Auto-Refactorer\")\n\n    # Parse args\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n\n    if args:\n        path = Path(args[0])\n    else:\n        path = find_project_root() or Path.cwd()\n\n    if not path.exists():\n        Console.fail(f\"Path not found: {path}\")\n        return 1\n\n    Console.info(f\"Analyzing: {path}\")\n\n    report = analyze_project(path)\n\n    print(report.to_markdown())\n\n    Console.info(f\"Found {len(report.suggestions)} refactoring suggestions\")\n    Console.info(f\"High priority: {len(report.high_priority)}\")\n\n    return 0", "chunk_type": "function", "line_start": 373, "line_end": 398, "language": "python", "name": "main"}, "be2178a1cbbc_func_high_priority": {"id": "be2178a1cbbc_func_high_priority", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\refactor.py", "content": "    def high_priority(self) -> List[RefactoringSuggestion]:\n        return [s for s in self.suggestions if s.severity == 'high']", "chunk_type": "function", "line_start": 46, "line_end": 47, "language": "python", "name": "high_priority"}, "be2178a1cbbc_func_to_markdown": {"id": "be2178a1cbbc_func_to_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\refactor.py", "content": "    def to_markdown(self) -> str:\n        lines = [\n            \"# Refactoring Suggestions\",\n            \"\",\n            f\"**Total suggestions:** {len(self.suggestions)}\",\n            f\"**High priority:** {len(self.high_priority)}\",\n            \"\",\n        ]\n\n        # Group by severity\n        for severity in ['high', 'medium', 'low']:\n            items = [s for s in self.suggestions if s.severity == severity]\n            if not items:\n                continue\n\n            lines.append(f\"## {severity.upper()} Priority\")\n            lines.append(\"\")\n\n            for s in items:\n                lines.append(f\"### {s.category}: {s.path}:{s.line_start}\")\n                lines.append(f\"**Issue:** {s.message}\")\n                lines.append(f\"**Suggestion:** {s.suggestion}\")\n                lines.append(\"\")\n\n        return \"\\n\".join(lines)", "chunk_type": "function", "line_start": 49, "line_end": 73, "language": "python", "name": "to_markdown"}, "be2178a1cbbc_func___init__": {"id": "be2178a1cbbc_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\refactor.py", "content": "    def __init__(self, path: Path):\n        self.path = path\n        self.issues: List[RefactoringSuggestion] = []", "chunk_type": "function", "line_start": 282, "line_end": 284, "language": "python", "name": "__init__"}, "be2178a1cbbc_func_visit_FunctionDef": {"id": "be2178a1cbbc_func_visit_FunctionDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\refactor.py", "content": "    def visit_FunctionDef(self, node: ast.FunctionDef):\n        self._check_params(node)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 286, "line_end": 288, "language": "python", "name": "visit_FunctionDef"}, "be2178a1cbbc_func_visit_AsyncFunctionDef": {"id": "be2178a1cbbc_func_visit_AsyncFunctionDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\refactor.py", "content": "    def visit_AsyncFunctionDef(self, node: ast.AsyncFunctionDef):\n        self._check_params(node)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 290, "line_end": 292, "language": "python", "name": "visit_AsyncFunctionDef"}, "be2178a1cbbc_func__check_function": {"id": "be2178a1cbbc_func__check_function", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\refactor.py", "content": "    def _check_function(self, node):\n        if node.end_lineno:\n            length = node.end_lineno - node.lineno\n            if length > self.MAX_LINES:\n                self.issues.append(RefactoringSuggestion(\n                    path=self.path,\n                    line_start=node.lineno,\n                    line_end=node.end_lineno,\n                    severity='high' if length > 100 else 'medium',\n                    category='long_function',\n                    message=f\"Function '{node.name}' is {length} lines (max: {self.MAX_LINES})\",\n                    suggestion=f\"Extract helper functions from '{node.name}'\"\n                ))", "chunk_type": "function", "line_start": 93, "line_end": 105, "language": "python", "name": "_check_function"}, "be2178a1cbbc_func_visit_If": {"id": "be2178a1cbbc_func_visit_If", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\refactor.py", "content": "    def visit_If(self, node: ast.If):\n        self._check_nesting(node)\n        self._nesting_level += 1\n        self.generic_visit(node)\n        self._nesting_level -= 1", "chunk_type": "function", "line_start": 127, "line_end": 131, "language": "python", "name": "visit_If"}, "be2178a1cbbc_func_visit_For": {"id": "be2178a1cbbc_func_visit_For", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\refactor.py", "content": "    def visit_For(self, node: ast.For):\n        self._check_nesting(node)\n        self._nesting_level += 1\n        self.generic_visit(node)\n        self._nesting_level -= 1", "chunk_type": "function", "line_start": 133, "line_end": 137, "language": "python", "name": "visit_For"}, "be2178a1cbbc_func_visit_While": {"id": "be2178a1cbbc_func_visit_While", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\refactor.py", "content": "    def visit_While(self, node: ast.While):\n        self._check_nesting(node)\n        self._nesting_level += 1\n        self.generic_visit(node)\n        self._nesting_level -= 1", "chunk_type": "function", "line_start": 139, "line_end": 143, "language": "python", "name": "visit_While"}, "be2178a1cbbc_func_visit_Try": {"id": "be2178a1cbbc_func_visit_Try", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\refactor.py", "content": "    def visit_Try(self, node: ast.Try):\n        self._check_nesting(node)\n        self._nesting_level += 1\n        self.generic_visit(node)\n        self._nesting_level -= 1", "chunk_type": "function", "line_start": 145, "line_end": 149, "language": "python", "name": "visit_Try"}, "be2178a1cbbc_func__check_nesting": {"id": "be2178a1cbbc_func__check_nesting", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\refactor.py", "content": "    def _check_nesting(self, node):\n        if self._nesting_level >= self.MAX_NESTED:\n            self.issues.append(RefactoringSuggestion(\n                path=self.path,\n                line_start=node.lineno,\n                line_end=node.end_lineno or node.lineno,\n                severity='high',\n                category='deep_nesting',\n                message=f\"Deeply nested code ({self._nesting_level + 1} levels)\",\n                suggestion=\"Extract nested logic into helper functions\"\n            ))", "chunk_type": "function", "line_start": 151, "line_end": 161, "language": "python", "name": "_check_nesting"}, "be2178a1cbbc_func_finalize": {"id": "be2178a1cbbc_func_finalize", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\refactor.py", "content": "    def finalize(self):\n        \"\"\"Generate issues for duplicates.\"\"\"\n        for code_hash, locations in self.code_hashes.items():\n            if len(locations) > 1:\n                files = list(set(str(loc[0]) for loc in locations))\n                for path, start, end in locations:\n                    self.issues.append(RefactoringSuggestion(\n                        path=path,\n                        line_start=start,\n                        line_end=end,\n                        severity='medium',\n                        category='duplicate_code',\n                        message=f\"Duplicate code found in {len(locations)} locations\",\n                        suggestion=f\"Extract common code into shared function\"\n                    ))", "chunk_type": "function", "line_start": 187, "line_end": 201, "language": "python", "name": "finalize"}, "be2178a1cbbc_func_visit_ClassDef": {"id": "be2178a1cbbc_func_visit_ClassDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\refactor.py", "content": "    def visit_ClassDef(self, node: ast.ClassDef):\n        self._check_class_name(node)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 215, "line_end": 217, "language": "python", "name": "visit_ClassDef"}, "be2178a1cbbc_func__check_function_name": {"id": "be2178a1cbbc_func__check_function_name", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\refactor.py", "content": "    def _check_function_name(self, node):\n        name = node.name\n        if name.startswith('_'):\n            return\n\n        # Check for camelCase\n        if any(c.isupper() for c in name[1:]) and '_' not in name:\n            self.issues.append(RefactoringSuggestion(\n                path=self.path,\n                line_start=node.lineno,\n                line_end=node.lineno,\n                severity='low',\n                category='naming',\n                message=f\"Function '{name}' uses camelCase\",\n                suggestion=f\"Rename to snake_case: '{self._to_snake_case(name)}'\"\n            ))\n\n        # Check single letter names (except i, j, k, x, y, z)\n        if len(name) == 1 and name not in 'ijkxyz':\n            self.issues.append(RefactoringSuggestion(\n                path=self.path,\n                line_start=node.lineno,\n                line_end=node.lineno,\n                severity='low',\n                category='naming',\n                message=f\"Function '{name}' has ", "chunk_type": "function", "line_start": 219, "line_end": 246, "language": "python", "name": "_check_function_name"}, "be2178a1cbbc_func__check_class_name": {"id": "be2178a1cbbc_func__check_class_name", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\refactor.py", "content": "    def _check_class_name(self, node):\n        name = node.name\n        if name.startswith('_'):\n            return\n\n        # Check for snake_case in class names\n        if '_' in name:\n            self.issues.append(RefactoringSuggestion(\n                path=self.path,\n                line_start=node.lineno,\n                line_end=node.lineno,\n                severity='low',\n                category='naming',\n                message=f\"Class '{name}' uses snake_case\",\n                suggestion=f\"Rename to CamelCase: '{self._to_camel_case(name)}'\"\n            ))", "chunk_type": "function", "line_start": 248, "line_end": 263, "language": "python", "name": "_check_class_name"}, "be2178a1cbbc_func__to_snake_case": {"id": "be2178a1cbbc_func__to_snake_case", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\refactor.py", "content": "    def _to_snake_case(self, name: str) -> str:\n        result = []\n        for i, c in enumerate(name):\n            if c.isupper() and i > 0:\n                result.append('_')\n            result.append(c.lower())\n        return ''.join(result)", "chunk_type": "function", "line_start": 265, "line_end": 271, "language": "python", "name": "_to_snake_case"}, "be2178a1cbbc_func__to_camel_case": {"id": "be2178a1cbbc_func__to_camel_case", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\refactor.py", "content": "    def _to_camel_case(self, name: str) -> str:\n        return ''.join(word.capitalize() for word in name.split('_'))", "chunk_type": "function", "line_start": 273, "line_end": 274, "language": "python", "name": "_to_camel_case"}, "be2178a1cbbc_func__check_params": {"id": "be2178a1cbbc_func__check_params", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\refactor.py", "content": "    def _check_params(self, node):\n        # Count params excluding self/cls\n        params = [a for a in node.args.args if a.arg not in ('self', 'cls')]\n        if len(params) > self.MAX_PARAMS:\n            self.issues.append(RefactoringSuggestion(\n                path=self.path,\n                line_start=node.lineno,\n                line_end=node.lineno,\n                severity='medium',\n                category='too_many_params',\n                message=f\"Function '{node.name}' has {len(params)} parameters (max: {self.MAX_PARAMS})\",\n                suggestion=\"Consider using a configuration object or dataclass\"\n            ))", "chunk_type": "function", "line_start": 294, "line_end": 306, "language": "python", "name": "_check_params"}, "be2178a1cbbc_class_RefactoringSuggestion": {"id": "be2178a1cbbc_class_RefactoringSuggestion", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\refactor.py", "content": "class RefactoringSuggestion:\n    \"\"\"A suggested refactoring.\"\"\"\n    path: Path\n    line_start: int\n    line_end: int\n    severity: str  # 'high', 'medium', 'low'\n    category: str  # 'long_function', 'duplicate', 'complex', 'naming'\n    message: str\n    suggestion: str", "chunk_type": "class", "line_start": 29, "line_end": 37, "language": "python", "name": "RefactoringSuggestion"}, "be2178a1cbbc_class_RefactoringReport": {"id": "be2178a1cbbc_class_RefactoringReport", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\refactor.py", "content": "class RefactoringReport:\n    \"\"\"Complete refactoring report.\"\"\"\n    suggestions: List[RefactoringSuggestion] = field(default_factory=list)\n\n    @property\n    def high_priority(self) -> List[RefactoringSuggestion]:\n        return [s for s in self.suggestions if s.severity == 'high']\n\n    def to_markdown(self) -> str:\n        lines = [\n            \"# Refactoring Suggestions\",\n            \"\",\n            f\"**Total suggestions:** {len(self.suggestions)}\",\n            f\"**High priority:** {len(self.high_priority)}\",\n            \"\",\n        ]\n\n        # Group by severity\n        for severity in ['high', 'medium', 'low']:\n            items = [s for s in self.suggestions if s.severity == severity]\n            if not items:\n                continue\n\n            lines.append(f\"## {severity.upper()} Priority\")\n            lines.append(\"\")\n\n            for s in items:\n                lines.append(f\"### {s.category}: {s.path}:{s.line_start}\")\n                lines.append(f\"**Issue:** {s.message}\")\n", "chunk_type": "class", "line_start": 41, "line_end": 73, "language": "python", "name": "RefactoringReport"}, "be2178a1cbbc_class_LongFunctionDetector": {"id": "be2178a1cbbc_class_LongFunctionDetector", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\refactor.py", "content": "class LongFunctionDetector(ast.NodeVisitor):\n    \"\"\"Detect functions that are too long.\"\"\"\n\n    MAX_LINES = 50\n\n    def __init__(self, path: Path):\n        self.path = path\n        self.issues: List[RefactoringSuggestion] = []\n\n    def visit_FunctionDef(self, node: ast.FunctionDef):\n        self._check_function(node)\n        self.generic_visit(node)\n\n    def visit_AsyncFunctionDef(self, node: ast.AsyncFunctionDef):\n        self._check_function(node)\n        self.generic_visit(node)\n\n    def _check_function(self, node):\n        if node.end_lineno:\n            length = node.end_lineno - node.lineno\n            if length > self.MAX_LINES:\n                self.issues.append(RefactoringSuggestion(\n                    path=self.path,\n                    line_start=node.lineno,\n                    line_end=node.end_lineno,\n                    severity='high' if length > 100 else 'medium',\n                    category='long_function',\n                    message=f\"Function '{node.name}' is {le", "chunk_type": "class", "line_start": 76, "line_end": 105, "language": "python", "name": "LongFunctionDetector"}, "be2178a1cbbc_class_ComplexityDetector": {"id": "be2178a1cbbc_class_ComplexityDetector", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\refactor.py", "content": "class ComplexityDetector(ast.NodeVisitor):\n    \"\"\"Detect overly complex code.\"\"\"\n\n    MAX_NESTED = 4\n    MAX_CONDITIONS = 5\n\n    def __init__(self, path: Path):\n        self.path = path\n        self.issues: List[RefactoringSuggestion] = []\n        self._nesting_level = 0\n        self._current_function = None\n\n    def visit_FunctionDef(self, node: ast.FunctionDef):\n        old_func = self._current_function\n        self._current_function = node.name\n        self._nesting_level = 0\n        self.generic_visit(node)\n        self._current_function = old_func\n\n    def visit_If(self, node: ast.If):\n        self._check_nesting(node)\n        self._nesting_level += 1\n        self.generic_visit(node)\n        self._nesting_level -= 1\n\n    def visit_For(self, node: ast.For):\n        self._check_nesting(node)\n        self._nesting_level += 1\n        self.generic_visit(node)\n        self._nesting_level -= 1\n\n    def visit_While(self, node: ast.While):\n        self._check_nesting(node)\n        self._ne", "chunk_type": "class", "line_start": 108, "line_end": 161, "language": "python", "name": "ComplexityDetector"}, "be2178a1cbbc_class_DuplicateCodeDetector": {"id": "be2178a1cbbc_class_DuplicateCodeDetector", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\refactor.py", "content": "class DuplicateCodeDetector:\n    \"\"\"Detect duplicate code blocks.\"\"\"\n\n    MIN_LINES = 5\n\n    def __init__(self):\n        self.code_hashes: Dict[str, List[Tuple[Path, int, int]]] = defaultdict(list)\n        self.issues: List[RefactoringSuggestion] = []\n\n    def analyze_file(self, path: Path, tree: ast.Module, source_lines: List[str]):\n        \"\"\"Analyze file for duplicate blocks.\"\"\"\n        for node in ast.walk(tree):\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n                if node.end_lineno:\n                    start = node.lineno - 1\n                    end = node.end_lineno\n                    if end - start >= self.MIN_LINES:\n                        content = '\\n'.join(source_lines[start:end])\n                        # Normalize whitespace\n                        normalized = ' '.join(content.split())\n                        code_hash = hashlib.md5(normalized.encode()).hexdigest()\n                        self.code_hashes[code_hash].append((path, sta", "chunk_type": "class", "line_start": 164, "line_end": 201, "language": "python", "name": "DuplicateCodeDetector"}, "be2178a1cbbc_class_NamingConventionChecker": {"id": "be2178a1cbbc_class_NamingConventionChecker", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\refactor.py", "content": "class NamingConventionChecker(ast.NodeVisitor):\n    \"\"\"Check naming conventions.\"\"\"\n\n    def __init__(self, path: Path):\n        self.path = path\n        self.issues: List[RefactoringSuggestion] = []\n\n    def visit_FunctionDef(self, node: ast.FunctionDef):\n        self._check_function_name(node)\n        self.generic_visit(node)\n\n    def visit_ClassDef(self, node: ast.ClassDef):\n        self._check_class_name(node)\n        self.generic_visit(node)\n\n    def _check_function_name(self, node):\n        name = node.name\n        if name.startswith('_'):\n            return\n\n        # Check for camelCase\n        if any(c.isupper() for c in name[1:]) and '_' not in name:\n            self.issues.append(RefactoringSuggestion(\n                path=self.path,\n                line_start=node.lineno,\n                line_end=node.lineno,\n                severity='low',\n                category='naming',\n                message=f\"Function '{name}' uses camelCase\",\n                suggestion=f\"Rename to ", "chunk_type": "class", "line_start": 204, "line_end": 274, "language": "python", "name": "NamingConventionChecker"}, "be2178a1cbbc_class_ParameterCountChecker": {"id": "be2178a1cbbc_class_ParameterCountChecker", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\refactor.py", "content": "class ParameterCountChecker(ast.NodeVisitor):\n    \"\"\"Check for functions with too many parameters.\"\"\"\n\n    MAX_PARAMS = 5\n\n    def __init__(self, path: Path):\n        self.path = path\n        self.issues: List[RefactoringSuggestion] = []\n\n    def visit_FunctionDef(self, node: ast.FunctionDef):\n        self._check_params(node)\n        self.generic_visit(node)\n\n    def visit_AsyncFunctionDef(self, node: ast.AsyncFunctionDef):\n        self._check_params(node)\n        self.generic_visit(node)\n\n    def _check_params(self, node):\n        # Count params excluding self/cls\n        params = [a for a in node.args.args if a.arg not in ('self', 'cls')]\n        if len(params) > self.MAX_PARAMS:\n            self.issues.append(RefactoringSuggestion(\n                path=self.path,\n                line_start=node.lineno,\n                line_end=node.lineno,\n                severity='medium',\n                category='too_many_params',\n                message=f\"Function '{node.name}' has {len(params)}", "chunk_type": "class", "line_start": 277, "line_end": 306, "language": "python", "name": "ParameterCountChecker"}, "46a875c5bd6b_file": {"id": "46a875c5bd6b_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\review.py", "content": "\"\"\"\nCode Review Automation\n======================\nPre-commit code review checklist - validates code quality before commit.\n\nUsage:\n    python review.py [path] [--strict]\n    python -m scripts.review [path]\n\"\"\"\n\nfrom dataclasses import dataclass, field\nfrom enum import Enum\nfrom pathlib import Path\nfrom typing import List, Dict, Optional, Tuple\nimport ast\nimport sys\n\nfrom .utils import (\n    find_python_files,\n    find_project_root,\n    parse_file,\n    get_staged_files,\n    analyze_module,\n    Console,\n    format_as_markdown_table\n)\n\n\nclass Severity(Enum):\n    \"\"\"Severity level for review issues.\"\"\"\n    ERROR = \"ERROR\"\n    WARNING = \"WARNING\"\n    INFO = \"INFO\"\n\n\n@dataclass\nclass ReviewIssue:\n    \"\"\"A single code review issue.\"\"\"\n    file: Path\n    line: int\n    severity: Severity\n    category: str\n    message: str\n\n\n@dataclass\nclass ReviewReport:\n    \"\"\"Complete code review report.\"\"\"\n    issues: List[ReviewIssue] = field(default_factory=list)\n    files_reviewed: int = 0\n\n    @property\n    def errors(self) -> List[ReviewIssue]:\n        return [i for i in self.issues if i.severity == Severity.ERROR]\n\n    @property\n    def warnings(self) -> List[ReviewIssue]:\n        return [i for i in self.issues if i.severity == Severity.WARNING]\n\n    @property\n    def passed(self) -> bool:\n        return len(self.errors) == 0\n\n\n# Review checks\nclass ReviewChecks:\n    \"\"\"Collection of review check functions.\"\"\"\n\n    @staticmethod\n    def check_docstrings(path: Path, tree: ast.Module) -> List[ReviewIssue]:\n        \"\"\"Check for missing docstrings.\"\"\"\n        issues = []\n\n        for node in ast.walk(tree):\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n                # Skip private and dunder methods\n                if node.name.startswith('_'):\n                    continue\n\n                if not ast.get_docstring(node):\n                    issues.append(ReviewIssue(\n                        file=path,\n                        line=node.lineno,\n              ", "chunk_type": "file", "line_start": 1, "line_end": 509, "language": "python", "name": "review.py"}, "46a875c5bd6b_func_review_file": {"id": "46a875c5bd6b_func_review_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\review.py", "content": "def review_file(path: Path, strict: bool = False) -> List[ReviewIssue]:\n    \"\"\"\n    Review a single Python file.\n\n    Args:\n        path: Path to file\n        strict: Enable strict mode (more checks)\n\n    Returns:\n        List of review issues\n    \"\"\"\n    issues = []\n\n    tree = parse_file(path)\n    if tree is None:\n        return issues\n\n    # Run all checks\n    issues.extend(ReviewChecks.check_docstrings(path, tree))\n    issues.extend(ReviewChecks.check_todo_fixme(path))\n    issues.extend(ReviewChecks.check_naming_conventions(path, tree))\n    issues.extend(ReviewChecks.check_file_length(path))\n    issues.extend(ReviewChecks.check_function_length(path, tree))\n    issues.extend(ReviewChecks.check_unused_imports(path, tree))\n    issues.extend(ReviewChecks.check_security_issues(path, tree))\n\n    if strict:\n        issues.extend(ReviewChecks.check_type_hints(path, tree))\n\n    return issues", "chunk_type": "function", "line_start": 337, "line_end": 366, "language": "python", "name": "review_file"}, "46a875c5bd6b_func_review_project": {"id": "46a875c5bd6b_func_review_project", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\review.py", "content": "def review_project(\n    root: Path,\n    staged_only: bool = False,\n    strict: bool = False,\n    exclude_patterns: List[str] = None\n) -> ReviewReport:\n    \"\"\"\n    Review a Python project.\n\n    Args:\n        root: Root directory\n        staged_only: Only review staged files\n        strict: Enable strict mode\n        exclude_patterns: Patterns to exclude\n\n    Returns:\n        ReviewReport\n    \"\"\"\n    report = ReviewReport()\n\n    if staged_only:\n        Console.info(\"Reviewing staged files only...\")\n        staged = get_staged_files(cwd=root)\n        files = [root / f for f in staged if f.endswith('.py')]\n    else:\n        Console.info(f\"Reviewing all Python files in {root}...\")\n        files = list(find_python_files(root, exclude_patterns))\n\n    Console.info(f\"Found {len(files)} files to review\")\n    report.files_reviewed = len(files)\n\n    for path in files:\n        issues = review_file(path, strict=strict)\n        report.issues.extend(issues)\n\n    return report", "chunk_type": "function", "line_start": 369, "line_end": 404, "language": "python", "name": "review_project"}, "46a875c5bd6b_func_format_report_console": {"id": "46a875c5bd6b_func_format_report_console", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\review.py", "content": "def format_report_console(report: ReviewReport) -> None:\n    \"\"\"Print report to console.\"\"\"\n    if not report.issues:\n        Console.ok(\"No issues found\")\n        return\n\n    # Group by file\n    by_file: Dict[Path, List[ReviewIssue]] = {}\n    for issue in report.issues:\n        if issue.file not in by_file:\n            by_file[issue.file] = []\n        by_file[issue.file].append(issue)\n\n    for file, issues in sorted(by_file.items()):\n        print(f\"\\n{file}:\")\n        for issue in sorted(issues, key=lambda x: x.line):\n            severity_color = {\n                Severity.ERROR: Console.fail,\n                Severity.WARNING: Console.warn,\n                Severity.INFO: Console.info\n            }\n            severity_color[issue.severity](f\"  L{issue.line}: [{issue.category}] {issue.message}\")", "chunk_type": "function", "line_start": 407, "line_end": 428, "language": "python", "name": "format_report_console"}, "46a875c5bd6b_func_format_report_markdown": {"id": "46a875c5bd6b_func_format_report_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\review.py", "content": "def format_report_markdown(report: ReviewReport) -> str:\n    \"\"\"Format report as Markdown.\"\"\"\n    lines = [\n        \"# Code Review Report\",\n        \"\",\n        \"## Summary\",\n        \"\",\n        f\"- **Files Reviewed:** {report.files_reviewed}\",\n        f\"- **Total Issues:** {len(report.issues)}\",\n        f\"- **Errors:** {len(report.errors)}\",\n        f\"- **Warnings:** {len(report.warnings)}\",\n        f\"- **Status:** {'PASSED' if report.passed else 'FAILED'}\",\n        \"\",\n    ]\n\n    if report.errors:\n        lines.extend([\n            \"## Errors (Must Fix)\",\n            \"\",\n        ])\n        rows = [[str(i.file), str(i.line), i.category, i.message] for i in report.errors]\n        lines.append(format_as_markdown_table([\"File\", \"Line\", \"Category\", \"Message\"], rows))\n        lines.append(\"\")\n\n    if report.warnings:\n        lines.extend([\n            \"## Warnings\",\n            \"\",\n        ])\n        rows = [[str(i.file), str(i.line), i.category, i.message] for i in report.warnings]\n       ", "chunk_type": "function", "line_start": 431, "line_end": 464, "language": "python", "name": "format_report_markdown"}, "46a875c5bd6b_func_main": {"id": "46a875c5bd6b_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\review.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Code Review Automation\")\n\n    # Parse args\n    strict = '--strict' in sys.argv\n    staged_only = '--staged' in sys.argv\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n\n    # Get path\n    if args:\n        path = Path(args[0])\n    else:\n        path = find_project_root() or Path.cwd()\n\n    if not path.exists():\n        Console.fail(f\"Path not found: {path}\")\n        sys.exit(1)\n\n    Console.info(f\"Reviewing: {path}\")\n    Console.info(f\"Mode: {'strict' if strict else 'standard'}\")\n\n    report = review_project(path, staged_only=staged_only, strict=strict)\n\n    print()\n    format_report_console(report)\n    print()\n\n    # Summary\n    Console.info(f\"Reviewed {report.files_reviewed} files\")\n    Console.info(f\"Found {len(report.issues)} issues ({len(report.errors)} errors, {len(report.warnings)} warnings)\")\n\n    if report.passed:\n        Console.ok(\"Code review PASSED\")\n        return 0\n    else:\n        Console.fail(\"Cod", "chunk_type": "function", "line_start": 467, "line_end": 504, "language": "python", "name": "main"}, "46a875c5bd6b_func_errors": {"id": "46a875c5bd6b_func_errors", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\review.py", "content": "    def errors(self) -> List[ReviewIssue]:\n        return [i for i in self.issues if i.severity == Severity.ERROR]", "chunk_type": "function", "line_start": 53, "line_end": 54, "language": "python", "name": "errors"}, "46a875c5bd6b_func_warnings": {"id": "46a875c5bd6b_func_warnings", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\review.py", "content": "    def warnings(self) -> List[ReviewIssue]:\n        return [i for i in self.issues if i.severity == Severity.WARNING]", "chunk_type": "function", "line_start": 57, "line_end": 58, "language": "python", "name": "warnings"}, "46a875c5bd6b_func_passed": {"id": "46a875c5bd6b_func_passed", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\review.py", "content": "    def passed(self) -> bool:\n        return len(self.errors) == 0", "chunk_type": "function", "line_start": 61, "line_end": 62, "language": "python", "name": "passed"}, "46a875c5bd6b_func_check_docstrings": {"id": "46a875c5bd6b_func_check_docstrings", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\review.py", "content": "    def check_docstrings(path: Path, tree: ast.Module) -> List[ReviewIssue]:\n        \"\"\"Check for missing docstrings.\"\"\"\n        issues = []\n\n        for node in ast.walk(tree):\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n                # Skip private and dunder methods\n                if node.name.startswith('_'):\n                    continue\n\n                if not ast.get_docstring(node):\n                    issues.append(ReviewIssue(\n                        file=path,\n                        line=node.lineno,\n                        severity=Severity.WARNING,\n                        category=\"documentation\",\n                        message=f\"Function '{node.name}' is missing a docstring\"\n                    ))\n\n            elif isinstance(node, ast.ClassDef):\n                if node.name.startswith('_'):\n                    continue\n\n                if not ast.get_docstring(node):\n                    issues.append(ReviewIssue(\n                        ", "chunk_type": "function", "line_start": 70, "line_end": 102, "language": "python", "name": "check_docstrings"}, "46a875c5bd6b_func_check_type_hints": {"id": "46a875c5bd6b_func_check_type_hints", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\review.py", "content": "    def check_type_hints(path: Path, tree: ast.Module) -> List[ReviewIssue]:\n        \"\"\"Check for missing type hints.\"\"\"\n        issues = []\n\n        for node in ast.walk(tree):\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n                # Skip private and dunder methods\n                if node.name.startswith('_'):\n                    continue\n\n                # Check return type\n                if node.returns is None and node.name != '__init__':\n                    issues.append(ReviewIssue(\n                        file=path,\n                        line=node.lineno,\n                        severity=Severity.INFO,\n                        category=\"types\",\n                        message=f\"Function '{node.name}' is missing return type hint\"\n                    ))\n\n                # Check argument types\n                for arg in node.args.args:\n                    if arg.arg not in ('self', 'cls') and arg.annotation is None:\n                        issue", "chunk_type": "function", "line_start": 105, "line_end": 136, "language": "python", "name": "check_type_hints"}, "46a875c5bd6b_func_check_todo_fixme": {"id": "46a875c5bd6b_func_check_todo_fixme", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\review.py", "content": "    def check_todo_fixme(path: Path) -> List[ReviewIssue]:\n        \"\"\"Check for TODO/FIXME comments.\"\"\"\n        issues = []\n\n        try:\n            with open(path, 'r', encoding='utf-8') as f:\n                for i, line in enumerate(f, 1):\n                    line_upper = line.upper()\n                    if 'TODO' in line_upper:\n                        issues.append(ReviewIssue(\n                            file=path,\n                            line=i,\n                            severity=Severity.INFO,\n                            category=\"todo\",\n                            message=f\"TODO comment found: {line.strip()[:50]}...\"\n                        ))\n                    elif 'FIXME' in line_upper:\n                        issues.append(ReviewIssue(\n                            file=path,\n                            line=i,\n                            severity=Severity.WARNING,\n                            category=\"fixme\",\n                            message=f\"FIXME comment found: ", "chunk_type": "function", "line_start": 139, "line_end": 174, "language": "python", "name": "check_todo_fixme"}, "46a875c5bd6b_func_check_naming_conventions": {"id": "46a875c5bd6b_func_check_naming_conventions", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\review.py", "content": "    def check_naming_conventions(path: Path, tree: ast.Module) -> List[ReviewIssue]:\n        \"\"\"Check naming conventions.\"\"\"\n        issues = []\n\n        for node in ast.walk(tree):\n            # Classes should be CamelCase\n            if isinstance(node, ast.ClassDef):\n                if not node.name[0].isupper() or '_' in node.name:\n                    if not node.name.startswith('_'):\n                        issues.append(ReviewIssue(\n                            file=path,\n                            line=node.lineno,\n                            severity=Severity.WARNING,\n                            category=\"naming\",\n                            message=f\"Class '{node.name}' should use CamelCase\"\n                        ))\n\n            # Functions should be snake_case\n            elif isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n                if not node.name.startswith('_'):\n                    # Check for camelCase (has lowercase followed by uppercase)\n           ", "chunk_type": "function", "line_start": 177, "line_end": 208, "language": "python", "name": "check_naming_conventions"}, "46a875c5bd6b_func_check_file_length": {"id": "46a875c5bd6b_func_check_file_length", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\review.py", "content": "    def check_file_length(path: Path, max_lines: int = 500) -> List[ReviewIssue]:\n        \"\"\"Check file length.\"\"\"\n        issues = []\n\n        try:\n            with open(path, 'r', encoding='utf-8') as f:\n                line_count = sum(1 for _ in f)\n\n            if line_count > max_lines:\n                issues.append(ReviewIssue(\n                    file=path,\n                    line=1,\n                    severity=Severity.WARNING,\n                    category=\"complexity\",\n                    message=f\"File has {line_count} lines (max recommended: {max_lines})\"\n                ))\n        except Exception:\n            pass\n\n        return issues", "chunk_type": "function", "line_start": 211, "line_end": 230, "language": "python", "name": "check_file_length"}, "46a875c5bd6b_func_check_function_length": {"id": "46a875c5bd6b_func_check_function_length", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\review.py", "content": "    def check_function_length(path: Path, tree: ast.Module, max_lines: int = 50) -> List[ReviewIssue]:\n        \"\"\"Check function length.\"\"\"\n        issues = []\n\n        for node in ast.walk(tree):\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n                if node.end_lineno:\n                    length = node.end_lineno - node.lineno\n                    if length > max_lines:\n                        issues.append(ReviewIssue(\n                            file=path,\n                            line=node.lineno,\n                            severity=Severity.WARNING,\n                            category=\"complexity\",\n                            message=f\"Function '{node.name}' is {length} lines (max: {max_lines})\"\n                        ))\n\n        return issues", "chunk_type": "function", "line_start": 233, "line_end": 250, "language": "python", "name": "check_function_length"}, "46a875c5bd6b_func_check_unused_imports": {"id": "46a875c5bd6b_func_check_unused_imports", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\review.py", "content": "    def check_unused_imports(path: Path, tree: ast.Module) -> List[ReviewIssue]:\n        \"\"\"Check for potentially unused imports.\"\"\"\n        issues = []\n\n        # Collect imports\n        imports = {}\n        for node in ast.walk(tree):\n            if isinstance(node, ast.Import):\n                for alias in node.names:\n                    name = alias.asname or alias.name.split('.')[0]\n                    imports[name] = node.lineno\n            elif isinstance(node, ast.ImportFrom):\n                for alias in node.names:\n                    if alias.name != '*':\n                        name = alias.asname or alias.name\n                        imports[name] = node.lineno\n\n        # Collect all used names\n        used_names = set()\n        for node in ast.walk(tree):\n            if isinstance(node, ast.Name):\n                used_names.add(node.id)\n            elif isinstance(node, ast.Attribute):\n                if isinstance(node.value, ast.Name):\n                    used_names.add", "chunk_type": "function", "line_start": 253, "line_end": 290, "language": "python", "name": "check_unused_imports"}, "46a875c5bd6b_func_check_security_issues": {"id": "46a875c5bd6b_func_check_security_issues", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\review.py", "content": "    def check_security_issues(path: Path, tree: ast.Module) -> List[ReviewIssue]:\n        \"\"\"Check for common security issues.\"\"\"\n        issues = []\n\n        for node in ast.walk(tree):\n            # Check for eval/exec\n            if isinstance(node, ast.Call):\n                if isinstance(node.func, ast.Name):\n                    if node.func.id in ('eval', 'exec'):\n                        issues.append(ReviewIssue(\n                            file=path,\n                            line=node.lineno,\n                            severity=Severity.ERROR,\n                            category=\"security\",\n                            message=f\"Use of '{node.func.id}' is a security risk\"\n                        ))\n                    elif node.func.id == 'input':\n                        issues.append(ReviewIssue(\n                            file=path,\n                            line=node.lineno,\n                            severity=Severity.INFO,\n                            category=\"secu", "chunk_type": "function", "line_start": 293, "line_end": 334, "language": "python", "name": "check_security_issues"}, "46a875c5bd6b_class_Severity": {"id": "46a875c5bd6b_class_Severity", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\review.py", "content": "class Severity(Enum):\n    \"\"\"Severity level for review issues.\"\"\"\n    ERROR = \"ERROR\"\n    WARNING = \"WARNING\"\n    INFO = \"INFO\"", "chunk_type": "class", "line_start": 29, "line_end": 33, "language": "python", "name": "Severity"}, "46a875c5bd6b_class_ReviewIssue": {"id": "46a875c5bd6b_class_ReviewIssue", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\review.py", "content": "class ReviewIssue:\n    \"\"\"A single code review issue.\"\"\"\n    file: Path\n    line: int\n    severity: Severity\n    category: str\n    message: str", "chunk_type": "class", "line_start": 37, "line_end": 43, "language": "python", "name": "ReviewIssue"}, "46a875c5bd6b_class_ReviewReport": {"id": "46a875c5bd6b_class_ReviewReport", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\review.py", "content": "class ReviewReport:\n    \"\"\"Complete code review report.\"\"\"\n    issues: List[ReviewIssue] = field(default_factory=list)\n    files_reviewed: int = 0\n\n    @property\n    def errors(self) -> List[ReviewIssue]:\n        return [i for i in self.issues if i.severity == Severity.ERROR]\n\n    @property\n    def warnings(self) -> List[ReviewIssue]:\n        return [i for i in self.issues if i.severity == Severity.WARNING]\n\n    @property\n    def passed(self) -> bool:\n        return len(self.errors) == 0", "chunk_type": "class", "line_start": 47, "line_end": 62, "language": "python", "name": "ReviewReport"}, "46a875c5bd6b_class_ReviewChecks": {"id": "46a875c5bd6b_class_ReviewChecks", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\review.py", "content": "class ReviewChecks:\n    \"\"\"Collection of review check functions.\"\"\"\n\n    @staticmethod\n    def check_docstrings(path: Path, tree: ast.Module) -> List[ReviewIssue]:\n        \"\"\"Check for missing docstrings.\"\"\"\n        issues = []\n\n        for node in ast.walk(tree):\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n                # Skip private and dunder methods\n                if node.name.startswith('_'):\n                    continue\n\n                if not ast.get_docstring(node):\n                    issues.append(ReviewIssue(\n                        file=path,\n                        line=node.lineno,\n                        severity=Severity.WARNING,\n                        category=\"documentation\",\n                        message=f\"Function '{node.name}' is missing a docstring\"\n                    ))\n\n            elif isinstance(node, ast.ClassDef):\n                if node.name.startswith('_'):\n                    continue\n\n                if not ast.get_d", "chunk_type": "class", "line_start": 66, "line_end": 334, "language": "python", "name": "ReviewChecks"}, "42ff9965cb0c_file": {"id": "42ff9965cb0c_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\security.py", "content": "\"\"\"\nSecurity Auditor\n================\nDeep security analysis for Python code - OWASP, secrets, injection detection.\n\nUsage:\n    python security.py [path] [--strict]\n    python -m scripts.security src/\n\"\"\"\n\nfrom dataclasses import dataclass, field\nfrom enum import Enum\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Set\nimport ast\nimport re\nimport sys\n\nfrom .utils import (\n    find_python_files,\n    find_project_root,\n    parse_file,\n    Console,\n    format_as_markdown_table\n)\n\n\nclass Severity(Enum):\n    CRITICAL = \"CRITICAL\"\n    HIGH = \"HIGH\"\n    MEDIUM = \"MEDIUM\"\n    LOW = \"LOW\"\n    INFO = \"INFO\"\n\n\n@dataclass\nclass SecurityIssue:\n    \"\"\"A security finding.\"\"\"\n    path: Path\n    line: int\n    severity: Severity\n    category: str\n    title: str\n    description: str\n    cwe: Optional[str] = None  # CWE identifier\n    fix: Optional[str] = None\n\n\n@dataclass\nclass SecurityReport:\n    \"\"\"Complete security audit report.\"\"\"\n    issues: List[SecurityIssue] = field(default_factory=list)\n    files_scanned: int = 0\n\n    @property\n    def critical(self) -> List[SecurityIssue]:\n        return [i for i in self.issues if i.severity == Severity.CRITICAL]\n\n    @property\n    def high(self) -> List[SecurityIssue]:\n        return [i for i in self.issues if i.severity == Severity.HIGH]\n\n    def to_markdown(self) -> str:\n        lines = [\n            \"# Security Audit Report\",\n            \"\",\n            \"## Summary\",\n            \"\",\n            f\"| Severity | Count |\",\n            f\"|----------|-------|\",\n        ]\n\n        for sev in Severity:\n            count = len([i for i in self.issues if i.severity == sev])\n            if count > 0:\n                lines.append(f\"| {sev.value} | {count} |\")\n\n        lines.extend([\"\", f\"**Files Scanned:** {self.files_scanned}\", \"\"])\n\n        if not self.issues:\n            lines.append(\"No security issues found.\")\n            return \"\\n\".join(lines)\n\n        # Group by severity\n        for sev in Severity:\n            items = [i f", "chunk_type": "file", "line_start": 1, "line_end": 411, "language": "python", "name": "security.py"}, "42ff9965cb0c_func_check_secrets": {"id": "42ff9965cb0c_func_check_secrets", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\security.py", "content": "def check_secrets(path: Path, source: str) -> List[SecurityIssue]:\n    \"\"\"Check for hardcoded secrets.\"\"\"\n    issues = []\n    lines = source.split('\\n')\n\n    for i, line in enumerate(lines, 1):\n        # Skip comments\n        stripped = line.strip()\n        if stripped.startswith('#'):\n            continue\n\n        for pattern, title in SECRET_PATTERNS:\n            if re.search(pattern, line):\n                # Exclude obvious non-secrets\n                if 'example' in line.lower() or 'test' in line.lower():\n                    continue\n                if '\"\"' in line or \"''\" in line:  # Empty strings\n                    continue\n                if 'os.environ' in line or 'getenv' in line:\n                    continue\n\n                issues.append(SecurityIssue(\n                    path=path,\n                    line=i,\n                    severity=Severity.CRITICAL,\n                    category=\"Hardcoded Secret\",\n                    title=title,\n                    description=f\"Po", "chunk_type": "function", "line_start": 263, "line_end": 296, "language": "python", "name": "check_secrets"}, "42ff9965cb0c_func_check_sql_injection": {"id": "42ff9965cb0c_func_check_sql_injection", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\security.py", "content": "def check_sql_injection(path: Path, source: str) -> List[SecurityIssue]:\n    \"\"\"Check for SQL injection patterns.\"\"\"\n    issues = []\n    lines = source.split('\\n')\n\n    for i, line in enumerate(lines, 1):\n        for pattern in SQL_INJECTION_PATTERNS:\n            if re.search(pattern, line, re.IGNORECASE):\n                issues.append(SecurityIssue(\n                    path=path,\n                    line=i,\n                    severity=Severity.HIGH,\n                    category=\"SQL Injection\",\n                    title=\"Potential SQL injection\",\n                    description=\"SQL query appears to use string formatting instead of parameterization\",\n                    cwe=\"CWE-89\",\n                    fix=\"Use parameterized queries with placeholders\"\n                ))\n                break\n\n    return issues", "chunk_type": "function", "line_start": 299, "line_end": 319, "language": "python", "name": "check_sql_injection"}, "42ff9965cb0c_func_audit_file": {"id": "42ff9965cb0c_func_audit_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\security.py", "content": "def audit_file(path: Path) -> List[SecurityIssue]:\n    \"\"\"Audit a single file for security issues.\"\"\"\n    issues = []\n\n    try:\n        with open(path, 'r', encoding='utf-8', errors='ignore') as f:\n            source = f.read()\n    except Exception:\n        return issues\n\n    # AST-based analysis\n    tree = parse_file(path)\n    if tree:\n        analyzer = SecurityAnalyzer(path, source)\n        analyzer.visit(tree)\n        issues.extend(analyzer.issues)\n\n    # Pattern-based checks\n    issues.extend(check_secrets(path, source))\n    issues.extend(check_sql_injection(path, source))\n\n    return issues", "chunk_type": "function", "line_start": 322, "line_end": 343, "language": "python", "name": "audit_file"}, "42ff9965cb0c_func_security_audit": {"id": "42ff9965cb0c_func_security_audit", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\security.py", "content": "def security_audit(\n    root: Path,\n    strict: bool = False,\n    exclude_patterns: List[str] = None\n) -> SecurityReport:\n    \"\"\"Perform security audit on a project.\"\"\"\n    report = SecurityReport()\n\n    Console.info(f\"Security audit of {root}...\")\n\n    files = list(find_python_files(root, exclude_patterns))\n    report.files_scanned = len(files)\n    Console.info(f\"Scanning {len(files)} files...\")\n\n    for path in files:\n        issues = audit_file(path)\n\n        # In strict mode, include all issues; otherwise filter INFO\n        if strict:\n            report.issues.extend(issues)\n        else:\n            report.issues.extend([i for i in issues if i.severity != Severity.INFO])\n\n    return report", "chunk_type": "function", "line_start": 346, "line_end": 369, "language": "python", "name": "security_audit"}, "42ff9965cb0c_func_main": {"id": "42ff9965cb0c_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\security.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Security Auditor\")\n\n    # Parse args\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n    strict = '--strict' in sys.argv\n\n    if args:\n        path = Path(args[0])\n    else:\n        path = find_project_root() or Path.cwd()\n\n    if not path.exists():\n        Console.fail(f\"Path not found: {path}\")\n        return 1\n\n    Console.info(f\"Auditing: {path}\")\n    Console.info(f\"Mode: {'strict' if strict else 'standard'}\")\n\n    report = security_audit(path, strict=strict)\n\n    print(report.to_markdown())\n\n    # Summary\n    if report.critical:\n        Console.fail(f\"CRITICAL: {len(report.critical)} critical issues found!\")\n    elif report.high:\n        Console.warn(f\"HIGH: {len(report.high)} high severity issues found\")\n    elif report.issues:\n        Console.warn(f\"Found {len(report.issues)} security issues\")\n    else:\n        Console.ok(\"No security issues found\")\n\n    return 1 if report.critical or report.high else 0", "chunk_type": "function", "line_start": 372, "line_end": 406, "language": "python", "name": "main"}, "42ff9965cb0c_func_critical": {"id": "42ff9965cb0c_func_critical", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\security.py", "content": "    def critical(self) -> List[SecurityIssue]:\n        return [i for i in self.issues if i.severity == Severity.CRITICAL]", "chunk_type": "function", "line_start": 56, "line_end": 57, "language": "python", "name": "critical"}, "42ff9965cb0c_func_high": {"id": "42ff9965cb0c_func_high", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\security.py", "content": "    def high(self) -> List[SecurityIssue]:\n        return [i for i in self.issues if i.severity == Severity.HIGH]", "chunk_type": "function", "line_start": 60, "line_end": 61, "language": "python", "name": "high"}, "42ff9965cb0c_func_to_markdown": {"id": "42ff9965cb0c_func_to_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\security.py", "content": "    def to_markdown(self) -> str:\n        lines = [\n            \"# Security Audit Report\",\n            \"\",\n            \"## Summary\",\n            \"\",\n            f\"| Severity | Count |\",\n            f\"|----------|-------|\",\n        ]\n\n        for sev in Severity:\n            count = len([i for i in self.issues if i.severity == sev])\n            if count > 0:\n                lines.append(f\"| {sev.value} | {count} |\")\n\n        lines.extend([\"\", f\"**Files Scanned:** {self.files_scanned}\", \"\"])\n\n        if not self.issues:\n            lines.append(\"No security issues found.\")\n            return \"\\n\".join(lines)\n\n        # Group by severity\n        for sev in Severity:\n            items = [i for i in self.issues if i.severity == sev]\n            if not items:\n                continue\n\n            lines.extend([f\"## {sev.value}\", \"\"])\n\n            for issue in items:\n                lines.append(f\"### {issue.category}: {issue.title}\")\n                lines.append(f\"**File:** `{issue.path}:{is", "chunk_type": "function", "line_start": 63, "line_end": 104, "language": "python", "name": "to_markdown"}, "42ff9965cb0c_func___init__": {"id": "42ff9965cb0c_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\security.py", "content": "    def __init__(self, path: Path, source: str):\n        self.path = path\n        self.source = source\n        self.source_lines = source.split('\\n')\n        self.issues: List[SecurityIssue] = []\n        self._imports: Set[str] = set()", "chunk_type": "function", "line_start": 165, "line_end": 170, "language": "python", "name": "__init__"}, "42ff9965cb0c_func_visit_Import": {"id": "42ff9965cb0c_func_visit_Import", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\security.py", "content": "    def visit_Import(self, node: ast.Import):\n        for alias in node.names:\n            self._imports.add(alias.name)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 172, "line_end": 175, "language": "python", "name": "visit_Import"}, "42ff9965cb0c_func_visit_ImportFrom": {"id": "42ff9965cb0c_func_visit_ImportFrom", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\security.py", "content": "    def visit_ImportFrom(self, node: ast.ImportFrom):\n        if node.module:\n            self._imports.add(node.module)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 177, "line_end": 180, "language": "python", "name": "visit_ImportFrom"}, "42ff9965cb0c_func_visit_Call": {"id": "42ff9965cb0c_func_visit_Call", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\security.py", "content": "    def visit_Call(self, node: ast.Call):\n        # Check for dangerous function calls\n        func_name = self._get_func_name(node.func)\n\n        if func_name in DANGEROUS_FUNCTIONS:\n            # Special case: Allow subprocess.Popen/call/run if shell=False is explicit\n            if func_name in ('subprocess.Popen', 'subprocess.call', 'subprocess.run'):\n                is_safe = False\n                for keyword in node.keywords:\n                    if keyword.arg == 'shell':\n                         if isinstance(keyword.value, ast.Constant) and keyword.value.value is False:\n                             is_safe = True\n                if is_safe:\n                    self.generic_visit(node)\n                    return\n\n            title, severity, cwe, desc = DANGEROUS_FUNCTIONS[func_name]\n            self.issues.append(SecurityIssue(\n                path=self.path,\n                line=node.lineno,\n                severity=severity,\n                category=\"Dangerous Function\",\n    ", "chunk_type": "function", "line_start": 182, "line_end": 238, "language": "python", "name": "visit_Call"}, "42ff9965cb0c_func_visit_Assert": {"id": "42ff9965cb0c_func_visit_Assert", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\security.py", "content": "    def visit_Assert(self, node: ast.Assert):\n        # Asserts are removed in optimized bytecode\n        self.issues.append(SecurityIssue(\n            path=self.path,\n            line=node.lineno,\n            severity=Severity.LOW,\n            category=\"Security Control\",\n            title=\"Assert used for security check\",\n            description=\"Assert statements are removed when Python runs with -O flag\",\n            fix=\"Use proper if/raise for security checks\"\n        ))\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 240, "line_end": 251, "language": "python", "name": "visit_Assert"}, "42ff9965cb0c_func__get_func_name": {"id": "42ff9965cb0c_func__get_func_name", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\security.py", "content": "    def _get_func_name(self, node) -> str:\n        if isinstance(node, ast.Name):\n            return node.id\n        elif isinstance(node, ast.Attribute):\n            if isinstance(node.value, ast.Name):\n                return f\"{node.value.id}.{node.attr}\"\n            return node.attr\n        return \"\"", "chunk_type": "function", "line_start": 253, "line_end": 260, "language": "python", "name": "_get_func_name"}, "42ff9965cb0c_class_Severity": {"id": "42ff9965cb0c_class_Severity", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\security.py", "content": "class Severity(Enum):\n    CRITICAL = \"CRITICAL\"\n    HIGH = \"HIGH\"\n    MEDIUM = \"MEDIUM\"\n    LOW = \"LOW\"\n    INFO = \"INFO\"", "chunk_type": "class", "line_start": 28, "line_end": 33, "language": "python", "name": "Severity"}, "42ff9965cb0c_class_SecurityIssue": {"id": "42ff9965cb0c_class_SecurityIssue", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\security.py", "content": "class SecurityIssue:\n    \"\"\"A security finding.\"\"\"\n    path: Path\n    line: int\n    severity: Severity\n    category: str\n    title: str\n    description: str\n    cwe: Optional[str] = None  # CWE identifier\n    fix: Optional[str] = None", "chunk_type": "class", "line_start": 37, "line_end": 46, "language": "python", "name": "SecurityIssue"}, "42ff9965cb0c_class_SecurityReport": {"id": "42ff9965cb0c_class_SecurityReport", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\security.py", "content": "class SecurityReport:\n    \"\"\"Complete security audit report.\"\"\"\n    issues: List[SecurityIssue] = field(default_factory=list)\n    files_scanned: int = 0\n\n    @property\n    def critical(self) -> List[SecurityIssue]:\n        return [i for i in self.issues if i.severity == Severity.CRITICAL]\n\n    @property\n    def high(self) -> List[SecurityIssue]:\n        return [i for i in self.issues if i.severity == Severity.HIGH]\n\n    def to_markdown(self) -> str:\n        lines = [\n            \"# Security Audit Report\",\n            \"\",\n            \"## Summary\",\n            \"\",\n            f\"| Severity | Count |\",\n            f\"|----------|-------|\",\n        ]\n\n        for sev in Severity:\n            count = len([i for i in self.issues if i.severity == sev])\n            if count > 0:\n                lines.append(f\"| {sev.value} | {count} |\")\n\n        lines.extend([\"\", f\"**Files Scanned:** {self.files_scanned}\", \"\"])\n\n        if not self.issues:\n            lines.append(\"No security issues found.\")\n  ", "chunk_type": "class", "line_start": 50, "line_end": 104, "language": "python", "name": "SecurityReport"}, "42ff9965cb0c_class_SecurityAnalyzer": {"id": "42ff9965cb0c_class_SecurityAnalyzer", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\security.py", "content": "class SecurityAnalyzer(ast.NodeVisitor):\n    \"\"\"Analyze code for security issues.\"\"\"\n\n    def __init__(self, path: Path, source: str):\n        self.path = path\n        self.source = source\n        self.source_lines = source.split('\\n')\n        self.issues: List[SecurityIssue] = []\n        self._imports: Set[str] = set()\n\n    def visit_Import(self, node: ast.Import):\n        for alias in node.names:\n            self._imports.add(alias.name)\n        self.generic_visit(node)\n\n    def visit_ImportFrom(self, node: ast.ImportFrom):\n        if node.module:\n            self._imports.add(node.module)\n        self.generic_visit(node)\n\n    def visit_Call(self, node: ast.Call):\n        # Check for dangerous function calls\n        func_name = self._get_func_name(node.func)\n\n        if func_name in DANGEROUS_FUNCTIONS:\n            # Special case: Allow subprocess.Popen/call/run if shell=False is explicit\n            if func_name in ('subprocess.Popen', 'subprocess.call', 'subprocess.run'):\n         ", "chunk_type": "class", "line_start": 162, "line_end": 260, "language": "python", "name": "SecurityAnalyzer"}, "30051a2b8fd1_file": {"id": "30051a2b8fd1_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\setup.py", "content": "\"\"\"\nMCP Setup Commands\n==================\nInstall hooks, profiles, and configure MCP.\n\nUsage:\n    python mcp.py setup --hooks     # Install git hooks\n    python mcp.py setup --profile   # Install shell profile\n    python mcp.py setup --all       # Full setup\n\"\"\"\n\nfrom pathlib import Path\nimport os\nimport shutil\nimport subprocess\nimport sys\n\nfrom .utils import Console, find_project_root, get_package_root\nimport importlib\nimport stat\n\n\ndef install_dependencies() -> int:\n    \"\"\"Install required Python dependencies.\"\"\"\n    Console.info(\"Checking dependencies...\")\n\n    # Detect NVIDIA GPU\n    has_gpu = False\n    try:\n        subprocess.run(['nvidia-smi'], capture_output=True, check=True)\n        has_gpu = True\n        Console.ok(\"NVIDIA GPU detected, will use faiss-gpu\")\n    except (subprocess.CalledProcessError, FileNotFoundError):\n        Console.info(\"No NVIDIA GPU detected, using faiss-cpu fallback\")\n\n    faiss_pkg = 'faiss-gpu' if has_gpu else 'faiss-cpu'\n    dependencies = [faiss_pkg, 'watchdog']\n\n    for dep in dependencies:\n        # Check for faiss generically but verify GPU support if needed\n        is_faiss = 'faiss' in dep\n        check_name = 'faiss' if is_faiss else dep.replace('-', '_')\n\n        try:\n            # Check if already installed\n            module = importlib.import_module(check_name)\n\n            # Special check for FAISS GPU support\n            if dep == 'faiss-gpu':\n                try:\n                    import faiss\n                    if faiss.get_num_gpus() > 0:\n                        Console.ok(f\"Dependency already satisfied: {dep} (GPU support verified)\")\n                        continue\n                    else:\n                        Console.warn(\"FAISS installed but NO GPU support found. Upgrading to faiss-gpu...\")\n                        raise ImportError(\"No GPU support\")\n                except Exception:\n                    raise ImportError(\"FAISS GPU check failed\")\n            else:\n                Console.ok(f\"Dependency al", "chunk_type": "file", "line_start": 1, "line_end": 272, "language": "python", "name": "setup.py"}, "30051a2b8fd1_func_install_dependencies": {"id": "30051a2b8fd1_func_install_dependencies", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\setup.py", "content": "def install_dependencies() -> int:\n    \"\"\"Install required Python dependencies.\"\"\"\n    Console.info(\"Checking dependencies...\")\n\n    # Detect NVIDIA GPU\n    has_gpu = False\n    try:\n        subprocess.run(['nvidia-smi'], capture_output=True, check=True)\n        has_gpu = True\n        Console.ok(\"NVIDIA GPU detected, will use faiss-gpu\")\n    except (subprocess.CalledProcessError, FileNotFoundError):\n        Console.info(\"No NVIDIA GPU detected, using faiss-cpu fallback\")\n\n    faiss_pkg = 'faiss-gpu' if has_gpu else 'faiss-cpu'\n    dependencies = [faiss_pkg, 'watchdog']\n\n    for dep in dependencies:\n        # Check for faiss generically but verify GPU support if needed\n        is_faiss = 'faiss' in dep\n        check_name = 'faiss' if is_faiss else dep.replace('-', '_')\n\n        try:\n            # Check if already installed\n            module = importlib.import_module(check_name)\n\n            # Special check for FAISS GPU support\n            if dep == 'faiss-gpu':\n                try:\n   ", "chunk_type": "function", "line_start": 23, "line_end": 85, "language": "python", "name": "install_dependencies"}, "30051a2b8fd1_func_install_git_hooks": {"id": "30051a2b8fd1_func_install_git_hooks", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\setup.py", "content": "def install_git_hooks(project_root: Path = None) -> int:\n    \"\"\"Install MCP git hooks to a project.\"\"\"\n    project_root = project_root or find_project_root() or Path.cwd()\n\n    # Find MCP installation\n    # Find MCP installation\n    mcp_root = get_package_root()\n    hooks_source = mcp_root / '.git-hooks'\n\n    if not hooks_source.exists():\n        Console.fail(f\"Hooks not found: {hooks_source}\")\n        return 1\n\n    # Target\n    git_hooks = project_root / '.git' / 'hooks'\n\n    if not (project_root / '.git').exists():\n        Console.fail(\"Not a git repository\")\n        return 1\n\n    git_hooks.mkdir(parents=True, exist_ok=True)\n\n    # Copy hooks\n    hooks = ['pre-commit', 'post-commit', 'commit-msg', 'pre-push', 'post-checkout', 'post-merge']\n    installed = 0\n\n    for hook in hooks:\n        source = hooks_source / hook\n        target = git_hooks / hook\n\n        if source.exists():\n            shutil.copy2(source, target)\n            # Make executable\n            target.chmod(target.sta", "chunk_type": "function", "line_start": 88, "line_end": 126, "language": "python", "name": "install_git_hooks"}, "30051a2b8fd1_func_install_shell_profile": {"id": "30051a2b8fd1_func_install_shell_profile", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\setup.py", "content": "def install_shell_profile() -> int:\n    \"\"\"Install shell startup script to user profile.\"\"\"\n    mcp_root = get_package_root()\n\n    home = Path.home()\n\n    # Detect shell\n    if os.name == 'nt':\n        # PowerShell\n        ps_profile = home / 'Documents' / 'PowerShell' / 'Microsoft.PowerShell_profile.ps1'\n        ps_profile.parent.mkdir(parents=True, exist_ok=True)\n\n        startup_script = mcp_root / 'scripts' / 'mcp-startup.ps1'\n\n        if startup_script.exists():\n            # Add source line to profile\n            source_line = f'. \"{startup_script}\"'\n\n            existing = ps_profile.read_text() if ps_profile.exists() else \"\"\n            if source_line not in existing:\n                with open(ps_profile, 'a') as f:\n                    f.write(f\"\\n# MCP Integration\\n{source_line}\\n\")\n                Console.ok(f\"Added to PowerShell profile: {ps_profile}\")\n            else:\n                Console.ok(\"PowerShell profile already configured\")\n    else:\n        # Bash/Zsh\n        s", "chunk_type": "function", "line_start": 129, "line_end": 169, "language": "python", "name": "install_shell_profile"}, "30051a2b8fd1_func_install_ci_cd": {"id": "30051a2b8fd1_func_install_ci_cd", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\setup.py", "content": "def install_ci_cd(project_root: Path = None) -> int:\n    \"\"\"Auto-create CI/CD if not exists.\"\"\"\n    project_root = project_root or find_project_root() or Path.cwd()\n\n    # Check if CI already exists\n    github_ci = project_root / '.github' / 'workflows' / 'ci.yml'\n    gitlab_ci = project_root / '.gitlab-ci.yml'\n\n    if github_ci.exists() or gitlab_ci.exists():\n        Console.ok(\"CI/CD already configured\")\n        return 0\n\n    # Check for .git\n    if not (project_root / '.git').exists():\n        Console.warn(\"Not a git repository, skipping CI setup\")\n        return 0\n\n    # Generate GitHub Action\n    try:\n        from .cicd import write_github_action\n        path = write_github_action(project_root)\n        Console.ok(f\"Created: {path}\")\n    except Exception as e:\n        Console.warn(f\"Could not create CI: {e}\")\n\n    return 0", "chunk_type": "function", "line_start": 172, "line_end": 197, "language": "python", "name": "install_ci_cd"}, "30051a2b8fd1_func_full_setup": {"id": "30051a2b8fd1_func_full_setup", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\setup.py", "content": "def full_setup(project_root: Path = None) -> int:\n    \"\"\"Run full MCP setup.\"\"\"\n    project_root = project_root or find_project_root() or Path.cwd()\n\n    Console.header(\"MCP Full Setup\")\n\n    # 0. Install dependencies\n    Console.info(\"Verifying dependencies...\")\n    if install_dependencies() != 0:\n        Console.fail(\"Dependency installation failed, aborting setup.\")\n        return 1\n\n    # 1. Install hooks\n    Console.info(\"Installing git hooks...\")\n    install_git_hooks(project_root)\n\n    # 2. Install shell profile\n    Console.info(\"Installing shell profile...\")\n    install_shell_profile()\n\n    # 3. Create CI/CD\n    Console.info(\"Setting up CI/CD...\")\n    install_ci_cd(project_root)\n\n    # 4. Initial index\n    Console.info(\"Building initial index...\")\n    try:\n        from .index_all import run_all_indexes\n        run_all_indexes(project_root, verbose=False)\n    except Exception:\n        Console.warn(\"Could not build initial index\")\n\n    # 5. Create .mcp directory\n    mcp_dir = pro", "chunk_type": "function", "line_start": 200, "line_end": 242, "language": "python", "name": "full_setup"}, "30051a2b8fd1_func_main": {"id": "30051a2b8fd1_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\setup.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"MCP Setup\")\n\n    if '--hooks' in sys.argv:\n        return install_git_hooks()\n\n    if '--profile' in sys.argv:\n        return install_shell_profile()\n\n    if '--ci' in sys.argv or '--cicd' in sys.argv:\n        return install_ci_cd()\n\n    if '--all' in sys.argv or len(sys.argv) <= 1:\n        return full_setup()\n\n    Console.info(\"Usage:\")\n    Console.info(\"  mcp setup --hooks     Install git hooks\")\n    Console.info(\"  mcp setup --profile   Install shell profile\")\n    Console.info(\"  mcp setup --ci        Create CI/CD pipeline\")\n    Console.info(\"  mcp setup --all       Full setup\")\n\n    return 0", "chunk_type": "function", "line_start": 245, "line_end": 267, "language": "python", "name": "main"}, "48c0fdf1cecd_file": {"id": "48c0fdf1cecd_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\summarize.py", "content": "\"\"\"\nCodebase Summarizer\n===================\nGenerate context summaries for AI agents to quickly understand codebases.\n\nUsage:\n    python summarize.py [path] [--output CODEBASE_SUMMARY.md]\n    python -m scripts.summarize [path]\n\"\"\"\n\nfrom collections import defaultdict\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Any\nimport datetime\nimport sys\n\nfrom .utils import (\n    find_python_files,\n    find_project_root,\n    analyze_module,\n    get_git_log,\n    get_changed_files,\n    ModuleInfo,\n    Console,\n    format_as_json\n)\n\n\n@dataclass\nclass CodebaseSummary:\n    \"\"\"Summary of an entire codebase.\"\"\"\n    root: Path\n    total_files: int = 0\n    total_lines: int = 0\n    total_functions: int = 0\n    total_classes: int = 0\n\n    # Structure\n    directory_tree: Dict[str, Any] = field(default_factory=dict)\n    modules: List[ModuleInfo] = field(default_factory=list)\n\n    # Dependencies\n    external_deps: List[str] = field(default_factory=list)\n    internal_deps: Dict[str, List[str]] = field(default_factory=dict)\n\n    # Entry points\n    entry_points: List[str] = field(default_factory=list)\n\n    # Patterns\n    patterns: List[str] = field(default_factory=list)\n\n    # Recent changes\n    recent_changes: List[str] = field(default_factory=list)\n\n\ndef count_lines(path: Path) -> int:\n    \"\"\"Count non-empty lines in a file.\"\"\"\n    try:\n        with open(path, 'r', encoding='utf-8') as f:\n            return sum(1 for line in f if line.strip())\n    except Exception:\n        return 0\n\n\ndef build_directory_tree(root: Path, files: List[Path]) -> Dict[str, Any]:\n    \"\"\"\n    Build a hierarchical directory tree structure.\n\n    Args:\n        root: Root directory\n        files: List of file paths\n\n    Returns:\n        Nested dictionary representing directory structure\n    \"\"\"\n    tree: Dict[str, Any] = {}\n\n    for file in files:\n        try:\n            relative = file.relative_to(root)\n            parts = relative.parts\n        except Value", "chunk_type": "file", "line_start": 1, "line_end": 448, "language": "python", "name": "summarize.py"}, "48c0fdf1cecd_func_count_lines": {"id": "48c0fdf1cecd_func_count_lines", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\summarize.py", "content": "def count_lines(path: Path) -> int:\n    \"\"\"Count non-empty lines in a file.\"\"\"\n    try:\n        with open(path, 'r', encoding='utf-8') as f:\n            return sum(1 for line in f if line.strip())\n    except Exception:\n        return 0", "chunk_type": "function", "line_start": 57, "line_end": 63, "language": "python", "name": "count_lines"}, "48c0fdf1cecd_func_build_directory_tree": {"id": "48c0fdf1cecd_func_build_directory_tree", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\summarize.py", "content": "def build_directory_tree(root: Path, files: List[Path]) -> Dict[str, Any]:\n    \"\"\"\n    Build a hierarchical directory tree structure.\n\n    Args:\n        root: Root directory\n        files: List of file paths\n\n    Returns:\n        Nested dictionary representing directory structure\n    \"\"\"\n    tree: Dict[str, Any] = {}\n\n    for file in files:\n        try:\n            relative = file.relative_to(root)\n            parts = relative.parts\n        except ValueError:\n            parts = file.parts\n\n        current = tree\n        for part in parts[:-1]:\n            if part not in current:\n                current[part] = {}\n            current = current[part]\n\n        # Add file with info\n        current[parts[-1]] = {\n            '_type': 'file',\n            '_lines': count_lines(file)\n        }\n\n    return tree", "chunk_type": "function", "line_start": 66, "line_end": 98, "language": "python", "name": "build_directory_tree"}, "48c0fdf1cecd_func_format_tree_ascii": {"id": "48c0fdf1cecd_func_format_tree_ascii", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\summarize.py", "content": "def format_tree_ascii(tree: Dict[str, Any], prefix: str = \"\", is_last: bool = True) -> str:\n    \"\"\"Format directory tree as ASCII art.\"\"\"\n    lines = []\n\n    items = sorted(tree.items(), key=lambda x: (x[1].get('_type') != 'file' if isinstance(x[1], dict) else 0, x[0]))\n\n    for i, (name, value) in enumerate(items):\n        if name.startswith('_'):\n            continue\n\n        is_last_item = i == len(items) - 1\n        connector = \"\u2514\u2500\u2500 \" if is_last_item else \"\u251c\u2500\u2500 \"\n\n        if isinstance(value, dict) and value.get('_type') == 'file':\n            line_count = value.get('_lines', 0)\n            lines.append(f\"{prefix}{connector}{name} ({line_count} lines)\")\n        elif isinstance(value, dict):\n            lines.append(f\"{prefix}{connector}{name}/\")\n            extension = \"    \" if is_last_item else \"\u2502   \"\n            lines.append(format_tree_ascii(value, prefix + extension, is_last_item))\n        else:\n            lines.append(f\"{prefix}{connector}{name}\")\n\n    return \"\\n\".join(filter", "chunk_type": "function", "line_start": 101, "line_end": 124, "language": "python", "name": "format_tree_ascii"}, "48c0fdf1cecd_func_detect_patterns": {"id": "48c0fdf1cecd_func_detect_patterns", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\summarize.py", "content": "def detect_patterns(modules: List[ModuleInfo]) -> List[str]:\n    \"\"\"Detect common patterns in the codebase.\"\"\"\n    patterns = []\n\n    # Check for common patterns\n    all_decorators = set()\n    all_bases = set()\n    all_imports = set()\n\n    for module in modules:\n        for func in module.functions:\n            all_decorators.update(func.decorators)\n        for cls in module.classes:\n            all_bases.update(cls.bases)\n            all_decorators.update(cls.decorators)\n        all_imports.update(module.imports)\n        for mod, names in module.from_imports:\n            all_imports.add(mod)\n\n    # Detect patterns\n    if 'dataclass' in all_decorators or 'dataclasses' in all_imports:\n        patterns.append(\"Uses dataclasses for data structures\")\n\n    if 'pytest' in all_imports or 'unittest' in all_imports:\n        patterns.append(\"Has test infrastructure\")\n\n    if 'flask' in all_imports or 'fastapi' in all_imports:\n        patterns.append(\"Web application (Flask/FastAPI)\")\n\n    if 'dj", "chunk_type": "function", "line_start": 127, "line_end": 180, "language": "python", "name": "detect_patterns"}, "48c0fdf1cecd_func_find_entry_points": {"id": "48c0fdf1cecd_func_find_entry_points", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\summarize.py", "content": "def find_entry_points(root: Path, modules: List[ModuleInfo]) -> List[str]:\n    \"\"\"Find likely entry points in the codebase.\"\"\"\n    entry_points = []\n\n    for module in modules:\n        # Check for if __name__ == '__main__'\n        try:\n            with open(module.path, 'r', encoding='utf-8') as f:\n                content = f.read()\n                if \"if __name__\" in content and \"__main__\" in content:\n                    relative = module.path.relative_to(root) if module.path.is_relative_to(root) else module.path\n                    entry_points.append(str(relative))\n        except Exception:\n            pass\n\n    # Check for common entry point files\n    common_entry_points = ['main.py', 'app.py', 'cli.py', 'run.py', '__main__.py', 'manage.py']\n    for ep in common_entry_points:\n        for module in modules:\n            if module.path.name == ep:\n                relative = module.path.relative_to(root) if module.path.is_relative_to(root) else module.path\n                if str(relati", "chunk_type": "function", "line_start": 183, "line_end": 207, "language": "python", "name": "find_entry_points"}, "48c0fdf1cecd_func_extract_external_deps": {"id": "48c0fdf1cecd_func_extract_external_deps", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\summarize.py", "content": "def extract_external_deps(modules: List[ModuleInfo]) -> List[str]:\n    \"\"\"Extract external dependencies from imports.\"\"\"\n    stdlib_modules = {\n        'os', 'sys', 're', 'json', 'pathlib', 'typing', 'collections',\n        'itertools', 'functools', 'datetime', 'time', 'logging', 'ast',\n        'subprocess', 'threading', 'multiprocessing', 'queue', 'socket',\n        'http', 'urllib', 'email', 'html', 'xml', 'configparser',\n        'argparse', 'io', 'string', 'textwrap', 'copy', 'pprint',\n        'dataclasses', 'abc', 'contextlib', 'warnings', 'traceback',\n        'unittest', 'doctest', 'sqlite3', 'csv', 'pickle', 'shelve',\n        'hashlib', 'hmac', 'secrets', 'random', 'math', 'statistics',\n        'fractions', 'decimal', 'struct', 'codecs', 'unicodedata',\n        'locale', 'gettext', 'operator', 'enum', 'graphlib', 'bisect',\n        'heapq', 'array', 'weakref', 'types', 'inspect', 'dis',\n        'gc', 'atexit', 'builtins', 'tempfile', 'shutil', 'glob',\n        'fnmatch', 'linecache', ", "chunk_type": "function", "line_start": 210, "line_end": 241, "language": "python", "name": "extract_external_deps"}, "48c0fdf1cecd_func_summarize_codebase": {"id": "48c0fdf1cecd_func_summarize_codebase", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\summarize.py", "content": "def summarize_codebase(root: Path, exclude_patterns: List[str] = None) -> CodebaseSummary:\n    \"\"\"\n    Generate a comprehensive summary of a codebase.\n\n    Args:\n        root: Root directory\n        exclude_patterns: Patterns to exclude\n\n    Returns:\n        CodebaseSummary object\n    \"\"\"\n    summary = CodebaseSummary(root=root)\n\n    Console.info(f\"Scanning {root}...\")\n\n    # Find all Python files\n    files = list(find_python_files(root, exclude_patterns))\n    summary.total_files = len(files)\n\n    Console.info(f\"Found {len(files)} Python files\")\n\n    # Build directory tree\n    summary.directory_tree = build_directory_tree(root, files)\n\n    # Analyze each module\n    for path in files:\n        module_info = analyze_module(path)\n        if module_info:\n            summary.modules.append(module_info)\n            summary.total_lines += count_lines(path)\n            summary.total_functions += len(module_info.functions)\n            summary.total_classes += len(module_info.classes)\n\n    Consol", "chunk_type": "function", "line_start": 244, "line_end": 292, "language": "python", "name": "summarize_codebase"}, "48c0fdf1cecd_func_format_summary_markdown": {"id": "48c0fdf1cecd_func_format_summary_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\summarize.py", "content": "def format_summary_markdown(summary: CodebaseSummary) -> str:\n    \"\"\"Format summary as Markdown.\"\"\"\n\n    lines = [\n        \"# Codebase Summary\",\n        \"\",\n        f\"**Root:** `{summary.root}`\",\n        f\"**Generated:** {datetime.datetime.now().isoformat()}\",\n        \"\",\n        \"## Overview\",\n        \"\",\n        f\"| Metric | Value |\",\n        f\"|--------|-------|\",\n        f\"| Python Files | {summary.total_files} |\",\n        f\"| Total Lines | {summary.total_lines:,} |\",\n        f\"| Functions | {summary.total_functions} |\",\n        f\"| Classes | {summary.total_classes} |\",\n        \"\",\n    ]\n\n    # Directory Structure\n    if summary.directory_tree:\n        lines.extend([\n            \"## Directory Structure\",\n            \"\",\n            \"```\",\n            format_tree_ascii(summary.directory_tree),\n            \"```\",\n            \"\",\n        ])\n\n    # Entry Points\n    if summary.entry_points:\n        lines.extend([\n            \"## Entry Points\",\n            \"\",\n        ])\n        for ep i", "chunk_type": "function", "line_start": 295, "line_end": 399, "language": "python", "name": "format_summary_markdown"}, "48c0fdf1cecd_func_main": {"id": "48c0fdf1cecd_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\summarize.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Codebase Summarizer\")\n\n    # Parse args\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n    output_file = None\n\n    for i, arg in enumerate(sys.argv):\n        if arg == '--output' and i + 1 < len(sys.argv):\n            output_file = Path(sys.argv[i + 1])\n\n    # Get path\n    if args:\n        path = Path(args[0])\n    else:\n        path = find_project_root() or Path.cwd()\n\n    if not path.exists():\n        Console.fail(f\"Path not found: {path}\")\n        sys.exit(1)\n\n    Console.info(f\"Analyzing: {path}\")\n\n    summary = summarize_codebase(path)\n    markdown = format_summary_markdown(summary)\n\n    # Output\n    if output_file:\n        with open(output_file, 'w', encoding='utf-8') as f:\n            f.write(markdown)\n        Console.ok(f\"Summary written to: {output_file}\")\n    else:\n        # Handle Windows encoding issues\n        try:\n            print(markdown)\n        except UnicodeEncodeError:\n            # Fallback: ", "chunk_type": "function", "line_start": 402, "line_end": 443, "language": "python", "name": "main"}, "48c0fdf1cecd_class_CodebaseSummary": {"id": "48c0fdf1cecd_class_CodebaseSummary", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\summarize.py", "content": "class CodebaseSummary:\n    \"\"\"Summary of an entire codebase.\"\"\"\n    root: Path\n    total_files: int = 0\n    total_lines: int = 0\n    total_functions: int = 0\n    total_classes: int = 0\n\n    # Structure\n    directory_tree: Dict[str, Any] = field(default_factory=dict)\n    modules: List[ModuleInfo] = field(default_factory=list)\n\n    # Dependencies\n    external_deps: List[str] = field(default_factory=list)\n    internal_deps: Dict[str, List[str]] = field(default_factory=dict)\n\n    # Entry points\n    entry_points: List[str] = field(default_factory=list)\n\n    # Patterns\n    patterns: List[str] = field(default_factory=list)\n\n    # Recent changes\n    recent_changes: List[str] = field(default_factory=list)", "chunk_type": "class", "line_start": 31, "line_end": 54, "language": "python", "name": "CodebaseSummary"}, "b1a335460cbb_file": {"id": "b1a335460cbb_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\telegram_bridge.py", "content": "#!/usr/bin/env python3\n\"\"\"\nTelegram C2 Bridge\nPolls Telegram for user instructions and dispatches them to active agents.\n\"\"\"\n\nfrom pathlib import Path\nimport json\nimport os\nimport sys\nimport time\n\nimport requests\n\n# MCP Path Resolution\nSCRIPTS_DIR = Path(__file__).resolve().parent\nsys.path.append(str(SCRIPTS_DIR))\n\ntry:\n    import agent_comms\nexcept ImportError:\n    pass\n\nCONFIG_FILE = Path(__file__).resolve().parent / \"telegram_config.json\"\n\ndef get_config():\n    if not CONFIG_FILE.exists():\n        return None\n    with open(CONFIG_FILE, \"r\") as f:\n        return json.load(f)\n\ndef poll_telegram(config):\n    # Only the primary host should poll for updates to avoid 409 Conflict\n    # We'll designate Quasar (Windows) as primary, WizardPanda as fallback.\n    hostname = agent_comms.get_hostname().lower()\n    is_windows = os.name == 'nt'\n\n    # Simple logic: If we are on Linux and a Windows agent was seen recently, don't poll.\n    if not is_windows:\n        remotes = agent_comms.AgentPresence.get_remote_status()\n        for host, data in remotes.items():\n            if data.get('hostname', '').lower() == 'quasar' or 'window' in host.lower():\n                age = time.time() - data.get('timestamp', 0)\n                if age < 120: # Quasar was seen in the last 2 minutes\n                    return\n\n    token = config.get(\"bot_token\")\n    chat_id = config.get(\"chat_id\")\n    last_update = config.get(\"last_update_id\", 0)\n\n    url = f\"https://api.telegram.org/bot{token}/getUpdates?offset={last_update + 1}&timeout=10\"\n    try:\n        r = requests.get(url, timeout=15)\n        if r.status_code == 200:\n            updates = r.json().get(\"result\", [])\n            for update in updates:\n                last_update = update[\"update_id\"]\n                msg = update.get(\"message\", {})\n                text = msg.get(\"text\", \"\")\n                from_id = msg.get(\"from\", {}).get(\"id\")\n\n                if str(from_id) == str(chat_id):\n                    handle_instruction(text)\n\n      ", "chunk_type": "file", "line_start": 1, "line_end": 195, "language": "python", "name": "telegram_bridge.py"}, "b1a335460cbb_func_get_config": {"id": "b1a335460cbb_func_get_config", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\telegram_bridge.py", "content": "def get_config():\n    if not CONFIG_FILE.exists():\n        return None\n    with open(CONFIG_FILE, \"r\") as f:\n        return json.load(f)", "chunk_type": "function", "line_start": 26, "line_end": 30, "language": "python", "name": "get_config"}, "b1a335460cbb_func_poll_telegram": {"id": "b1a335460cbb_func_poll_telegram", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\telegram_bridge.py", "content": "def poll_telegram(config):\n    # Only the primary host should poll for updates to avoid 409 Conflict\n    # We'll designate Quasar (Windows) as primary, WizardPanda as fallback.\n    hostname = agent_comms.get_hostname().lower()\n    is_windows = os.name == 'nt'\n\n    # Simple logic: If we are on Linux and a Windows agent was seen recently, don't poll.\n    if not is_windows:\n        remotes = agent_comms.AgentPresence.get_remote_status()\n        for host, data in remotes.items():\n            if data.get('hostname', '').lower() == 'quasar' or 'window' in host.lower():\n                age = time.time() - data.get('timestamp', 0)\n                if age < 120: # Quasar was seen in the last 2 minutes\n                    return\n\n    token = config.get(\"bot_token\")\n    chat_id = config.get(\"chat_id\")\n    last_update = config.get(\"last_update_id\", 0)\n\n    url = f\"https://api.telegram.org/bot{token}/getUpdates?offset={last_update + 1}&timeout=10\"\n    try:\n        r = requests.get(url, timeout=15)\n ", "chunk_type": "function", "line_start": 32, "line_end": 72, "language": "python", "name": "poll_telegram"}, "b1a335460cbb_func_handle_instruction": {"id": "b1a335460cbb_func_handle_instruction", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\telegram_bridge.py", "content": "def handle_instruction(text):\n    print(f\"[BRIDGE] Received instruction: {text}\")\n    target_host = agent_comms.get_hostname().lower()\n\n    if text.lower().startswith(\"to \"):\n        parts = text.split(\":\", 1)\n        if len(parts) == 2:\n            target_host = parts[0].replace(\"to \", \"\").strip().lower()\n            text = parts[1].strip()\n\n    inbox = agent_comms.get_telegram_inbox_dir()\n    msg_id = int(time.time() * 1000)\n\n    # If the user says \"to antigravity\", \"to assistant\", or just \"to me\"\n    if text.lower().startswith(\"to antigravity\") or text.lower().startswith(\"to assistant\"):\n         target_host = \"Antigravity\"\n         if \":\" in text:\n             text = text.split(\":\", 1)[1].strip()\n\n    msg_file = inbox / f\"{target_host}_{msg_id}.json\"\n\n    with open(msg_file, \"w\") as f:\n        json.dump({\"text\": text, \"timestamp\": time.time()}, f, indent=2)", "chunk_type": "function", "line_start": 74, "line_end": 96, "language": "python", "name": "handle_instruction"}, "b1a335460cbb_func_check_outbox": {"id": "b1a335460cbb_func_check_outbox", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\telegram_bridge.py", "content": "def check_outbox(config):\n    token = config.get(\"bot_token\")\n    chat_id = config.get(\"chat_id\")\n    outbox = agent_comms.get_comms_dir() / \"telegram_outbox\"\n\n    if not outbox.exists():\n        return\n\n    # Use a temp directory outside of the NSync synced tree for processing\n    import tempfile\n    buffer_dir = Path(tempfile.gettempdir()) / \"mcp_telegram_buffer\"\n    if not buffer_dir.exists():\n        buffer_dir.mkdir(parents=True, exist_ok=True)\n\n    for f in outbox.glob(\"*.json\"):\n        if f.is_dir() or f.name.startswith(\".\"): continue\n        try:\n            # Move to local temp buffer first (breaks sync lock)\n            target = buffer_dir / f.name\n            try:\n                # Force replace if target exists (stale)\n                if target.exists(): os.remove(target)\n                os.rename(str(f), str(target))\n            except OSError:\n                continue # Still locked by NSync or Git\n\n            with open(target, \"r\") as mf:\n                data = json.lo", "chunk_type": "function", "line_start": 98, "line_end": 148, "language": "python", "name": "check_outbox"}, "b1a335460cbb_func_main": {"id": "b1a335460cbb_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\telegram_bridge.py", "content": "def main():\n    print(\"--- Telegram C2 Bridge ---\")\n\n    # [NEW] PID-based singleton protection\n    import tempfile\n    pid_file = Path(tempfile.gettempdir()) / \"telegram_bridge.pid\"\n    if pid_file.exists():\n        try:\n            with open(pid_file, \"r\") as f:\n                old_pid = int(f.read().strip())\n                if os.name == 'nt':\n                    subprocess.run([\"tasklist\", \"/FI\", f\"PID eq {old_pid}\"], check=True, capture_output=True)\n                else:\n                    os.kill(old_pid, 0)\n                print(f\"[BRIDGE] Service already running (PID {old_pid}). Exiting.\")\n                return 0\n        except:\n            pid_file.unlink()\n\n    with open(pid_file, \"w\") as f:\n        f.write(str(os.getpid()))\n\n    try:\n        config = get_config()\n        if not config:\n            print(\"[FAIL] telegram_config.json missing. Please create it with bot_token and chat_id.\")\n            return 1\n\n        print(f\"[BRIDGE] Configuration loaded. Chat ID: {config.g", "chunk_type": "function", "line_start": 150, "line_end": 191, "language": "python", "name": "main"}, "603242c80fc5_file": {"id": "603242c80fc5_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\test_gen.py", "content": "\"\"\"\nAuto-Test Implementation Generator\n==================================\nGenerate actual test implementations, not just stubs.\n\nUsage:\n    python mcp.py test-gen [file] --impl\n\"\"\"\n\nfrom dataclasses import dataclass\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Tuple\nimport ast\nimport sys\n\nfrom .utils import Console, find_project_root\n\n\n@dataclass\nclass FunctionSignature:\n    \"\"\"Function signature info.\"\"\"\n    name: str\n    args: List[Tuple[str, Optional[str]]]  # (name, type_hint)\n    return_type: Optional[str]\n    decorators: List[str]\n    docstring: Optional[str]\n    is_async: bool\n    line_num: int\n\n\nclass SignatureExtractor(ast.NodeVisitor):\n    \"\"\"Extract function signatures.\"\"\"\n\n    def __init__(self):\n        self.functions: List[FunctionSignature] = []\n\n    def visit_FunctionDef(self, node):\n        self._extract(node, is_async=False)\n        self.generic_visit(node)\n\n    def visit_AsyncFunctionDef(self, node):\n        self._extract(node, is_async=True)\n        self.generic_visit(node)\n\n    def _extract(self, node, is_async: bool):\n        # Skip private and magic methods (except __init__)\n        if node.name.startswith('_') and not node.name == '__init__':\n            return\n\n        # Get args with type hints\n        args = []\n        for arg in node.args.args:\n            if arg.arg != 'self':\n                type_hint = None\n                if arg.annotation:\n                    type_hint = ast.unparse(arg.annotation)\n                args.append((arg.arg, type_hint))\n\n        # Get return type\n        return_type = None\n        if node.returns:\n            return_type = ast.unparse(node.returns)\n\n        # Get decorators\n        decorators = []\n        for dec in node.decorator_list:\n            if isinstance(dec, ast.Name):\n                decorators.append(dec.id)\n            elif isinstance(dec, ast.Attribute):\n                decorators.append(dec.attr)\n\n        self.functions.append(FunctionSignature(\n            name=node.name", "chunk_type": "file", "line_start": 1, "line_end": 297, "language": "python", "name": "test_gen.py"}, "603242c80fc5_func_get_test_value": {"id": "603242c80fc5_func_get_test_value", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\test_gen.py", "content": "def get_test_value(type_hint: Optional[str]) -> str:\n    \"\"\"Get example test value for a type.\"\"\"\n    if not type_hint:\n        return '\"test_value\"'\n\n    type_lower = type_hint.lower()\n\n    if 'int' in type_lower:\n        return '42'\n    elif 'float' in type_lower:\n        return '3.14'\n    elif 'str' in type_lower:\n        return '\"test_string\"'\n    elif 'bool' in type_lower:\n        return 'True'\n    elif 'list' in type_lower:\n        return '[]'\n    elif 'dict' in type_lower:\n        return '{}'\n    elif 'none' in type_lower:\n        return 'None'\n    elif 'path' in type_lower:\n        return 'Path(\".\")'\n    elif 'optional' in type_lower:\n        return 'None'\n    else:\n        return 'None  # TODO: provide test value'", "chunk_type": "function", "line_start": 83, "line_end": 109, "language": "python", "name": "get_test_value"}, "603242c80fc5_func_get_assertion": {"id": "603242c80fc5_func_get_assertion", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\test_gen.py", "content": "def get_assertion(return_type: Optional[str]) -> str:\n    \"\"\"Get appropriate assertion for return type.\"\"\"\n    if not return_type:\n        return 'assert result is not None'\n\n    type_lower = return_type.lower()\n\n    if 'bool' in type_lower:\n        return 'assert isinstance(result, bool)'\n    elif 'int' in type_lower:\n        return 'assert isinstance(result, int)'\n    elif 'float' in type_lower:\n        return 'assert isinstance(result, (int, float))'\n    elif 'str' in type_lower:\n        return 'assert isinstance(result, str)'\n    elif 'list' in type_lower:\n        return 'assert isinstance(result, list)'\n    elif 'dict' in type_lower:\n        return 'assert isinstance(result, dict)'\n    elif 'none' in type_lower:\n        return 'assert result is None'\n    else:\n        return 'assert result is not None'", "chunk_type": "function", "line_start": 112, "line_end": 134, "language": "python", "name": "get_assertion"}, "603242c80fc5_func_generate_test_impl": {"id": "603242c80fc5_func_generate_test_impl", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\test_gen.py", "content": "def generate_test_impl(func: FunctionSignature, module_name: str) -> str:\n    \"\"\"Generate full test implementation for a function.\"\"\"\n    lines = []\n\n    # Test function signature\n    async_prefix = 'async ' if func.is_async else ''\n    lines.append(f'{async_prefix}def test_{func.name}():')\n\n    # Docstring\n    if func.docstring:\n        lines.append(f'    \"\"\"Test {func.name}: {func.docstring[:50]}...\"\"\"')\n    else:\n        lines.append(f'    \"\"\"Test {func.name} function.\"\"\"')\n\n    # Arrange\n    lines.append('    # Arrange')\n    args_call = []\n    for arg_name, arg_type in func.args:\n        value = get_test_value(arg_type)\n        lines.append(f'    {arg_name} = {value}')\n        args_call.append(arg_name)\n\n    lines.append('')\n    lines.append('    # Act')\n\n    args_str = ', '.join(args_call)\n    if func.is_async:\n        lines.append(f'    result = await {func.name}({args_str})')\n    else:\n        lines.append(f'    result = {func.name}({args_str})')\n\n    lines.append('')\n    lines.", "chunk_type": "function", "line_start": 137, "line_end": 172, "language": "python", "name": "generate_test_impl"}, "603242c80fc5_func_generate_edge_case_tests": {"id": "603242c80fc5_func_generate_edge_case_tests", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\test_gen.py", "content": "def generate_edge_case_tests(func: FunctionSignature) -> List[str]:\n    \"\"\"Generate edge case tests.\"\"\"\n    tests = []\n\n    for arg_name, arg_type in func.args:\n        if not arg_type:\n            continue\n\n        type_lower = arg_type.lower()\n\n        # None tests for Optional types\n        if 'optional' in type_lower:\n            test = f'''def test_{func.name}_{arg_name}_none():\n    \"\"\"Test {func.name} with {arg_name}=None.\"\"\"\n    result = {func.name}({arg_name}=None)\n    assert result is not None or True  # Handle None case'''\n            tests.append(test)\n\n        # Empty tests for collections\n        if 'list' in type_lower:\n            test = f'''def test_{func.name}_{arg_name}_empty():\n    \"\"\"Test {func.name} with empty list.\"\"\"\n    result = {func.name}({arg_name}=[])\n    assert result is not None'''\n            tests.append(test)\n\n        if 'str' in type_lower:\n            test = f'''def test_{func.name}_{arg_name}_empty_string():\n    \"\"\"Test {func.name} with empty string.", "chunk_type": "function", "line_start": 175, "line_end": 221, "language": "python", "name": "generate_edge_case_tests"}, "603242c80fc5_func_generate_test_file": {"id": "603242c80fc5_func_generate_test_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\test_gen.py", "content": "def generate_test_file(file_path: Path) -> str:\n    \"\"\"Generate full test file for a module.\"\"\"\n    try:\n        source = file_path.read_text(encoding='utf-8')\n        tree = ast.parse(source)\n    except Exception as e:\n        return f\"# Error parsing {file_path}: {e}\"\n\n    extractor = SignatureExtractor()\n    extractor.visit(tree)\n\n    module_name = file_path.stem\n\n    lines = [\n        '\"\"\"',\n        f'Auto-generated tests for {module_name}',\n        '\"\"\"',\n        '',\n        'import pytest',\n        f'from {module_name} import *',\n        '',\n        '',\n    ]\n\n    for func in extractor.functions:\n        # Main test\n        lines.append(generate_test_impl(func, module_name))\n        lines.append('')\n        lines.append('')\n\n        # Edge case tests\n        edge_tests = generate_edge_case_tests(func)\n        for test in edge_tests[:2]:  # Limit edge cases\n            lines.append(test)\n            lines.append('')\n            lines.append('')\n\n    return '\\n'.join(lines)", "chunk_type": "function", "line_start": 224, "line_end": 261, "language": "python", "name": "generate_test_file"}, "603242c80fc5_func_main": {"id": "603242c80fc5_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\test_gen.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Auto-Test Generator (Full Implementation)\")\n\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n\n    if not args:\n        Console.info(\"Usage: mcp test-gen <file.py> [--impl]\")\n        return 1\n\n    file_path = Path(args[0])\n\n    if not file_path.exists():\n        Console.fail(f\"File not found: {file_path}\")\n        return 1\n\n    Console.info(f\"Generating tests for: {file_path}\")\n\n    test_code = generate_test_file(file_path)\n\n    if '--impl' in sys.argv or '--write' in sys.argv:\n        # Write to test file\n        test_file = file_path.parent / f'test_{file_path.name}'\n        test_file.write_text(test_code)\n        Console.ok(f\"Written to: {test_file}\")\n    else:\n        print(test_code)\n\n    return 0", "chunk_type": "function", "line_start": 264, "line_end": 292, "language": "python", "name": "main"}, "603242c80fc5_func___init__": {"id": "603242c80fc5_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\test_gen.py", "content": "    def __init__(self):\n        self.functions: List[FunctionSignature] = []", "chunk_type": "function", "line_start": 34, "line_end": 35, "language": "python", "name": "__init__"}, "603242c80fc5_func_visit_FunctionDef": {"id": "603242c80fc5_func_visit_FunctionDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\test_gen.py", "content": "    def visit_FunctionDef(self, node):\n        self._extract(node, is_async=False)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 37, "line_end": 39, "language": "python", "name": "visit_FunctionDef"}, "603242c80fc5_func_visit_AsyncFunctionDef": {"id": "603242c80fc5_func_visit_AsyncFunctionDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\test_gen.py", "content": "    def visit_AsyncFunctionDef(self, node):\n        self._extract(node, is_async=True)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 41, "line_end": 43, "language": "python", "name": "visit_AsyncFunctionDef"}, "603242c80fc5_func__extract": {"id": "603242c80fc5_func__extract", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\test_gen.py", "content": "    def _extract(self, node, is_async: bool):\n        # Skip private and magic methods (except __init__)\n        if node.name.startswith('_') and not node.name == '__init__':\n            return\n\n        # Get args with type hints\n        args = []\n        for arg in node.args.args:\n            if arg.arg != 'self':\n                type_hint = None\n                if arg.annotation:\n                    type_hint = ast.unparse(arg.annotation)\n                args.append((arg.arg, type_hint))\n\n        # Get return type\n        return_type = None\n        if node.returns:\n            return_type = ast.unparse(node.returns)\n\n        # Get decorators\n        decorators = []\n        for dec in node.decorator_list:\n            if isinstance(dec, ast.Name):\n                decorators.append(dec.id)\n            elif isinstance(dec, ast.Attribute):\n                decorators.append(dec.attr)\n\n        self.functions.append(FunctionSignature(\n            name=node.name,\n            args=args,\n      ", "chunk_type": "function", "line_start": 45, "line_end": 80, "language": "python", "name": "_extract"}, "603242c80fc5_class_FunctionSignature": {"id": "603242c80fc5_class_FunctionSignature", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\test_gen.py", "content": "class FunctionSignature:\n    \"\"\"Function signature info.\"\"\"\n    name: str\n    args: List[Tuple[str, Optional[str]]]  # (name, type_hint)\n    return_type: Optional[str]\n    decorators: List[str]\n    docstring: Optional[str]\n    is_async: bool\n    line_num: int", "chunk_type": "class", "line_start": 20, "line_end": 28, "language": "python", "name": "FunctionSignature"}, "603242c80fc5_class_SignatureExtractor": {"id": "603242c80fc5_class_SignatureExtractor", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\test_gen.py", "content": "class SignatureExtractor(ast.NodeVisitor):\n    \"\"\"Extract function signatures.\"\"\"\n\n    def __init__(self):\n        self.functions: List[FunctionSignature] = []\n\n    def visit_FunctionDef(self, node):\n        self._extract(node, is_async=False)\n        self.generic_visit(node)\n\n    def visit_AsyncFunctionDef(self, node):\n        self._extract(node, is_async=True)\n        self.generic_visit(node)\n\n    def _extract(self, node, is_async: bool):\n        # Skip private and magic methods (except __init__)\n        if node.name.startswith('_') and not node.name == '__init__':\n            return\n\n        # Get args with type hints\n        args = []\n        for arg in node.args.args:\n            if arg.arg != 'self':\n                type_hint = None\n                if arg.annotation:\n                    type_hint = ast.unparse(arg.annotation)\n                args.append((arg.arg, type_hint))\n\n        # Get return type\n        return_type = None\n        if node.returns:\n            return_type = a", "chunk_type": "class", "line_start": 31, "line_end": 80, "language": "python", "name": "SignatureExtractor"}, "59381aa4209e_file": {"id": "59381aa4209e_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\todo_index.py", "content": "\"\"\"\nTODO/FIXME Index\n================\nScan and index all TODOs, FIXMEs, HACKs, and NOTEs in code.\n\nUsage:\n    python mcp.py todos\n    python mcp.py todos --priority high\n\"\"\"\n\nfrom collections import Counter\nfrom dataclasses import dataclass, field, asdict\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Tuple\nimport json\nimport re\nimport sys\n\nfrom .utils import Console, find_python_files, find_project_root\n\n\n@dataclass\nclass TodoItem:\n    \"\"\"A TODO/FIXME item.\"\"\"\n    type: str  # TODO, FIXME, HACK, XXX, NOTE\n    message: str\n    file: str\n    line: int\n    author: Optional[str] = None\n    priority: int = 2  # 1=high, 2=medium, 3=low\n    context: str = \"\"\n\n\n# Patterns to detect\nTODO_PATTERNS = [\n    (r'#\\s*(TODO|FIXME|HACK|XXX|NOTE)(?:\\(([^)]+)\\))?:\\s*(.+?)$', 'python'),\n    (r'//\\s*(TODO|FIXME|HACK|XXX|NOTE)(?:\\(([^)]+)\\))?:\\s*(.+?)$', 'js'),\n    (r'/\\*\\s*(TODO|FIXME|HACK|XXX|NOTE)(?:\\(([^)]+)\\))?:\\s*(.+?)\\*/', 'block'),\n]\n\nPRIORITY_MAP = {\n    'FIXME': 1,\n    'XXX': 1,\n    'HACK': 2,\n    'TODO': 2,\n    'NOTE': 3,\n}\n\nPRIORITY_KEYWORDS = {\n    'urgent': 1,\n    'critical': 1,\n    'important': 1,\n    'P0': 1, 'P1': 1,\n    'P2': 2, 'P3': 3,\n    'low': 3,\n    'minor': 3,\n}\n\n\ndef detect_priority(todo_type: str, message: str, author: str = None) -> int:\n    \"\"\"Detect priority from type and message.\"\"\"\n    priority = PRIORITY_MAP.get(todo_type, 2)\n\n    # Check for priority keywords\n    text = (message + (author or '')).lower()\n    for keyword, p in PRIORITY_KEYWORDS.items():\n        if keyword.lower() in text:\n            priority = min(priority, p)\n            break\n\n    # ! at end indicates high priority\n    if message.rstrip().endswith('!'):\n        priority = 1\n\n    return priority\n\n\ndef scan_file(file_path: Path) -> List[TodoItem]:\n    \"\"\"Scan a file for TODOs.\"\"\"\n    todos = []\n\n    try:\n        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n            lines = f.readlines()\n    except Exception:\n        return todos\n\n    for i, li", "chunk_type": "file", "line_start": 1, "line_end": 260, "language": "python", "name": "todo_index.py"}, "59381aa4209e_func_detect_priority": {"id": "59381aa4209e_func_detect_priority", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\todo_index.py", "content": "def detect_priority(todo_type: str, message: str, author: str = None) -> int:\n    \"\"\"Detect priority from type and message.\"\"\"\n    priority = PRIORITY_MAP.get(todo_type, 2)\n\n    # Check for priority keywords\n    text = (message + (author or '')).lower()\n    for keyword, p in PRIORITY_KEYWORDS.items():\n        if keyword.lower() in text:\n            priority = min(priority, p)\n            break\n\n    # ! at end indicates high priority\n    if message.rstrip().endswith('!'):\n        priority = 1\n\n    return priority", "chunk_type": "function", "line_start": 60, "line_end": 75, "language": "python", "name": "detect_priority"}, "59381aa4209e_func_scan_file": {"id": "59381aa4209e_func_scan_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\todo_index.py", "content": "def scan_file(file_path: Path) -> List[TodoItem]:\n    \"\"\"Scan a file for TODOs.\"\"\"\n    todos = []\n\n    try:\n        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n            lines = f.readlines()\n    except Exception:\n        return todos\n\n    for i, line in enumerate(lines, 1):\n        for pattern, _ in TODO_PATTERNS:\n            match = re.search(pattern, line, re.IGNORECASE)\n            if match:\n                todo_type = match.group(1).upper()\n                author = match.group(2) if match.lastindex >= 2 else None\n                message = match.group(3) if match.lastindex >= 3 else match.group(2)\n\n                if message:\n                    # Get context (surrounding lines)\n                    context_start = max(0, i - 2)\n                    context_end = min(len(lines), i + 2)\n                    context = ''.join(lines[context_start:context_end])\n\n                    todos.append(TodoItem(\n                        type=todo_type,\n                    ", "chunk_type": "function", "line_start": 78, "line_end": 113, "language": "python", "name": "scan_file"}, "59381aa4209e_func_scan_project": {"id": "59381aa4209e_func_scan_project", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\todo_index.py", "content": "def scan_project(\n    root: Path,\n    exclude_patterns: List[str] = None\n) -> List[TodoItem]:\n    \"\"\"Scan entire project for TODOs.\"\"\"\n    all_todos = []\n\n    # Find all code files\n    extensions = ['.py', '.js', '.ts', '.jsx', '.tsx', '.java', '.go', '.rs', '.c', '.cpp', '.h']\n\n    for ext in extensions:\n        for file_path in root.rglob(f'*{ext}'):\n            # Skip excluded\n            if exclude_patterns:\n                skip = False\n                for pattern in exclude_patterns:\n                    if pattern in str(file_path):\n                        skip = True\n                        break\n                if skip:\n                    continue\n\n            todos = scan_file(file_path)\n            all_todos.extend(todos)\n\n    return all_todos", "chunk_type": "function", "line_start": 116, "line_end": 141, "language": "python", "name": "scan_project"}, "59381aa4209e_func_group_by_priority": {"id": "59381aa4209e_func_group_by_priority", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\todo_index.py", "content": "def group_by_priority(todos: List[TodoItem]) -> Dict[int, List[TodoItem]]:\n    \"\"\"Group TODOs by priority.\"\"\"\n    groups = {1: [], 2: [], 3: []}\n    for todo in todos:\n        groups[todo.priority].append(todo)\n    return groups", "chunk_type": "function", "line_start": 144, "line_end": 149, "language": "python", "name": "group_by_priority"}, "59381aa4209e_func_group_by_type": {"id": "59381aa4209e_func_group_by_type", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\todo_index.py", "content": "def group_by_type(todos: List[TodoItem]) -> Dict[str, List[TodoItem]]:\n    \"\"\"Group TODOs by type.\"\"\"\n    groups = {}\n    for todo in todos:\n        if todo.type not in groups:\n            groups[todo.type] = []\n        groups[todo.type].append(todo)\n    return groups", "chunk_type": "function", "line_start": 152, "line_end": 159, "language": "python", "name": "group_by_type"}, "59381aa4209e_func_index_todos": {"id": "59381aa4209e_func_index_todos", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\todo_index.py", "content": "def index_todos(root: Path = None) -> Dict:\n    \"\"\"Build TODO index and save to disk.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    Console.info(f\"Scanning for TODOs in {root}...\")\n\n    exclude = ['node_modules', 'venv', '.venv', '__pycache__', '.git', 'vendor']\n    todos = scan_project(root, exclude)\n\n    # Build index\n    index = {\n        \"total\": len(todos),\n        \"by_type\": {},\n        \"by_priority\": {1: 0, 2: 0, 3: 0},\n        \"by_file\": {},\n        \"items\": []\n    }\n\n    for todo in todos:\n        # Count by type\n        if todo.type not in index[\"by_type\"]:\n            index[\"by_type\"][todo.type] = 0\n        index[\"by_type\"][todo.type] += 1\n\n        # Count by priority\n        index[\"by_priority\"][todo.priority] += 1\n\n        # Count by file\n        if todo.file not in index[\"by_file\"]:\n            index[\"by_file\"][todo.file] = 0\n        index[\"by_file\"][todo.file] += 1\n\n        # Store item\n        index[\"items\"].append(asdict(todo))\n\n    # Save index\n    inde", "chunk_type": "function", "line_start": 162, "line_end": 206, "language": "python", "name": "index_todos"}, "59381aa4209e_func_main": {"id": "59381aa4209e_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\todo_index.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"TODO/FIXME Index\")\n\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n    root = find_project_root() or Path.cwd()\n\n    if '--index' in sys.argv:\n        index_todos(root)\n        return 0\n\n    # Scan and display\n    exclude = ['node_modules', 'venv', '.venv', '__pycache__', '.git', 'vendor']\n    todos = scan_project(root, exclude)\n\n    if not todos:\n        Console.ok(\"No TODOs found!\")\n        return 0\n\n    # Filter by priority\n    if '--high' in sys.argv or '--priority' in sys.argv:\n        todos = [t for t in todos if t.priority == 1]\n\n    # Filter by type\n    for todo_type in ['TODO', 'FIXME', 'HACK', 'NOTE']:\n        if f'--{todo_type.lower()}' in sys.argv:\n            todos = [t for t in todos if t.type == todo_type]\n\n    # Group by priority\n    by_priority = group_by_priority(todos)\n\n    # Display\n    priority_names = {1: 'HIGH', 2: 'MEDIUM', 3: 'LOW'}\n    priority_colors = {1: '\\033[91m', 2: '\\033[93m', 3: ", "chunk_type": "function", "line_start": 209, "line_end": 255, "language": "python", "name": "main"}, "59381aa4209e_class_TodoItem": {"id": "59381aa4209e_class_TodoItem", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\todo_index.py", "content": "class TodoItem:\n    \"\"\"A TODO/FIXME item.\"\"\"\n    type: str  # TODO, FIXME, HACK, XXX, NOTE\n    message: str\n    file: str\n    line: int\n    author: Optional[str] = None\n    priority: int = 2  # 1=high, 2=medium, 3=low\n    context: str = \"\"", "chunk_type": "class", "line_start": 23, "line_end": 31, "language": "python", "name": "TodoItem"}, "459d8a387e89_file": {"id": "459d8a387e89_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\treesitter_utils.py", "content": "\"\"\"\nTree-sitter Utilities\n=====================\nMulti-language code parsing using tree-sitter.\nSupports Python, JavaScript, TypeScript, Go, Rust, Java, C, C++, and more.\n\nUsage:\n    from scripts.treesitter_utils import parse_file, get_functions, get_classes\n\"\"\"\n\nimport sys\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Any, Iterator, Callable\nfrom dataclasses import dataclass, field\n\n# Try to import tree-sitter, fall back gracefully\ntry:\n    import tree_sitter\n    from tree_sitter import Language, Parser, Tree, Node\n    TREE_SITTER_AVAILABLE = True\nexcept ImportError:\n    TREE_SITTER_AVAILABLE = False\n    Tree = Any\n    Node = Any\n\nfrom .utils import Console\n\n\n@dataclass\nclass CodeItem:\n    \"\"\"A code item (function, class, etc).\"\"\"\n    name: str\n    item_type: str  # 'function', 'class', 'method', 'import', 'variable'\n    line_start: int\n    line_end: int\n    signature: str = \"\"\n    docstring: Optional[str] = None\n    language: str = \"\"\n    children: List['CodeItem'] = field(default_factory=list)\n\n\n@dataclass\nclass ParsedFile:\n    \"\"\"Result of parsing a file.\"\"\"\n    path: Path\n    language: str\n    tree: Optional[Any] = None\n    source: bytes = b\"\"\n    functions: List[CodeItem] = field(default_factory=list)\n    classes: List[CodeItem] = field(default_factory=list)\n    imports: List[str] = field(default_factory=list)\n    error: Optional[str] = None\n\n\n# Language detection by extension\nLANGUAGE_MAP = {\n    '.py': 'python',\n    '.js': 'javascript',\n    '.jsx': 'javascript',\n    '.ts': 'typescript',\n    '.tsx': 'typescript',\n    '.go': 'go',\n    '.rs': 'rust',\n    '.java': 'java',\n    '.c': 'c',\n    '.h': 'c',\n    '.cpp': 'cpp',\n    '.cc': 'cpp',\n    '.cxx': 'cpp',\n    '.hpp': 'cpp',\n    '.cs': 'c_sharp',\n    '.rb': 'ruby',\n    '.php': 'php',\n    '.swift': 'swift',\n    '.kt': 'kotlin',\n    '.scala': 'scala',\n    '.lua': 'lua',\n    '.sh': 'bash',\n    '.bash': 'bash',\n    '.json': 'json',\n    '.yaml': 'yaml',\n    '.yml': 'yaml',\n    '.html': 'html',\n    ", "chunk_type": "file", "line_start": 1, "line_end": 432, "language": "python", "name": "treesitter_utils.py"}, "459d8a387e89_func_detect_language": {"id": "459d8a387e89_func_detect_language", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\treesitter_utils.py", "content": "def detect_language(path: Path) -> Optional[str]:\n    \"\"\"Detect language from file extension.\"\"\"\n    return LANGUAGE_MAP.get(path.suffix.lower())", "chunk_type": "function", "line_start": 128, "line_end": 130, "language": "python", "name": "detect_language"}, "459d8a387e89_func_get_parser": {"id": "459d8a387e89_func_get_parser", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\treesitter_utils.py", "content": "def get_parser(language: str) -> Optional[Any]:\n    \"\"\"Get or create parser for language.\"\"\"\n    if not TREE_SITTER_AVAILABLE:\n        return None\n\n    if language in _parsers:\n        return _parsers[language]\n\n    try:\n        # Try to load language\n        import importlib\n        lang_module = importlib.import_module(f'tree_sitter_{language}')\n        if hasattr(lang_module, 'language'):\n            lang = Language(lang_module.language())\n            parser = Parser(lang)\n            _parsers[language] = parser\n            _languages[language] = lang\n            return parser\n    except ImportError:\n        pass\n    except Exception as e:\n        Console.warn(f\"Could not load tree-sitter-{language}: {e}\")\n\n    return None", "chunk_type": "function", "line_start": 133, "line_end": 156, "language": "python", "name": "get_parser"}, "459d8a387e89_func_parse_source": {"id": "459d8a387e89_func_parse_source", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\treesitter_utils.py", "content": "def parse_source(source: bytes, language: str) -> Optional[Tree]:\n    \"\"\"Parse source code into tree.\"\"\"\n    parser = get_parser(language)\n    if parser is None:\n        return None\n\n    return parser.parse(source)", "chunk_type": "function", "line_start": 159, "line_end": 165, "language": "python", "name": "parse_source"}, "459d8a387e89_func_parse_file": {"id": "459d8a387e89_func_parse_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\treesitter_utils.py", "content": "def parse_file(path: Path) -> ParsedFile:\n    \"\"\"Parse a source file.\"\"\"\n    result = ParsedFile(path=path, language=\"\")\n\n    # Detect language\n    language = detect_language(path)\n    if not language:\n        result.error = f\"Unknown language for {path.suffix}\"\n        return result\n\n    result.language = language\n\n    # Read file\n    try:\n        with open(path, 'rb') as f:\n            source = f.read()\n        result.source = source\n    except Exception as e:\n        result.error = f\"Could not read file: {e}\"\n        return result\n\n    # Parse with tree-sitter if available\n    if TREE_SITTER_AVAILABLE:\n        tree = parse_source(source, language)\n        if tree:\n            result.tree = tree\n            result.functions = extract_functions(tree, language, source)\n            result.classes = extract_classes(tree, language, source)\n            result.imports = extract_imports(tree, language, source)\n            return result\n\n    # Fallback to Python's ast for Python files\n    if ", "chunk_type": "function", "line_start": 168, "line_end": 203, "language": "python", "name": "parse_file"}, "459d8a387e89_func__parse_python_fallback": {"id": "459d8a387e89_func__parse_python_fallback", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\treesitter_utils.py", "content": "def _parse_python_fallback(path: Path, source: bytes, result: ParsedFile) -> ParsedFile:\n    \"\"\"Fallback parser for Python using stdlib ast.\"\"\"\n    import ast\n\n    try:\n        tree = ast.parse(source.decode('utf-8', errors='ignore'))\n\n        for node in ast.walk(tree):\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n                item = CodeItem(\n                    name=node.name,\n                    item_type='function',\n                    line_start=node.lineno,\n                    line_end=node.end_lineno or node.lineno,\n                    docstring=ast.get_docstring(node),\n                    language='python'\n                )\n                result.functions.append(item)\n\n            elif isinstance(node, ast.ClassDef):\n                item = CodeItem(\n                    name=node.name,\n                    item_type='class',\n                    line_start=node.lineno,\n                    line_end=node.end_lineno or node.lineno,\n                  ", "chunk_type": "function", "line_start": 206, "line_end": 247, "language": "python", "name": "_parse_python_fallback"}, "459d8a387e89_func_extract_functions": {"id": "459d8a387e89_func_extract_functions", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\treesitter_utils.py", "content": "def extract_functions(tree: Tree, language: str, source: bytes) -> List[CodeItem]:\n    \"\"\"Extract functions from tree.\"\"\"\n    functions = []\n    func_types = FUNCTION_TYPES.get(language, [])\n\n    def visit(node: Node):\n        if node.type in func_types:\n            name = _get_node_name(node, language)\n            if name:\n                item = CodeItem(\n                    name=name,\n                    item_type='function',\n                    line_start=node.start_point[0] + 1,\n                    line_end=node.end_point[0] + 1,\n                    signature=_get_signature(node, source),\n                    language=language\n                )\n                functions.append(item)\n\n        for child in node.children:\n            visit(child)\n\n    if tree and tree.root_node:\n        visit(tree.root_node)\n\n    return functions", "chunk_type": "function", "line_start": 250, "line_end": 275, "language": "python", "name": "extract_functions"}, "459d8a387e89_func_extract_classes": {"id": "459d8a387e89_func_extract_classes", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\treesitter_utils.py", "content": "def extract_classes(tree: Tree, language: str, source: bytes) -> List[CodeItem]:\n    \"\"\"Extract classes from tree.\"\"\"\n    classes = []\n    class_types = CLASS_TYPES.get(language, [])\n\n    def visit(node: Node):\n        if node.type in class_types:\n            name = _get_node_name(node, language)\n            if name:\n                item = CodeItem(\n                    name=name,\n                    item_type='class',\n                    line_start=node.start_point[0] + 1,\n                    line_end=node.end_point[0] + 1,\n                    language=language\n                )\n                classes.append(item)\n\n        for child in node.children:\n            visit(child)\n\n    if tree and tree.root_node:\n        visit(tree.root_node)\n\n    return classes", "chunk_type": "function", "line_start": 278, "line_end": 302, "language": "python", "name": "extract_classes"}, "459d8a387e89_func_extract_imports": {"id": "459d8a387e89_func_extract_imports", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\treesitter_utils.py", "content": "def extract_imports(tree: Tree, language: str, source: bytes) -> List[str]:\n    \"\"\"Extract imports from tree.\"\"\"\n    imports = []\n    import_types = IMPORT_TYPES.get(language, [])\n\n    def visit(node: Node):\n        if node.type in import_types:\n            # Get the import text\n            import_text = source[node.start_byte:node.end_byte].decode('utf-8', errors='ignore')\n            imports.append(import_text.strip())\n\n        for child in node.children:\n            visit(child)\n\n    if tree and tree.root_node:\n        visit(tree.root_node)\n\n    return imports", "chunk_type": "function", "line_start": 305, "line_end": 322, "language": "python", "name": "extract_imports"}, "459d8a387e89_func__get_node_name": {"id": "459d8a387e89_func__get_node_name", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\treesitter_utils.py", "content": "def _get_node_name(node: Node, language: str) -> Optional[str]:\n    \"\"\"Extract name from node.\"\"\"\n    # Look for identifier child\n    for child in node.children:\n        if child.type in ('identifier', 'name', 'property_identifier'):\n            return child.text.decode('utf-8', errors='ignore')\n    return None", "chunk_type": "function", "line_start": 325, "line_end": 331, "language": "python", "name": "_get_node_name"}, "459d8a387e89_func__get_signature": {"id": "459d8a387e89_func__get_signature", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\treesitter_utils.py", "content": "def _get_signature(node: Node, source: bytes) -> str:\n    \"\"\"Get function/method signature.\"\"\"\n    # Get first line\n    start = node.start_byte\n    end = node.end_byte\n    text = source[start:end].decode('utf-8', errors='ignore')\n    first_line = text.split('\\n')[0]\n    return first_line[:100]", "chunk_type": "function", "line_start": 334, "line_end": 341, "language": "python", "name": "_get_signature"}, "459d8a387e89_func_walk_tree": {"id": "459d8a387e89_func_walk_tree", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\treesitter_utils.py", "content": "def walk_tree(tree: Tree, callback: Callable[[Node], None]):\n    \"\"\"Walk entire tree calling callback on each node.\"\"\"\n    def visit(node: Node):\n        callback(node)\n        for child in node.children:\n            visit(child)\n\n    if tree and tree.root_node:\n        visit(tree.root_node)", "chunk_type": "function", "line_start": 344, "line_end": 352, "language": "python", "name": "walk_tree"}, "459d8a387e89_func_find_nodes": {"id": "459d8a387e89_func_find_nodes", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\treesitter_utils.py", "content": "def find_nodes(tree: Tree, node_types: List[str]) -> List[Node]:\n    \"\"\"Find all nodes of given types.\"\"\"\n    results = []\n\n    def visit(node: Node):\n        if node.type in node_types:\n            results.append(node)\n        for child in node.children:\n            visit(child)\n\n    if tree and tree.root_node:\n        visit(tree.root_node)\n\n    return results", "chunk_type": "function", "line_start": 355, "line_end": 368, "language": "python", "name": "find_nodes"}, "459d8a387e89_func_get_node_text": {"id": "459d8a387e89_func_get_node_text", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\treesitter_utils.py", "content": "def get_node_text(node: Node, source: bytes) -> str:\n    \"\"\"Get text content of node.\"\"\"\n    return source[node.start_byte:node.end_byte].decode('utf-8', errors='ignore')", "chunk_type": "function", "line_start": 371, "line_end": 373, "language": "python", "name": "get_node_text"}, "459d8a387e89_func_supported_languages": {"id": "459d8a387e89_func_supported_languages", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\treesitter_utils.py", "content": "def supported_languages() -> List[str]:\n    \"\"\"Get list of supported languages.\"\"\"\n    return list(LANGUAGE_MAP.values())", "chunk_type": "function", "line_start": 376, "line_end": 378, "language": "python", "name": "supported_languages"}, "459d8a387e89_func_is_tree_sitter_available": {"id": "459d8a387e89_func_is_tree_sitter_available", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\treesitter_utils.py", "content": "def is_tree_sitter_available() -> bool:\n    \"\"\"Check if tree-sitter is available.\"\"\"\n    return TREE_SITTER_AVAILABLE", "chunk_type": "function", "line_start": 381, "line_end": 383, "language": "python", "name": "is_tree_sitter_available"}, "459d8a387e89_func_main": {"id": "459d8a387e89_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\treesitter_utils.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Tree-sitter Utilities\")\n\n    if not TREE_SITTER_AVAILABLE:\n        Console.warn(\"tree-sitter not installed, using Python ast fallback\")\n    else:\n        Console.ok(\"tree-sitter available\")\n\n    # Parse arguments\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n\n    if not args:\n        Console.info(\"Supported languages:\")\n        for ext, lang in sorted(LANGUAGE_MAP.items()):\n            Console.info(f\"  {ext} -> {lang}\")\n        return 0\n\n    path = Path(args[0])\n    if not path.exists():\n        Console.fail(f\"File not found: {path}\")\n        return 1\n\n    result = parse_file(path)\n\n    print(f\"\\nFile: {result.path}\")\n    print(f\"Language: {result.language}\")\n    print(f\"Functions: {len(result.functions)}\")\n    print(f\"Classes: {len(result.classes)}\")\n    print(f\"Imports: {len(result.imports)}\")\n\n    if result.functions:\n        print(\"\\n## Functions\")\n        for f in result.functions[:10]:\n            print(f\"", "chunk_type": "function", "line_start": 386, "line_end": 427, "language": "python", "name": "main"}, "459d8a387e89_func_visit": {"id": "459d8a387e89_func_visit", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\treesitter_utils.py", "content": "    def visit(node: Node):\n        if node.type in node_types:\n            results.append(node)\n        for child in node.children:\n            visit(child)", "chunk_type": "function", "line_start": 359, "line_end": 363, "language": "python", "name": "visit"}, "459d8a387e89_class_CodeItem": {"id": "459d8a387e89_class_CodeItem", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\treesitter_utils.py", "content": "class CodeItem:\n    \"\"\"A code item (function, class, etc).\"\"\"\n    name: str\n    item_type: str  # 'function', 'class', 'method', 'import', 'variable'\n    line_start: int\n    line_end: int\n    signature: str = \"\"\n    docstring: Optional[str] = None\n    language: str = \"\"\n    children: List['CodeItem'] = field(default_factory=list)", "chunk_type": "class", "line_start": 30, "line_end": 39, "language": "python", "name": "CodeItem"}, "459d8a387e89_class_ParsedFile": {"id": "459d8a387e89_class_ParsedFile", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\treesitter_utils.py", "content": "class ParsedFile:\n    \"\"\"Result of parsing a file.\"\"\"\n    path: Path\n    language: str\n    tree: Optional[Any] = None\n    source: bytes = b\"\"\n    functions: List[CodeItem] = field(default_factory=list)\n    classes: List[CodeItem] = field(default_factory=list)\n    imports: List[str] = field(default_factory=list)\n    error: Optional[str] = None", "chunk_type": "class", "line_start": 43, "line_end": 52, "language": "python", "name": "ParsedFile"}, "5a5ec12a1a9b_file": {"id": "5a5ec12a1a9b_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\trigger_loop.py", "content": "\"\"\"\nAuto-Dev Loop Trigger\n=====================\nTriggers the autonomous development loop if enabled by the user.\n\"\"\"\n\nfrom pathlib import Path\nimport sys\n\nfrom .utils import Console, find_project_root\nimport config.loop_config as loop_config\n\ndef main():\n    \"\"\"Check config and trigger loop if enabled.\"\"\"\n    if not loop_config.ENABLE_AUTO_LOOP:\n        Console.info(\"Auto-Dev Loop: Disabled (User controllable via mcp-global-rules/config/loop_config.py)\")\n        return 0\n\n    # Locate the prompt file\n    root = find_project_root() or Path.cwd()\n    # Check standard location first\n    prompt_path = root / \"mcp-global-rules\" / \"prompts\" / \"auto_dev.md\"\n\n    if not prompt_path.exists():\n        # Fallback to the user's legacy temp file as requested (but preferring permanent)\n        fallback = root / \"ai-script-to-make-it-continue-development.md\"\n        if fallback.exists():\n            prompt_path = fallback\n        else:\n            Console.warn(\"Auto-Dev Loop: Enabled but prompt file not found.\")\n            return 1\n\n    try:\n        content = prompt_path.read_text(encoding='utf-8').strip()\n        Console.header(\"AUTO-DEV LOOP TRIGGERED\")\n        print(\"\\n\" + \"=\"*40)\n        print(\">>> INJECTION START >>>\")\n        print(content)\n        print(\"<<< INJECTION END <<<\")\n        print(\"=\"*40 + \"\\n\")\n        Console.ok(\"Prompt sent to agent stream.\")\n    except Exception as e:\n        Console.fail(f\"Failed to read prompt: {e}\")\n        return 1\n\n    return 0\n\nif __name__ == \"__main__\":\n    sys.exit(main())\n", "chunk_type": "file", "line_start": 1, "line_end": 50, "language": "python", "name": "trigger_loop.py"}, "5a5ec12a1a9b_func_main": {"id": "5a5ec12a1a9b_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\trigger_loop.py", "content": "def main():\n    \"\"\"Check config and trigger loop if enabled.\"\"\"\n    if not loop_config.ENABLE_AUTO_LOOP:\n        Console.info(\"Auto-Dev Loop: Disabled (User controllable via mcp-global-rules/config/loop_config.py)\")\n        return 0\n\n    # Locate the prompt file\n    root = find_project_root() or Path.cwd()\n    # Check standard location first\n    prompt_path = root / \"mcp-global-rules\" / \"prompts\" / \"auto_dev.md\"\n\n    if not prompt_path.exists():\n        # Fallback to the user's legacy temp file as requested (but preferring permanent)\n        fallback = root / \"ai-script-to-make-it-continue-development.md\"\n        if fallback.exists():\n            prompt_path = fallback\n        else:\n            Console.warn(\"Auto-Dev Loop: Enabled but prompt file not found.\")\n            return 1\n\n    try:\n        content = prompt_path.read_text(encoding='utf-8').strip()\n        Console.header(\"AUTO-DEV LOOP TRIGGERED\")\n        print(\"\\n\" + \"=\"*40)\n        print(\">>> INJECTION START >>>\")\n        print", "chunk_type": "function", "line_start": 13, "line_end": 46, "language": "python", "name": "main"}, "1ca90d2b9f5a_file": {"id": "1ca90d2b9f5a_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "\"\"\"\nMCP Global Rules - Shared Utilities\n====================================\nCore utility functions used by all AI agent enhancement tools.\n\nPython 3.11+ compatible, uses only stdlib.\n\"\"\"\n\nfrom dataclasses import dataclass, field\nfrom datetime import datetime\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Any, Iterator, Tuple\nimport ast\nimport json\nimport os\nimport subprocess\n\n\n# =============================================================================\n# DATA CLASSES\n# =============================================================================\n\n@dataclass\nclass FunctionInfo:\n    \"\"\"Information about a Python function.\"\"\"\n    name: str\n    lineno: int\n    end_lineno: int\n    args: List[str]\n    arg_types: Dict[str, str]\n    return_type: Optional[str]\n    docstring: Optional[str]\n    is_async: bool = False\n    is_method: bool = False\n    decorators: List[str] = field(default_factory=list)\n\n\n@dataclass\nclass ClassInfo:\n    \"\"\"Information about a Python class.\"\"\"\n    name: str\n    lineno: int\n    end_lineno: int\n    docstring: Optional[str]\n    methods: List[FunctionInfo] = field(default_factory=list)\n    bases: List[str] = field(default_factory=list)\n    decorators: List[str] = field(default_factory=list)\n\n\n@dataclass\nclass ModuleInfo:\n    \"\"\"Information about a Python module.\"\"\"\n    path: Path\n    docstring: Optional[str]\n    imports: List[str] = field(default_factory=list)\n    from_imports: List[Tuple[str, List[str]]] = field(default_factory=list)\n    functions: List[FunctionInfo] = field(default_factory=list)\n    classes: List[ClassInfo] = field(default_factory=list)\n    global_vars: List[str] = field(default_factory=list)\n\n\n@dataclass\nclass GitCommit:\n    \"\"\"Information about a git commit.\"\"\"\n    hash: str\n    short_hash: str\n    author: str\n    date: str\n    message: str\n    body: str = \"\"\n    files_changed: List[str] = field(default_factory=list)\n\n\n# =============================================================================\n# FILE DISC", "chunk_type": "file", "line_start": 1, "line_end": 659, "language": "python", "name": "utils.py"}, "1ca90d2b9f5a_func_find_python_files": {"id": "1ca90d2b9f5a_func_find_python_files", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "def find_python_files(\n    root: Path,\n    exclude_patterns: List[str] = None\n) -> Iterator[Path]:\n    \"\"\"\n    Find all Python files in a directory tree.\n\n    Args:\n        root: Root directory to search\n        exclude_patterns: Patterns to exclude (e.g., ['__pycache__', '.venv'])\n\n    Yields:\n        Path objects for each Python file found\n    \"\"\"\n    if exclude_patterns is None:\n        exclude_patterns = [\n            '__pycache__', '.venv', 'venv', '.git', 'node_modules',\n            '.eggs', '*.egg-info', 'dist', 'build', '.tox', '.pytest_cache'\n        ]\n\n    root = Path(root)\n    if not root.exists():\n        return\n\n    for item in root.rglob('*.py'):\n        # Check if any parent directory matches exclude patterns\n        skip = False\n        for part in item.parts:\n            for pattern in exclude_patterns:\n                if pattern.startswith('*'):\n                    if part.endswith(pattern[1:]):\n                        skip = True\n                        break\n       ", "chunk_type": "function", "line_start": 78, "line_end": 118, "language": "python", "name": "find_python_files"}, "1ca90d2b9f5a_func_find_project_root": {"id": "1ca90d2b9f5a_func_find_project_root", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "def find_project_root(start: Path = None) -> Optional[Path]:\n    \"\"\"\n    Find the project root by looking for common markers.\n\n    Args:\n        start: Starting directory (defaults to cwd)\n\n    Returns:\n        Project root path or None\n    \"\"\"\n    # 1. Try environment variable set by mcp.py\n    mcp_root_env = os.environ.get('MCP_ROOT')\n\n    if start is None:\n        start = Path.cwd()\n\n    markers = ['.git', 'pyproject.toml', 'setup.py', 'setup.cfg', '.mcp']\n\n    # helper to check markers\n    def check_dir(d: Path) -> bool:\n        for marker in markers:\n            if (d / marker).exists():\n                return True\n        return False\n\n    # A. Search up from the MCP package location first (Strongest signal)\n    # If mcp-global-rules is inside a project, that's likely the project we want.\n    if mcp_root_env:\n        mcp_root = Path(mcp_root_env).resolve()\n\n        # Check parent of mcp-global-rules (common case)\n        if check_dir(mcp_root.parent):\n            return mcp_root.", "chunk_type": "function", "line_start": 121, "line_end": 176, "language": "python", "name": "find_project_root"}, "1ca90d2b9f5a_func_get_package_root": {"id": "1ca90d2b9f5a_func_get_package_root", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "def get_package_root() -> Path:\n    \"\"\"Get the absolute path to the mcp-global-rules package directory.\"\"\"\n    mcp_root_env = os.environ.get('MCP_ROOT')\n    if mcp_root_env:\n        return Path(mcp_root_env).resolve()\n\n    # Fallback to __file__ resolution\n    return Path(__file__).resolve().parent.parent", "chunk_type": "function", "line_start": 179, "line_end": 186, "language": "python", "name": "get_package_root"}, "1ca90d2b9f5a_func_parse_file": {"id": "1ca90d2b9f5a_func_parse_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "def parse_file(path: Path) -> Optional[ast.Module]:\n    \"\"\"\n    Parse a Python file into an AST.\n\n    Args:\n        path: Path to Python file\n\n    Returns:\n        AST module or None if parsing fails\n    \"\"\"\n    try:\n        with open(path, 'r', encoding='utf-8') as f:\n            source = f.read()\n        return ast.parse(source, filename=str(path))\n    except (SyntaxError, UnicodeDecodeError, FileNotFoundError):\n        return None", "chunk_type": "function", "line_start": 193, "line_end": 208, "language": "python", "name": "parse_file"}, "1ca90d2b9f5a_func_get_type_annotation": {"id": "1ca90d2b9f5a_func_get_type_annotation", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "def get_type_annotation(node: ast.expr) -> str:\n    \"\"\"Convert an AST type annotation to a string.\"\"\"\n    if node is None:\n        return \"\"\n\n    if isinstance(node, ast.Name):\n        return node.id\n    elif isinstance(node, ast.Constant):\n        return repr(node.value)\n    elif isinstance(node, ast.Subscript):\n        base = get_type_annotation(node.value)\n        if isinstance(node.slice, ast.Tuple):\n            args = ', '.join(get_type_annotation(e) for e in node.slice.elts)\n        else:\n            args = get_type_annotation(node.slice)\n        return f\"{base}[{args}]\"\n    elif isinstance(node, ast.Attribute):\n        return f\"{get_type_annotation(node.value)}.{node.attr}\"\n    elif isinstance(node, ast.BinOp) and isinstance(node.op, ast.BitOr):\n        # Union type with | operator\n        left = get_type_annotation(node.left)\n        right = get_type_annotation(node.right)\n        return f\"{left} | {right}\"\n    else:\n        return ast.unparse(node) if hasattr(ast, 'unparse') e", "chunk_type": "function", "line_start": 211, "line_end": 235, "language": "python", "name": "get_type_annotation"}, "1ca90d2b9f5a_func_extract_function_info": {"id": "1ca90d2b9f5a_func_extract_function_info", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "def extract_function_info(node: ast.FunctionDef | ast.AsyncFunctionDef) -> FunctionInfo:\n    \"\"\"\n    Extract information from a function definition node.\n\n    Args:\n        node: AST function definition node\n\n    Returns:\n        FunctionInfo dataclass\n    \"\"\"\n    # Get arguments\n    args = []\n    arg_types = {}\n\n    for arg in node.args.args:\n        arg_name = arg.arg\n        args.append(arg_name)\n        if arg.annotation:\n            arg_types[arg_name] = get_type_annotation(arg.annotation)\n\n    # Get return type\n    return_type = None\n    if node.returns:\n        return_type = get_type_annotation(node.returns)\n\n    # Get docstring\n    docstring = ast.get_docstring(node)\n\n    # Get decorators\n    decorators = []\n    for dec in node.decorator_list:\n        if isinstance(dec, ast.Name):\n            decorators.append(dec.id)\n        elif isinstance(dec, ast.Attribute):\n            decorators.append(f\"{get_type_annotation(dec.value)}.{dec.attr}\")\n        elif isinstance(dec, ast.Call):", "chunk_type": "function", "line_start": 238, "line_end": 289, "language": "python", "name": "extract_function_info"}, "1ca90d2b9f5a_func_extract_class_info": {"id": "1ca90d2b9f5a_func_extract_class_info", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "def extract_class_info(node: ast.ClassDef) -> ClassInfo:\n    \"\"\"\n    Extract information from a class definition node.\n\n    Args:\n        node: AST class definition node\n\n    Returns:\n        ClassInfo dataclass\n    \"\"\"\n    # Get methods\n    methods = []\n    for item in node.body:\n        if isinstance(item, (ast.FunctionDef, ast.AsyncFunctionDef)):\n            func_info = extract_function_info(item)\n            func_info.is_method = True\n            methods.append(func_info)\n\n    # Get base classes\n    bases = [get_type_annotation(base) for base in node.bases]\n\n    # Get decorators\n    decorators = []\n    for dec in node.decorator_list:\n        if isinstance(dec, ast.Name):\n            decorators.append(dec.id)\n\n    return ClassInfo(\n        name=node.name,\n        lineno=node.lineno,\n        end_lineno=node.end_lineno or node.lineno,\n        docstring=ast.get_docstring(node),\n        methods=methods,\n        bases=bases,\n        decorators=decorators\n    )", "chunk_type": "function", "line_start": 292, "line_end": 327, "language": "python", "name": "extract_class_info"}, "1ca90d2b9f5a_func_analyze_module": {"id": "1ca90d2b9f5a_func_analyze_module", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "def analyze_module(path: Path) -> Optional[ModuleInfo]:\n    \"\"\"\n    Analyze a Python module and extract all information.\n\n    Args:\n        path: Path to Python file\n\n    Returns:\n        ModuleInfo dataclass or None if parsing fails\n    \"\"\"\n    tree = parse_file(path)\n    if tree is None:\n        return None\n\n    info = ModuleInfo(\n        path=path,\n        docstring=ast.get_docstring(tree)\n    )\n\n    for node in ast.walk(tree):\n        # Imports\n        if isinstance(node, ast.Import):\n            for alias in node.names:\n                info.imports.append(alias.name)\n        elif isinstance(node, ast.ImportFrom):\n            if node.module:\n                names = [alias.name for alias in node.names]\n                info.from_imports.append((node.module, names))\n\n    # Top-level items only\n    for node in tree.body:\n        if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n            info.functions.append(extract_function_info(node))\n        elif isinstance(node, ast.", "chunk_type": "function", "line_start": 330, "line_end": 370, "language": "python", "name": "analyze_module"}, "1ca90d2b9f5a_func_run_git_command": {"id": "1ca90d2b9f5a_func_run_git_command", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "def run_git_command(args: List[str], cwd: Path = None) -> Optional[str]:\n    \"\"\"\n    Run a git command and return output.\n\n    Args:\n        args: Git command arguments\n        cwd: Working directory\n\n    Returns:\n        Command output or None if failed\n    \"\"\"\n    try:\n        result = subprocess.run(\n            ['git'] + args,\n            capture_output=True,\n            text=True,\n            cwd=cwd or Path.cwd(),\n            timeout=30\n        )\n        if result and result.returncode == 0:\n            return (result.stdout or \"\").strip()\n        return None\n    except Exception:\n        return None", "chunk_type": "function", "line_start": 377, "line_end": 400, "language": "python", "name": "run_git_command"}, "1ca90d2b9f5a_func_get_git_log": {"id": "1ca90d2b9f5a_func_get_git_log", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "def get_git_log(\n    count: int = 50,\n    cwd: Path = None\n) -> List[GitCommit]:\n    \"\"\"\n    Get recent git commits.\n\n    Args:\n        count: Number of commits to retrieve\n        cwd: Working directory\n\n    Returns:\n        List of GitCommit objects\n    \"\"\"\n    # Use a delimiter that won't appear in commit messages\n    delimiter = \"---COMMIT_DELIMITER---\"\n    format_str = f\"%H{delimiter}%h{delimiter}%an{delimiter}%ai{delimiter}%s{delimiter}%b\"\n\n    output = run_git_command(\n        ['log', f'-{count}', f'--format={format_str}'],\n        cwd=cwd\n    )\n\n    if not output:\n        return []\n\n    commits = []\n    for entry in output.split('\\n'):\n        if not entry.strip():\n            continue\n\n        parts = entry.split(delimiter)\n        if len(parts) >= 5:\n            commits.append(GitCommit(\n                hash=parts[0],\n                short_hash=parts[1],\n                author=parts[2],\n                date=parts[3],\n                message=parts[4],\n                body=part", "chunk_type": "function", "line_start": 403, "line_end": 445, "language": "python", "name": "get_git_log"}, "1ca90d2b9f5a_func_get_changed_files": {"id": "1ca90d2b9f5a_func_get_changed_files", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "def get_changed_files(since_commit: str = \"HEAD~1\", cwd: Path = None) -> List[str]:\n    \"\"\"\n    Get list of files changed since a commit.\n\n    Args:\n        since_commit: Git reference to compare against\n        cwd: Working directory\n\n    Returns:\n        List of changed file paths\n    \"\"\"\n    output = run_git_command(\n        ['diff', '--name-only', since_commit],\n        cwd=cwd\n    )\n\n    if not output:\n        return []\n\n    return [f for f in output.split('\\n') if f.strip()]", "chunk_type": "function", "line_start": 448, "line_end": 467, "language": "python", "name": "get_changed_files"}, "1ca90d2b9f5a_func_get_staged_files": {"id": "1ca90d2b9f5a_func_get_staged_files", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "def get_staged_files(cwd: Path = None) -> List[str]:\n    \"\"\"Get list of staged files.\"\"\"\n    output = run_git_command(['diff', '--cached', '--name-only'], cwd=cwd)\n    return [f for f in (output or '').split('\\n') if f.strip()]", "chunk_type": "function", "line_start": 470, "line_end": 473, "language": "python", "name": "get_staged_files"}, "1ca90d2b9f5a_func_format_as_json": {"id": "1ca90d2b9f5a_func_format_as_json", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "def format_as_json(data: Any, indent: int = 2) -> str:\n    \"\"\"Format data as JSON string.\"\"\"\n    def default_serializer(obj):\n        if isinstance(obj, Path):\n            return str(obj)\n        if hasattr(obj, '__dataclass_fields__'):\n            return {k: getattr(obj, k) for k in obj.__dataclass_fields__}\n        raise TypeError(f\"Object of type {type(obj)} is not JSON serializable\")\n\n    return json.dumps(data, indent=indent, default=default_serializer)", "chunk_type": "function", "line_start": 480, "line_end": 489, "language": "python", "name": "format_as_json"}, "1ca90d2b9f5a_func_format_as_markdown_table": {"id": "1ca90d2b9f5a_func_format_as_markdown_table", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "def format_as_markdown_table(\n    headers: List[str],\n    rows: List[List[str]]\n) -> str:\n    \"\"\"Format data as a Markdown table.\"\"\"\n    if not headers or not rows:\n        return \"\"\n\n    # Calculate column widths\n    widths = [len(h) for h in headers]\n    for row in rows:\n        for i, cell in enumerate(row):\n            if i < len(widths):\n                widths[i] = max(widths[i], len(str(cell)))\n\n    # Format header\n    header_row = \"| \" + \" | \".join(h.ljust(widths[i]) for i, h in enumerate(headers)) + \" |\"\n    separator = \"|\" + \"|\".join(\"-\" * (w + 2) for w in widths) + \"|\"\n\n    # Format rows\n    data_rows = []\n    for row in rows:\n        cells = []\n        for i, cell in enumerate(row):\n            width = widths[i] if i < len(widths) else len(str(cell))\n            cells.append(str(cell).ljust(width))\n        data_rows.append(\"| \" + \" | \".join(cells) + \" |\")\n\n    return \"\\n\".join([header_row, separator] + data_rows)", "chunk_type": "function", "line_start": 492, "line_end": 520, "language": "python", "name": "format_as_markdown_table"}, "1ca90d2b9f5a_func_get_mcp_data_dir": {"id": "1ca90d2b9f5a_func_get_mcp_data_dir", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "def get_mcp_data_dir() -> Optional[Path]:\n    \"\"\"Find the .mcp directory.\"\"\"\n    project_root = find_project_root()\n    if project_root:\n        mcp_dir = project_root / '.mcp'\n        if mcp_dir.exists():\n            return mcp_dir\n    return None", "chunk_type": "function", "line_start": 527, "line_end": 534, "language": "python", "name": "get_mcp_data_dir"}, "1ca90d2b9f5a_func_record_to_memory": {"id": "1ca90d2b9f5a_func_record_to_memory", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "def record_to_memory(\n    entry_type: str,\n    content: str,\n    tags: List[str] = None,\n    metadata: Dict[str, Any] = None\n) -> bool:\n    \"\"\"\n    Record an entry to MCP memory.\n\n    Args:\n        entry_type: Type of entry (action, decision, todo, etc.)\n        content: Content of the entry\n        tags: Optional tags\n        metadata: Optional metadata\n\n    Returns:\n        True if successful\n    \"\"\"\n    mcp_data = get_mcp_data_dir()\n    if not mcp_data:\n        return False\n\n    memory_dir = mcp_data / 'memory'\n    if not memory_dir.exists():\n        memory_dir.mkdir(parents=True)\n\n    # Map entry types to files\n    type_files = {\n        'action': 'actions.json',\n        'decision': 'decisions.json',\n        'todo': 'todos.json',\n        'milestone': 'milestones.json',\n        'session': 'sessions.json'\n    }\n\n    filename = type_files.get(entry_type, 'actions.json')\n    filepath = memory_dir / filename\n\n    # Load existing entries\n    entries = []\n    if filepath.exists():\n       ", "chunk_type": "function", "line_start": 537, "line_end": 602, "language": "python", "name": "record_to_memory"}, "1ca90d2b9f5a_func_check_dir": {"id": "1ca90d2b9f5a_func_check_dir", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "    def check_dir(d: Path) -> bool:\n        for marker in markers:\n            if (d / marker).exists():\n                return True\n        return False", "chunk_type": "function", "line_start": 140, "line_end": 144, "language": "python", "name": "check_dir"}, "1ca90d2b9f5a_func_default_serializer": {"id": "1ca90d2b9f5a_func_default_serializer", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "    def default_serializer(obj):\n        if isinstance(obj, Path):\n            return str(obj)\n        if hasattr(obj, '__dataclass_fields__'):\n            return {k: getattr(obj, k) for k in obj.__dataclass_fields__}\n        raise TypeError(f\"Object of type {type(obj)} is not JSON serializable\")", "chunk_type": "function", "line_start": 482, "line_end": 487, "language": "python", "name": "default_serializer"}, "1ca90d2b9f5a_func__supports_color": {"id": "1ca90d2b9f5a_func__supports_color", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "    def _supports_color(cls) -> bool:\n        \"\"\"Check if terminal supports color.\"\"\"\n        import sys\n        return hasattr(sys.stdout, 'isatty') and sys.stdout.isatty()", "chunk_type": "function", "line_start": 623, "line_end": 626, "language": "python", "name": "_supports_color"}, "1ca90d2b9f5a_func__color": {"id": "1ca90d2b9f5a_func__color", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "    def _color(cls, text: str, color: str) -> str:\n        \"\"\"Apply color to text.\"\"\"\n        if not cls._supports_color():\n            return text\n        return f\"{cls.COLORS.get(color, '')}{text}{cls.COLORS['reset']}\"", "chunk_type": "function", "line_start": 629, "line_end": 633, "language": "python", "name": "_color"}, "1ca90d2b9f5a_func_info": {"id": "1ca90d2b9f5a_func_info", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "    def info(cls, msg: str):\n        \"\"\"Print info message.\"\"\"\n        print(f\"{cls._color('[INFO]', 'blue')} {msg}\")", "chunk_type": "function", "line_start": 636, "line_end": 638, "language": "python", "name": "info"}, "1ca90d2b9f5a_func_ok": {"id": "1ca90d2b9f5a_func_ok", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "    def ok(cls, msg: str):\n        \"\"\"Print success message.\"\"\"\n        print(f\"{cls._color('[OK]', 'green')} {msg}\")", "chunk_type": "function", "line_start": 641, "line_end": 643, "language": "python", "name": "ok"}, "1ca90d2b9f5a_func_warn": {"id": "1ca90d2b9f5a_func_warn", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "    def warn(cls, msg: str):\n        \"\"\"Print warning message.\"\"\"\n        print(f\"{cls._color('[WARNING]', 'yellow')} {msg}\")", "chunk_type": "function", "line_start": 646, "line_end": 648, "language": "python", "name": "warn"}, "1ca90d2b9f5a_func_fail": {"id": "1ca90d2b9f5a_func_fail", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "    def fail(cls, msg: str):\n        \"\"\"Print failure message.\"\"\"\n        print(f\"{cls._color('[FAIL]', 'red')} {msg}\")", "chunk_type": "function", "line_start": 651, "line_end": 653, "language": "python", "name": "fail"}, "1ca90d2b9f5a_func_header": {"id": "1ca90d2b9f5a_func_header", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "    def header(cls, msg: str):\n        \"\"\"Print header.\"\"\"\n        print(f\"\\n{cls._color('=== ' + msg + ' ===', 'cyan')}\\n\")", "chunk_type": "function", "line_start": 656, "line_end": 658, "language": "python", "name": "header"}, "1ca90d2b9f5a_class_FunctionInfo": {"id": "1ca90d2b9f5a_class_FunctionInfo", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "class FunctionInfo:\n    \"\"\"Information about a Python function.\"\"\"\n    name: str\n    lineno: int\n    end_lineno: int\n    args: List[str]\n    arg_types: Dict[str, str]\n    return_type: Optional[str]\n    docstring: Optional[str]\n    is_async: bool = False\n    is_method: bool = False\n    decorators: List[str] = field(default_factory=list)", "chunk_type": "class", "line_start": 24, "line_end": 35, "language": "python", "name": "FunctionInfo"}, "1ca90d2b9f5a_class_ClassInfo": {"id": "1ca90d2b9f5a_class_ClassInfo", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "class ClassInfo:\n    \"\"\"Information about a Python class.\"\"\"\n    name: str\n    lineno: int\n    end_lineno: int\n    docstring: Optional[str]\n    methods: List[FunctionInfo] = field(default_factory=list)\n    bases: List[str] = field(default_factory=list)\n    decorators: List[str] = field(default_factory=list)", "chunk_type": "class", "line_start": 39, "line_end": 47, "language": "python", "name": "ClassInfo"}, "1ca90d2b9f5a_class_ModuleInfo": {"id": "1ca90d2b9f5a_class_ModuleInfo", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "class ModuleInfo:\n    \"\"\"Information about a Python module.\"\"\"\n    path: Path\n    docstring: Optional[str]\n    imports: List[str] = field(default_factory=list)\n    from_imports: List[Tuple[str, List[str]]] = field(default_factory=list)\n    functions: List[FunctionInfo] = field(default_factory=list)\n    classes: List[ClassInfo] = field(default_factory=list)\n    global_vars: List[str] = field(default_factory=list)", "chunk_type": "class", "line_start": 51, "line_end": 59, "language": "python", "name": "ModuleInfo"}, "1ca90d2b9f5a_class_GitCommit": {"id": "1ca90d2b9f5a_class_GitCommit", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "class GitCommit:\n    \"\"\"Information about a git commit.\"\"\"\n    hash: str\n    short_hash: str\n    author: str\n    date: str\n    message: str\n    body: str = \"\"\n    files_changed: List[str] = field(default_factory=list)", "chunk_type": "class", "line_start": 63, "line_end": 71, "language": "python", "name": "GitCommit"}, "1ca90d2b9f5a_class_Console": {"id": "1ca90d2b9f5a_class_Console", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "class Console:\n    \"\"\"Simple console output with colors.\"\"\"\n\n    COLORS = {\n        'red': '\\033[0;31m',\n        'green': '\\033[0;32m',\n        'yellow': '\\033[1;33m',\n        'blue': '\\033[0;34m',\n        'cyan': '\\033[0;36m',\n        'bold': '\\033[1m',\n        'reset': '\\033[0m'\n    }\n\n    @classmethod\n    def _supports_color(cls) -> bool:\n        \"\"\"Check if terminal supports color.\"\"\"\n        import sys\n        return hasattr(sys.stdout, 'isatty') and sys.stdout.isatty()\n\n    @classmethod\n    def _color(cls, text: str, color: str) -> str:\n        \"\"\"Apply color to text.\"\"\"\n        if not cls._supports_color():\n            return text\n        return f\"{cls.COLORS.get(color, '')}{text}{cls.COLORS['reset']}\"\n\n    @classmethod\n    def info(cls, msg: str):\n        \"\"\"Print info message.\"\"\"\n        print(f\"{cls._color('[INFO]', 'blue')} {msg}\")\n\n    @classmethod\n    def ok(cls, msg: str):\n        \"\"\"Print success message.\"\"\"\n        print(f\"{cls._color('[OK]', 'green')} {msg}\")\n\n    @cla", "chunk_type": "class", "line_start": 609, "line_end": 658, "language": "python", "name": "Console"}, "2e186fb57b6b_file": {"id": "2e186fb57b6b_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\vector_store.py", "content": "\"\"\"\nVector Store\n=============\nLocal FAISS-based vector database for semantic code search.\n\nUsage:\n    from scripts.vector_store import VectorStore\n\n    store = VectorStore(path)\n    store.index_codebase(root)\n    results = store.search(\"authentication handler\", k=10)\n\"\"\"\n\nimport json\nimport sys\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Tuple\nfrom dataclasses import dataclass, field, asdict\nimport hashlib\n\nfrom .utils import Console, find_python_files, find_project_root\nfrom .embeddings import embed_text, embed_texts, cosine_similarity, embedding_dimension\n\n\n# Try to import FAISS\ntry:\n    import faiss\n    FAISS_AVAILABLE = True\nexcept ImportError:\n    FAISS_AVAILABLE = False\n\n# Try numpy\ntry:\n    import numpy as np\n    NUMPY_AVAILABLE = True\nexcept ImportError:\n    NUMPY_AVAILABLE = False\n\n\n@dataclass\nclass CodeChunk:\n    \"\"\"A chunk of code with metadata.\"\"\"\n    id: str\n    path: str\n    content: str\n    chunk_type: str  # 'function', 'class', 'file', 'block'\n    line_start: int\n    line_end: int\n    language: str = \"\"\n    name: str = \"\"\n\n\n@dataclass\nclass SearchResult:\n    \"\"\"A search result.\"\"\"\n    chunk: CodeChunk\n    score: float\n    rank: int\n\n\nclass VectorStore:\n    \"\"\"Local vector store for semantic code search.\"\"\"\n\n    def __init__(self, index_path: Optional[Path] = None):\n        if index_path is None:\n            root = find_project_root() or Path.cwd()\n            self.index_path = root / \".mcp\" / \"vector_index\"\n        else:\n            self.index_path = Path(index_path)\n\n        self.chunks: Dict[str, CodeChunk] = {}\n        self.embeddings: Dict[str, List[float]] = {}\n        self._faiss_index = None\n        self._id_to_idx: Dict[str, int] = {}\n        self._idx_to_id: Dict[int, str] = {}\n\n    def index_codebase(self, root: Path, exclude_patterns: List[str] = None) -> int:\n        \"\"\"Index all code files in directory.\"\"\"\n        Console.info(f\"Indexing {root}...\")\n\n        files = list(find_python_files(root, exclude_patterns))\n", "chunk_type": "file", "line_start": 1, "line_end": 386, "language": "python", "name": "vector_store.py"}, "2e186fb57b6b_func_main": {"id": "2e186fb57b6b_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\vector_store.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Vector Store\")\n\n    if FAISS_AVAILABLE:\n        Console.ok(\"FAISS available\")\n    else:\n        Console.warn(\"FAISS not available, using brute force search\")\n\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n\n    if len(args) < 1:\n        Console.info(\"Usage: python vector_store.py <command> [args]\")\n        Console.info(\"Commands:\")\n        Console.info(\"  index <path>     Index codebase\")\n        Console.info(\"  search <query>   Search index\")\n        return 1\n\n    command = args[0]\n    store = VectorStore()\n\n    if command == 'index':\n        root = find_project_root() or Path.cwd()\n        path = Path(args[1]) if len(args) > 1 else root\n        store.index_codebase(path)\n\n    elif command == 'search':\n        query = ' '.join(args[1:]) if len(args) > 1 else ''\n        if not query:\n            Console.fail(\"No query provided\")\n            return 1\n\n        # Load existing index\n        if not store.load():\n    ", "chunk_type": "function", "line_start": 336, "line_end": 381, "language": "python", "name": "main"}, "2e186fb57b6b_func___init__": {"id": "2e186fb57b6b_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\vector_store.py", "content": "    def __init__(self, index_path: Optional[Path] = None):\n        if index_path is None:\n            root = find_project_root() or Path.cwd()\n            self.index_path = root / \".mcp\" / \"vector_index\"\n        else:\n            self.index_path = Path(index_path)\n\n        self.chunks: Dict[str, CodeChunk] = {}\n        self.embeddings: Dict[str, List[float]] = {}\n        self._faiss_index = None\n        self._id_to_idx: Dict[str, int] = {}\n        self._idx_to_id: Dict[int, str] = {}", "chunk_type": "function", "line_start": 64, "line_end": 75, "language": "python", "name": "__init__"}, "2e186fb57b6b_func_index_codebase": {"id": "2e186fb57b6b_func_index_codebase", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\vector_store.py", "content": "    def index_codebase(self, root: Path, exclude_patterns: List[str] = None) -> int:\n        \"\"\"Index all code files in directory.\"\"\"\n        Console.info(f\"Indexing {root}...\")\n\n        files = list(find_python_files(root, exclude_patterns))\n        Console.info(f\"Found {len(files)} files\")\n\n        chunks = []\n        for path in files:\n            file_chunks = self._extract_chunks(path)\n            chunks.extend(file_chunks)\n\n        Console.info(f\"Extracted {len(chunks)} code chunks\")\n\n        if not chunks:\n            return 0\n\n        # Generate embeddings\n        Console.info(\"Generating embeddings...\")\n        texts = [c.content[:1000] for c in chunks]  # Limit text length\n        embeddings = embed_texts(texts)\n\n        # Store chunks and embeddings\n        for chunk, emb in zip(chunks, embeddings):\n            self.chunks[chunk.id] = chunk\n            self.embeddings[chunk.id] = emb\n\n        # Build FAISS index if available\n        if FAISS_AVAILABLE and NUMPY_AVAILABLE:\n  ", "chunk_type": "function", "line_start": 77, "line_end": 112, "language": "python", "name": "index_codebase"}, "2e186fb57b6b_func__extract_chunks": {"id": "2e186fb57b6b_func__extract_chunks", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\vector_store.py", "content": "    def _extract_chunks(self, path: Path) -> List[CodeChunk]:\n        \"\"\"Extract code chunks from file.\"\"\"\n        chunks = []\n\n        try:\n            with open(path, 'r', encoding='utf-8', errors='ignore') as f:\n                content = f.read()\n        except Exception:\n            return chunks\n\n        # Detect language\n        ext = path.suffix.lower()\n        lang_map = {'.py': 'python', '.js': 'javascript', '.ts': 'typescript',\n                    '.go': 'go', '.rs': 'rust', '.java': 'java'}\n        language = lang_map.get(ext, 'unknown')\n\n        # Create file-level chunk\n        file_id = hashlib.md5(str(path).encode()).hexdigest()[:12]\n        chunks.append(CodeChunk(\n            id=f\"{file_id}_file\",\n            path=str(path),\n            content=content[:2000],  # First 2000 chars\n            chunk_type='file',\n            line_start=1,\n            line_end=content.count('\\n') + 1,\n            language=language,\n            name=path.name\n        ))\n\n        # Try to ex", "chunk_type": "function", "line_start": 114, "line_end": 179, "language": "python", "name": "_extract_chunks"}, "2e186fb57b6b_func__build_faiss_index": {"id": "2e186fb57b6b_func__build_faiss_index", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\vector_store.py", "content": "    def _build_faiss_index(self):\n        \"\"\"Build FAISS index from embeddings.\"\"\"\n        if not self.embeddings:\n            return\n\n        dim = len(next(iter(self.embeddings.values())))\n\n        # Create index\n        self._faiss_index = faiss.IndexFlatIP(dim)  # Inner product = cosine for normalized\n\n        # Add vectors\n        ids = list(self.embeddings.keys())\n        vectors = np.array([self.embeddings[id] for id in ids], dtype='float32')\n\n        # Normalize for cosine similarity\n        faiss.normalize_L2(vectors)\n\n        self._faiss_index.add(vectors)\n\n        # Build ID mappings\n        for idx, id in enumerate(ids):\n            self._id_to_idx[id] = idx\n            self._idx_to_id[idx] = id", "chunk_type": "function", "line_start": 181, "line_end": 203, "language": "python", "name": "_build_faiss_index"}, "2e186fb57b6b_func_search": {"id": "2e186fb57b6b_func_search", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\vector_store.py", "content": "    def search(self, query: str, k: int = 10) -> List[SearchResult]:\n        \"\"\"Search for code matching query.\"\"\"\n        if not self.embeddings:\n            return []\n\n        # Generate query embedding\n        query_emb = embed_text(query)\n        if query_emb is None:\n            return []\n\n        # Use FAISS if available\n        if self._faiss_index is not None and NUMPY_AVAILABLE:\n            return self._faiss_search(query_emb, k)\n\n        # Fallback to brute force\n        return self._brute_force_search(query_emb, k)", "chunk_type": "function", "line_start": 205, "line_end": 220, "language": "python", "name": "search"}, "2e186fb57b6b_func__faiss_search": {"id": "2e186fb57b6b_func__faiss_search", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\vector_store.py", "content": "    def _faiss_search(self, query_emb: List[float], k: int) -> List[SearchResult]:\n        \"\"\"Search using FAISS.\"\"\"\n        query_vec = np.array([query_emb], dtype='float32')\n        faiss.normalize_L2(query_vec)\n\n        k = min(k, len(self.embeddings))\n        distances, indices = self._faiss_index.search(query_vec, k)\n\n        results = []\n        for rank, (dist, idx) in enumerate(zip(distances[0], indices[0])):\n            if idx < 0:\n                continue\n            chunk_id = self._idx_to_id.get(int(idx))\n            if chunk_id and chunk_id in self.chunks:\n                results.append(SearchResult(\n                    chunk=self.chunks[chunk_id],\n                    score=float(dist),\n                    rank=rank + 1\n                ))\n\n        return results", "chunk_type": "function", "line_start": 222, "line_end": 242, "language": "python", "name": "_faiss_search"}, "2e186fb57b6b_func__brute_force_search": {"id": "2e186fb57b6b_func__brute_force_search", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\vector_store.py", "content": "    def _brute_force_search(self, query_emb: List[float], k: int) -> List[SearchResult]:\n        \"\"\"Brute force cosine similarity search.\"\"\"\n        scores = []\n\n        for chunk_id, emb in self.embeddings.items():\n            score = cosine_similarity(query_emb, emb)\n            scores.append((chunk_id, score))\n\n        # Sort by score descending\n        scores.sort(key=lambda x: x[1], reverse=True)\n\n        results = []\n        for rank, (chunk_id, score) in enumerate(scores[:k]):\n            if chunk_id in self.chunks:\n                results.append(SearchResult(\n                    chunk=self.chunks[chunk_id],\n                    score=score,\n                    rank=rank + 1\n                ))\n\n        return results", "chunk_type": "function", "line_start": 244, "line_end": 264, "language": "python", "name": "_brute_force_search"}, "2e186fb57b6b_func_save": {"id": "2e186fb57b6b_func_save", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\vector_store.py", "content": "    def save(self):\n        \"\"\"Save index to disk.\"\"\"\n        self.index_path.mkdir(parents=True, exist_ok=True)\n\n        # Save chunks\n        chunks_file = self.index_path / \"chunks.json\"\n        with open(chunks_file, 'w', encoding='utf-8') as f:\n            json.dump({k: asdict(v) for k, v in self.chunks.items()}, f)\n\n        # Save embeddings\n        emb_file = self.index_path / \"embeddings.json\"\n        with open(emb_file, 'w', encoding='utf-8') as f:\n            json.dump(self.embeddings, f)\n\n        Console.ok(f\"Index saved to {self.index_path}\")", "chunk_type": "function", "line_start": 266, "line_end": 280, "language": "python", "name": "save"}, "2e186fb57b6b_func_load": {"id": "2e186fb57b6b_func_load", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\vector_store.py", "content": "    def load(self) -> bool:\n        \"\"\"Load index from disk.\"\"\"\n        chunks_file = self.index_path / \"chunks.json\"\n        emb_file = self.index_path / \"embeddings.json\"\n\n        if not chunks_file.exists() or not emb_file.exists():\n            return False\n\n        try:\n            with open(chunks_file, 'r', encoding='utf-8') as f:\n                data = json.load(f)\n                self.chunks = {k: CodeChunk(**v) for k, v in data.items()}\n\n            with open(emb_file, 'r', encoding='utf-8') as f:\n                self.embeddings = json.load(f)\n\n            if FAISS_AVAILABLE and NUMPY_AVAILABLE:\n                self._build_faiss_index()\n\n            Console.ok(f\"Loaded {len(self.chunks)} chunks from index\")\n            return True\n\n        except Exception as e:\n            Console.warn(f\"Could not load index: {e}\")\n            return False", "chunk_type": "function", "line_start": 282, "line_end": 306, "language": "python", "name": "load"}, "2e186fb57b6b_func_update": {"id": "2e186fb57b6b_func_update", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\vector_store.py", "content": "    def update(self, changed_files: List[Path]):\n        \"\"\"Update index for changed files.\"\"\"\n        for path in changed_files:\n            # Remove old chunks for this file\n            to_remove = [k for k, v in self.chunks.items() if v.path == str(path)]\n            for k in to_remove:\n                del self.chunks[k]\n                if k in self.embeddings:\n                    del self.embeddings[k]\n\n            # Re-index file\n            if path.exists():\n                new_chunks = self._extract_chunks(path)\n                if new_chunks:\n                    texts = [c.content[:1000] for c in new_chunks]\n                    embeddings = embed_texts(texts)\n\n                    for chunk, emb in zip(new_chunks, embeddings):\n                        self.chunks[chunk.id] = chunk\n                        self.embeddings[chunk.id] = emb\n\n        # Rebuild FAISS index\n        if FAISS_AVAILABLE and NUMPY_AVAILABLE:\n            self._build_faiss_index()\n\n        self.save()", "chunk_type": "function", "line_start": 308, "line_end": 333, "language": "python", "name": "update"}, "2e186fb57b6b_class_CodeChunk": {"id": "2e186fb57b6b_class_CodeChunk", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\vector_store.py", "content": "class CodeChunk:\n    \"\"\"A chunk of code with metadata.\"\"\"\n    id: str\n    path: str\n    content: str\n    chunk_type: str  # 'function', 'class', 'file', 'block'\n    line_start: int\n    line_end: int\n    language: str = \"\"\n    name: str = \"\"", "chunk_type": "class", "line_start": 41, "line_end": 50, "language": "python", "name": "CodeChunk"}, "2e186fb57b6b_class_SearchResult": {"id": "2e186fb57b6b_class_SearchResult", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\vector_store.py", "content": "class SearchResult:\n    \"\"\"A search result.\"\"\"\n    chunk: CodeChunk\n    score: float\n    rank: int", "chunk_type": "class", "line_start": 54, "line_end": 58, "language": "python", "name": "SearchResult"}, "2e186fb57b6b_class_VectorStore": {"id": "2e186fb57b6b_class_VectorStore", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\vector_store.py", "content": "class VectorStore:\n    \"\"\"Local vector store for semantic code search.\"\"\"\n\n    def __init__(self, index_path: Optional[Path] = None):\n        if index_path is None:\n            root = find_project_root() or Path.cwd()\n            self.index_path = root / \".mcp\" / \"vector_index\"\n        else:\n            self.index_path = Path(index_path)\n\n        self.chunks: Dict[str, CodeChunk] = {}\n        self.embeddings: Dict[str, List[float]] = {}\n        self._faiss_index = None\n        self._id_to_idx: Dict[str, int] = {}\n        self._idx_to_id: Dict[int, str] = {}\n\n    def index_codebase(self, root: Path, exclude_patterns: List[str] = None) -> int:\n        \"\"\"Index all code files in directory.\"\"\"\n        Console.info(f\"Indexing {root}...\")\n\n        files = list(find_python_files(root, exclude_patterns))\n        Console.info(f\"Found {len(files)} files\")\n\n        chunks = []\n        for path in files:\n            file_chunks = self._extract_chunks(path)\n            chunks.extend(file_chunks)\n\n ", "chunk_type": "class", "line_start": 61, "line_end": 333, "language": "python", "name": "VectorStore"}, "65d5fb734105_file": {"id": "65d5fb734105_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\warm.py", "content": "\"\"\"\nWarm-Up Command\n===============\nPre-warm all indexes for faster AI agent responses.\n\nUsage:\n    python mcp.py warm\n\"\"\"\n\nfrom pathlib import Path\nimport sys\nimport time\n\nfrom .utils import Console, find_project_root\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\n\n\ndef warm_all(root: Path = None) -> dict:\n    \"\"\"Pre-warm all indexes and caches.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    Console.header(\"Warming Indexes\")\n    Console.info(f\"Project: {root}\")\n\n    start_time = time.time()\n    results = {}\n\n    # Define warm-up tasks\n    tasks = {\n        'semantic': ('vector_store', 'VectorStore', 'index_codebase'),\n        'todos': ('todo_index', 'index_todos', None),\n        'impact': ('impact', 'save_impact_graph', None),\n        'docs': ('doc_index', 'index_documentation', None),\n        'config': ('config_index', 'index_configs', None),\n        'context': ('autocontext', 'warm_context', None),\n    }\n\n    def run_task(name, module_name, func_or_class, method):\n        try:\n            import importlib\n            module = importlib.import_module(f\"scripts.{module_name}\")\n\n            if method:\n                # Class with method\n                cls = getattr(module, func_or_class)\n                instance = cls(root / '.mcp' / 'vector_index')\n                getattr(instance, method)(root)\n            else:\n                # Direct function\n                func = getattr(module, func_or_class)\n                func(root)\n\n            return name, 'ok', None\n        except Exception as e:\n            return name, 'error', str(e)\n\n    # Run tasks in parallel\n    Console.info(\"Running warm-up tasks...\")\n\n    with ThreadPoolExecutor(max_workers=4) as executor:\n        futures = {}\n        for name, (module, func, method) in tasks.items():\n            future = executor.submit(run_task, name, module, func, method)\n            futures[future] = name\n\n        for future in as_completed(futures):\n            name, status, error = future.", "chunk_type": "file", "line_start": 1, "line_end": 117, "language": "python", "name": "warm.py"}, "65d5fb734105_func_warm_all": {"id": "65d5fb734105_func_warm_all", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\warm.py", "content": "def warm_all(root: Path = None) -> dict:\n    \"\"\"Pre-warm all indexes and caches.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    Console.header(\"Warming Indexes\")\n    Console.info(f\"Project: {root}\")\n\n    start_time = time.time()\n    results = {}\n\n    # Define warm-up tasks\n    tasks = {\n        'semantic': ('vector_store', 'VectorStore', 'index_codebase'),\n        'todos': ('todo_index', 'index_todos', None),\n        'impact': ('impact', 'save_impact_graph', None),\n        'docs': ('doc_index', 'index_documentation', None),\n        'config': ('config_index', 'index_configs', None),\n        'context': ('autocontext', 'warm_context', None),\n    }\n\n    def run_task(name, module_name, func_or_class, method):\n        try:\n            import importlib\n            module = importlib.import_module(f\"scripts.{module_name}\")\n\n            if method:\n                # Class with method\n                cls = getattr(module, func_or_class)\n                instance = cls(root / '.mcp' /", "chunk_type": "function", "line_start": 18, "line_end": 83, "language": "python", "name": "warm_all"}, "65d5fb734105_func_main": {"id": "65d5fb734105_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\warm.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    root = find_project_root() or Path.cwd()\n\n    if '--quick' in sys.argv:\n        # Quick warm - just semantic and todos\n        Console.header(\"Quick Warm\")\n\n        try:\n            from .vector_store import VectorStore\n            store = VectorStore(root / '.mcp' / 'vector_index')\n            store.index_codebase(root)\n            Console.ok(\"Semantic index warmed\")\n        except Exception:\n            pass\n\n        try:\n            from .todo_index import index_todos\n            index_todos(root)\n            Console.ok(\"TODO index warmed\")\n        except Exception:\n            pass\n\n        return 0\n\n    warm_all(root)\n    return 0", "chunk_type": "function", "line_start": 86, "line_end": 112, "language": "python", "name": "main"}, "65d5fb734105_func_run_task": {"id": "65d5fb734105_func_run_task", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\warm.py", "content": "    def run_task(name, module_name, func_or_class, method):\n        try:\n            import importlib\n            module = importlib.import_module(f\"scripts.{module_name}\")\n\n            if method:\n                # Class with method\n                cls = getattr(module, func_or_class)\n                instance = cls(root / '.mcp' / 'vector_index')\n                getattr(instance, method)(root)\n            else:\n                # Direct function\n                func = getattr(module, func_or_class)\n                func(root)\n\n            return name, 'ok', None\n        except Exception as e:\n            return name, 'error', str(e)", "chunk_type": "function", "line_start": 38, "line_end": 55, "language": "python", "name": "run_task"}, "12671320e282_file": {"id": "12671320e282_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\watcher.py", "content": "\"\"\"\nFile System Watcher\n===================\nBackground process for live semantic index updates.\n\nUsage:\n    python mcp.py watch           # Start watching\n    python mcp.py watch --stop    # Stop watching\n\"\"\"\n\nfrom dataclasses import dataclass\nfrom datetime import datetime\nfrom pathlib import Path\nfrom typing import Dict, Set, Optional\nimport hashlib\nimport json\nimport os\nimport sys\nimport time\n\nfrom .utils import Console, find_python_files, find_project_root\nimport signal\n\n\n# Try watchdog for efficient file watching\ntry:\n    from watchdog.observers import Observer\n    from watchdog.events import FileSystemEventHandler, FileModifiedEvent\n    WATCHDOG_AVAILABLE = True\nexcept ImportError:\n    WATCHDOG_AVAILABLE = False\n\n\n@dataclass\nclass WatcherState:\n    \"\"\"State of the file watcher.\"\"\"\n    pid_file: Path\n    index_path: Path\n    debounce_ms: int = 500\n    save_interval_s: int = 30\n    running: bool = False\n\n\nclass CodeChangeHandler:\n    \"\"\"Handles file changes for indexing.\"\"\"\n\n    def __init__(self, root: Path, state: WatcherState):\n        self.root = root\n        self.state = state\n        self.pending_files: Set[Path] = set()\n        self.last_change_time: float = 0\n        self.file_hashes: Dict[str, str] = {}\n\n    def on_modified(self, path: Path):\n        \"\"\"Handle file modification.\"\"\"\n        if not path.suffix == '.py':\n            return\n\n        # Check if file actually changed (not just touched)\n        current_hash = self._get_file_hash(path)\n        if self.file_hashes.get(str(path)) == current_hash:\n            return\n\n        self.file_hashes[str(path)] = current_hash\n        self.pending_files.add(path)\n        self.last_change_time = time.time()\n\n    def _get_file_hash(self, path: Path) -> str:\n        \"\"\"Get hash of file contents.\"\"\"\n        try:\n            with open(path, 'rb') as f:\n                return hashlib.md5(f.read()).hexdigest()\n        except Exception:\n            return \"\"\n\n    def process_pending(self) -> int:\n        \"\"\"Process ", "chunk_type": "file", "line_start": 1, "line_end": 291, "language": "python", "name": "watcher.py"}, "12671320e282_func_poll_watch": {"id": "12671320e282_func_poll_watch", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\watcher.py", "content": "def poll_watch(root: Path, state: WatcherState):\n    \"\"\"Polling-based file watcher (fallback).\"\"\"\n    handler = CodeChangeHandler(root, state)\n    last_save = time.time()\n\n    # Initial scan\n    Console.info(\"Initial file scan...\")\n    for path in find_python_files(root):\n        handler.file_hashes[str(path)] = handler._get_file_hash(path)\n    Console.ok(f\"Tracking {len(handler.file_hashes)} files\")\n\n    Console.info(f\"Watching {root} (polling mode)...\")\n    Console.info(\"Press Ctrl+C to stop\")\n\n    while state.running:\n        # Check for changes\n        for path in find_python_files(root):\n            current_hash = handler._get_file_hash(path)\n            if handler.file_hashes.get(str(path)) != current_hash:\n                handler.on_modified(path)\n\n        # Process pending\n        handler.process_pending()\n\n        # Periodic save\n        if time.time() - last_save > state.save_interval_s:\n            last_save = time.time()\n\n        time.sleep(1)", "chunk_type": "function", "line_start": 120, "line_end": 148, "language": "python", "name": "poll_watch"}, "12671320e282_func_watchdog_watch": {"id": "12671320e282_func_watchdog_watch", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\watcher.py", "content": "def watchdog_watch(root: Path, state: WatcherState):\n    \"\"\"Watchdog-based efficient file watching.\"\"\"\n    handler = CodeChangeHandler(root, state)\n    watchdog_handler = WatchdogHandler(handler)\n\n    observer = Observer()\n    observer.schedule(watchdog_handler, str(root), recursive=True)\n    observer.start()\n\n    Console.info(f\"Watching {root} (watchdog mode)...\")\n    Console.info(\"Press Ctrl+C to stop\")\n\n    try:\n        while state.running:\n            handler.process_pending()\n            time.sleep(0.5)\n    finally:\n        observer.stop()\n        observer.join()", "chunk_type": "function", "line_start": 151, "line_end": 169, "language": "python", "name": "watchdog_watch"}, "12671320e282_func_start_watch": {"id": "12671320e282_func_start_watch", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\watcher.py", "content": "def start_watch(root: Path = None, background: bool = False):\n    \"\"\"Start the file watcher.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    mcp_dir = root / '.mcp'\n    mcp_dir.mkdir(exist_ok=True)\n\n    state = WatcherState(\n        pid_file=mcp_dir / 'watcher.pid',\n        index_path=mcp_dir / 'vector_index',\n        running=True\n    )\n\n    # Check if already running\n    if state.pid_file.exists():\n        try:\n            pid = int(state.pid_file.read_text().strip())\n            # Check if process exists\n            os.kill(pid, 0)\n            Console.warn(f\"Watcher already running (PID {pid})\")\n            return 1\n        except (ProcessLookupError, ValueError):\n            state.pid_file.unlink()\n\n    # Write PID\n    state.pid_file.write_text(str(os.getpid()))\n\n    # Handle shutdown\n    def shutdown(signum, frame):\n        Console.info(\"Stopping watcher...\")\n        state.running = False\n        if state.pid_file.exists():\n            state.pid_file.unlink()\n\n    sign", "chunk_type": "function", "line_start": 172, "line_end": 219, "language": "python", "name": "start_watch"}, "12671320e282_func_stop_watch": {"id": "12671320e282_func_stop_watch", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\watcher.py", "content": "def stop_watch(root: Path = None):\n    \"\"\"Stop the file watcher.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n    pid_file = root / '.mcp' / 'watcher.pid'\n\n    if not pid_file.exists():\n        Console.warn(\"No watcher running\")\n        return 1\n\n    try:\n        pid = int(pid_file.read_text().strip())\n        os.kill(pid, signal.SIGTERM)\n        Console.ok(f\"Stopped watcher (PID {pid})\")\n        pid_file.unlink()\n        return 0\n    except ProcessLookupError:\n        Console.warn(\"Watcher process not found\")\n        pid_file.unlink()\n        return 1\n    except Exception as e:\n        Console.fail(f\"Could not stop watcher: {e}\")\n        return 1", "chunk_type": "function", "line_start": 222, "line_end": 243, "language": "python", "name": "stop_watch"}, "12671320e282_func_get_watch_status": {"id": "12671320e282_func_get_watch_status", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\watcher.py", "content": "def get_watch_status(root: Path = None) -> Optional[int]:\n    \"\"\"Get watcher PID if running.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n    pid_file = root / '.mcp' / 'watcher.pid'\n\n    if not pid_file.exists():\n        return None\n\n    try:\n        pid = int(pid_file.read_text().strip())\n        os.kill(pid, 0)  # Check if process exists\n        return pid\n    except (ProcessLookupError, ValueError):\n        return None", "chunk_type": "function", "line_start": 246, "line_end": 259, "language": "python", "name": "get_watch_status"}, "12671320e282_func_main": {"id": "12671320e282_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\watcher.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"File Watcher\")\n\n    if WATCHDOG_AVAILABLE:\n        Console.ok(\"watchdog available (efficient mode)\")\n    else:\n        Console.warn(\"watchdog not installed, using polling\")\n\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n\n    if '--stop' in sys.argv:\n        return stop_watch()\n\n    if '--status' in sys.argv:\n        pid = get_watch_status()\n        if pid:\n            Console.ok(f\"Watcher running (PID {pid})\")\n        else:\n            Console.info(\"Watcher not running\")\n        return 0\n\n    # Start watching\n    path = Path(args[0]) if args else None\n    return start_watch(path)", "chunk_type": "function", "line_start": 262, "line_end": 286, "language": "python", "name": "main"}, "12671320e282_func___init__": {"id": "12671320e282_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\watcher.py", "content": "        def __init__(self, change_handler: CodeChangeHandler):\n            self.change_handler = change_handler", "chunk_type": "function", "line_start": 108, "line_end": 109, "language": "python", "name": "__init__"}, "12671320e282_func_on_modified": {"id": "12671320e282_func_on_modified", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\watcher.py", "content": "        def on_modified(self, event):\n            if not event.is_directory:\n                self.change_handler.on_modified(Path(event.src_path))", "chunk_type": "function", "line_start": 111, "line_end": 113, "language": "python", "name": "on_modified"}, "12671320e282_func__get_file_hash": {"id": "12671320e282_func__get_file_hash", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\watcher.py", "content": "    def _get_file_hash(self, path: Path) -> str:\n        \"\"\"Get hash of file contents.\"\"\"\n        try:\n            with open(path, 'rb') as f:\n                return hashlib.md5(f.read()).hexdigest()\n        except Exception:\n            return \"\"", "chunk_type": "function", "line_start": 68, "line_end": 74, "language": "python", "name": "_get_file_hash"}, "12671320e282_func_process_pending": {"id": "12671320e282_func_process_pending", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\watcher.py", "content": "    def process_pending(self) -> int:\n        \"\"\"Process pending files if debounce period passed.\"\"\"\n        if not self.pending_files:\n            return 0\n\n        # Check debounce\n        elapsed_ms = (time.time() - self.last_change_time) * 1000\n        if elapsed_ms < self.state.debounce_ms:\n            return 0\n\n        # Process files\n        files = list(self.pending_files)\n        self.pending_files.clear()\n\n        Console.info(f\"Updating index for {len(files)} files...\")\n\n        try:\n            from .vector_store import VectorStore\n            store = VectorStore(self.state.index_path)\n            store.load()\n            store.update(files)\n            Console.ok(f\"Index updated\")\n            return len(files)\n        except Exception as e:\n            Console.warn(f\"Index update failed: {e}\")\n            return 0", "chunk_type": "function", "line_start": 76, "line_end": 101, "language": "python", "name": "process_pending"}, "12671320e282_func_shutdown": {"id": "12671320e282_func_shutdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\watcher.py", "content": "    def shutdown(signum, frame):\n        Console.info(\"Stopping watcher...\")\n        state.running = False\n        if state.pid_file.exists():\n            state.pid_file.unlink()", "chunk_type": "function", "line_start": 200, "line_end": 204, "language": "python", "name": "shutdown"}, "12671320e282_func_on_created": {"id": "12671320e282_func_on_created", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\watcher.py", "content": "        def on_created(self, event):\n            if not event.is_directory:\n                self.change_handler.on_modified(Path(event.src_path))", "chunk_type": "function", "line_start": 115, "line_end": 117, "language": "python", "name": "on_created"}, "12671320e282_class_WatcherState": {"id": "12671320e282_class_WatcherState", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\watcher.py", "content": "class WatcherState:\n    \"\"\"State of the file watcher.\"\"\"\n    pid_file: Path\n    index_path: Path\n    debounce_ms: int = 500\n    save_interval_s: int = 30\n    running: bool = False", "chunk_type": "class", "line_start": 35, "line_end": 41, "language": "python", "name": "WatcherState"}, "12671320e282_class_CodeChangeHandler": {"id": "12671320e282_class_CodeChangeHandler", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\watcher.py", "content": "class CodeChangeHandler:\n    \"\"\"Handles file changes for indexing.\"\"\"\n\n    def __init__(self, root: Path, state: WatcherState):\n        self.root = root\n        self.state = state\n        self.pending_files: Set[Path] = set()\n        self.last_change_time: float = 0\n        self.file_hashes: Dict[str, str] = {}\n\n    def on_modified(self, path: Path):\n        \"\"\"Handle file modification.\"\"\"\n        if not path.suffix == '.py':\n            return\n\n        # Check if file actually changed (not just touched)\n        current_hash = self._get_file_hash(path)\n        if self.file_hashes.get(str(path)) == current_hash:\n            return\n\n        self.file_hashes[str(path)] = current_hash\n        self.pending_files.add(path)\n        self.last_change_time = time.time()\n\n    def _get_file_hash(self, path: Path) -> str:\n        \"\"\"Get hash of file contents.\"\"\"\n        try:\n            with open(path, 'rb') as f:\n                return hashlib.md5(f.read()).hexdigest()\n        except Exception:\n  ", "chunk_type": "class", "line_start": 44, "line_end": 101, "language": "python", "name": "CodeChangeHandler"}, "12671320e282_class_WatchdogHandler": {"id": "12671320e282_class_WatchdogHandler", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\watcher.py", "content": "    class WatchdogHandler(FileSystemEventHandler):\n        \"\"\"Watchdog event handler.\"\"\"\n\n        def __init__(self, change_handler: CodeChangeHandler):\n            self.change_handler = change_handler\n\n        def on_modified(self, event):\n            if not event.is_directory:\n                self.change_handler.on_modified(Path(event.src_path))\n\n        def on_created(self, event):\n            if not event.is_directory:\n                self.change_handler.on_modified(Path(event.src_path))", "chunk_type": "class", "line_start": 105, "line_end": 117, "language": "python", "name": "WatchdogHandler"}, "b0e467084cb6_file": {"id": "b0e467084cb6_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\scripts\\__init__.py", "content": "\"\"\"\nMCP Global Rules - Scripts Package\n==================================\nAI Agent Enhancement Tools for autonomous development.\n\"\"\"\n\nfrom .utils import (\n    FunctionInfo,\n    ClassInfo,\n    ModuleInfo,\n    GitCommit,\n    find_python_files,\n    find_project_root,\n    parse_file,\n    analyze_module,\n    get_git_log,\n    get_changed_files,\n    get_staged_files,\n    format_as_json,\n    format_as_markdown_table,\n    record_to_memory,\n    Console\n)\n\n__version__ = \"2.0.0\"\n__all__ = [\n    'FunctionInfo',\n    'ClassInfo',\n    'ModuleInfo',\n    'GitCommit',\n    'find_python_files',\n    'find_project_root',\n    'parse_file',\n    'analyze_module',\n    'get_git_log',\n    'get_changed_files',\n    'get_staged_files',\n    'format_as_json',\n    'format_as_markdown_table',\n    'record_to_memory',\n    'Console'\n]\n", "chunk_type": "file", "line_start": 1, "line_end": 43, "language": "python", "name": "__init__.py"}, "4c1fe222b209_file": {"id": "4c1fe222b209_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\tests\\test_scripts.py", "content": "\"\"\"\nTests for MCP Global Rules Scripts\n==================================\nComprehensive test suite for all AI agent enhancement tools.\n\"\"\"\n\nfrom pathlib import Path\nimport os\nimport tempfile\n\nimport pytest\n\n# Create a sample Python file for testing\nSAMPLE_PYTHON_CODE = '''\n\"\"\"Sample module for testing.\"\"\"\n\nimport os\nimport sys\nfrom pathlib import Path\n\n\nclass SampleClass:\n    \"\"\"A sample class.\"\"\"\n\n    def __init__(self, name: str):\n        self.name = name\n\n    def get_name(self) -> str:\n        \"\"\"Get the name.\"\"\"\n        return self.name\n\n\ndef sample_function(arg1: str, arg2: int = 10) -> bool:\n    \"\"\"\n    Sample function with docstring.\n\n    Args:\n        arg1: First argument\n        arg2: Second argument\n\n    Returns:\n        True if successful\n    \"\"\"\n    return True\n\n\ndef undocumented_function(x, y):\n    # This function has no docstring\n    return x + y\n\n\nCONSTANT_VALUE = 42\nunused_variable = \"not used\"\n'''\n\nSAMPLE_CODE_NO_DOCS = '''\nimport json\n\nclass NoDocClass:\n    def __init__(self):\n        self.value = 1\n\n    def method(self):\n        return self.value\n\ndef no_doc_function():\n    return True\n'''\n\n\n@pytest.fixture\ndef temp_project():\n    \"\"\"Create a temporary project directory with sample files.\"\"\"\n    with tempfile.TemporaryDirectory() as tmpdir:\n        project_dir = Path(tmpdir)\n\n        # Create sample files\n        (project_dir / \"sample.py\").write_text(SAMPLE_PYTHON_CODE)\n        (project_dir / \"no_docs.py\").write_text(SAMPLE_CODE_NO_DOCS)\n\n        # Create src directory\n        (project_dir / \"src\").mkdir()\n        (project_dir / \"src\" / \"__init__.py\").write_text(\"\")\n        (project_dir / \"src\" / \"module.py\").write_text(SAMPLE_PYTHON_CODE)\n\n        yield project_dir\n\n\nclass TestUtils:\n    \"\"\"Tests for utils.py module.\"\"\"\n\n    def test_find_python_files(self, temp_project):\n        \"\"\"Test finding Python files.\"\"\"\n        from scripts.utils import find_python_files\n\n        files = list(find_python_files(temp_project))\n        if not len(files) >=", "chunk_type": "file", "line_start": 1, "line_end": 330, "language": "python", "name": "test_scripts.py"}, "4c1fe222b209_func_temp_project": {"id": "4c1fe222b209_func_temp_project", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\tests\\test_scripts.py", "content": "def temp_project():\n    \"\"\"Create a temporary project directory with sample files.\"\"\"\n    with tempfile.TemporaryDirectory() as tmpdir:\n        project_dir = Path(tmpdir)\n\n        # Create sample files\n        (project_dir / \"sample.py\").write_text(SAMPLE_PYTHON_CODE)\n        (project_dir / \"no_docs.py\").write_text(SAMPLE_CODE_NO_DOCS)\n\n        # Create src directory\n        (project_dir / \"src\").mkdir()\n        (project_dir / \"src\" / \"__init__.py\").write_text(\"\")\n        (project_dir / \"src\" / \"module.py\").write_text(SAMPLE_PYTHON_CODE)\n\n        yield project_dir", "chunk_type": "function", "line_start": 72, "line_end": 86, "language": "python", "name": "temp_project"}, "4c1fe222b209_func_test_find_python_files": {"id": "4c1fe222b209_func_test_find_python_files", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\tests\\test_scripts.py", "content": "    def test_find_python_files(self, temp_project):\n        \"\"\"Test finding Python files.\"\"\"\n        from scripts.utils import find_python_files\n\n        files = list(find_python_files(temp_project))\n        if not len(files) >= 2:\n            raise AssertionError(\"Should have found at least 2 files\")\n        if not any(f.name == \"sample.py\" for f in files):\n            raise AssertionError(\"Should have found sample.py\")", "chunk_type": "function", "line_start": 92, "line_end": 100, "language": "python", "name": "test_find_python_files"}, "4c1fe222b209_func_test_parse_file": {"id": "4c1fe222b209_func_test_parse_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\tests\\test_scripts.py", "content": "    def test_parse_file(self, temp_project):\n        \"\"\"Test parsing Python file.\"\"\"\n        from scripts.utils import parse_file\n\n        tree = parse_file(temp_project / \"sample.py\")\n        if tree is None:\n            raise AssertionError(\"Tree should not be None\")", "chunk_type": "function", "line_start": 102, "line_end": 108, "language": "python", "name": "test_parse_file"}, "4c1fe222b209_func_test_analyze_module": {"id": "4c1fe222b209_func_test_analyze_module", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\tests\\test_scripts.py", "content": "    def test_analyze_module(self, temp_project):\n        \"\"\"Test analyzing module.\"\"\"\n        from scripts.utils import analyze_module\n\n        info = analyze_module(temp_project / \"sample.py\")\n        if info is None:\n            raise AssertionError(\"Info should not be None\")\n        if not len(info.functions) >= 2:\n            raise AssertionError(\"Should identify at least 2 functions\")\n        if not len(info.classes) >= 1:\n            raise AssertionError(\"Should identify at least 1 class\")", "chunk_type": "function", "line_start": 110, "line_end": 120, "language": "python", "name": "test_analyze_module"}, "4c1fe222b209_func_test_format_as_markdown_table": {"id": "4c1fe222b209_func_test_format_as_markdown_table", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\tests\\test_scripts.py", "content": "    def test_format_as_markdown_table(self):\n        \"\"\"Test markdown table formatting.\"\"\"\n        from scripts.utils import format_as_markdown_table\n\n        table = format_as_markdown_table(\n            [\"Name\", \"Value\"],\n            [[\"foo\", \"bar\"], [\"baz\", \"qux\"]]\n        )\n        if \"Name\" not in table:\n            raise AssertionError(\"Table should contain header 'Name'\")\n        if \"foo\" not in table:\n            raise AssertionError(\"Table should contain value 'foo'\")", "chunk_type": "function", "line_start": 122, "line_end": 133, "language": "python", "name": "test_format_as_markdown_table"}, "4c1fe222b209_func_test_detect_dead_code": {"id": "4c1fe222b209_func_test_detect_dead_code", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\tests\\test_scripts.py", "content": "    def test_detect_dead_code(self, temp_project):\n        \"\"\"Test dead code detection.\"\"\"\n        from scripts.dead_code import detect_dead_code\n\n        report = detect_dead_code(temp_project)\n        if report is None:\n            raise AssertionError(\"Report should not be None\")\n        if not report.total_issues >= 0:\n            raise AssertionError(\"Total issues should be non-negative\")", "chunk_type": "function", "line_start": 139, "line_end": 147, "language": "python", "name": "test_detect_dead_code"}, "4c1fe222b209_func_test_report_to_markdown": {"id": "4c1fe222b209_func_test_report_to_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\tests\\test_scripts.py", "content": "    def test_report_to_markdown(self, temp_project):\n        \"\"\"Test report conversion to markdown.\"\"\"\n        from scripts.dead_code import detect_dead_code\n\n        report = detect_dead_code(temp_project)\n        markdown = report.to_markdown()\n        if \"Dead Code Report\" not in markdown:\n            raise AssertionError(\"Markdown should contain 'Dead Code Report'\")", "chunk_type": "function", "line_start": 149, "line_end": 156, "language": "python", "name": "test_report_to_markdown"}, "4c1fe222b209_func_test_analyze_file_for_docstrings": {"id": "4c1fe222b209_func_test_analyze_file_for_docstrings", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\tests\\test_scripts.py", "content": "    def test_analyze_file_for_docstrings(self, temp_project):\n        \"\"\"Test docstring analysis.\"\"\"\n        from scripts.auto_docs import analyze_file_for_docstrings\n\n        suggestions = analyze_file_for_docstrings(temp_project / \"no_docs.py\")\n        if not len(suggestions) >= 2:\n            raise AssertionError(\"Should find at least 2 suggestions\")", "chunk_type": "function", "line_start": 162, "line_end": 168, "language": "python", "name": "test_analyze_file_for_docstrings"}, "4c1fe222b209_func_test_generate_function_docstring": {"id": "4c1fe222b209_func_test_generate_function_docstring", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\tests\\test_scripts.py", "content": "    def test_generate_function_docstring(self):\n        \"\"\"Test docstring generation.\"\"\"\n        from scripts.auto_docs import generate_function_docstring\n        from scripts.utils import FunctionInfo\n        import ast\n\n        # Create a mock function node\n        code = \"def test_func(arg1: str, arg2: int) -> bool: pass\"\n        tree = ast.parse(code)\n        node = tree.body[0]\n\n        docstring = generate_function_docstring(node, \"    \")\n        if '\"\"\"' not in docstring:\n            raise AssertionError(\"Docstring should contain quotes\")\n        if 'Args:' not in docstring:\n            raise AssertionError(\"Docstring should contain Args section\")", "chunk_type": "function", "line_start": 170, "line_end": 185, "language": "python", "name": "test_generate_function_docstring"}, "4c1fe222b209_func_test_generate_test_function": {"id": "4c1fe222b209_func_test_generate_test_function", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\tests\\test_scripts.py", "content": "    def test_generate_test_function(self):\n        \"\"\"Test test function generation.\"\"\"\n        from scripts.auto_test import generate_test_function\n        from scripts.utils import FunctionInfo\n\n        func = FunctionInfo(\n            name=\"my_function\",\n            lineno=1,\n            end_lineno=10,\n            args=[\"arg1\", \"arg2\"],\n            arg_types={\"arg1\": \"str\", \"arg2\": \"int\"},\n            return_type=\"bool\",\n            docstring=\"Test function.\"\n        )\n\n        test_code = generate_test_function(func, \"mymodule\")\n        if \"def test_my_function\" not in test_code:\n            raise AssertionError(\"Should generate test function definition\")\n        if \"assert\" not in test_code:\n            raise AssertionError(\"Should contain assertion in generated code\")", "chunk_type": "function", "line_start": 191, "line_end": 210, "language": "python", "name": "test_generate_test_function"}, "4c1fe222b209_func_test_summarize_codebase": {"id": "4c1fe222b209_func_test_summarize_codebase", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\tests\\test_scripts.py", "content": "    def test_summarize_codebase(self, temp_project):\n        \"\"\"Test codebase summarization.\"\"\"\n        from scripts.summarize import summarize_codebase\n\n        summary = summarize_codebase(temp_project)\n        if not summary.total_files >= 2:\n            raise AssertionError(\"Should handle at least 2 files\")\n        if not summary.total_functions >= 2:\n            raise AssertionError(\"Should handle at least 2 functions\")", "chunk_type": "function", "line_start": 216, "line_end": 224, "language": "python", "name": "test_summarize_codebase"}, "4c1fe222b209_func_test_format_summary_markdown": {"id": "4c1fe222b209_func_test_format_summary_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\tests\\test_scripts.py", "content": "    def test_format_summary_markdown(self, temp_project):\n        \"\"\"Test summary markdown formatting.\"\"\"\n        from scripts.summarize import summarize_codebase, format_summary_markdown\n\n        summary = summarize_codebase(temp_project)\n        markdown = format_summary_markdown(summary)\n        if \"# Codebase Summary\" not in markdown:\n            raise AssertionError(\"Markdown should contain header\")", "chunk_type": "function", "line_start": 226, "line_end": 233, "language": "python", "name": "test_format_summary_markdown"}, "4c1fe222b209_func_test_parse_commit_message": {"id": "4c1fe222b209_func_test_parse_commit_message", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\tests\\test_scripts.py", "content": "    def test_parse_commit_message(self):\n        \"\"\"Test commit message parsing.\"\"\"\n        from scripts.changelog import parse_commit_message\n\n        entry = parse_commit_message(\"feat(auth): add login functionality\")\n        if entry is None:\n            raise AssertionError(\"Entry should not be None\")\n        if entry.commit_type != \"feat\":\n            raise AssertionError(\"Commit type should be feat\")\n        if entry.scope != \"auth\":\n            raise AssertionError(\"Scope should be auth\")\n        if \"login\" not in entry.description:\n            raise AssertionError(\"Description should contain login\")", "chunk_type": "function", "line_start": 239, "line_end": 251, "language": "python", "name": "test_parse_commit_message"}, "4c1fe222b209_func_test_parse_commit_message_breaking": {"id": "4c1fe222b209_func_test_parse_commit_message_breaking", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\tests\\test_scripts.py", "content": "    def test_parse_commit_message_breaking(self):\n        \"\"\"Test breaking change detection.\"\"\"\n        from scripts.changelog import parse_commit_message\n\n        entry = parse_commit_message(\"feat!: breaking change\")\n        if entry is None:\n            raise AssertionError(\"Entry should not be None\")\n        if entry.breaking != True:\n            raise AssertionError(\"Should detect breaking change\")", "chunk_type": "function", "line_start": 253, "line_end": 261, "language": "python", "name": "test_parse_commit_message_breaking"}, "4c1fe222b209_func_test_analyze_dependencies": {"id": "4c1fe222b209_func_test_analyze_dependencies", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\tests\\test_scripts.py", "content": "    def test_analyze_dependencies(self, temp_project):\n        \"\"\"Test dependency analysis.\"\"\"\n        from scripts.deps import analyze_dependencies\n\n        report = analyze_dependencies(temp_project)\n        if report is None:\n            raise AssertionError(\"Report should not be None\")\n        if not len(report.modules) >= 2:\n            raise AssertionError(\"Should find at least 2 modules\")", "chunk_type": "function", "line_start": 267, "line_end": 275, "language": "python", "name": "test_analyze_dependencies"}, "4c1fe222b209_func_test_format_report_markdown": {"id": "4c1fe222b209_func_test_format_report_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\tests\\test_scripts.py", "content": "    def test_format_report_markdown(self, temp_project):\n        \"\"\"Test dependency report markdown.\"\"\"\n        from scripts.deps import analyze_dependencies, format_report_markdown\n\n        report = analyze_dependencies(temp_project)\n        markdown = format_report_markdown(report)\n        if \"# Dependency Analysis\" not in markdown:\n            raise AssertionError(\"Markdown should contain header\")", "chunk_type": "function", "line_start": 277, "line_end": 284, "language": "python", "name": "test_format_report_markdown"}, "4c1fe222b209_func_test_review_file": {"id": "4c1fe222b209_func_test_review_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\tests\\test_scripts.py", "content": "    def test_review_file(self, temp_project):\n        \"\"\"Test file review.\"\"\"\n        from scripts.review import review_file\n\n        issues = review_file(temp_project / \"no_docs.py\")\n        if not len(issues) >= 1:\n            raise AssertionError(\"Should find missing docstrings\")", "chunk_type": "function", "line_start": 290, "line_end": 296, "language": "python", "name": "test_review_file"}, "4c1fe222b209_func_test_review_project": {"id": "4c1fe222b209_func_test_review_project", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\tests\\test_scripts.py", "content": "    def test_review_project(self, temp_project):\n        \"\"\"Test project review.\"\"\"\n        from scripts.review import review_project\n\n        report = review_project(temp_project)\n        if not report.files_reviewed >= 2:\n            raise AssertionError(\"Should review at least 2 files\")", "chunk_type": "function", "line_start": 298, "line_end": 304, "language": "python", "name": "test_review_project"}, "4c1fe222b209_func_test_security_check": {"id": "4c1fe222b209_func_test_security_check", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\tests\\test_scripts.py", "content": "    def test_security_check(self):\n        \"\"\"Test security issue detection.\"\"\"\n        from scripts.review import ReviewChecks\n        import ast\n\n        code = '''\ntest_val = \"mock\" + \"_\" + \"credential\"\neval(user_input)\n'''\n        tree = ast.parse(code)\n\n        with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:\n            f.write(code)\n            f.flush()\n\n            issues = ReviewChecks.check_security_issues(Path(f.name), tree)\n            if not len(issues) >= 1:\n                raise AssertionError(\"Should find security issue\")\n\n            os.unlink(f.name)", "chunk_type": "function", "line_start": 306, "line_end": 325, "language": "python", "name": "test_security_check"}, "4c1fe222b209_class_TestUtils": {"id": "4c1fe222b209_class_TestUtils", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\tests\\test_scripts.py", "content": "class TestUtils:\n    \"\"\"Tests for utils.py module.\"\"\"\n\n    def test_find_python_files(self, temp_project):\n        \"\"\"Test finding Python files.\"\"\"\n        from scripts.utils import find_python_files\n\n        files = list(find_python_files(temp_project))\n        if not len(files) >= 2:\n            raise AssertionError(\"Should have found at least 2 files\")\n        if not any(f.name == \"sample.py\" for f in files):\n            raise AssertionError(\"Should have found sample.py\")\n\n    def test_parse_file(self, temp_project):\n        \"\"\"Test parsing Python file.\"\"\"\n        from scripts.utils import parse_file\n\n        tree = parse_file(temp_project / \"sample.py\")\n        if tree is None:\n            raise AssertionError(\"Tree should not be None\")\n\n    def test_analyze_module(self, temp_project):\n        \"\"\"Test analyzing module.\"\"\"\n        from scripts.utils import analyze_module\n\n        info = analyze_module(temp_project / \"sample.py\")\n        if info is None:\n            raise AssertionEr", "chunk_type": "class", "line_start": 89, "line_end": 133, "language": "python", "name": "TestUtils"}, "4c1fe222b209_class_TestDeadCode": {"id": "4c1fe222b209_class_TestDeadCode", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\tests\\test_scripts.py", "content": "class TestDeadCode:\n    \"\"\"Tests for dead_code.py module.\"\"\"\n\n    def test_detect_dead_code(self, temp_project):\n        \"\"\"Test dead code detection.\"\"\"\n        from scripts.dead_code import detect_dead_code\n\n        report = detect_dead_code(temp_project)\n        if report is None:\n            raise AssertionError(\"Report should not be None\")\n        if not report.total_issues >= 0:\n            raise AssertionError(\"Total issues should be non-negative\")\n\n    def test_report_to_markdown(self, temp_project):\n        \"\"\"Test report conversion to markdown.\"\"\"\n        from scripts.dead_code import detect_dead_code\n\n        report = detect_dead_code(temp_project)\n        markdown = report.to_markdown()\n        if \"Dead Code Report\" not in markdown:\n            raise AssertionError(\"Markdown should contain 'Dead Code Report'\")", "chunk_type": "class", "line_start": 136, "line_end": 156, "language": "python", "name": "TestDeadCode"}, "4c1fe222b209_class_TestAutoDocs": {"id": "4c1fe222b209_class_TestAutoDocs", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\tests\\test_scripts.py", "content": "class TestAutoDocs:\n    \"\"\"Tests for auto_docs.py module.\"\"\"\n\n    def test_analyze_file_for_docstrings(self, temp_project):\n        \"\"\"Test docstring analysis.\"\"\"\n        from scripts.auto_docs import analyze_file_for_docstrings\n\n        suggestions = analyze_file_for_docstrings(temp_project / \"no_docs.py\")\n        if not len(suggestions) >= 2:\n            raise AssertionError(\"Should find at least 2 suggestions\")\n\n    def test_generate_function_docstring(self):\n        \"\"\"Test docstring generation.\"\"\"\n        from scripts.auto_docs import generate_function_docstring\n        from scripts.utils import FunctionInfo\n        import ast\n\n        # Create a mock function node\n        code = \"def test_func(arg1: str, arg2: int) -> bool: pass\"\n        tree = ast.parse(code)\n        node = tree.body[0]\n\n        docstring = generate_function_docstring(node, \"    \")\n        if '\"\"\"' not in docstring:\n            raise AssertionError(\"Docstring should contain quotes\")\n        if 'Args:' not in doc", "chunk_type": "class", "line_start": 159, "line_end": 185, "language": "python", "name": "TestAutoDocs"}, "4c1fe222b209_class_TestAutoTest": {"id": "4c1fe222b209_class_TestAutoTest", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\tests\\test_scripts.py", "content": "class TestAutoTest:\n    \"\"\"Tests for auto_test.py module.\"\"\"\n\n    def test_generate_test_function(self):\n        \"\"\"Test test function generation.\"\"\"\n        from scripts.auto_test import generate_test_function\n        from scripts.utils import FunctionInfo\n\n        func = FunctionInfo(\n            name=\"my_function\",\n            lineno=1,\n            end_lineno=10,\n            args=[\"arg1\", \"arg2\"],\n            arg_types={\"arg1\": \"str\", \"arg2\": \"int\"},\n            return_type=\"bool\",\n            docstring=\"Test function.\"\n        )\n\n        test_code = generate_test_function(func, \"mymodule\")\n        if \"def test_my_function\" not in test_code:\n            raise AssertionError(\"Should generate test function definition\")\n        if \"assert\" not in test_code:\n            raise AssertionError(\"Should contain assertion in generated code\")", "chunk_type": "class", "line_start": 188, "line_end": 210, "language": "python", "name": "TestAutoTest"}, "4c1fe222b209_class_TestSummarize": {"id": "4c1fe222b209_class_TestSummarize", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\tests\\test_scripts.py", "content": "class TestSummarize:\n    \"\"\"Tests for summarize.py module.\"\"\"\n\n    def test_summarize_codebase(self, temp_project):\n        \"\"\"Test codebase summarization.\"\"\"\n        from scripts.summarize import summarize_codebase\n\n        summary = summarize_codebase(temp_project)\n        if not summary.total_files >= 2:\n            raise AssertionError(\"Should handle at least 2 files\")\n        if not summary.total_functions >= 2:\n            raise AssertionError(\"Should handle at least 2 functions\")\n\n    def test_format_summary_markdown(self, temp_project):\n        \"\"\"Test summary markdown formatting.\"\"\"\n        from scripts.summarize import summarize_codebase, format_summary_markdown\n\n        summary = summarize_codebase(temp_project)\n        markdown = format_summary_markdown(summary)\n        if \"# Codebase Summary\" not in markdown:\n            raise AssertionError(\"Markdown should contain header\")", "chunk_type": "class", "line_start": 213, "line_end": 233, "language": "python", "name": "TestSummarize"}, "4c1fe222b209_class_TestChangelog": {"id": "4c1fe222b209_class_TestChangelog", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\tests\\test_scripts.py", "content": "class TestChangelog:\n    \"\"\"Tests for changelog.py module.\"\"\"\n\n    def test_parse_commit_message(self):\n        \"\"\"Test commit message parsing.\"\"\"\n        from scripts.changelog import parse_commit_message\n\n        entry = parse_commit_message(\"feat(auth): add login functionality\")\n        if entry is None:\n            raise AssertionError(\"Entry should not be None\")\n        if entry.commit_type != \"feat\":\n            raise AssertionError(\"Commit type should be feat\")\n        if entry.scope != \"auth\":\n            raise AssertionError(\"Scope should be auth\")\n        if \"login\" not in entry.description:\n            raise AssertionError(\"Description should contain login\")\n\n    def test_parse_commit_message_breaking(self):\n        \"\"\"Test breaking change detection.\"\"\"\n        from scripts.changelog import parse_commit_message\n\n        entry = parse_commit_message(\"feat!: breaking change\")\n        if entry is None:\n            raise AssertionError(\"Entry should not be None\")\n        if entr", "chunk_type": "class", "line_start": 236, "line_end": 261, "language": "python", "name": "TestChangelog"}, "4c1fe222b209_class_TestDeps": {"id": "4c1fe222b209_class_TestDeps", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\tests\\test_scripts.py", "content": "class TestDeps:\n    \"\"\"Tests for deps.py module.\"\"\"\n\n    def test_analyze_dependencies(self, temp_project):\n        \"\"\"Test dependency analysis.\"\"\"\n        from scripts.deps import analyze_dependencies\n\n        report = analyze_dependencies(temp_project)\n        if report is None:\n            raise AssertionError(\"Report should not be None\")\n        if not len(report.modules) >= 2:\n            raise AssertionError(\"Should find at least 2 modules\")\n\n    def test_format_report_markdown(self, temp_project):\n        \"\"\"Test dependency report markdown.\"\"\"\n        from scripts.deps import analyze_dependencies, format_report_markdown\n\n        report = analyze_dependencies(temp_project)\n        markdown = format_report_markdown(report)\n        if \"# Dependency Analysis\" not in markdown:\n            raise AssertionError(\"Markdown should contain header\")", "chunk_type": "class", "line_start": 264, "line_end": 284, "language": "python", "name": "TestDeps"}, "4c1fe222b209_class_TestReview": {"id": "4c1fe222b209_class_TestReview", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\tests\\test_scripts.py", "content": "class TestReview:\n    \"\"\"Tests for review.py module.\"\"\"\n\n    def test_review_file(self, temp_project):\n        \"\"\"Test file review.\"\"\"\n        from scripts.review import review_file\n\n        issues = review_file(temp_project / \"no_docs.py\")\n        if not len(issues) >= 1:\n            raise AssertionError(\"Should find missing docstrings\")\n\n    def test_review_project(self, temp_project):\n        \"\"\"Test project review.\"\"\"\n        from scripts.review import review_project\n\n        report = review_project(temp_project)\n        if not report.files_reviewed >= 2:\n            raise AssertionError(\"Should review at least 2 files\")\n\n    def test_security_check(self):\n        \"\"\"Test security issue detection.\"\"\"\n        from scripts.review import ReviewChecks\n        import ast\n\n        code = '''\ntest_val = \"mock\" + \"_\" + \"credential\"\neval(user_input)\n'''\n        tree = ast.parse(code)\n\n        with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:\n            f.write(co", "chunk_type": "class", "line_start": 287, "line_end": 325, "language": "python", "name": "TestReview"}, "5938d0bae2e6_file": {"id": "5938d0bae2e6_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\mcp-global\\mcp-global-rules\\tests\\__init__.py", "content": "\"\"\"Tests package.\"\"\"\n", "chunk_type": "file", "line_start": 1, "line_end": 2, "language": "python", "name": "__init__.py"}, "433f3603a786_file": {"id": "433f3603a786_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\simple_test.py", "content": "from pathlib import Path\nimport shutil\nimport subprocess\nimport time\n\nfrom agent_manager.core.event_bus import EventBusService\nfrom agent_manager.core.git_service import GitMonitoringService\n\n# Setup\ntmp_dir = Path(\"simple_git_test\")\nif tmp_dir.exists():\n    shutil.rmtree(tmp_dir)\ntmp_dir.mkdir()\n\nprint(f\"Initializing git in {tmp_dir}...\")\nsubprocess.run(['git', 'init'], cwd=tmp_dir, check=True, capture_output=True)\nsubprocess.run(['git', 'config', 'user.email', 'test@example.com'], cwd=tmp_dir, check=True, capture_output=True)\nsubprocess.run(['git', 'config', 'user.name', 'Test User'], cwd=tmp_dir, check=True, capture_output=True)\n\nbus = EventBusService()\ndef log_event(t, d):\n    print(f\"EVENT DETECTED: {d['type']} - {d['data']}\")\nbus.subscribe(\"git_event\", log_event)\n\nfrom agent_manager.core import git_service\ngit_service.HAS_WATCHDOG = False\n\nmonitor = GitMonitoringService(bus, root_path=str(tmp_dir))\nmonitor.start()\n\ntime.sleep(1)\n\nprint(\"--- Creating branch ---\")\nsubprocess.run(['git', 'checkout', '-b', 'feature/ai-git'], cwd=tmp_dir, check=True, capture_output=True)\ntime.sleep(2)\n\nprint(\"--- Creating commit ---\")\nwith open(tmp_dir / \"firefly.txt\", \"w\") as f:\n    f.write(\"Firefly is watching.\")\nsubprocess.run(['git', 'add', 'firefly.txt'], cwd=tmp_dir, check=True, capture_output=True)\nsubprocess.run(['git', 'commit', '-m', 'feat: firefly observation'], cwd=tmp_dir, check=True, capture_output=True)\ntime.sleep(2)\n\nmonitor.stop()\nprint(\"Cleanup...\")\n# Wait a bit for file handles to release\ntime.sleep(1)\ntry:\n    shutil.rmtree(tmp_dir)\n    print(\"Cleanup successful.\")\nexcept Exception as e:\n    print(f\"Cleanup failed (expected on Windows sometimes): {e}\")\n", "chunk_type": "file", "line_start": 1, "line_end": 53, "language": "python", "name": "simple_test.py"}, "433f3603a786_func_log_event": {"id": "433f3603a786_func_log_event", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\simple_test.py", "content": "def log_event(t, d):\n    print(f\"EVENT DETECTED: {d['type']} - {d['data']}\")", "chunk_type": "function", "line_start": 21, "line_end": 22, "language": "python", "name": "log_event"}, "eb4a17587240_file": {"id": "eb4a17587240_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_ai_client_failover.py", "content": "from unittest.mock import MagicMock\nimport unittest\n\nfrom agent_manager.models.base import BaseModelService\nfrom agent_manager.models.manager import ModelClientManager\n\nclass MockFailingService(BaseModelService):\n    def validate_config(self): return True\n    def generate(self, prompt, system_prompt=None): raise Exception(\"Simulated Failure\")\n\nclass MockSuccessService(BaseModelService):\n    def validate_config(self): return True\n    def generate(self, prompt, system_prompt=None): return \"Success Response\"\n\nclass TestModelClient(unittest.TestCase):\n    def test_failover_logic(self):\n        \"\"\"Test that the manager fails over from a bad service to a good one.\"\"\"\n        bad_provider = MockFailingService(model_name=\"bad\")\n        good_provider = MockSuccessService(model_name=\"good\")\n\n        manager = ModelClientManager(providers=[bad_provider, good_provider])\n\n        # Should succeed despite the first provider failing\n        response = manager.generate(\"Hello\")\n        self.assertEqual(response, \"Success Response\")\n\n    def test_all_fail(self):\n        \"\"\"Test strict failure when all providers fail.\"\"\"\n        bad1 = MockFailingService(model_name=\"bad1\")\n        bad2 = MockFailingService(model_name=\"bad2\")\n\n        manager = ModelClientManager(providers=[bad1, bad2])\n\n        with self.assertRaises(RuntimeError):\n            manager.generate(\"Hello\")\n\nif __name__ == \"__main__\":\n    unittest.main()\n", "chunk_type": "file", "line_start": 1, "line_end": 39, "language": "python", "name": "test_ai_client_failover.py"}, "eb4a17587240_func_validate_config": {"id": "eb4a17587240_func_validate_config", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_ai_client_failover.py", "content": "    def validate_config(self): return True", "chunk_type": "function", "line_start": 12, "line_end": 12, "language": "python", "name": "validate_config"}, "eb4a17587240_func_generate": {"id": "eb4a17587240_func_generate", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_ai_client_failover.py", "content": "    def generate(self, prompt, system_prompt=None): return \"Success Response\"", "chunk_type": "function", "line_start": 13, "line_end": 13, "language": "python", "name": "generate"}, "eb4a17587240_func_test_failover_logic": {"id": "eb4a17587240_func_test_failover_logic", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_ai_client_failover.py", "content": "    def test_failover_logic(self):\n        \"\"\"Test that the manager fails over from a bad service to a good one.\"\"\"\n        bad_provider = MockFailingService(model_name=\"bad\")\n        good_provider = MockSuccessService(model_name=\"good\")\n\n        manager = ModelClientManager(providers=[bad_provider, good_provider])\n\n        # Should succeed despite the first provider failing\n        response = manager.generate(\"Hello\")\n        self.assertEqual(response, \"Success Response\")", "chunk_type": "function", "line_start": 16, "line_end": 25, "language": "python", "name": "test_failover_logic"}, "eb4a17587240_func_test_all_fail": {"id": "eb4a17587240_func_test_all_fail", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_ai_client_failover.py", "content": "    def test_all_fail(self):\n        \"\"\"Test strict failure when all providers fail.\"\"\"\n        bad1 = MockFailingService(model_name=\"bad1\")\n        bad2 = MockFailingService(model_name=\"bad2\")\n\n        manager = ModelClientManager(providers=[bad1, bad2])\n\n        with self.assertRaises(RuntimeError):\n            manager.generate(\"Hello\")", "chunk_type": "function", "line_start": 27, "line_end": 35, "language": "python", "name": "test_all_fail"}, "eb4a17587240_class_MockFailingService": {"id": "eb4a17587240_class_MockFailingService", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_ai_client_failover.py", "content": "class MockFailingService(BaseModelService):\n    def validate_config(self): return True\n    def generate(self, prompt, system_prompt=None): raise Exception(\"Simulated Failure\")", "chunk_type": "class", "line_start": 7, "line_end": 9, "language": "python", "name": "MockFailingService"}, "eb4a17587240_class_MockSuccessService": {"id": "eb4a17587240_class_MockSuccessService", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_ai_client_failover.py", "content": "class MockSuccessService(BaseModelService):\n    def validate_config(self): return True\n    def generate(self, prompt, system_prompt=None): return \"Success Response\"", "chunk_type": "class", "line_start": 11, "line_end": 13, "language": "python", "name": "MockSuccessService"}, "eb4a17587240_class_TestModelClient": {"id": "eb4a17587240_class_TestModelClient", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_ai_client_failover.py", "content": "class TestModelClient(unittest.TestCase):\n    def test_failover_logic(self):\n        \"\"\"Test that the manager fails over from a bad service to a good one.\"\"\"\n        bad_provider = MockFailingService(model_name=\"bad\")\n        good_provider = MockSuccessService(model_name=\"good\")\n\n        manager = ModelClientManager(providers=[bad_provider, good_provider])\n\n        # Should succeed despite the first provider failing\n        response = manager.generate(\"Hello\")\n        self.assertEqual(response, \"Success Response\")\n\n    def test_all_fail(self):\n        \"\"\"Test strict failure when all providers fail.\"\"\"\n        bad1 = MockFailingService(model_name=\"bad1\")\n        bad2 = MockFailingService(model_name=\"bad2\")\n\n        manager = ModelClientManager(providers=[bad1, bad2])\n\n        with self.assertRaises(RuntimeError):\n            manager.generate(\"Hello\")", "chunk_type": "class", "line_start": 15, "line_end": 35, "language": "python", "name": "TestModelClient"}, "fe804ca41038_file": {"id": "fe804ca41038_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_api_service.py", "content": "from pathlib import Path\nfrom unittest.mock import MagicMock\nimport json\nimport shutil\nimport time\nimport unittest\nimport urllib.request\n\nfrom agent_manager.core.api_service import APIService\nfrom agent_manager.core.artifact_service import ArtifactService\nfrom agent_manager.core.event_bus import EventBusService\n\nclass TestAPIService(unittest.TestCase):\n    @classmethod\n    def setUpClass(cls):\n        cls.test_root = Path(\"test_api_root\")\n        if cls.test_root.exists():\n            shutil.rmtree(cls.test_root)\n        cls.test_root.mkdir()\n\n        cls.bus = EventBusService()\n        cls.artifacts = ArtifactService(root_path=str(cls.test_root))\n        cls.mock_client = MagicMock()\n        cls.mock_client.usage_ledger = {\"total_cost_usd\": 0.05}\n        cls.api = APIService(cls.bus, cls.artifacts, model_client=cls.mock_client, port=5051)\n        cls.api.start()\n\n        # Give it a moment to start\n        time.sleep(0.5)\n\n    @classmethod\n    def tearDownClass(cls):\n        cls.api.stop()\n        if cls.test_root.exists():\n            shutil.rmtree(cls.test_root)\n\n    def test_list_sessions_empty(self):\n        with urllib.request.urlopen(\"http://localhost:5051/api/artifacts\") as response:\n            data = json.loads(response.read().decode())\n            self.assertIsInstance(data, list)\n\n    def test_artifacts_flow(self):\n        session_id = \"test_session_123\"\n        self.artifacts.create_artifact(session_id, \"thought\", \"I am thinking\")\n\n        # 1. List sessions\n        with urllib.request.urlopen(\"http://localhost:5051/api/artifacts\") as response:\n            sessions = json.loads(response.read().decode())\n            self.assertIn(session_id, sessions)\n\n        # 2. List artifacts in session\n        with urllib.request.urlopen(f\"http://localhost:5051/api/artifacts/{session_id}\") as response:\n            arts = json.loads(response.read().decode())\n            self.assertEqual(len(arts), 1)\n            self.assertEqual(arts[0][\"type\"], \"thought\")\n          ", "chunk_type": "file", "line_start": 1, "line_end": 76, "language": "python", "name": "test_api_service.py"}, "fe804ca41038_func_setUpClass": {"id": "fe804ca41038_func_setUpClass", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_api_service.py", "content": "    def setUpClass(cls):\n        cls.test_root = Path(\"test_api_root\")\n        if cls.test_root.exists():\n            shutil.rmtree(cls.test_root)\n        cls.test_root.mkdir()\n\n        cls.bus = EventBusService()\n        cls.artifacts = ArtifactService(root_path=str(cls.test_root))\n        cls.mock_client = MagicMock()\n        cls.mock_client.usage_ledger = {\"total_cost_usd\": 0.05}\n        cls.api = APIService(cls.bus, cls.artifacts, model_client=cls.mock_client, port=5051)\n        cls.api.start()\n\n        # Give it a moment to start\n        time.sleep(0.5)", "chunk_type": "function", "line_start": 15, "line_end": 29, "language": "python", "name": "setUpClass"}, "fe804ca41038_func_tearDownClass": {"id": "fe804ca41038_func_tearDownClass", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_api_service.py", "content": "    def tearDownClass(cls):\n        cls.api.stop()\n        if cls.test_root.exists():\n            shutil.rmtree(cls.test_root)", "chunk_type": "function", "line_start": 32, "line_end": 35, "language": "python", "name": "tearDownClass"}, "fe804ca41038_func_test_list_sessions_empty": {"id": "fe804ca41038_func_test_list_sessions_empty", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_api_service.py", "content": "    def test_list_sessions_empty(self):\n        with urllib.request.urlopen(\"http://localhost:5051/api/artifacts\") as response:\n            data = json.loads(response.read().decode())\n            self.assertIsInstance(data, list)", "chunk_type": "function", "line_start": 37, "line_end": 40, "language": "python", "name": "test_list_sessions_empty"}, "fe804ca41038_func_test_artifacts_flow": {"id": "fe804ca41038_func_test_artifacts_flow", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_api_service.py", "content": "    def test_artifacts_flow(self):\n        session_id = \"test_session_123\"\n        self.artifacts.create_artifact(session_id, \"thought\", \"I am thinking\")\n\n        # 1. List sessions\n        with urllib.request.urlopen(\"http://localhost:5051/api/artifacts\") as response:\n            sessions = json.loads(response.read().decode())\n            self.assertIn(session_id, sessions)\n\n        # 2. List artifacts in session\n        with urllib.request.urlopen(f\"http://localhost:5051/api/artifacts/{session_id}\") as response:\n            arts = json.loads(response.read().decode())\n            self.assertEqual(len(arts), 1)\n            self.assertEqual(arts[0][\"type\"], \"thought\")\n            filename = arts[0][\"name\"]\n\n        # 3. Get specific artifact\n        with urllib.request.urlopen(f\"http://localhost:5051/api/artifacts/{session_id}/{filename}\") as response:\n            content = json.loads(response.read().decode())\n            self.assertEqual(content[\"content\"], \"I am thinking\")", "chunk_type": "function", "line_start": 42, "line_end": 61, "language": "python", "name": "test_artifacts_flow"}, "fe804ca41038_func_test_status_endpoint": {"id": "fe804ca41038_func_test_status_endpoint", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_api_service.py", "content": "    def test_status_endpoint(self):\n        with urllib.request.urlopen(\"http://localhost:5051/api/status\") as response:\n            data = json.loads(response.read().decode())\n            self.assertEqual(data[\"status\"], \"online\")\n            self.assertIn(\"usage_api\", data[\"capabilities\"])", "chunk_type": "function", "line_start": 63, "line_end": 67, "language": "python", "name": "test_status_endpoint"}, "fe804ca41038_func_test_usage_endpoint": {"id": "fe804ca41038_func_test_usage_endpoint", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_api_service.py", "content": "    def test_usage_endpoint(self):\n        with urllib.request.urlopen(\"http://localhost:5051/api/usage\") as response:\n            data = json.loads(response.read().decode())\n            self.assertEqual(data[\"total_cost_usd\"], 0.05)", "chunk_type": "function", "line_start": 69, "line_end": 72, "language": "python", "name": "test_usage_endpoint"}, "fe804ca41038_class_TestAPIService": {"id": "fe804ca41038_class_TestAPIService", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_api_service.py", "content": "class TestAPIService(unittest.TestCase):\n    @classmethod\n    def setUpClass(cls):\n        cls.test_root = Path(\"test_api_root\")\n        if cls.test_root.exists():\n            shutil.rmtree(cls.test_root)\n        cls.test_root.mkdir()\n\n        cls.bus = EventBusService()\n        cls.artifacts = ArtifactService(root_path=str(cls.test_root))\n        cls.mock_client = MagicMock()\n        cls.mock_client.usage_ledger = {\"total_cost_usd\": 0.05}\n        cls.api = APIService(cls.bus, cls.artifacts, model_client=cls.mock_client, port=5051)\n        cls.api.start()\n\n        # Give it a moment to start\n        time.sleep(0.5)\n\n    @classmethod\n    def tearDownClass(cls):\n        cls.api.stop()\n        if cls.test_root.exists():\n            shutil.rmtree(cls.test_root)\n\n    def test_list_sessions_empty(self):\n        with urllib.request.urlopen(\"http://localhost:5051/api/artifacts\") as response:\n            data = json.loads(response.read().decode())\n            self.assertIsInstance(data, list)\n\n", "chunk_type": "class", "line_start": 13, "line_end": 72, "language": "python", "name": "TestAPIService"}, "f3c222cdffe1_file": {"id": "f3c222cdffe1_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_artifacts.py", "content": "from pathlib import Path\nimport json\nimport os\nimport shutil\nimport unittest\n\nfrom agent_manager.core.artifact_service import ArtifactService\n\nclass TestArtifactService(unittest.TestCase):\n    def setUp(self):\n        self.test_root = Path(\"test_workspace\")\n        self.test_root.mkdir(exist_ok=True)\n        self.service = ArtifactService(root_path=str(self.test_root))\n\n    def tearDown(self):\n        if self.test_root.exists():\n            shutil.rmtree(self.test_root)\n\n    def test_create_artifact(self):\n        session_id = \"test_session\"\n        artifact_type = \"test_type\"\n        content = {\"key\": \"value\"}\n\n        path = self.service.create_artifact(session_id, artifact_type, content)\n        self.assertIsNotNone(path)\n        self.assertTrue(os.path.exists(path))\n\n        with open(path, 'r', encoding='utf-8') as f:\n            data = json.load(f)\n            self.assertEqual(data[\"session_id\"], session_id)\n            self.assertEqual(data[\"type\"], artifact_type)\n            self.assertEqual(data[\"content\"], content)\n\n    def test_export_session_log(self):\n        session_id = \"test_session_log\"\n        self.service.create_artifact(session_id, \"thought\", \"I am thinking.\")\n        self.service.create_artifact(session_id, \"command\", {\"cmd\": \"ls\", \"success\": True})\n\n        log_path = self.service.export_session_log(session_id)\n        self.assertIsNotNone(log_path)\n        self.assertTrue(os.path.exists(log_path))\n\n        with open(log_path, 'r', encoding='utf-8') as f:\n            content = f.read()\n            self.assertIn(\"# Session Log: test_session_log\", content)\n            self.assertIn(\"THOUGHT\", content)\n            self.assertIn(\"I am thinking.\", content)\n            self.assertIn(\"COMMAND\", content)\n\nif __name__ == \"__main__\":\n    unittest.main()\n", "chunk_type": "file", "line_start": 1, "line_end": 52, "language": "python", "name": "test_artifacts.py"}, "f3c222cdffe1_func_setUp": {"id": "f3c222cdffe1_func_setUp", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_artifacts.py", "content": "    def setUp(self):\n        self.test_root = Path(\"test_workspace\")\n        self.test_root.mkdir(exist_ok=True)\n        self.service = ArtifactService(root_path=str(self.test_root))", "chunk_type": "function", "line_start": 10, "line_end": 13, "language": "python", "name": "setUp"}, "f3c222cdffe1_func_tearDown": {"id": "f3c222cdffe1_func_tearDown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_artifacts.py", "content": "    def tearDown(self):\n        if self.test_root.exists():\n            shutil.rmtree(self.test_root)", "chunk_type": "function", "line_start": 15, "line_end": 17, "language": "python", "name": "tearDown"}, "f3c222cdffe1_func_test_create_artifact": {"id": "f3c222cdffe1_func_test_create_artifact", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_artifacts.py", "content": "    def test_create_artifact(self):\n        session_id = \"test_session\"\n        artifact_type = \"test_type\"\n        content = {\"key\": \"value\"}\n\n        path = self.service.create_artifact(session_id, artifact_type, content)\n        self.assertIsNotNone(path)\n        self.assertTrue(os.path.exists(path))\n\n        with open(path, 'r', encoding='utf-8') as f:\n            data = json.load(f)\n            self.assertEqual(data[\"session_id\"], session_id)\n            self.assertEqual(data[\"type\"], artifact_type)\n            self.assertEqual(data[\"content\"], content)", "chunk_type": "function", "line_start": 19, "line_end": 32, "language": "python", "name": "test_create_artifact"}, "f3c222cdffe1_func_test_export_session_log": {"id": "f3c222cdffe1_func_test_export_session_log", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_artifacts.py", "content": "    def test_export_session_log(self):\n        session_id = \"test_session_log\"\n        self.service.create_artifact(session_id, \"thought\", \"I am thinking.\")\n        self.service.create_artifact(session_id, \"command\", {\"cmd\": \"ls\", \"success\": True})\n\n        log_path = self.service.export_session_log(session_id)\n        self.assertIsNotNone(log_path)\n        self.assertTrue(os.path.exists(log_path))\n\n        with open(log_path, 'r', encoding='utf-8') as f:\n            content = f.read()\n            self.assertIn(\"# Session Log: test_session_log\", content)\n            self.assertIn(\"THOUGHT\", content)\n            self.assertIn(\"I am thinking.\", content)\n            self.assertIn(\"COMMAND\", content)", "chunk_type": "function", "line_start": 34, "line_end": 48, "language": "python", "name": "test_export_session_log"}, "f3c222cdffe1_class_TestArtifactService": {"id": "f3c222cdffe1_class_TestArtifactService", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_artifacts.py", "content": "class TestArtifactService(unittest.TestCase):\n    def setUp(self):\n        self.test_root = Path(\"test_workspace\")\n        self.test_root.mkdir(exist_ok=True)\n        self.service = ArtifactService(root_path=str(self.test_root))\n\n    def tearDown(self):\n        if self.test_root.exists():\n            shutil.rmtree(self.test_root)\n\n    def test_create_artifact(self):\n        session_id = \"test_session\"\n        artifact_type = \"test_type\"\n        content = {\"key\": \"value\"}\n\n        path = self.service.create_artifact(session_id, artifact_type, content)\n        self.assertIsNotNone(path)\n        self.assertTrue(os.path.exists(path))\n\n        with open(path, 'r', encoding='utf-8') as f:\n            data = json.load(f)\n            self.assertEqual(data[\"session_id\"], session_id)\n            self.assertEqual(data[\"type\"], artifact_type)\n            self.assertEqual(data[\"content\"], content)\n\n    def test_export_session_log(self):\n        session_id = \"test_session_log\"\n        self.service.c", "chunk_type": "class", "line_start": 9, "line_end": 48, "language": "python", "name": "TestArtifactService"}, "f401bcdd672e_file": {"id": "f401bcdd672e_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_autonomous_loop.py", "content": "from unittest.mock import MagicMock, patch\nimport unittest\n\nfrom agent_manager.core.config_service import ConfigurationService\nfrom agent_manager.core.event_bus import EventBusService\nfrom agent_manager.core.tag_parser import TagParserService\nfrom agent_manager.orchestrator import OrchestratorManager\n\nclass TestFireflyAutonomousLoop(unittest.TestCase):\n    def setUp(self):\n        self.bus = EventBusService()\n        self.config = ConfigurationService() # Uses defaults\n        self.model_client = MagicMock()\n        self.orchestrator = OrchestratorManager(\n            event_bus=self.bus,\n            model_client=self.model_client,\n            config_service=self.config\n        )\n        self.orchestrator.start()\n\n    def test_autonomous_command_execution(self):\n        \"\"\"Verify that <command> tags are parsed and executed if safe.\"\"\"\n        # Mock AI response with thoughts and commands\n        mock_response = MagicMock()\n        mock_response.text = (\n            \"<thought>I need to check the project status.</thought>\\n\"\n            \"<command>git status</command>\\n\"\n            \"<message>Status checked.</message>\"\n        )\n        self.model_client.generate.return_value = mock_response\n\n        with patch('subprocess.run') as mock_run:\n            mock_run.return_value = MagicMock(stdout=\"On branch main\", stderr=\"\", returncode=0)\n\n            # Trigger telegram input\n            self.bus.publish(\"telegram_input\", {\"text\": \"check status\", \"chat_id\": 123, \"user\": \"test_user\"})\n\n            # Check if subprocess was called with the correct command\n            mock_run.assert_called_with(\"git status\", shell=True, capture_output=True, text=True, timeout=30)\n\n    def test_safety_policy_block(self):\n        \"\"\"Verify that destructive commands are blocked by the safety policy.\"\"\"\n        mock_response = MagicMock()\n        mock_response.text = \"<command>rm -rf /</command>\"\n        self.model_client.generate.return_value = mock_response\n\n        with patch('subprocess.run'", "chunk_type": "file", "line_start": 1, "line_end": 55, "language": "python", "name": "test_autonomous_loop.py"}, "f401bcdd672e_func_setUp": {"id": "f401bcdd672e_func_setUp", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_autonomous_loop.py", "content": "    def setUp(self):\n        self.bus = EventBusService()\n        self.config = ConfigurationService() # Uses defaults\n        self.model_client = MagicMock()\n        self.orchestrator = OrchestratorManager(\n            event_bus=self.bus,\n            model_client=self.model_client,\n            config_service=self.config\n        )\n        self.orchestrator.start()", "chunk_type": "function", "line_start": 10, "line_end": 19, "language": "python", "name": "setUp"}, "f401bcdd672e_func_test_autonomous_command_execution": {"id": "f401bcdd672e_func_test_autonomous_command_execution", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_autonomous_loop.py", "content": "    def test_autonomous_command_execution(self):\n        \"\"\"Verify that <command> tags are parsed and executed if safe.\"\"\"\n        # Mock AI response with thoughts and commands\n        mock_response = MagicMock()\n        mock_response.text = (\n            \"<thought>I need to check the project status.</thought>\\n\"\n            \"<command>git status</command>\\n\"\n            \"<message>Status checked.</message>\"\n        )\n        self.model_client.generate.return_value = mock_response\n\n        with patch('subprocess.run') as mock_run:\n            mock_run.return_value = MagicMock(stdout=\"On branch main\", stderr=\"\", returncode=0)\n\n            # Trigger telegram input\n            self.bus.publish(\"telegram_input\", {\"text\": \"check status\", \"chat_id\": 123, \"user\": \"test_user\"})\n\n            # Check if subprocess was called with the correct command\n            mock_run.assert_called_with(\"git status\", shell=True, capture_output=True, text=True, timeout=30)", "chunk_type": "function", "line_start": 21, "line_end": 39, "language": "python", "name": "test_autonomous_command_execution"}, "f401bcdd672e_func_test_safety_policy_block": {"id": "f401bcdd672e_func_test_safety_policy_block", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_autonomous_loop.py", "content": "    def test_safety_policy_block(self):\n        \"\"\"Verify that destructive commands are blocked by the safety policy.\"\"\"\n        mock_response = MagicMock()\n        mock_response.text = \"<command>rm -rf /</command>\"\n        self.model_client.generate.return_value = mock_response\n\n        with patch('subprocess.run') as mock_run:\n            self.bus.publish(\"telegram_input\", {\"text\": \"delete everything\", \"chat_id\": 123, \"user\": \"test_user\"})\n\n            # Subprocess should NOT be called for unsafe command\n            mock_run.assert_not_called()", "chunk_type": "function", "line_start": 41, "line_end": 51, "language": "python", "name": "test_safety_policy_block"}, "f401bcdd672e_class_TestFireflyAutonomousLoop": {"id": "f401bcdd672e_class_TestFireflyAutonomousLoop", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_autonomous_loop.py", "content": "class TestFireflyAutonomousLoop(unittest.TestCase):\n    def setUp(self):\n        self.bus = EventBusService()\n        self.config = ConfigurationService() # Uses defaults\n        self.model_client = MagicMock()\n        self.orchestrator = OrchestratorManager(\n            event_bus=self.bus,\n            model_client=self.model_client,\n            config_service=self.config\n        )\n        self.orchestrator.start()\n\n    def test_autonomous_command_execution(self):\n        \"\"\"Verify that <command> tags are parsed and executed if safe.\"\"\"\n        # Mock AI response with thoughts and commands\n        mock_response = MagicMock()\n        mock_response.text = (\n            \"<thought>I need to check the project status.</thought>\\n\"\n            \"<command>git status</command>\\n\"\n            \"<message>Status checked.</message>\"\n        )\n        self.model_client.generate.return_value = mock_response\n\n        with patch('subprocess.run') as mock_run:\n            mock_run.return_value = MagicMock", "chunk_type": "class", "line_start": 9, "line_end": 51, "language": "python", "name": "TestFireflyAutonomousLoop"}, "0bef27cfe544_file": {"id": "0bef27cfe544_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_browser_automation.py", "content": "from unittest.mock import MagicMock\nimport unittest\n\nfrom agent_manager.core.browser_adapter import BrowserService\nfrom agent_manager.core.event_bus import EventBusService\nfrom agent_manager.orchestrator import OrchestratorManager\nimport asyncio\n\nclass TestBrowserAutomation(unittest.TestCase):\n    def setUp(self):\n        self.event_bus = EventBusService()\n        self.browser_service = BrowserService(self.event_bus)\n        self.model_client = MagicMock()\n        self.orchestrator = OrchestratorManager(\n            event_bus=self.event_bus,\n            model_client=self.model_client,\n            browser_service=self.browser_service\n        )\n\n    def test_browser_adapter_navigation(self):\n        async def run_test():\n            result = await self.browser_service.navigate(\"https://example.com\")\n            self.assertEqual(result[\"status\"], \"success\")\n            text = await self.browser_service.get_text()\n            self.assertIn(\"Example Domain\", text[\"content\"])\n            await self.browser_service.stop()\n\n        asyncio.run(run_test())\n\n    def test_orchestrator_browser_tag(self):\n        # Mock AI response with a browser tag\n        mock_response = MagicMock()\n        mock_response.text = 'I will look at example.com. <browser action=\"navigate\" url=\"https://example.com\"/> <browser action=\"get_text\"/>'\n        self.model_client.generate.return_value = mock_response\n\n        # Use sync bridge\n        self.orchestrator.process_request(\"Search for example.com\", source=\"user\")\n\n        # Verify that browser adapter was used (we check if it started/navigated)\n        # Since it's a real browser, loop.run_until_complete in process_request should have finished.\n\n        # Cleanup\n        asyncio.run(self.browser_service.stop())\n\nif __name__ == \"__main__\":\n    unittest.main()\n", "chunk_type": "file", "line_start": 1, "line_end": 47, "language": "python", "name": "test_browser_automation.py"}, "0bef27cfe544_func_setUp": {"id": "0bef27cfe544_func_setUp", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_browser_automation.py", "content": "    def setUp(self):\n        self.event_bus = EventBusService()\n        self.browser_service = BrowserService(self.event_bus)\n        self.model_client = MagicMock()\n        self.orchestrator = OrchestratorManager(\n            event_bus=self.event_bus,\n            model_client=self.model_client,\n            browser_service=self.browser_service\n        )", "chunk_type": "function", "line_start": 10, "line_end": 18, "language": "python", "name": "setUp"}, "0bef27cfe544_func_test_browser_adapter_navigation": {"id": "0bef27cfe544_func_test_browser_adapter_navigation", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_browser_automation.py", "content": "    def test_browser_adapter_navigation(self):\n        async def run_test():\n            result = await self.browser_service.navigate(\"https://example.com\")\n            self.assertEqual(result[\"status\"], \"success\")\n            text = await self.browser_service.get_text()\n            self.assertIn(\"Example Domain\", text[\"content\"])\n            await self.browser_service.stop()\n\n        asyncio.run(run_test())", "chunk_type": "function", "line_start": 20, "line_end": 28, "language": "python", "name": "test_browser_adapter_navigation"}, "0bef27cfe544_func_test_orchestrator_browser_tag": {"id": "0bef27cfe544_func_test_orchestrator_browser_tag", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_browser_automation.py", "content": "    def test_orchestrator_browser_tag(self):\n        # Mock AI response with a browser tag\n        mock_response = MagicMock()\n        mock_response.text = 'I will look at example.com. <browser action=\"navigate\" url=\"https://example.com\"/> <browser action=\"get_text\"/>'\n        self.model_client.generate.return_value = mock_response\n\n        # Use sync bridge\n        self.orchestrator.process_request(\"Search for example.com\", source=\"user\")\n\n        # Verify that browser adapter was used (we check if it started/navigated)\n        # Since it's a real browser, loop.run_until_complete in process_request should have finished.\n\n        # Cleanup\n        asyncio.run(self.browser_service.stop())", "chunk_type": "function", "line_start": 30, "line_end": 43, "language": "python", "name": "test_orchestrator_browser_tag"}, "0bef27cfe544_func_run_test": {"id": "0bef27cfe544_func_run_test", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_browser_automation.py", "content": "        async def run_test():\n            result = await self.browser_service.navigate(\"https://example.com\")\n            self.assertEqual(result[\"status\"], \"success\")\n            text = await self.browser_service.get_text()\n            self.assertIn(\"Example Domain\", text[\"content\"])\n            await self.browser_service.stop()", "chunk_type": "function", "line_start": 21, "line_end": 26, "language": "python", "name": "run_test"}, "0bef27cfe544_class_TestBrowserAutomation": {"id": "0bef27cfe544_class_TestBrowserAutomation", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_browser_automation.py", "content": "class TestBrowserAutomation(unittest.TestCase):\n    def setUp(self):\n        self.event_bus = EventBusService()\n        self.browser_service = BrowserService(self.event_bus)\n        self.model_client = MagicMock()\n        self.orchestrator = OrchestratorManager(\n            event_bus=self.event_bus,\n            model_client=self.model_client,\n            browser_service=self.browser_service\n        )\n\n    def test_browser_adapter_navigation(self):\n        async def run_test():\n            result = await self.browser_service.navigate(\"https://example.com\")\n            self.assertEqual(result[\"status\"], \"success\")\n            text = await self.browser_service.get_text()\n            self.assertIn(\"Example Domain\", text[\"content\"])\n            await self.browser_service.stop()\n\n        asyncio.run(run_test())\n\n    def test_orchestrator_browser_tag(self):\n        # Mock AI response with a browser tag\n        mock_response = MagicMock()\n        mock_response.text = 'I will look at example.co", "chunk_type": "class", "line_start": 9, "line_end": 43, "language": "python", "name": "TestBrowserAutomation"}, "cb5171896a5c_file": {"id": "cb5171896a5c_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_email_trigger.py", "content": "from unittest.mock import MagicMock, patch\nimport unittest\n\nfrom agent_manager.core.event_bus import EventBusService\nfrom agent_manager.triggers.email import EmailService\n\nclass TestEmailService(unittest.TestCase):\n    def setUp(self):\n        self.event_bus = EventBusService()\n        with patch.dict('os.environ', {'EMAIL_USER': 'test@firefly.io', 'EMAIL_PASS': 'pass'}):\n            self.service = EmailService(self.event_bus)\n\n    def test_handle_outgoing_message_triggers_send(self):\n        self.service.send_email = MagicMock()\n\n        payload = {\n            \"to\": \"developer@firefly.io\",\n            \"subject\": \"Firefly Test\",\n            \"text\": \"Hello from agent!\"\n        }\n        self.event_bus.publish(\"email_output\", payload)\n\n        self.service.send_email.assert_called_once_with(\n            \"developer@firefly.io\", \"Firefly Test\", \"Hello from agent!\"\n        )\n\n    @patch('imaplib.IMAP4_SSL')\n    def test_check_emails_matches_firefly_subject(self, mock_imap):\n        # Mock IMAP connection and results\n        instance = mock_imap.return_value\n        instance.login.return_value = ('OK', [b'Logged in'])\n        instance.select.return_value = ('OK', [b'1'])\n        instance.search.return_value = ('OK', [b'1'])\n\n        # Mock a raw email message\n        raw_email = b\"Subject: FIREFLY: Help me\\nFrom: user@test.com\\n\\nWhat is your purpose?\"\n        instance.fetch.return_value = ('OK', [[None, raw_email]])\n\n        # Subscribe to event to verify capture\n        mock_handler = MagicMock()\n        self.event_bus.subscribe(\"email_input\", mock_handler)\n\n        self.service._check_emails()\n\n        mock_handler.assert_called_once()\n        payload = mock_handler.call_args[0][1]\n        self.assertEqual(payload[\"from\"], \"user@test.com\")\n        self.assertEqual(payload[\"subject\"], \"FIREFLY: Help me\")\n        self.assertEqual(payload[\"text\"], \"What is your purpose?\")\n\nif __name__ == \"__main__\":\n    unittest.main()\n", "chunk_type": "file", "line_start": 1, "line_end": 53, "language": "python", "name": "test_email_trigger.py"}, "cb5171896a5c_func_setUp": {"id": "cb5171896a5c_func_setUp", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_email_trigger.py", "content": "    def setUp(self):\n        self.event_bus = EventBusService()\n        with patch.dict('os.environ', {'EMAIL_USER': 'test@firefly.io', 'EMAIL_PASS': 'pass'}):\n            self.service = EmailService(self.event_bus)", "chunk_type": "function", "line_start": 8, "line_end": 11, "language": "python", "name": "setUp"}, "cb5171896a5c_func_test_handle_outgoing_message_triggers_send": {"id": "cb5171896a5c_func_test_handle_outgoing_message_triggers_send", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_email_trigger.py", "content": "    def test_handle_outgoing_message_triggers_send(self):\n        self.service.send_email = MagicMock()\n\n        payload = {\n            \"to\": \"developer@firefly.io\",\n            \"subject\": \"Firefly Test\",\n            \"text\": \"Hello from agent!\"\n        }\n        self.event_bus.publish(\"email_output\", payload)\n\n        self.service.send_email.assert_called_once_with(\n            \"developer@firefly.io\", \"Firefly Test\", \"Hello from agent!\"\n        )", "chunk_type": "function", "line_start": 13, "line_end": 25, "language": "python", "name": "test_handle_outgoing_message_triggers_send"}, "cb5171896a5c_func_test_check_emails_matches_firefly_subject": {"id": "cb5171896a5c_func_test_check_emails_matches_firefly_subject", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_email_trigger.py", "content": "    def test_check_emails_matches_firefly_subject(self, mock_imap):\n        # Mock IMAP connection and results\n        instance = mock_imap.return_value\n        instance.login.return_value = ('OK', [b'Logged in'])\n        instance.select.return_value = ('OK', [b'1'])\n        instance.search.return_value = ('OK', [b'1'])\n\n        # Mock a raw email message\n        raw_email = b\"Subject: FIREFLY: Help me\\nFrom: user@test.com\\n\\nWhat is your purpose?\"\n        instance.fetch.return_value = ('OK', [[None, raw_email]])\n\n        # Subscribe to event to verify capture\n        mock_handler = MagicMock()\n        self.event_bus.subscribe(\"email_input\", mock_handler)\n\n        self.service._check_emails()\n\n        mock_handler.assert_called_once()\n        payload = mock_handler.call_args[0][1]\n        self.assertEqual(payload[\"from\"], \"user@test.com\")\n        self.assertEqual(payload[\"subject\"], \"FIREFLY: Help me\")\n        self.assertEqual(payload[\"text\"], \"What is your purpose?\")", "chunk_type": "function", "line_start": 28, "line_end": 49, "language": "python", "name": "test_check_emails_matches_firefly_subject"}, "cb5171896a5c_class_TestEmailService": {"id": "cb5171896a5c_class_TestEmailService", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_email_trigger.py", "content": "class TestEmailService(unittest.TestCase):\n    def setUp(self):\n        self.event_bus = EventBusService()\n        with patch.dict('os.environ', {'EMAIL_USER': 'test@firefly.io', 'EMAIL_PASS': 'pass'}):\n            self.service = EmailService(self.event_bus)\n\n    def test_handle_outgoing_message_triggers_send(self):\n        self.service.send_email = MagicMock()\n\n        payload = {\n            \"to\": \"developer@firefly.io\",\n            \"subject\": \"Firefly Test\",\n            \"text\": \"Hello from agent!\"\n        }\n        self.event_bus.publish(\"email_output\", payload)\n\n        self.service.send_email.assert_called_once_with(\n            \"developer@firefly.io\", \"Firefly Test\", \"Hello from agent!\"\n        )\n\n    @patch('imaplib.IMAP4_SSL')\n    def test_check_emails_matches_firefly_subject(self, mock_imap):\n        # Mock IMAP connection and results\n        instance = mock_imap.return_value\n        instance.login.return_value = ('OK', [b'Logged in'])\n        instance.select.return_value = ('", "chunk_type": "class", "line_start": 7, "line_end": 49, "language": "python", "name": "TestEmailService"}, "38340c849363_file": {"id": "38340c849363_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_git_monitoring.py", "content": "from pathlib import Path\nimport os\nimport shutil\nimport subprocess\nimport time\nimport unittest\n\nfrom agent_manager.core.event_bus import EventBusService\nfrom agent_manager.core.git_service import GitMonitoringService\n\nclass TestGitMonitoring(unittest.TestCase):\n    def setUp(self):\n        self.tmp_dir = Path(\"tmp_test_git\")\n        if self.tmp_dir.exists():\n            shutil.rmtree(self.tmp_dir)\n        self.tmp_dir.mkdir()\n\n        # Initialize git repo in tmp_dir\n        subprocess.run(['git', 'init'], cwd=self.tmp_dir, check=True, capture_output=True)\n        subprocess.run(['git', 'config', 'user.email', 'test@example.com'], cwd=self.tmp_dir, check=True, capture_output=True)\n        subprocess.run(['git', 'config', 'user.name', 'Test User'], cwd=self.tmp_dir, check=True, capture_output=True)\n\n        self.bus = EventBusService()\n        self.events = []\n        def log_event(t, d):\n            print(f\"EVENT: {d['type']} - {d.get('data')}\")\n            self.events.append(d)\n        self.bus.subscribe(\"git_event\", log_event)\n\n        from agent_manager.core import git_service\n        git_service.HAS_WATCHDOG = False # Force polling for test stability\n\n        self.monitor = GitMonitoringService(self.bus, root_path=str(self.tmp_dir))\n        self.monitor.start()\n\n    def tearDown(self):\n        self.monitor.stop()\n        shutil.rmtree(self.tmp_dir)\n\n    def test_detection(self):\n        try:\n            print(\"--- Branch Checkout ---\")\n            subprocess.run(['git', 'checkout', '-b', 'test-branch'], cwd=self.tmp_dir, check=True, capture_output=True)\n            time.sleep(2)\n\n            checkout_branches = [e['data']['branch'] for e in self.events if e['type'] == 'branch_checkout']\n            print(f\"Detected branches: {checkout_branches}\")\n            self.assertIn('test-branch', checkout_branches)\n\n            print(\"--- Git Commit ---\")\n            with open(self.tmp_dir / \"test.txt\", \"w\") as f:\n                f.write(\"test content\")\n            subpro", "chunk_type": "file", "line_start": 1, "line_end": 66, "language": "python", "name": "test_git_monitoring.py"}, "38340c849363_func_setUp": {"id": "38340c849363_func_setUp", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_git_monitoring.py", "content": "    def setUp(self):\n        self.tmp_dir = Path(\"tmp_test_git\")\n        if self.tmp_dir.exists():\n            shutil.rmtree(self.tmp_dir)\n        self.tmp_dir.mkdir()\n\n        # Initialize git repo in tmp_dir\n        subprocess.run(['git', 'init'], cwd=self.tmp_dir, check=True, capture_output=True)\n        subprocess.run(['git', 'config', 'user.email', 'test@example.com'], cwd=self.tmp_dir, check=True, capture_output=True)\n        subprocess.run(['git', 'config', 'user.name', 'Test User'], cwd=self.tmp_dir, check=True, capture_output=True)\n\n        self.bus = EventBusService()\n        self.events = []\n        def log_event(t, d):\n            print(f\"EVENT: {d['type']} - {d.get('data')}\")\n            self.events.append(d)\n        self.bus.subscribe(\"git_event\", log_event)\n\n        from agent_manager.core import git_service\n        git_service.HAS_WATCHDOG = False # Force polling for test stability\n\n        self.monitor = GitMonitoringService(self.bus, root_path=str(self.tmp_dir))\n     ", "chunk_type": "function", "line_start": 12, "line_end": 34, "language": "python", "name": "setUp"}, "38340c849363_func_tearDown": {"id": "38340c849363_func_tearDown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_git_monitoring.py", "content": "    def tearDown(self):\n        self.monitor.stop()\n        shutil.rmtree(self.tmp_dir)", "chunk_type": "function", "line_start": 36, "line_end": 38, "language": "python", "name": "tearDown"}, "38340c849363_func_test_detection": {"id": "38340c849363_func_test_detection", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_git_monitoring.py", "content": "    def test_detection(self):\n        try:\n            print(\"--- Branch Checkout ---\")\n            subprocess.run(['git', 'checkout', '-b', 'test-branch'], cwd=self.tmp_dir, check=True, capture_output=True)\n            time.sleep(2)\n\n            checkout_branches = [e['data']['branch'] for e in self.events if e['type'] == 'branch_checkout']\n            print(f\"Detected branches: {checkout_branches}\")\n            self.assertIn('test-branch', checkout_branches)\n\n            print(\"--- Git Commit ---\")\n            with open(self.tmp_dir / \"test.txt\", \"w\") as f:\n                f.write(\"test content\")\n            subprocess.run(['git', 'add', 'test.txt'], cwd=self.tmp_dir, check=True, capture_output=True)\n            subprocess.run(['git', 'commit', '-m', 'test commit'], cwd=self.tmp_dir, check=True, capture_output=True)\n            time.sleep(2)\n\n            commit_events = [e for e in self.events if e['type'] == 'commit_detected']\n            print(f\"Detected commits: {[e['data']['branc", "chunk_type": "function", "line_start": 40, "line_end": 62, "language": "python", "name": "test_detection"}, "38340c849363_func_log_event": {"id": "38340c849363_func_log_event", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_git_monitoring.py", "content": "        def log_event(t, d):\n            print(f\"EVENT: {d['type']} - {d.get('data')}\")\n            self.events.append(d)", "chunk_type": "function", "line_start": 25, "line_end": 27, "language": "python", "name": "log_event"}, "38340c849363_class_TestGitMonitoring": {"id": "38340c849363_class_TestGitMonitoring", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_git_monitoring.py", "content": "class TestGitMonitoring(unittest.TestCase):\n    def setUp(self):\n        self.tmp_dir = Path(\"tmp_test_git\")\n        if self.tmp_dir.exists():\n            shutil.rmtree(self.tmp_dir)\n        self.tmp_dir.mkdir()\n\n        # Initialize git repo in tmp_dir\n        subprocess.run(['git', 'init'], cwd=self.tmp_dir, check=True, capture_output=True)\n        subprocess.run(['git', 'config', 'user.email', 'test@example.com'], cwd=self.tmp_dir, check=True, capture_output=True)\n        subprocess.run(['git', 'config', 'user.name', 'Test User'], cwd=self.tmp_dir, check=True, capture_output=True)\n\n        self.bus = EventBusService()\n        self.events = []\n        def log_event(t, d):\n            print(f\"EVENT: {d['type']} - {d.get('data')}\")\n            self.events.append(d)\n        self.bus.subscribe(\"git_event\", log_event)\n\n        from agent_manager.core import git_service\n        git_service.HAS_WATCHDOG = False # Force polling for test stability\n\n        self.monitor = GitMonitoringService(", "chunk_type": "class", "line_start": 11, "line_end": 62, "language": "python", "name": "TestGitMonitoring"}, "b1a40addcf80_file": {"id": "b1a40addcf80_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_ide_control.py", "content": "from unittest.mock import MagicMock\nimport json\nimport os\nimport sys\nimport time\n\n# Add project root to path\nsys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\")))\n\nfrom agent_manager.triggers.ide_control import IDEControlService\n\ndef test_ide_control():\n    mock_bus = MagicMock()\n    service = IDEControlService(mock_bus)\n\n    # We need to mock stdin for this test\n    import io\n    fake_stdin = io.StringIO('{\"type\": \"set_mode\", \"autonomous\": true}\\n{\"type\": \"intent\", \"id\": \"test_cmd\", \"args\": [1, 2]}\\n')\n    sys.stdin = fake_stdin\n\n    print(\"Starting IDE Control Service test...\")\n    service.start()\n\n    # Give it a moment to process\n    time.sleep(1)\n\n    service.stop()\n\n    # Verify events were published\n    print(f\"Call count: {mock_bus.publish.call_count}\")\n    for call in mock_bus.publish.call_args_list:\n        print(f\"Published: {call}\")\n\n    assert mock_bus.publish.call_count >= 2\n    print(\"Test passed!\")\n\nif __name__ == \"__main__\":\n    test_ide_control()\n", "chunk_type": "file", "line_start": 1, "line_end": 39, "language": "python", "name": "test_ide_control.py"}, "b1a40addcf80_func_test_ide_control": {"id": "b1a40addcf80_func_test_ide_control", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_ide_control.py", "content": "def test_ide_control():\n    mock_bus = MagicMock()\n    service = IDEControlService(mock_bus)\n\n    # We need to mock stdin for this test\n    import io\n    fake_stdin = io.StringIO('{\"type\": \"set_mode\", \"autonomous\": true}\\n{\"type\": \"intent\", \"id\": \"test_cmd\", \"args\": [1, 2]}\\n')\n    sys.stdin = fake_stdin\n\n    print(\"Starting IDE Control Service test...\")\n    service.start()\n\n    # Give it a moment to process\n    time.sleep(1)\n\n    service.stop()\n\n    # Verify events were published\n    print(f\"Call count: {mock_bus.publish.call_count}\")\n    for call in mock_bus.publish.call_args_list:\n        print(f\"Published: {call}\")\n\n    assert mock_bus.publish.call_count >= 2\n    print(\"Test passed!\")", "chunk_type": "function", "line_start": 12, "line_end": 35, "language": "python", "name": "test_ide_control"}, "42da773318ab_file": {"id": "42da773318ab_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_intelligence_visibility.py", "content": "from unittest.mock import MagicMock\nimport time\nimport unittest\n\nfrom agent_manager.core.dashboard_service import DashboardService\nfrom agent_manager.core.event_bus import EventBusService\nfrom agent_manager.core.session_manager import SessionManager\n\nclass TestIntelligenceVisibility(unittest.TestCase):\n    def setUp(self):\n        self.bus = EventBusService()\n        self.sessions = SessionManager(max_history=5)\n        self.dashboard = DashboardService(event_bus=self.bus)\n\n    def test_session_history(self):\n        \"\"\"Verify that SessionManager tracks and formats history correctly.\"\"\"\n        sid = \"test_user\"\n        self.sessions.add_message(sid, \"user\", \"Hello\")\n        self.sessions.add_message(sid, \"assistant\", \"Hi there!\")\n\n        history = self.sessions.get_history(sid)\n        self.assertEqual(len(history), 2)\n        self.assertEqual(history[0][\"role\"], \"user\")\n\n        formatted = self.sessions.format_for_ai(sid)\n        self.assertIn(\"USER: Hello\", formatted)\n        self.assertIn(\"ASSISTANT: Hi there!\", formatted)\n\n    def test_session_sliding_window(self):\n        \"\"\"Verify max history limits.\"\"\"\n        sid = \"limit_test\"\n        for i in range(10):\n            self.sessions.add_message(sid, \"user\", f\"Msg {i}\")\n\n        history = self.sessions.get_history(sid)\n        self.assertEqual(len(history), 5) # Max history is 5\n        self.assertEqual(history[0][\"content\"], \"Msg 5\")\n\n    def test_dashboard_aggregation(self):\n        \"\"\"Verify that DashboardService correctly catches events.\"\"\"\n        self.dashboard.start()\n\n        # 1. Test Usage\n        self.bus.publish(\"usage_report\", {\"total_tokens\": 100, \"cost_usd\": 0.05})\n        self.assertEqual(self.dashboard.usage[\"tokens\"], 100)\n        self.assertEqual(self.dashboard.usage[\"cost\"], 0.05)\n\n        # 2. Test Peers\n        self.bus.publish(\"peer_joined\", {\"identity\": \"Panda\", \"hostname\": \"local\", \"status\": \"idle\"})\n        self.assertIn(\"Panda\", self.dashboard.peers)\n\n        self.bus.publish(\"peer", "chunk_type": "file", "line_start": 1, "line_end": 63, "language": "python", "name": "test_intelligence_visibility.py"}, "42da773318ab_func_setUp": {"id": "42da773318ab_func_setUp", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_intelligence_visibility.py", "content": "    def setUp(self):\n        self.bus = EventBusService()\n        self.sessions = SessionManager(max_history=5)\n        self.dashboard = DashboardService(event_bus=self.bus)", "chunk_type": "function", "line_start": 10, "line_end": 13, "language": "python", "name": "setUp"}, "42da773318ab_func_test_session_history": {"id": "42da773318ab_func_test_session_history", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_intelligence_visibility.py", "content": "    def test_session_history(self):\n        \"\"\"Verify that SessionManager tracks and formats history correctly.\"\"\"\n        sid = \"test_user\"\n        self.sessions.add_message(sid, \"user\", \"Hello\")\n        self.sessions.add_message(sid, \"assistant\", \"Hi there!\")\n\n        history = self.sessions.get_history(sid)\n        self.assertEqual(len(history), 2)\n        self.assertEqual(history[0][\"role\"], \"user\")\n\n        formatted = self.sessions.format_for_ai(sid)\n        self.assertIn(\"USER: Hello\", formatted)\n        self.assertIn(\"ASSISTANT: Hi there!\", formatted)", "chunk_type": "function", "line_start": 15, "line_end": 27, "language": "python", "name": "test_session_history"}, "42da773318ab_func_test_session_sliding_window": {"id": "42da773318ab_func_test_session_sliding_window", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_intelligence_visibility.py", "content": "    def test_session_sliding_window(self):\n        \"\"\"Verify max history limits.\"\"\"\n        sid = \"limit_test\"\n        for i in range(10):\n            self.sessions.add_message(sid, \"user\", f\"Msg {i}\")\n\n        history = self.sessions.get_history(sid)\n        self.assertEqual(len(history), 5) # Max history is 5\n        self.assertEqual(history[0][\"content\"], \"Msg 5\")", "chunk_type": "function", "line_start": 29, "line_end": 37, "language": "python", "name": "test_session_sliding_window"}, "42da773318ab_func_test_dashboard_aggregation": {"id": "42da773318ab_func_test_dashboard_aggregation", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_intelligence_visibility.py", "content": "    def test_dashboard_aggregation(self):\n        \"\"\"Verify that DashboardService correctly catches events.\"\"\"\n        self.dashboard.start()\n\n        # 1. Test Usage\n        self.bus.publish(\"usage_report\", {\"total_tokens\": 100, \"cost_usd\": 0.05})\n        self.assertEqual(self.dashboard.usage[\"tokens\"], 100)\n        self.assertEqual(self.dashboard.usage[\"cost\"], 0.05)\n\n        # 2. Test Peers\n        self.bus.publish(\"peer_joined\", {\"identity\": \"Panda\", \"hostname\": \"local\", \"status\": \"idle\"})\n        self.assertIn(\"Panda\", self.dashboard.peers)\n\n        self.bus.publish(\"peer_left\", {\"identity\": \"Panda\"})\n        self.assertNotIn(\"Panda\", self.dashboard.peers)\n\n        # 3. Test Activity Log\n        self.bus.publish(\"system_event\", {\"type\": \"test\"})\n        self.assertTrue(any(\"system_event\" in ev for ev in self.dashboard.last_events))\n\n        self.dashboard.stop()", "chunk_type": "function", "line_start": 39, "line_end": 59, "language": "python", "name": "test_dashboard_aggregation"}, "42da773318ab_class_TestIntelligenceVisibility": {"id": "42da773318ab_class_TestIntelligenceVisibility", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_intelligence_visibility.py", "content": "class TestIntelligenceVisibility(unittest.TestCase):\n    def setUp(self):\n        self.bus = EventBusService()\n        self.sessions = SessionManager(max_history=5)\n        self.dashboard = DashboardService(event_bus=self.bus)\n\n    def test_session_history(self):\n        \"\"\"Verify that SessionManager tracks and formats history correctly.\"\"\"\n        sid = \"test_user\"\n        self.sessions.add_message(sid, \"user\", \"Hello\")\n        self.sessions.add_message(sid, \"assistant\", \"Hi there!\")\n\n        history = self.sessions.get_history(sid)\n        self.assertEqual(len(history), 2)\n        self.assertEqual(history[0][\"role\"], \"user\")\n\n        formatted = self.sessions.format_for_ai(sid)\n        self.assertIn(\"USER: Hello\", formatted)\n        self.assertIn(\"ASSISTANT: Hi there!\", formatted)\n\n    def test_session_sliding_window(self):\n        \"\"\"Verify max history limits.\"\"\"\n        sid = \"limit_test\"\n        for i in range(10):\n            self.sessions.add_message(sid, \"user\", f\"Msg {i}\")\n\n  ", "chunk_type": "class", "line_start": 9, "line_end": 59, "language": "python", "name": "TestIntelligenceVisibility"}, "4e97cb3fb331_file": {"id": "4e97cb3fb331_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_memory_system.py", "content": "from pathlib import Path\nfrom unittest.mock import MagicMock\nimport os\nimport shutil\nimport unittest\n\nfrom agent_manager.core.memory_service import MemoryService\n\nclass TestMemoryService(unittest.TestCase):\n    def setUp(self):\n        self.test_path = Path(\"test_memory\")\n        if self.test_path.exists():\n            shutil.rmtree(self.test_path)\n\n        self.model_client = MagicMock()\n        # Mock embedding [0.1, 0.2, ...] with dimension 1536\n        self.model_client.embed.return_value = [0.1] * 1536\n\n        self.service = MemoryService(self.model_client, memory_path=str(self.test_path))\n\n    def tearDown(self):\n        if self.test_path.exists():\n            shutil.rmtree(self.test_path)\n\n    def test_upsert_and_query(self):\n        text = \"Firefly uses FAISS for semantic memory.\"\n        meta = {\"test\": True}\n\n        success = self.service.upsert(text, meta)\n        self.assertTrue(success)\n        self.assertEqual(len(self.service.metadata), 1)\n\n        # Query\n        results = self.service.query(\"vector search\", top_k=1)\n        self.assertEqual(len(results), 1)\n        self.assertEqual(results[0][\"text\"], text)\n        self.assertTrue(\"score\" in results[0])\n\n    def test_persistence(self):\n        self.service.upsert(\"Persistent thought\", {\"p\": 1})\n        self.service.save()\n\n        # Create a new service instance pointing to same path\n        new_service = MemoryService(self.model_client, memory_path=str(self.test_path))\n        self.assertEqual(len(new_service.metadata), 1)\n        self.assertEqual(new_service.metadata[0][\"text\"], \"Persistent thought\")\n\nif __name__ == \"__main__\":\n    unittest.main()\n", "chunk_type": "file", "line_start": 1, "line_end": 50, "language": "python", "name": "test_memory_system.py"}, "4e97cb3fb331_func_setUp": {"id": "4e97cb3fb331_func_setUp", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_memory_system.py", "content": "    def setUp(self):\n        self.test_path = Path(\"test_memory\")\n        if self.test_path.exists():\n            shutil.rmtree(self.test_path)\n\n        self.model_client = MagicMock()\n        # Mock embedding [0.1, 0.2, ...] with dimension 1536\n        self.model_client.embed.return_value = [0.1] * 1536\n\n        self.service = MemoryService(self.model_client, memory_path=str(self.test_path))", "chunk_type": "function", "line_start": 10, "line_end": 19, "language": "python", "name": "setUp"}, "4e97cb3fb331_func_tearDown": {"id": "4e97cb3fb331_func_tearDown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_memory_system.py", "content": "    def tearDown(self):\n        if self.test_path.exists():\n            shutil.rmtree(self.test_path)", "chunk_type": "function", "line_start": 21, "line_end": 23, "language": "python", "name": "tearDown"}, "4e97cb3fb331_func_test_upsert_and_query": {"id": "4e97cb3fb331_func_test_upsert_and_query", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_memory_system.py", "content": "    def test_upsert_and_query(self):\n        text = \"Firefly uses FAISS for semantic memory.\"\n        meta = {\"test\": True}\n\n        success = self.service.upsert(text, meta)\n        self.assertTrue(success)\n        self.assertEqual(len(self.service.metadata), 1)\n\n        # Query\n        results = self.service.query(\"vector search\", top_k=1)\n        self.assertEqual(len(results), 1)\n        self.assertEqual(results[0][\"text\"], text)\n        self.assertTrue(\"score\" in results[0])", "chunk_type": "function", "line_start": 25, "line_end": 37, "language": "python", "name": "test_upsert_and_query"}, "4e97cb3fb331_func_test_persistence": {"id": "4e97cb3fb331_func_test_persistence", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_memory_system.py", "content": "    def test_persistence(self):\n        self.service.upsert(\"Persistent thought\", {\"p\": 1})\n        self.service.save()\n\n        # Create a new service instance pointing to same path\n        new_service = MemoryService(self.model_client, memory_path=str(self.test_path))\n        self.assertEqual(len(new_service.metadata), 1)\n        self.assertEqual(new_service.metadata[0][\"text\"], \"Persistent thought\")", "chunk_type": "function", "line_start": 39, "line_end": 46, "language": "python", "name": "test_persistence"}, "4e97cb3fb331_class_TestMemoryService": {"id": "4e97cb3fb331_class_TestMemoryService", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_memory_system.py", "content": "class TestMemoryService(unittest.TestCase):\n    def setUp(self):\n        self.test_path = Path(\"test_memory\")\n        if self.test_path.exists():\n            shutil.rmtree(self.test_path)\n\n        self.model_client = MagicMock()\n        # Mock embedding [0.1, 0.2, ...] with dimension 1536\n        self.model_client.embed.return_value = [0.1] * 1536\n\n        self.service = MemoryService(self.model_client, memory_path=str(self.test_path))\n\n    def tearDown(self):\n        if self.test_path.exists():\n            shutil.rmtree(self.test_path)\n\n    def test_upsert_and_query(self):\n        text = \"Firefly uses FAISS for semantic memory.\"\n        meta = {\"test\": True}\n\n        success = self.service.upsert(text, meta)\n        self.assertTrue(success)\n        self.assertEqual(len(self.service.metadata), 1)\n\n        # Query\n        results = self.service.query(\"vector search\", top_k=1)\n        self.assertEqual(len(results), 1)\n        self.assertEqual(results[0][\"text\"], text)\n        self.assert", "chunk_type": "class", "line_start": 9, "line_end": 46, "language": "python", "name": "TestMemoryService"}, "308221cc2174_file": {"id": "308221cc2174_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_multi_agent.py", "content": "from pathlib import Path\nfrom unittest.mock import MagicMock, patch\nimport json\nimport os\nimport shutil\nimport time\nimport unittest\n\nfrom agent_manager.core.event_bus import EventBusService\nfrom agent_manager.core.peer_discovery import PeerDiscoveryService\nfrom agent_manager.orchestrator import OrchestratorManager\n\nclass TestMultiAgentCoordination(unittest.TestCase):\n    def setUp(self):\n        self.test_dir = Path(\"tests/tmp_nsync\")\n        self.test_dir.mkdir(parents=True, exist_ok=True)\n\n        self.bus = EventBusService()\n        self.model_client = MagicMock()\n        # Pass test directory to PeerDiscovery\n        self.peer_discovery = PeerDiscoveryService(event_bus=self.bus, nsync_path=str(self.test_dir))\n\n        self.orchestrator = OrchestratorManager(\n            event_bus=self.bus,\n            model_client=self.model_client,\n            peer_discovery=self.peer_discovery\n        )\n        self.orchestrator.start()\n        self.peer_discovery.start()\n\n    def tearDown(self):\n        self.peer_discovery.stop()\n        self.orchestrator.stop()\n        if self.test_dir.exists():\n            shutil.rmtree(self.test_dir)\n\n    def test_peer_discovery_and_delegation(self):\n        \"\"\"Verify that a peer is discovered and a task is delegated to it.\"\"\"\n        # 1. Simulate a peer heartbeat\n        peer_identity = \"WizardPanda\"\n        peer_file = self.test_dir / \".nsync_agents\" / \"remote_host.json\"\n        peer_file.parent.mkdir(parents=True, exist_ok=True)\n\n        with open(peer_file, \"w\") as f:\n            json.dump({\n                \"hostname\": \"remote_host\",\n                \"identity\": peer_identity,\n                \"timestamp\": time.time(),\n                \"status\": \"active\"\n            }, f)\n\n        # Synchronously refresh discovery\n        self.peer_discovery.refresh()\n\n        self.assertIn(peer_identity, self.peer_discovery.peers)\n\n        # 2. Mock AI response to delegate a task\n        mock_response = MagicMock()\n        mock_response.text = f'<delega", "chunk_type": "file", "line_start": 1, "line_end": 154, "language": "python", "name": "test_multi_agent.py"}, "308221cc2174_func_setUp": {"id": "308221cc2174_func_setUp", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_multi_agent.py", "content": "    def setUp(self):\n        self.test_dir = Path(\"tests/tmp_nsync\")\n        self.test_dir.mkdir(parents=True, exist_ok=True)\n\n        self.bus = EventBusService()\n        self.model_client = MagicMock()\n        # Pass test directory to PeerDiscovery\n        self.peer_discovery = PeerDiscoveryService(event_bus=self.bus, nsync_path=str(self.test_dir))\n\n        self.orchestrator = OrchestratorManager(\n            event_bus=self.bus,\n            model_client=self.model_client,\n            peer_discovery=self.peer_discovery\n        )\n        self.orchestrator.start()\n        self.peer_discovery.start()", "chunk_type": "function", "line_start": 14, "line_end": 29, "language": "python", "name": "setUp"}, "308221cc2174_func_tearDown": {"id": "308221cc2174_func_tearDown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_multi_agent.py", "content": "    def tearDown(self):\n        self.peer_discovery.stop()\n        self.orchestrator.stop()\n        if self.test_dir.exists():\n            shutil.rmtree(self.test_dir)", "chunk_type": "function", "line_start": 31, "line_end": 35, "language": "python", "name": "tearDown"}, "308221cc2174_func_test_peer_discovery_and_delegation": {"id": "308221cc2174_func_test_peer_discovery_and_delegation", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_multi_agent.py", "content": "    def test_peer_discovery_and_delegation(self):\n        \"\"\"Verify that a peer is discovered and a task is delegated to it.\"\"\"\n        # 1. Simulate a peer heartbeat\n        peer_identity = \"WizardPanda\"\n        peer_file = self.test_dir / \".nsync_agents\" / \"remote_host.json\"\n        peer_file.parent.mkdir(parents=True, exist_ok=True)\n\n        with open(peer_file, \"w\") as f:\n            json.dump({\n                \"hostname\": \"remote_host\",\n                \"identity\": peer_identity,\n                \"timestamp\": time.time(),\n                \"status\": \"active\"\n            }, f)\n\n        # Synchronously refresh discovery\n        self.peer_discovery.refresh()\n\n        self.assertIn(peer_identity, self.peer_discovery.peers)\n\n        # 2. Mock AI response to delegate a task\n        mock_response = MagicMock()\n        mock_response.text = f'<delegate recipient=\"{peer_identity}\">Scan the network for vulnerabilities.</delegate>'\n        self.model_client.generate.return_value = mock_response\n\n", "chunk_type": "function", "line_start": 37, "line_end": 74, "language": "python", "name": "test_peer_discovery_and_delegation"}, "308221cc2174_func_test_role_based_delegation": {"id": "308221cc2174_func_test_role_based_delegation", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_multi_agent.py", "content": "    def test_role_based_delegation(self):\n        \"\"\"Verify that a task is delegated to an agent with a specific role.\"\"\"\n        # 1. Simulate an 'auditor' agent\n        peer_identity = \"SecurityPanda\"\n        peer_file = self.test_dir / \".nsync_agents\" / \"auditor_host.json\"\n        peer_file.parent.mkdir(parents=True, exist_ok=True)\n\n        with open(peer_file, \"w\") as f:\n            json.dump({\n                \"hostname\": \"auditor_host\",\n                \"identity\": peer_identity,\n                \"role\": \"auditor\",\n                \"capabilities\": [\"security_scan\", \"log_audit\"],\n                \"timestamp\": time.time(),\n                \"status\": \"active\"\n            }, f)\n\n        self.peer_discovery.refresh()\n\n        # 2. Mock AI to delegate to the 'auditor' role\n        mock_response = MagicMock()\n        mock_response.text = '<delegate recipient=\"auditor\">Run a security audit on the latest commit.</delegate>'\n        self.model_client.generate.return_value = mock_response\n\n      ", "chunk_type": "function", "line_start": 76, "line_end": 112, "language": "python", "name": "test_role_based_delegation"}, "308221cc2174_func_test_capability_based_delegation": {"id": "308221cc2174_func_test_capability_based_delegation", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_multi_agent.py", "content": "    def test_capability_based_delegation(self):\n        \"\"\"Verify that a task is delegated to an agent with a specific capability.\"\"\"\n        # 1. Simulate an agent with 'security_scan' capability\n        peer_identity = \"VulnScanner\"\n        peer_file = self.test_dir / \".nsync_agents\" / \"scanner_host.json\"\n        peer_file.parent.mkdir(parents=True, exist_ok=True)\n\n        with open(peer_file, \"w\") as f:\n            json.dump({\n                \"hostname\": \"scanner_host\",\n                \"identity\": peer_identity,\n                \"role\": \"worker\",\n                \"capabilities\": [\"security_scan\", \"network_map\"],\n                \"timestamp\": time.time(),\n                \"status\": \"active\"\n            }, f)\n\n        self.peer_discovery.refresh()\n\n        # 2. Mock AI to delegate to the 'security_scan' capability\n        mock_response = MagicMock()\n        mock_response.text = '<delegate recipient=\"security_scan\">Scan the web server for open ports.</delegate>'\n        self.model_client.g", "chunk_type": "function", "line_start": 114, "line_end": 150, "language": "python", "name": "test_capability_based_delegation"}, "308221cc2174_class_TestMultiAgentCoordination": {"id": "308221cc2174_class_TestMultiAgentCoordination", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_multi_agent.py", "content": "class TestMultiAgentCoordination(unittest.TestCase):\n    def setUp(self):\n        self.test_dir = Path(\"tests/tmp_nsync\")\n        self.test_dir.mkdir(parents=True, exist_ok=True)\n\n        self.bus = EventBusService()\n        self.model_client = MagicMock()\n        # Pass test directory to PeerDiscovery\n        self.peer_discovery = PeerDiscoveryService(event_bus=self.bus, nsync_path=str(self.test_dir))\n\n        self.orchestrator = OrchestratorManager(\n            event_bus=self.bus,\n            model_client=self.model_client,\n            peer_discovery=self.peer_discovery\n        )\n        self.orchestrator.start()\n        self.peer_discovery.start()\n\n    def tearDown(self):\n        self.peer_discovery.stop()\n        self.orchestrator.stop()\n        if self.test_dir.exists():\n            shutil.rmtree(self.test_dir)\n\n    def test_peer_discovery_and_delegation(self):\n        \"\"\"Verify that a peer is discovered and a task is delegated to it.\"\"\"\n        # 1. Simulate a peer heartbeat\n    ", "chunk_type": "class", "line_start": 13, "line_end": 150, "language": "python", "name": "TestMultiAgentCoordination"}, "d791a18f4f49_file": {"id": "d791a18f4f49_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_notifications.py", "content": "from unittest.mock import MagicMock\nimport unittest\n\nfrom agent_manager.core.event_bus import EventBusService\nfrom agent_manager.core.notification_service import NotificationService\n\nclass TestNotificationService(unittest.TestCase):\n    def setUp(self):\n        self.event_bus = EventBusService()\n        self.service = NotificationService(self.event_bus)\n\n    def test_notify_publishes_to_bus(self):\n        # Mock subscribers\n        mock_tg = MagicMock()\n        mock_webhook = MagicMock()\n\n        self.event_bus.subscribe(\"telegram_output\", mock_tg)\n        self.event_bus.subscribe(\"webhook_event\", mock_webhook)\n\n        self.service.notify(\"Test alert\", priority=\"critical\")\n\n        # Verify Telegram call\n        mock_tg.assert_called_once()\n        payload_tg = mock_tg.call_args[0][1]\n        self.assertEqual(payload_tg[\"text\"], \"[CRITICAL] Test alert\")\n\n        # Verify Webhook call\n        mock_webhook.assert_called_once()\n        payload_wh = mock_webhook.call_args[0][1]\n        self.assertEqual(payload_wh[\"type\"], \"notification\")\n        self.assertEqual(payload_wh[\"data\"][\"priority\"], \"critical\")\n\n    def test_broadcast_trigger(self):\n        # Trigger via broadcast event\n        self.service.notify = MagicMock()\n        self.event_bus.publish(\"broadcast_notification\", {\"text\": \"System update\", \"priority\": \"info\"})\n\n        self.service.notify.assert_called_once_with(\"System update\", \"info\", None)\n\nif __name__ == \"__main__\":\n    unittest.main()\n", "chunk_type": "file", "line_start": 1, "line_end": 42, "language": "python", "name": "test_notifications.py"}, "d791a18f4f49_func_setUp": {"id": "d791a18f4f49_func_setUp", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_notifications.py", "content": "    def setUp(self):\n        self.event_bus = EventBusService()\n        self.service = NotificationService(self.event_bus)", "chunk_type": "function", "line_start": 8, "line_end": 10, "language": "python", "name": "setUp"}, "d791a18f4f49_func_test_notify_publishes_to_bus": {"id": "d791a18f4f49_func_test_notify_publishes_to_bus", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_notifications.py", "content": "    def test_notify_publishes_to_bus(self):\n        # Mock subscribers\n        mock_tg = MagicMock()\n        mock_webhook = MagicMock()\n\n        self.event_bus.subscribe(\"telegram_output\", mock_tg)\n        self.event_bus.subscribe(\"webhook_event\", mock_webhook)\n\n        self.service.notify(\"Test alert\", priority=\"critical\")\n\n        # Verify Telegram call\n        mock_tg.assert_called_once()\n        payload_tg = mock_tg.call_args[0][1]\n        self.assertEqual(payload_tg[\"text\"], \"[CRITICAL] Test alert\")\n\n        # Verify Webhook call\n        mock_webhook.assert_called_once()\n        payload_wh = mock_webhook.call_args[0][1]\n        self.assertEqual(payload_wh[\"type\"], \"notification\")\n        self.assertEqual(payload_wh[\"data\"][\"priority\"], \"critical\")", "chunk_type": "function", "line_start": 12, "line_end": 31, "language": "python", "name": "test_notify_publishes_to_bus"}, "d791a18f4f49_func_test_broadcast_trigger": {"id": "d791a18f4f49_func_test_broadcast_trigger", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_notifications.py", "content": "    def test_broadcast_trigger(self):\n        # Trigger via broadcast event\n        self.service.notify = MagicMock()\n        self.event_bus.publish(\"broadcast_notification\", {\"text\": \"System update\", \"priority\": \"info\"})\n\n        self.service.notify.assert_called_once_with(\"System update\", \"info\", None)", "chunk_type": "function", "line_start": 33, "line_end": 38, "language": "python", "name": "test_broadcast_trigger"}, "d791a18f4f49_class_TestNotificationService": {"id": "d791a18f4f49_class_TestNotificationService", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_notifications.py", "content": "class TestNotificationService(unittest.TestCase):\n    def setUp(self):\n        self.event_bus = EventBusService()\n        self.service = NotificationService(self.event_bus)\n\n    def test_notify_publishes_to_bus(self):\n        # Mock subscribers\n        mock_tg = MagicMock()\n        mock_webhook = MagicMock()\n\n        self.event_bus.subscribe(\"telegram_output\", mock_tg)\n        self.event_bus.subscribe(\"webhook_event\", mock_webhook)\n\n        self.service.notify(\"Test alert\", priority=\"critical\")\n\n        # Verify Telegram call\n        mock_tg.assert_called_once()\n        payload_tg = mock_tg.call_args[0][1]\n        self.assertEqual(payload_tg[\"text\"], \"[CRITICAL] Test alert\")\n\n        # Verify Webhook call\n        mock_webhook.assert_called_once()\n        payload_wh = mock_webhook.call_args[0][1]\n        self.assertEqual(payload_wh[\"type\"], \"notification\")\n        self.assertEqual(payload_wh[\"data\"][\"priority\"], \"critical\")\n\n    def test_broadcast_trigger(self):\n        # Trigger via br", "chunk_type": "class", "line_start": 7, "line_end": 38, "language": "python", "name": "TestNotificationService"}, "c0890f9b81df_file": {"id": "c0890f9b81df_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_sms_trigger.py", "content": "from unittest.mock import MagicMock, patch\nimport unittest\n\nfrom agent_manager.core.event_bus import EventBusService\nfrom agent_manager.triggers.sms import SMSService\n\nclass TestSMSService(unittest.TestCase):\n    def setUp(self):\n        self.event_bus = EventBusService()\n        with patch.dict('os.environ', {\n            'TWILIO_ACCOUNT_SID': 'AC_test',\n            'TWILIO_AUTH_TOKEN': 'token_test',\n            'TWILIO_NUMBER': '+1234567890'\n        }):\n            self.service = SMSService(self.event_bus)\n\n    def test_handle_incoming_webhook_as_sms(self):\n        # Mock payload as if it came from Twilio form data (parsed as dict)\n        payload = {\n            \"From\": \"+1987654321\",\n            \"To\": \"+1234567890\",\n            \"Body\": \"Status check\"\n        }\n\n        mock_handler = MagicMock()\n        self.event_bus.subscribe(\"sms_input\", mock_handler)\n\n        self.event_bus.publish(\"webhook_event\", payload)\n\n        mock_handler.assert_called_once()\n        processed = mock_handler.call_args[0][1]\n        self.assertEqual(processed[\"text\"], \"Status check\")\n        self.assertEqual(processed[\"from\"], \"+1987654321\")\n\n    @patch('urllib.request.urlopen')\n    def test_send_sms_calls_api(self, mock_urlopen):\n        # Setup mock response\n        mock_response = MagicMock()\n        mock_response.read.return_value = b'{\"sid\": \"SM_test\"}'\n        mock_urlopen.return_value.__enter__.return_value = mock_response\n\n        self.service.send_sms(\"+1987654321\", \"Agent response\")\n\n        # Verify it attempted to call Twilio\n        args, kwargs = mock_urlopen.call_args\n        req = args[0]\n        self.assertIn(\"api.twilio.com\", req.full_url)\n        self.assertEqual(req.get_method(), \"POST\")\n\nif __name__ == \"__main__\":\n    unittest.main()\n", "chunk_type": "file", "line_start": 1, "line_end": 52, "language": "python", "name": "test_sms_trigger.py"}, "c0890f9b81df_func_setUp": {"id": "c0890f9b81df_func_setUp", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_sms_trigger.py", "content": "    def setUp(self):\n        self.event_bus = EventBusService()\n        with patch.dict('os.environ', {\n            'TWILIO_ACCOUNT_SID': 'AC_test',\n            'TWILIO_AUTH_TOKEN': 'token_test',\n            'TWILIO_NUMBER': '+1234567890'\n        }):\n            self.service = SMSService(self.event_bus)", "chunk_type": "function", "line_start": 8, "line_end": 15, "language": "python", "name": "setUp"}, "c0890f9b81df_func_test_handle_incoming_webhook_as_sms": {"id": "c0890f9b81df_func_test_handle_incoming_webhook_as_sms", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_sms_trigger.py", "content": "    def test_handle_incoming_webhook_as_sms(self):\n        # Mock payload as if it came from Twilio form data (parsed as dict)\n        payload = {\n            \"From\": \"+1987654321\",\n            \"To\": \"+1234567890\",\n            \"Body\": \"Status check\"\n        }\n\n        mock_handler = MagicMock()\n        self.event_bus.subscribe(\"sms_input\", mock_handler)\n\n        self.event_bus.publish(\"webhook_event\", payload)\n\n        mock_handler.assert_called_once()\n        processed = mock_handler.call_args[0][1]\n        self.assertEqual(processed[\"text\"], \"Status check\")\n        self.assertEqual(processed[\"from\"], \"+1987654321\")", "chunk_type": "function", "line_start": 17, "line_end": 33, "language": "python", "name": "test_handle_incoming_webhook_as_sms"}, "c0890f9b81df_func_test_send_sms_calls_api": {"id": "c0890f9b81df_func_test_send_sms_calls_api", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_sms_trigger.py", "content": "    def test_send_sms_calls_api(self, mock_urlopen):\n        # Setup mock response\n        mock_response = MagicMock()\n        mock_response.read.return_value = b'{\"sid\": \"SM_test\"}'\n        mock_urlopen.return_value.__enter__.return_value = mock_response\n\n        self.service.send_sms(\"+1987654321\", \"Agent response\")\n\n        # Verify it attempted to call Twilio\n        args, kwargs = mock_urlopen.call_args\n        req = args[0]\n        self.assertIn(\"api.twilio.com\", req.full_url)\n        self.assertEqual(req.get_method(), \"POST\")", "chunk_type": "function", "line_start": 36, "line_end": 48, "language": "python", "name": "test_send_sms_calls_api"}, "c0890f9b81df_class_TestSMSService": {"id": "c0890f9b81df_class_TestSMSService", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_sms_trigger.py", "content": "class TestSMSService(unittest.TestCase):\n    def setUp(self):\n        self.event_bus = EventBusService()\n        with patch.dict('os.environ', {\n            'TWILIO_ACCOUNT_SID': 'AC_test',\n            'TWILIO_AUTH_TOKEN': 'token_test',\n            'TWILIO_NUMBER': '+1234567890'\n        }):\n            self.service = SMSService(self.event_bus)\n\n    def test_handle_incoming_webhook_as_sms(self):\n        # Mock payload as if it came from Twilio form data (parsed as dict)\n        payload = {\n            \"From\": \"+1987654321\",\n            \"To\": \"+1234567890\",\n            \"Body\": \"Status check\"\n        }\n\n        mock_handler = MagicMock()\n        self.event_bus.subscribe(\"sms_input\", mock_handler)\n\n        self.event_bus.publish(\"webhook_event\", payload)\n\n        mock_handler.assert_called_once()\n        processed = mock_handler.call_args[0][1]\n        self.assertEqual(processed[\"text\"], \"Status check\")\n        self.assertEqual(processed[\"from\"], \"+1987654321\")\n\n    @patch('urllib.request.", "chunk_type": "class", "line_start": 7, "line_end": 48, "language": "python", "name": "TestSMSService"}, "354ebbf4eb13_file": {"id": "354ebbf4eb13_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_specialized_agents.py", "content": "from unittest.mock import MagicMock\nimport re\nimport unittest\n\nfrom agent_manager.core.event_bus import EventBusService\nfrom agent_manager.core.prompt_service import PromptService\nfrom agent_manager.orchestrator import OrchestratorManager\n\nclass TestSpecializedAgents(unittest.TestCase):\n    def setUp(self):\n        self.prompt_service = PromptService()\n        self.event_bus = EventBusService()\n        self.model_client = MagicMock()\n        self.orchestrator = OrchestratorManager(\n            event_bus=self.event_bus,\n            model_client=self.model_client,\n            prompt_service=self.prompt_service\n        )\n\n    def test_prompt_service_roles(self):\n        roles = self.prompt_service.list_roles()\n        self.assertIn(\"Lead Orchestrator\", roles)\n        self.assertIn(\"Test Engineer\", roles)\n        self.assertIn(\"Documentarian\", roles)\n\n        prompt = self.prompt_service.get_prompt(\"Documentarian\")\n        self.assertIn(\"Firefly Documentarian\", prompt)\n        self.assertIn(\"<thought>\", prompt)\n\n    def test_task_decomposition_parsing(self):\n        plan_text = \"\"\"\n        I will decompose this task.\n        <plan>\n        - [ ] Write tests (Test Engineer)\n        - [ ] Update README (Documentarian)\n        </plan>\n        \"\"\"\n        # Mock delegate_task\n        self.orchestrator.delegate_task = MagicMock()\n\n        self.orchestrator._handle_plans(plan_text, \"test_session\")\n\n        self.assertEqual(self.orchestrator.delegate_task.call_count, 2)\n        args = [call.args for call in self.orchestrator.delegate_task.call_args_list]\n        self.assertEqual(args[0][0], \"Test Engineer\")\n        self.assertEqual(args[1][0], \"Documentarian\")\n\n    def test_orchestrator_uses_prompt_service(self):\n        # Trigger an async process\n        self.model_client.generate.return_value = MagicMock(text=\"<thought>OK</thought> <message>Done</message>\")\n\n        # We need to run the async method\n        import asyncio\n        async def run_req():\n            await self.o", "chunk_type": "file", "line_start": 1, "line_end": 65, "language": "python", "name": "test_specialized_agents.py"}, "354ebbf4eb13_func_setUp": {"id": "354ebbf4eb13_func_setUp", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_specialized_agents.py", "content": "    def setUp(self):\n        self.prompt_service = PromptService()\n        self.event_bus = EventBusService()\n        self.model_client = MagicMock()\n        self.orchestrator = OrchestratorManager(\n            event_bus=self.event_bus,\n            model_client=self.model_client,\n            prompt_service=self.prompt_service\n        )", "chunk_type": "function", "line_start": 10, "line_end": 18, "language": "python", "name": "setUp"}, "354ebbf4eb13_func_test_prompt_service_roles": {"id": "354ebbf4eb13_func_test_prompt_service_roles", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_specialized_agents.py", "content": "    def test_prompt_service_roles(self):\n        roles = self.prompt_service.list_roles()\n        self.assertIn(\"Lead Orchestrator\", roles)\n        self.assertIn(\"Test Engineer\", roles)\n        self.assertIn(\"Documentarian\", roles)\n\n        prompt = self.prompt_service.get_prompt(\"Documentarian\")\n        self.assertIn(\"Firefly Documentarian\", prompt)\n        self.assertIn(\"<thought>\", prompt)", "chunk_type": "function", "line_start": 20, "line_end": 28, "language": "python", "name": "test_prompt_service_roles"}, "354ebbf4eb13_func_test_task_decomposition_parsing": {"id": "354ebbf4eb13_func_test_task_decomposition_parsing", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_specialized_agents.py", "content": "    def test_task_decomposition_parsing(self):\n        plan_text = \"\"\"\n        I will decompose this task.\n        <plan>\n        - [ ] Write tests (Test Engineer)\n        - [ ] Update README (Documentarian)\n        </plan>\n        \"\"\"\n        # Mock delegate_task\n        self.orchestrator.delegate_task = MagicMock()\n\n        self.orchestrator._handle_plans(plan_text, \"test_session\")\n\n        self.assertEqual(self.orchestrator.delegate_task.call_count, 2)\n        args = [call.args for call in self.orchestrator.delegate_task.call_args_list]\n        self.assertEqual(args[0][0], \"Test Engineer\")\n        self.assertEqual(args[1][0], \"Documentarian\")", "chunk_type": "function", "line_start": 30, "line_end": 46, "language": "python", "name": "test_task_decomposition_parsing"}, "354ebbf4eb13_func_test_orchestrator_uses_prompt_service": {"id": "354ebbf4eb13_func_test_orchestrator_uses_prompt_service", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_specialized_agents.py", "content": "    def test_orchestrator_uses_prompt_service(self):\n        # Trigger an async process\n        self.model_client.generate.return_value = MagicMock(text=\"<thought>OK</thought> <message>Done</message>\")\n\n        # We need to run the async method\n        import asyncio\n        async def run_req():\n            await self.orchestrator.process_request_async(\"Hello\", \"terminal\")\n\n        asyncio.run(run_req())\n\n        # Verify that prompt_service was called (indirectly through system_prompt)\n        sys_prompt = self.model_client.generate.call_args[1]['system_prompt']\n        self.assertIn(\"Firefly Lead Orchestrator\", sys_prompt)", "chunk_type": "function", "line_start": 48, "line_end": 61, "language": "python", "name": "test_orchestrator_uses_prompt_service"}, "354ebbf4eb13_func_run_req": {"id": "354ebbf4eb13_func_run_req", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_specialized_agents.py", "content": "        async def run_req():\n            await self.orchestrator.process_request_async(\"Hello\", \"terminal\")", "chunk_type": "function", "line_start": 54, "line_end": 55, "language": "python", "name": "run_req"}, "354ebbf4eb13_class_TestSpecializedAgents": {"id": "354ebbf4eb13_class_TestSpecializedAgents", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_specialized_agents.py", "content": "class TestSpecializedAgents(unittest.TestCase):\n    def setUp(self):\n        self.prompt_service = PromptService()\n        self.event_bus = EventBusService()\n        self.model_client = MagicMock()\n        self.orchestrator = OrchestratorManager(\n            event_bus=self.event_bus,\n            model_client=self.model_client,\n            prompt_service=self.prompt_service\n        )\n\n    def test_prompt_service_roles(self):\n        roles = self.prompt_service.list_roles()\n        self.assertIn(\"Lead Orchestrator\", roles)\n        self.assertIn(\"Test Engineer\", roles)\n        self.assertIn(\"Documentarian\", roles)\n\n        prompt = self.prompt_service.get_prompt(\"Documentarian\")\n        self.assertIn(\"Firefly Documentarian\", prompt)\n        self.assertIn(\"<thought>\", prompt)\n\n    def test_task_decomposition_parsing(self):\n        plan_text = \"\"\"\n        I will decompose this task.\n        <plan>\n        - [ ] Write tests (Test Engineer)\n        - [ ] Update README (Documentarian)\n        ", "chunk_type": "class", "line_start": 9, "line_end": 61, "language": "python", "name": "TestSpecializedAgents"}, "281a0b946198_file": {"id": "281a0b946198_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_telegram_trigger.py", "content": "from unittest.mock import MagicMock, patch\nimport json\nimport unittest\n\nfrom agent_manager.core.event_bus import EventBusService\nfrom agent_manager.triggers.telegram import TelegramService\n\nclass TestTelegramService(unittest.TestCase):\n    def setUp(self):\n        self.bus = EventBusService()\n        self.service = TelegramService(event_bus=self.bus, token=\"TEST_TOKEN\")\n\n    @patch(\"urllib.request.urlopen\")\n    def test_poll_updates(self, mock_urlopen):\n        \"\"\"Test that polling processes updates and publishes events.\"\"\"\n        # Mock response from getUpdates\n        mock_response = MagicMock()\n        mock_response.read.return_value = json.dumps({\n            \"ok\": True,\n            \"result\": [{\n                \"update_id\": 123,\n                \"message\": {\n                    \"chat\": {\"id\": 999},\n                    \"text\": \"Hello Firefly\",\n                    \"from\": {\"username\": \"tester\"}\n                }\n            }]\n        }).encode(\"utf-8\")\n        mock_urlopen.return_value.__enter__.return_value = mock_response\n\n        # Mock event bus publish to verify call\n        self.bus.publish = MagicMock()\n\n        # Manually trigger one check\n        self.service._check_updates()\n\n        # Verify event was published\n        self.bus.publish.assert_called_with(\"telegram_input\", {\n            \"type\": \"message\",\n            \"chat_id\": 999,\n            \"text\": \"Hello Firefly\",\n            \"user\": \"tester\"\n        })\n\n    @patch(\"urllib.request.urlopen\")\n    def test_send_message(self, mock_urlopen):\n        \"\"\"Test sending a message via telegram_output event.\"\"\"\n        # Mock successful dispatch\n        mock_response = MagicMock()\n        mock_urlopen.return_value.__enter__.return_value = mock_response\n\n        # publish event\n        self.bus.publish(\"telegram_output\", {\"chat_id\": 888, \"text\": \"Reply\"})\n\n        # Verify socket/api call via mock\n        # Since handle_outgoing_message is subscribed, it should call send_message\n        # We need to wait or ver", "chunk_type": "file", "line_start": 1, "line_end": 70, "language": "python", "name": "test_telegram_trigger.py"}, "281a0b946198_func_setUp": {"id": "281a0b946198_func_setUp", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_telegram_trigger.py", "content": "    def setUp(self):\n        self.bus = EventBusService()\n        self.service = TelegramService(event_bus=self.bus, token=\"TEST_TOKEN\")", "chunk_type": "function", "line_start": 9, "line_end": 11, "language": "python", "name": "setUp"}, "281a0b946198_func_test_poll_updates": {"id": "281a0b946198_func_test_poll_updates", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_telegram_trigger.py", "content": "    def test_poll_updates(self, mock_urlopen):\n        \"\"\"Test that polling processes updates and publishes events.\"\"\"\n        # Mock response from getUpdates\n        mock_response = MagicMock()\n        mock_response.read.return_value = json.dumps({\n            \"ok\": True,\n            \"result\": [{\n                \"update_id\": 123,\n                \"message\": {\n                    \"chat\": {\"id\": 999},\n                    \"text\": \"Hello Firefly\",\n                    \"from\": {\"username\": \"tester\"}\n                }\n            }]\n        }).encode(\"utf-8\")\n        mock_urlopen.return_value.__enter__.return_value = mock_response\n\n        # Mock event bus publish to verify call\n        self.bus.publish = MagicMock()\n\n        # Manually trigger one check\n        self.service._check_updates()\n\n        # Verify event was published\n        self.bus.publish.assert_called_with(\"telegram_input\", {\n            \"type\": \"message\",\n            \"chat_id\": 999,\n            \"text\": \"Hello Firefly\",\n      ", "chunk_type": "function", "line_start": 14, "line_end": 43, "language": "python", "name": "test_poll_updates"}, "281a0b946198_func_test_send_message": {"id": "281a0b946198_func_test_send_message", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_telegram_trigger.py", "content": "    def test_send_message(self, mock_urlopen):\n        \"\"\"Test sending a message via telegram_output event.\"\"\"\n        # Mock successful dispatch\n        mock_response = MagicMock()\n        mock_urlopen.return_value.__enter__.return_value = mock_response\n\n        # publish event\n        self.bus.publish(\"telegram_output\", {\"chat_id\": 888, \"text\": \"Reply\"})\n\n        # Verify socket/api call via mock\n        # Since handle_outgoing_message is subscribed, it should call send_message\n        # We need to wait or verify behavior.\n        # Since EventBus is synchronous for now (based on previous files), it should call immediately?\n        # Let's check event_bus implementation. Assuming synchronous for now.\n\n        # Actually EventBus might be async/threaded?\n        # Let's verify send_message calls urlopen\n\n        self.service.send_message(888, \"Reply\")\n\n        args, kwargs = mock_urlopen.call_args\n        req = args[0]\n        self.assertIn(\"sendMessage\", req.full_url)\n        self.as", "chunk_type": "function", "line_start": 46, "line_end": 69, "language": "python", "name": "test_send_message"}, "281a0b946198_class_TestTelegramService": {"id": "281a0b946198_class_TestTelegramService", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_telegram_trigger.py", "content": "class TestTelegramService(unittest.TestCase):\n    def setUp(self):\n        self.bus = EventBusService()\n        self.service = TelegramService(event_bus=self.bus, token=\"TEST_TOKEN\")\n\n    @patch(\"urllib.request.urlopen\")\n    def test_poll_updates(self, mock_urlopen):\n        \"\"\"Test that polling processes updates and publishes events.\"\"\"\n        # Mock response from getUpdates\n        mock_response = MagicMock()\n        mock_response.read.return_value = json.dumps({\n            \"ok\": True,\n            \"result\": [{\n                \"update_id\": 123,\n                \"message\": {\n                    \"chat\": {\"id\": 999},\n                    \"text\": \"Hello Firefly\",\n                    \"from\": {\"username\": \"tester\"}\n                }\n            }]\n        }).encode(\"utf-8\")\n        mock_urlopen.return_value.__enter__.return_value = mock_response\n\n        # Mock event bus publish to verify call\n        self.bus.publish = MagicMock()\n\n        # Manually trigger one check\n        self.service.", "chunk_type": "class", "line_start": 8, "line_end": 69, "language": "python", "name": "TestTelegramService"}, "29e486da3f4e_file": {"id": "29e486da3f4e_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_usage_management.py", "content": "from unittest.mock import MagicMock\nimport unittest\n\nfrom agent_manager.core.event_bus import EventBusService\nfrom agent_manager.models.base import ModelResponse, BaseModelService\nfrom agent_manager.models.manager import ModelClientManager\n\nclass MockProvider(BaseModelService):\n    def validate_config(self):\n        return True\n\n    def generate(self, prompt: str, system_prompt=None):\n        return ModelResponse(\n            text=\"Mock response\",\n            prompt_tokens=10,\n            completion_tokens=20,\n            model_name=\"mock-model\",\n            cost_usd=0.01\n        )\n\nclass TestUsageManagement(unittest.TestCase):\n    def setUp(self):\n        self.bus = EventBusService()\n        self.provider = MockProvider()\n        self.manager = ModelClientManager([self.provider], event_bus=self.bus)\n\n    def test_usage_tracking(self):\n        # Subscribe to usage events\n        self.event_received = False\n        def on_usage(event_type, payload):\n            self.event_received = True\n            self.payload = payload\n\n        self.bus.subscribe(\"usage_report\", on_usage)\n\n        # Generate\n        response = self.manager.generate(\"Hello\")\n\n        # Verify response\n        self.assertEqual(response.text, \"Mock response\")\n        self.assertEqual(response.prompt_tokens, 10)\n\n        # Verify ledger\n        self.assertEqual(self.manager.usage_ledger[\"total_prompt_tokens\"], 10)\n        self.assertEqual(self.manager.usage_ledger[\"total_cost_usd\"], 0.01)\n\n        # Verify event\n        self.assertTrue(self.event_received)\n        self.assertEqual(self.payload[\"current_response\"][\"model\"], \"mock-model\")\n\nif __name__ == \"__main__\":\n    unittest.main()\n", "chunk_type": "file", "line_start": 1, "line_end": 53, "language": "python", "name": "test_usage_management.py"}, "29e486da3f4e_func_validate_config": {"id": "29e486da3f4e_func_validate_config", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_usage_management.py", "content": "    def validate_config(self):\n        return True", "chunk_type": "function", "line_start": 9, "line_end": 10, "language": "python", "name": "validate_config"}, "29e486da3f4e_func_generate": {"id": "29e486da3f4e_func_generate", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_usage_management.py", "content": "    def generate(self, prompt: str, system_prompt=None):\n        return ModelResponse(\n            text=\"Mock response\",\n            prompt_tokens=10,\n            completion_tokens=20,\n            model_name=\"mock-model\",\n            cost_usd=0.01\n        )", "chunk_type": "function", "line_start": 12, "line_end": 19, "language": "python", "name": "generate"}, "29e486da3f4e_func_setUp": {"id": "29e486da3f4e_func_setUp", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_usage_management.py", "content": "    def setUp(self):\n        self.bus = EventBusService()\n        self.provider = MockProvider()\n        self.manager = ModelClientManager([self.provider], event_bus=self.bus)", "chunk_type": "function", "line_start": 22, "line_end": 25, "language": "python", "name": "setUp"}, "29e486da3f4e_func_test_usage_tracking": {"id": "29e486da3f4e_func_test_usage_tracking", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_usage_management.py", "content": "    def test_usage_tracking(self):\n        # Subscribe to usage events\n        self.event_received = False\n        def on_usage(event_type, payload):\n            self.event_received = True\n            self.payload = payload\n\n        self.bus.subscribe(\"usage_report\", on_usage)\n\n        # Generate\n        response = self.manager.generate(\"Hello\")\n\n        # Verify response\n        self.assertEqual(response.text, \"Mock response\")\n        self.assertEqual(response.prompt_tokens, 10)\n\n        # Verify ledger\n        self.assertEqual(self.manager.usage_ledger[\"total_prompt_tokens\"], 10)\n        self.assertEqual(self.manager.usage_ledger[\"total_cost_usd\"], 0.01)\n\n        # Verify event\n        self.assertTrue(self.event_received)\n        self.assertEqual(self.payload[\"current_response\"][\"model\"], \"mock-model\")", "chunk_type": "function", "line_start": 27, "line_end": 49, "language": "python", "name": "test_usage_tracking"}, "29e486da3f4e_func_on_usage": {"id": "29e486da3f4e_func_on_usage", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_usage_management.py", "content": "        def on_usage(event_type, payload):\n            self.event_received = True\n            self.payload = payload", "chunk_type": "function", "line_start": 30, "line_end": 32, "language": "python", "name": "on_usage"}, "29e486da3f4e_class_MockProvider": {"id": "29e486da3f4e_class_MockProvider", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_usage_management.py", "content": "class MockProvider(BaseModelService):\n    def validate_config(self):\n        return True\n\n    def generate(self, prompt: str, system_prompt=None):\n        return ModelResponse(\n            text=\"Mock response\",\n            prompt_tokens=10,\n            completion_tokens=20,\n            model_name=\"mock-model\",\n            cost_usd=0.01\n        )", "chunk_type": "class", "line_start": 8, "line_end": 19, "language": "python", "name": "MockProvider"}, "29e486da3f4e_class_TestUsageManagement": {"id": "29e486da3f4e_class_TestUsageManagement", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\test_usage_management.py", "content": "class TestUsageManagement(unittest.TestCase):\n    def setUp(self):\n        self.bus = EventBusService()\n        self.provider = MockProvider()\n        self.manager = ModelClientManager([self.provider], event_bus=self.bus)\n\n    def test_usage_tracking(self):\n        # Subscribe to usage events\n        self.event_received = False\n        def on_usage(event_type, payload):\n            self.event_received = True\n            self.payload = payload\n\n        self.bus.subscribe(\"usage_report\", on_usage)\n\n        # Generate\n        response = self.manager.generate(\"Hello\")\n\n        # Verify response\n        self.assertEqual(response.text, \"Mock response\")\n        self.assertEqual(response.prompt_tokens, 10)\n\n        # Verify ledger\n        self.assertEqual(self.manager.usage_ledger[\"total_prompt_tokens\"], 10)\n        self.assertEqual(self.manager.usage_ledger[\"total_cost_usd\"], 0.01)\n\n        # Verify event\n        self.assertTrue(self.event_received)\n        self.assertEqual(self.payload[\"curr", "chunk_type": "class", "line_start": 21, "line_end": 49, "language": "python", "name": "TestUsageManagement"}, "a2c694afcc65_file": {"id": "a2c694afcc65_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\tests\\__init__.py", "content": "", "chunk_type": "file", "line_start": 1, "line_end": 1, "language": "python", "name": "__init__.py"}, "304688355d21_file": {"id": "304688355d21_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\vscode\\extensions\\vscode-colorize-tests\\test\\colorize-fixtures\\test-freeze-56377.py", "content": "record = {\n    \"headers\": {k: str(v) for k, v in self.request.META.items() if k.startswith('HTTP_')}\n}\ncmd = \"git-clang-format --style=\\\"{{BasedOnStyle: Google, ColumnLimit: 100, IndentWidth: 2, \" \\ \"AlignConsecutiveAssignments: true}}\\\" {COMMIT_SHA} -- ./**/*.proto > {OUTPUT}\".format(\n", "chunk_type": "file", "line_start": 1, "line_end": 5, "language": "python", "name": "test-freeze-56377.py"}, "fe1a3fd8b9ca_file": {"id": "fe1a3fd8b9ca_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Project-Firefly\\vscode\\extensions\\vscode-colorize-tests\\test\\colorize-fixtures\\test.py", "content": "from banana import *\n\nclass Monkey:\n\t# Bananas the monkey can eat.\n\tcapacity = 10\n\tdef eat(self, N):\n\t\t'''Make the monkey eat N bananas!'''\n\t\tcapacity = capacity - N*banana.size\n\n\tdef feeding_frenzy(self):\n\t\teat(9.25)\n\t\treturn \"Yum yum\"\n\n\tdef some_func(a:\n\t\t\t\t\tlambda x=None:\n\t\t\t\t\t{key: val\n\t\t\t\t\t\tfor key, val in\n\t\t\t\t\t\t\t(x if x is not None else [])\n\t\t\t\t\t}=42):\n\t\tpass\n\npass\n\ndef firstn(g, n):\n\tfor _ in range(n):\n\t\tyield g.next()\n\nreduce(lambda x,y: x+y, [47,11,42,13])\nwoerter = {\"house\" : \"Haus\", \"cat\":\"Katze\", \"black\":\"schwarz\"}\n\nmydictionary = {\n    'foo': 23, #comment\n    'bar': \"hello\" #sqadsad\n}\n\ndef steuern(einkommen):\n\t\"\"\"Berechnung der zu zahlenden Steuern fuer ein zu versteuerndes Einkommen von x\"\"\"\n\tif einkommen <= 8004:\n\t\treturn 0\n\telif einkommen <= 13469:\n\t\ty = (einkommen -8004.0)/10000.0\n\t\treturn (912.17 * y + 1400)*y\n\telse:\n\t\treturn einkommen * 0.44 - 15694\n\ndef beliebig(x, y, *mehr):\n    print \"x=\", x, \", x=\", y\n    print \"mehr: \", mehr\n\nclass Memoize:\n    def __init__(self, fn):\n        self.fn = fn\n        self.memo = {}\n    def __call__(self, *args):\n        if args not in self.memo:\n                self.memo[args] = self.fn(*args)\n        return self.memo[args]\n\nres = re.search(r\"([0-9-]*)\\s*([A-Za-z]+),\\s+(.*)\", i)\n\nwhile True:\n    try:\n        n = raw_input(\"Number: \")\n        n = int(n)\n        break\n    except ValueError:\n        print(\"Not a number\")\n\nasync with EXPR as VAR:\n    BLOCK\n\n# Comments in dictionary items should be colorized accordingly\nmy_dictionary = {\n    'foo':23, # this should be colorized as comment\n    'bar':\"foobar\" #this should be colorized as comment\n}\n\n# test raw strings\ntext = r\"\"\"\ninterval ``[1,2)`` leads to\n\"\"\"\nhighlight_error = True\n\n# highlight doctests\nr'''Module docstring\n\n    Some text followed by code sample:\n    >>> for a in foo(2, b=1,\n    ...                 c=3):\n    ...   print(a)\n    0\n    1\n'''\n", "chunk_type": "file", "line_start": 1, "line_end": 94, "language": "python", "name": "test.py"}}